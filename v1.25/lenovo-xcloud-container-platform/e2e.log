I0710 07:57:19.162064      21 e2e.go:116] Starting e2e run "feee08b5-d807-4939-9381-6d0e6aee29af" on Ginkgo node 1
Jul 10 07:57:19.177: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1688975839 - will randomize all specs

Will run 360 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Jul 10 07:57:19.285: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 07:57:19.286: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E0710 07:57:19.287568      21 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp 127.0.0.1:8099: connect: connection refused
E0710 07:57:19.287568      21 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp 127.0.0.1:8099: connect: connection refused
Jul 10 07:57:19.302: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul 10 07:57:19.334: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul 10 07:57:19.334: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Jul 10 07:57:19.334: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul 10 07:57:19.341: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jul 10 07:57:19.341: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-node' (0 seconds elapsed)
Jul 10 07:57:19.341: INFO: e2e test version: v1.25.9
Jul 10 07:57:19.342: INFO: kube-apiserver version: v1.25.9
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Jul 10 07:57:19.342: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 07:57:19.391: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.106 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Jul 10 07:57:19.285: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 07:57:19.286: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    E0710 07:57:19.287568      21 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp 127.0.0.1:8099: connect: connection refused
    Jul 10 07:57:19.302: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Jul 10 07:57:19.334: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Jul 10 07:57:19.334: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
    Jul 10 07:57:19.334: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Jul 10 07:57:19.341: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Jul 10 07:57:19.341: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-node' (0 seconds elapsed)
    Jul 10 07:57:19.341: INFO: e2e test version: v1.25.9
    Jul 10 07:57:19.342: INFO: kube-apiserver version: v1.25.9
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Jul 10 07:57:19.342: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 07:57:19.391: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:57:19.413
Jul 10 07:57:19.413: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 07:57:19.415
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:57:19.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:57:19.453
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-4232 07/10/23 07:57:19.459
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[] 07/10/23 07:57:19.478
Jul 10 07:57:19.501: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Jul 10 07:57:20.512: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4232 07/10/23 07:57:20.512
Jul 10 07:57:20.526: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4232" to be "running and ready"
Jul 10 07:57:20.530: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.491895ms
Jul 10 07:57:20.530: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 07:57:22.535: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009320809s
Jul 10 07:57:22.536: INFO: The phase of Pod pod1 is Running (Ready = true)
Jul 10 07:57:22.536: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[pod1:[100]] 07/10/23 07:57:22.54
Jul 10 07:57:22.553: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-4232 07/10/23 07:57:22.553
Jul 10 07:57:22.568: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4232" to be "running and ready"
Jul 10 07:57:22.572: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.766497ms
Jul 10 07:57:22.572: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 07:57:24.577: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.008672769s
Jul 10 07:57:24.577: INFO: The phase of Pod pod2 is Running (Ready = true)
Jul 10 07:57:24.577: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[pod1:[100] pod2:[101]] 07/10/23 07:57:24.581
Jul 10 07:57:24.595: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 07/10/23 07:57:24.595
Jul 10 07:57:24.595: INFO: Creating new exec pod
Jul 10 07:57:24.603: INFO: Waiting up to 5m0s for pod "execpod8bz55" in namespace "services-4232" to be "running"
Jul 10 07:57:24.606: INFO: Pod "execpod8bz55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.989041ms
Jul 10 07:57:26.614: INFO: Pod "execpod8bz55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01051474s
Jul 10 07:57:28.613: INFO: Pod "execpod8bz55": Phase="Running", Reason="", readiness=true. Elapsed: 4.009459678s
Jul 10 07:57:28.613: INFO: Pod "execpod8bz55" satisfied condition "running"
Jul 10 07:57:29.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Jul 10 07:57:29.832: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Jul 10 07:57:29.832: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 07:57:29.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.110.77 80'
Jul 10 07:57:29.981: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.110.77 80\nConnection to 192.168.110.77 80 port [tcp/http] succeeded!\n"
Jul 10 07:57:29.981: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 07:57:29.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Jul 10 07:57:30.150: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Jul 10 07:57:30.150: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 07:57:30.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.110.77 81'
Jul 10 07:57:30.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.110.77 81\nConnection to 192.168.110.77 81 port [tcp/*] succeeded!\n"
Jul 10 07:57:30.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4232 07/10/23 07:57:30.304
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[pod2:[101]] 07/10/23 07:57:30.344
Jul 10 07:57:31.404: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-4232 07/10/23 07:57:31.404
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[] 07/10/23 07:57:31.446
Jul 10 07:57:32.482: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 07:57:32.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4232" for this suite. 07/10/23 07:57:32.542
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":1,"skipped":10,"failed":0}
------------------------------
• [SLOW TEST] [13.139 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:57:19.413
    Jul 10 07:57:19.413: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 07:57:19.415
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:57:19.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:57:19.453
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-4232 07/10/23 07:57:19.459
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[] 07/10/23 07:57:19.478
    Jul 10 07:57:19.501: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Jul 10 07:57:20.512: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4232 07/10/23 07:57:20.512
    Jul 10 07:57:20.526: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4232" to be "running and ready"
    Jul 10 07:57:20.530: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.491895ms
    Jul 10 07:57:20.530: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 07:57:22.535: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009320809s
    Jul 10 07:57:22.536: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jul 10 07:57:22.536: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[pod1:[100]] 07/10/23 07:57:22.54
    Jul 10 07:57:22.553: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-4232 07/10/23 07:57:22.553
    Jul 10 07:57:22.568: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4232" to be "running and ready"
    Jul 10 07:57:22.572: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.766497ms
    Jul 10 07:57:22.572: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 07:57:24.577: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.008672769s
    Jul 10 07:57:24.577: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jul 10 07:57:24.577: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[pod1:[100] pod2:[101]] 07/10/23 07:57:24.581
    Jul 10 07:57:24.595: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 07/10/23 07:57:24.595
    Jul 10 07:57:24.595: INFO: Creating new exec pod
    Jul 10 07:57:24.603: INFO: Waiting up to 5m0s for pod "execpod8bz55" in namespace "services-4232" to be "running"
    Jul 10 07:57:24.606: INFO: Pod "execpod8bz55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.989041ms
    Jul 10 07:57:26.614: INFO: Pod "execpod8bz55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01051474s
    Jul 10 07:57:28.613: INFO: Pod "execpod8bz55": Phase="Running", Reason="", readiness=true. Elapsed: 4.009459678s
    Jul 10 07:57:28.613: INFO: Pod "execpod8bz55" satisfied condition "running"
    Jul 10 07:57:29.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Jul 10 07:57:29.832: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Jul 10 07:57:29.832: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 07:57:29.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.110.77 80'
    Jul 10 07:57:29.981: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.110.77 80\nConnection to 192.168.110.77 80 port [tcp/http] succeeded!\n"
    Jul 10 07:57:29.981: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 07:57:29.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Jul 10 07:57:30.150: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Jul 10 07:57:30.150: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 07:57:30.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4232 exec execpod8bz55 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.110.77 81'
    Jul 10 07:57:30.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.110.77 81\nConnection to 192.168.110.77 81 port [tcp/*] succeeded!\n"
    Jul 10 07:57:30.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4232 07/10/23 07:57:30.304
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[pod2:[101]] 07/10/23 07:57:30.344
    Jul 10 07:57:31.404: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-4232 07/10/23 07:57:31.404
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4232 to expose endpoints map[] 07/10/23 07:57:31.446
    Jul 10 07:57:32.482: INFO: successfully validated that service multi-endpoint-test in namespace services-4232 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 07:57:32.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4232" for this suite. 07/10/23 07:57:32.542
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:57:32.553
Jul 10 07:57:32.553: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 07:57:32.555
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:57:32.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:57:32.609
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-539a72ed-151a-41e1-9a1b-a9300655b844 in namespace container-probe-3203 07/10/23 07:57:32.612
Jul 10 07:57:32.623: INFO: Waiting up to 5m0s for pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844" in namespace "container-probe-3203" to be "not pending"
Jul 10 07:57:32.627: INFO: Pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032622ms
Jul 10 07:57:34.633: INFO: Pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844": Phase="Running", Reason="", readiness=true. Elapsed: 2.010065603s
Jul 10 07:57:34.633: INFO: Pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844" satisfied condition "not pending"
Jul 10 07:57:34.633: INFO: Started pod busybox-539a72ed-151a-41e1-9a1b-a9300655b844 in namespace container-probe-3203
STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 07:57:34.633
Jul 10 07:57:34.637: INFO: Initial restart count of pod busybox-539a72ed-151a-41e1-9a1b-a9300655b844 is 0
Jul 10 07:58:24.794: INFO: Restart count of pod container-probe-3203/busybox-539a72ed-151a-41e1-9a1b-a9300655b844 is now 1 (50.15677772s elapsed)
STEP: deleting the pod 07/10/23 07:58:24.794
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 07:58:24.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3203" for this suite. 07/10/23 07:58:24.839
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":2,"skipped":10,"failed":0}
------------------------------
• [SLOW TEST] [52.297 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:57:32.553
    Jul 10 07:57:32.553: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 07:57:32.555
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:57:32.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:57:32.609
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-539a72ed-151a-41e1-9a1b-a9300655b844 in namespace container-probe-3203 07/10/23 07:57:32.612
    Jul 10 07:57:32.623: INFO: Waiting up to 5m0s for pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844" in namespace "container-probe-3203" to be "not pending"
    Jul 10 07:57:32.627: INFO: Pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032622ms
    Jul 10 07:57:34.633: INFO: Pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844": Phase="Running", Reason="", readiness=true. Elapsed: 2.010065603s
    Jul 10 07:57:34.633: INFO: Pod "busybox-539a72ed-151a-41e1-9a1b-a9300655b844" satisfied condition "not pending"
    Jul 10 07:57:34.633: INFO: Started pod busybox-539a72ed-151a-41e1-9a1b-a9300655b844 in namespace container-probe-3203
    STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 07:57:34.633
    Jul 10 07:57:34.637: INFO: Initial restart count of pod busybox-539a72ed-151a-41e1-9a1b-a9300655b844 is 0
    Jul 10 07:58:24.794: INFO: Restart count of pod container-probe-3203/busybox-539a72ed-151a-41e1-9a1b-a9300655b844 is now 1 (50.15677772s elapsed)
    STEP: deleting the pod 07/10/23 07:58:24.794
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 07:58:24.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3203" for this suite. 07/10/23 07:58:24.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:58:24.851
Jul 10 07:58:24.851: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename runtimeclass 07/10/23 07:58:24.852
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:24.882
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:24.886
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Jul 10 07:58:24.917: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1381 to be scheduled
Jul 10 07:58:24.921: INFO: 1 pods are not scheduled: [runtimeclass-1381/test-runtimeclass-runtimeclass-1381-preconfigured-handler-mqb67(637e19e1-fb68-418c-b71f-2828101e3f5e)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jul 10 07:58:26.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1381" for this suite. 07/10/23 07:58:26.951
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":3,"skipped":15,"failed":0}
------------------------------
• [2.119 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:58:24.851
    Jul 10 07:58:24.851: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename runtimeclass 07/10/23 07:58:24.852
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:24.882
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:24.886
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Jul 10 07:58:24.917: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1381 to be scheduled
    Jul 10 07:58:24.921: INFO: 1 pods are not scheduled: [runtimeclass-1381/test-runtimeclass-runtimeclass-1381-preconfigured-handler-mqb67(637e19e1-fb68-418c-b71f-2828101e3f5e)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jul 10 07:58:26.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1381" for this suite. 07/10/23 07:58:26.951
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:58:26.97
Jul 10 07:58:26.970: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sysctl 07/10/23 07:58:26.971
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:26.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:26.999
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 07/10/23 07:58:27.002
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 07:58:27.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-2507" for this suite. 07/10/23 07:58:27.013
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":4,"skipped":18,"failed":0}
------------------------------
• [0.155 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:58:26.97
    Jul 10 07:58:26.970: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sysctl 07/10/23 07:58:26.971
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:26.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:26.999
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 07/10/23 07:58:27.002
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 07:58:27.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-2507" for this suite. 07/10/23 07:58:27.013
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:58:27.125
Jul 10 07:58:27.125: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 07:58:27.126
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:27.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:27.16
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
STEP: fetching services 07/10/23 07:58:27.164
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 07:58:27.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9410" for this suite. 07/10/23 07:58:27.174
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":5,"skipped":29,"failed":0}
------------------------------
• [0.059 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:58:27.125
    Jul 10 07:58:27.125: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 07:58:27.126
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:27.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:27.16
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3185
    STEP: fetching services 07/10/23 07:58:27.164
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 07:58:27.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9410" for this suite. 07/10/23 07:58:27.174
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:58:27.184
Jul 10 07:58:27.184: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 07:58:27.185
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:27.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:27.221
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 07/10/23 07:58:27.224
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_tcp@PTR;sleep 1; done
 07/10/23 07:58:27.27
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_tcp@PTR;sleep 1; done
 07/10/23 07:58:27.27
STEP: creating a pod to probe DNS 07/10/23 07:58:27.27
STEP: submitting the pod to kubernetes 07/10/23 07:58:27.27
Jul 10 07:58:27.293: INFO: Waiting up to 15m0s for pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9" in namespace "dns-7297" to be "running"
Jul 10 07:58:27.297: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725311ms
Jul 10 07:58:29.303: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010014855s
Jul 10 07:58:31.304: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011739538s
Jul 10 07:58:31.304: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9" satisfied condition "running"
STEP: retrieving the pod 07/10/23 07:58:31.304
STEP: looking for the results for each expected name from probers 07/10/23 07:58:31.309
Jul 10 07:58:31.315: INFO: Unable to read wheezy_udp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.320: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.325: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.330: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.355: INFO: Unable to read jessie_udp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.360: INFO: Unable to read jessie_tcp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.365: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.369: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
Jul 10 07:58:31.386: INFO: Lookups using dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9 failed for: [wheezy_udp@dns-test-service.dns-7297.svc.cluster.local wheezy_tcp@dns-test-service.dns-7297.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local jessie_udp@dns-test-service.dns-7297.svc.cluster.local jessie_tcp@dns-test-service.dns-7297.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local]

Jul 10 07:58:36.470: INFO: DNS probes using dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9 succeeded

STEP: deleting the pod 07/10/23 07:58:36.47
STEP: deleting the test service 07/10/23 07:58:36.505
STEP: deleting the test headless service 07/10/23 07:58:36.577
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 07:58:36.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7297" for this suite. 07/10/23 07:58:36.638
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":6,"skipped":32,"failed":0}
------------------------------
• [SLOW TEST] [9.471 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:58:27.184
    Jul 10 07:58:27.184: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 07:58:27.185
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:27.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:27.221
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 07/10/23 07:58:27.224
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_tcp@PTR;sleep 1; done
     07/10/23 07:58:27.27
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7297.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7297.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7297.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.76.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.76.43_tcp@PTR;sleep 1; done
     07/10/23 07:58:27.27
    STEP: creating a pod to probe DNS 07/10/23 07:58:27.27
    STEP: submitting the pod to kubernetes 07/10/23 07:58:27.27
    Jul 10 07:58:27.293: INFO: Waiting up to 15m0s for pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9" in namespace "dns-7297" to be "running"
    Jul 10 07:58:27.297: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725311ms
    Jul 10 07:58:29.303: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010014855s
    Jul 10 07:58:31.304: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011739538s
    Jul 10 07:58:31.304: INFO: Pod "dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 07:58:31.304
    STEP: looking for the results for each expected name from probers 07/10/23 07:58:31.309
    Jul 10 07:58:31.315: INFO: Unable to read wheezy_udp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.320: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.325: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.330: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.355: INFO: Unable to read jessie_udp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.360: INFO: Unable to read jessie_tcp@dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.365: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.369: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local from pod dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9: the server could not find the requested resource (get pods dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9)
    Jul 10 07:58:31.386: INFO: Lookups using dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9 failed for: [wheezy_udp@dns-test-service.dns-7297.svc.cluster.local wheezy_tcp@dns-test-service.dns-7297.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local jessie_udp@dns-test-service.dns-7297.svc.cluster.local jessie_tcp@dns-test-service.dns-7297.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7297.svc.cluster.local]

    Jul 10 07:58:36.470: INFO: DNS probes using dns-7297/dns-test-eea1c5af-1b27-4f42-be1a-b2d7345b5ff9 succeeded

    STEP: deleting the pod 07/10/23 07:58:36.47
    STEP: deleting the test service 07/10/23 07:58:36.505
    STEP: deleting the test headless service 07/10/23 07:58:36.577
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 07:58:36.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7297" for this suite. 07/10/23 07:58:36.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:58:36.657
Jul 10 07:58:36.657: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pod-network-test 07/10/23 07:58:36.658
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:36.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:36.693
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-301 07/10/23 07:58:36.696
STEP: creating a selector 07/10/23 07:58:36.697
STEP: Creating the service pods in kubernetes 07/10/23 07:58:36.697
Jul 10 07:58:36.697: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul 10 07:58:36.751: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-301" to be "running and ready"
Jul 10 07:58:36.779: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 27.624697ms
Jul 10 07:58:36.779: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 07:58:38.783: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.03169793s
Jul 10 07:58:38.783: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:40.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.034603438s
Jul 10 07:58:40.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:42.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.034445143s
Jul 10 07:58:42.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:44.783: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.03208455s
Jul 10 07:58:44.783: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:46.789: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.037626522s
Jul 10 07:58:46.789: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:48.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.033924522s
Jul 10 07:58:48.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:50.784: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.033052468s
Jul 10 07:58:50.784: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:52.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.035089262s
Jul 10 07:58:52.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:54.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.033975319s
Jul 10 07:58:54.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:56.784: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.033104202s
Jul 10 07:58:56.784: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 07:58:58.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.034012928s
Jul 10 07:58:58.785: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jul 10 07:58:58.785: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jul 10 07:58:58.789: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-301" to be "running and ready"
Jul 10 07:58:58.793: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.904123ms
Jul 10 07:58:58.793: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jul 10 07:58:58.793: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jul 10 07:58:58.798: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-301" to be "running and ready"
Jul 10 07:58:58.802: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.221926ms
Jul 10 07:58:58.802: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jul 10 07:58:58.802: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 07/10/23 07:58:58.805
Jul 10 07:58:58.825: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-301" to be "running"
Jul 10 07:58:58.834: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.807526ms
Jul 10 07:59:00.840: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015275719s
Jul 10 07:59:00.840: INFO: Pod "test-container-pod" satisfied condition "running"
Jul 10 07:59:00.845: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-301" to be "running"
Jul 10 07:59:00.850: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.940082ms
Jul 10 07:59:00.850: INFO: Pod "host-test-container-pod" satisfied condition "running"
Jul 10 07:59:00.864: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul 10 07:59:00.864: INFO: Going to poll 192.168.172.6 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul 10 07:59:00.868: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.172.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-301 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 07:59:00.868: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 07:59:00.869: INFO: ExecWithOptions: Clientset creation
Jul 10 07:59:00.869: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-301/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.172.6+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 07:59:01.972: INFO: Found all 1 expected endpoints: [netserver-0]
Jul 10 07:59:01.972: INFO: Going to poll 192.168.103.111 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul 10 07:59:01.977: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.103.111 8081 | grep -v '^\s*$'] Namespace:pod-network-test-301 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 07:59:01.977: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 07:59:01.977: INFO: ExecWithOptions: Clientset creation
Jul 10 07:59:01.977: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-301/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.103.111+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 07:59:03.045: INFO: Found all 1 expected endpoints: [netserver-1]
Jul 10 07:59:03.045: INFO: Going to poll 192.168.120.10 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul 10 07:59:03.049: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.120.10 8081 | grep -v '^\s*$'] Namespace:pod-network-test-301 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 07:59:03.050: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 07:59:03.050: INFO: ExecWithOptions: Clientset creation
Jul 10 07:59:03.050: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-301/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.120.10+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 07:59:04.130: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jul 10 07:59:04.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-301" for this suite. 07/10/23 07:59:04.135
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":7,"skipped":61,"failed":0}
------------------------------
• [SLOW TEST] [27.488 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:58:36.657
    Jul 10 07:58:36.657: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pod-network-test 07/10/23 07:58:36.658
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:58:36.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:58:36.693
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-301 07/10/23 07:58:36.696
    STEP: creating a selector 07/10/23 07:58:36.697
    STEP: Creating the service pods in kubernetes 07/10/23 07:58:36.697
    Jul 10 07:58:36.697: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jul 10 07:58:36.751: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-301" to be "running and ready"
    Jul 10 07:58:36.779: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 27.624697ms
    Jul 10 07:58:36.779: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 07:58:38.783: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.03169793s
    Jul 10 07:58:38.783: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:40.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.034603438s
    Jul 10 07:58:40.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:42.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.034445143s
    Jul 10 07:58:42.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:44.783: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.03208455s
    Jul 10 07:58:44.783: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:46.789: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.037626522s
    Jul 10 07:58:46.789: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:48.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.033924522s
    Jul 10 07:58:48.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:50.784: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.033052468s
    Jul 10 07:58:50.784: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:52.786: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.035089262s
    Jul 10 07:58:52.786: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:54.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.033975319s
    Jul 10 07:58:54.785: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:56.784: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.033104202s
    Jul 10 07:58:56.784: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 07:58:58.785: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.034012928s
    Jul 10 07:58:58.785: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jul 10 07:58:58.785: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jul 10 07:58:58.789: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-301" to be "running and ready"
    Jul 10 07:58:58.793: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.904123ms
    Jul 10 07:58:58.793: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jul 10 07:58:58.793: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jul 10 07:58:58.798: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-301" to be "running and ready"
    Jul 10 07:58:58.802: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.221926ms
    Jul 10 07:58:58.802: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jul 10 07:58:58.802: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 07/10/23 07:58:58.805
    Jul 10 07:58:58.825: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-301" to be "running"
    Jul 10 07:58:58.834: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.807526ms
    Jul 10 07:59:00.840: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015275719s
    Jul 10 07:59:00.840: INFO: Pod "test-container-pod" satisfied condition "running"
    Jul 10 07:59:00.845: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-301" to be "running"
    Jul 10 07:59:00.850: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.940082ms
    Jul 10 07:59:00.850: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Jul 10 07:59:00.864: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jul 10 07:59:00.864: INFO: Going to poll 192.168.172.6 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Jul 10 07:59:00.868: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.172.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-301 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 07:59:00.868: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 07:59:00.869: INFO: ExecWithOptions: Clientset creation
    Jul 10 07:59:00.869: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-301/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.172.6+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 07:59:01.972: INFO: Found all 1 expected endpoints: [netserver-0]
    Jul 10 07:59:01.972: INFO: Going to poll 192.168.103.111 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Jul 10 07:59:01.977: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.103.111 8081 | grep -v '^\s*$'] Namespace:pod-network-test-301 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 07:59:01.977: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 07:59:01.977: INFO: ExecWithOptions: Clientset creation
    Jul 10 07:59:01.977: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-301/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.103.111+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 07:59:03.045: INFO: Found all 1 expected endpoints: [netserver-1]
    Jul 10 07:59:03.045: INFO: Going to poll 192.168.120.10 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Jul 10 07:59:03.049: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.120.10 8081 | grep -v '^\s*$'] Namespace:pod-network-test-301 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 07:59:03.050: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 07:59:03.050: INFO: ExecWithOptions: Clientset creation
    Jul 10 07:59:03.050: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-301/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.120.10+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 07:59:04.130: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jul 10 07:59:04.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-301" for this suite. 07/10/23 07:59:04.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:59:04.148
Jul 10 07:59:04.148: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 07:59:04.15
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:04.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:04.195
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Jul 10 07:59:04.220: INFO: Waiting up to 5m0s for pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc" in namespace "container-probe-1910" to be "running and ready"
Jul 10 07:59:04.226: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.687174ms
Jul 10 07:59:04.226: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Pending, waiting for it to be Running (with Ready = true)
Jul 10 07:59:06.234: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 2.013443051s
Jul 10 07:59:06.234: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:08.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 4.01252758s
Jul 10 07:59:08.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:10.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 6.011968243s
Jul 10 07:59:10.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:12.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 8.012226491s
Jul 10 07:59:12.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:14.231: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 10.010414944s
Jul 10 07:59:14.231: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:16.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 12.011338053s
Jul 10 07:59:16.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:18.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 14.012066011s
Jul 10 07:59:18.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:20.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 16.0115059s
Jul 10 07:59:20.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:22.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 18.012437067s
Jul 10 07:59:22.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:24.234: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 20.013740268s
Jul 10 07:59:24.234: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
Jul 10 07:59:26.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=true. Elapsed: 22.011180294s
Jul 10 07:59:26.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = true)
Jul 10 07:59:26.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc" satisfied condition "running and ready"
Jul 10 07:59:26.236: INFO: Container started at 2023-07-10 07:59:05 +0000 UTC, pod became ready at 2023-07-10 07:59:24 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 07:59:26.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1910" for this suite. 07/10/23 07:59:26.241
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":8,"skipped":98,"failed":0}
------------------------------
• [SLOW TEST] [22.103 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:59:04.148
    Jul 10 07:59:04.148: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 07:59:04.15
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:04.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:04.195
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Jul 10 07:59:04.220: INFO: Waiting up to 5m0s for pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc" in namespace "container-probe-1910" to be "running and ready"
    Jul 10 07:59:04.226: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.687174ms
    Jul 10 07:59:04.226: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 07:59:06.234: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 2.013443051s
    Jul 10 07:59:06.234: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:08.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 4.01252758s
    Jul 10 07:59:08.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:10.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 6.011968243s
    Jul 10 07:59:10.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:12.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 8.012226491s
    Jul 10 07:59:12.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:14.231: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 10.010414944s
    Jul 10 07:59:14.231: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:16.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 12.011338053s
    Jul 10 07:59:16.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:18.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 14.012066011s
    Jul 10 07:59:18.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:20.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 16.0115059s
    Jul 10 07:59:20.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:22.233: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 18.012437067s
    Jul 10 07:59:22.233: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:24.234: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=false. Elapsed: 20.013740268s
    Jul 10 07:59:24.234: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = false)
    Jul 10 07:59:26.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc": Phase="Running", Reason="", readiness=true. Elapsed: 22.011180294s
    Jul 10 07:59:26.232: INFO: The phase of Pod test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc is Running (Ready = true)
    Jul 10 07:59:26.232: INFO: Pod "test-webserver-99929eb3-ada5-4671-b725-e35bdb07c3fc" satisfied condition "running and ready"
    Jul 10 07:59:26.236: INFO: Container started at 2023-07-10 07:59:05 +0000 UTC, pod became ready at 2023-07-10 07:59:24 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 07:59:26.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1910" for this suite. 07/10/23 07:59:26.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:59:26.258
Jul 10 07:59:26.259: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 07:59:26.26
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:26.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:26.297
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Jul 10 07:59:26.301: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 07:59:29.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-852" for this suite. 07/10/23 07:59:29.586
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":9,"skipped":162,"failed":0}
------------------------------
• [3.340 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:59:26.258
    Jul 10 07:59:26.259: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 07:59:26.26
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:26.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:26.297
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Jul 10 07:59:26.301: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 07:59:29.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-852" for this suite. 07/10/23 07:59:29.586
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:59:29.599
Jul 10 07:59:29.599: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 07:59:29.6
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:29.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:29.627
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 07/10/23 07:59:29.63
STEP: Counting existing ResourceQuota 07/10/23 07:59:34.635
STEP: Creating a ResourceQuota 07/10/23 07:59:39.641
STEP: Ensuring resource quota status is calculated 07/10/23 07:59:39.657
STEP: Creating a Secret 07/10/23 07:59:41.663
STEP: Ensuring resource quota status captures secret creation 07/10/23 07:59:41.689
STEP: Deleting a secret 07/10/23 07:59:43.694
STEP: Ensuring resource quota status released usage 07/10/23 07:59:43.704
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 07:59:45.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1066" for this suite. 07/10/23 07:59:45.714
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":10,"skipped":163,"failed":0}
------------------------------
• [SLOW TEST] [16.128 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:59:29.599
    Jul 10 07:59:29.599: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 07:59:29.6
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:29.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:29.627
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 07/10/23 07:59:29.63
    STEP: Counting existing ResourceQuota 07/10/23 07:59:34.635
    STEP: Creating a ResourceQuota 07/10/23 07:59:39.641
    STEP: Ensuring resource quota status is calculated 07/10/23 07:59:39.657
    STEP: Creating a Secret 07/10/23 07:59:41.663
    STEP: Ensuring resource quota status captures secret creation 07/10/23 07:59:41.689
    STEP: Deleting a secret 07/10/23 07:59:43.694
    STEP: Ensuring resource quota status released usage 07/10/23 07:59:43.704
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 07:59:45.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1066" for this suite. 07/10/23 07:59:45.714
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:59:45.728
Jul 10 07:59:45.729: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 07:59:45.729
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:45.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:45.775
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Jul 10 07:59:45.778: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul 10 07:59:45.795: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 10 07:59:50.802: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 07/10/23 07:59:50.802
Jul 10 07:59:50.802: INFO: Creating deployment "test-rolling-update-deployment"
Jul 10 07:59:50.813: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul 10 07:59:50.821: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul 10 07:59:52.832: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul 10 07:59:52.836: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 07:59:54.842: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 07:59:54.853: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4503  deaa53b0-74f4-4500-adc5-755d681f80d6 69390 1 2023-07-10 07:59:50 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-07-10 07:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a56fd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-07-10 07:59:50 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-07-10 07:59:53 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul 10 07:59:54.857: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-4503  7b8cd3c1-60b6-4206-bb2b-77dc1c978199 69380 1 2023-07-10 07:59:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment deaa53b0-74f4-4500-adc5-755d681f80d6 0xc003a574d7 0xc003a574d8}] [] [{kube-controller-manager Update apps/v1 2023-07-10 07:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"deaa53b0-74f4-4500-adc5-755d681f80d6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a57588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul 10 07:59:54.857: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul 10 07:59:54.858: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4503  6a056a33-329b-440f-8210-a8d8fafc9ea5 69389 2 2023-07-10 07:59:45 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment deaa53b0-74f4-4500-adc5-755d681f80d6 0xc003a573a7 0xc003a573a8}] [] [{e2e.test Update apps/v1 2023-07-10 07:59:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"deaa53b0-74f4-4500-adc5-755d681f80d6\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003a57468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 07:59:54.862: INFO: Pod "test-rolling-update-deployment-78f575d8ff-rttrw" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-rttrw test-rolling-update-deployment-78f575d8ff- deployment-4503  7281375d-d097-4e29-bf0a-a13ebc88fca0 69379 0 2023-07-10 07:59:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:febcb211aa406af8c8c73a5bd06f60958f684ee730c173322b1f0f3886ae6595 cni.projectcalico.org/podIP:192.168.172.12/32 cni.projectcalico.org/podIPs:192.168.172.12/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 7b8cd3c1-60b6-4206-bb2b-77dc1c978199 0xc003959477 0xc003959478}] [] [{kube-controller-manager Update v1 2023-07-10 07:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b8cd3c1-60b6-4206-bb2b-77dc1c978199\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 07:59:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cft26,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cft26,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.12,StartTime:2023-07-10 07:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 07:59:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://1da2f8d74b2fabcfb6f56b6cb1ca735f50433cfb397250688eb74a54be4ea78d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 07:59:54.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4503" for this suite. 07/10/23 07:59:54.868
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":11,"skipped":197,"failed":0}
------------------------------
• [SLOW TEST] [9.155 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:59:45.728
    Jul 10 07:59:45.729: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 07:59:45.729
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:45.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:45.775
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Jul 10 07:59:45.778: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Jul 10 07:59:45.795: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jul 10 07:59:50.802: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 07/10/23 07:59:50.802
    Jul 10 07:59:50.802: INFO: Creating deployment "test-rolling-update-deployment"
    Jul 10 07:59:50.813: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Jul 10 07:59:50.821: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Jul 10 07:59:52.832: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Jul 10 07:59:52.836: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 7, 59, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 07:59:54.842: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 07:59:54.853: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4503  deaa53b0-74f4-4500-adc5-755d681f80d6 69390 1 2023-07-10 07:59:50 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-07-10 07:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a56fd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-07-10 07:59:50 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-07-10 07:59:53 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jul 10 07:59:54.857: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-4503  7b8cd3c1-60b6-4206-bb2b-77dc1c978199 69380 1 2023-07-10 07:59:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment deaa53b0-74f4-4500-adc5-755d681f80d6 0xc003a574d7 0xc003a574d8}] [] [{kube-controller-manager Update apps/v1 2023-07-10 07:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"deaa53b0-74f4-4500-adc5-755d681f80d6\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a57588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 07:59:54.857: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Jul 10 07:59:54.858: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4503  6a056a33-329b-440f-8210-a8d8fafc9ea5 69389 2 2023-07-10 07:59:45 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment deaa53b0-74f4-4500-adc5-755d681f80d6 0xc003a573a7 0xc003a573a8}] [] [{e2e.test Update apps/v1 2023-07-10 07:59:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"deaa53b0-74f4-4500-adc5-755d681f80d6\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003a57468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 07:59:54.862: INFO: Pod "test-rolling-update-deployment-78f575d8ff-rttrw" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-rttrw test-rolling-update-deployment-78f575d8ff- deployment-4503  7281375d-d097-4e29-bf0a-a13ebc88fca0 69379 0 2023-07-10 07:59:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:febcb211aa406af8c8c73a5bd06f60958f684ee730c173322b1f0f3886ae6595 cni.projectcalico.org/podIP:192.168.172.12/32 cni.projectcalico.org/podIPs:192.168.172.12/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 7b8cd3c1-60b6-4206-bb2b-77dc1c978199 0xc003959477 0xc003959478}] [] [{kube-controller-manager Update v1 2023-07-10 07:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b8cd3c1-60b6-4206-bb2b-77dc1c978199\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 07:59:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 07:59:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cft26,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cft26,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 07:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.12,StartTime:2023-07-10 07:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 07:59:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://1da2f8d74b2fabcfb6f56b6cb1ca735f50433cfb397250688eb74a54be4ea78d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 07:59:54.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4503" for this suite. 07/10/23 07:59:54.868
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 07:59:54.888
Jul 10 07:59:54.888: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename proxy 07/10/23 07:59:54.889
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:54.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:54.928
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 07/10/23 07:59:54.957
STEP: creating replication controller proxy-service-l4bzw in namespace proxy-6559 07/10/23 07:59:54.957
I0710 07:59:54.977394      21 runners.go:193] Created replication controller with name: proxy-service-l4bzw, namespace: proxy-6559, replica count: 1
I0710 07:59:56.028795      21 runners.go:193] proxy-service-l4bzw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0710 07:59:57.028993      21 runners.go:193] proxy-service-l4bzw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0710 07:59:58.029266      21 runners.go:193] proxy-service-l4bzw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 07:59:58.034: INFO: setup took 3.102641255s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 07/10/23 07:59:58.034
Jul 10 07:59:58.045: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 10.84127ms)
Jul 10 07:59:58.045: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 10.787464ms)
Jul 10 07:59:58.046: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 11.662605ms)
Jul 10 07:59:58.046: INFO: (0) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.017701ms)
Jul 10 07:59:58.046: INFO: (0) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 11.631466ms)
Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 13.723411ms)
Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 13.5435ms)
Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 13.821432ms)
Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 13.855929ms)
Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 14.417884ms)
Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 14.447154ms)
Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 14.232682ms)
Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 14.42792ms)
Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 14.730769ms)
Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 14.66336ms)
Jul 10 07:59:58.050: INFO: (0) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 16.096317ms)
Jul 10 07:59:58.055: INFO: (1) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.752538ms)
Jul 10 07:59:58.056: INFO: (1) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.383335ms)
Jul 10 07:59:58.057: INFO: (1) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.469053ms)
Jul 10 07:59:58.057: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.526799ms)
Jul 10 07:59:58.057: INFO: (1) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.785131ms)
Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.561568ms)
Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 8.584309ms)
Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.593459ms)
Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.802885ms)
Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 9.18183ms)
Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 9.347698ms)
Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.274243ms)
Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.959208ms)
Jul 10 07:59:58.061: INFO: (1) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 10.242663ms)
Jul 10 07:59:58.061: INFO: (1) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.000798ms)
Jul 10 07:59:58.061: INFO: (1) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.066218ms)
Jul 10 07:59:58.068: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.253717ms)
Jul 10 07:59:58.068: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.159451ms)
Jul 10 07:59:58.070: INFO: (2) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.865857ms)
Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 8.466808ms)
Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.739118ms)
Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.631271ms)
Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 8.044563ms)
Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.441457ms)
Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.042995ms)
Jul 10 07:59:58.073: INFO: (2) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.915403ms)
Jul 10 07:59:58.073: INFO: (2) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 10.516691ms)
Jul 10 07:59:58.073: INFO: (2) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.808266ms)
Jul 10 07:59:58.074: INFO: (2) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 10.502374ms)
Jul 10 07:59:58.074: INFO: (2) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.011263ms)
Jul 10 07:59:58.074: INFO: (2) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 12.228184ms)
Jul 10 07:59:58.075: INFO: (2) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 12.239384ms)
Jul 10 07:59:58.079: INFO: (3) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 3.804703ms)
Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 3.97421ms)
Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.442495ms)
Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.309067ms)
Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.683952ms)
Jul 10 07:59:58.081: INFO: (3) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 4.077983ms)
Jul 10 07:59:58.082: INFO: (3) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 5.293394ms)
Jul 10 07:59:58.082: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.80475ms)
Jul 10 07:59:58.083: INFO: (3) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 6.885496ms)
Jul 10 07:59:58.083: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.526512ms)
Jul 10 07:59:58.083: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.103413ms)
Jul 10 07:59:58.085: INFO: (3) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 8.819052ms)
Jul 10 07:59:58.085: INFO: (3) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.624771ms)
Jul 10 07:59:58.085: INFO: (3) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 8.766909ms)
Jul 10 07:59:58.086: INFO: (3) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.534324ms)
Jul 10 07:59:58.086: INFO: (3) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.435519ms)
Jul 10 07:59:58.092: INFO: (4) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.368381ms)
Jul 10 07:59:58.093: INFO: (4) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.580801ms)
Jul 10 07:59:58.093: INFO: (4) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.80815ms)
Jul 10 07:59:58.093: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 7.140107ms)
Jul 10 07:59:58.094: INFO: (4) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.65877ms)
Jul 10 07:59:58.095: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.960544ms)
Jul 10 07:59:58.095: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.989676ms)
Jul 10 07:59:58.095: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 8.722835ms)
Jul 10 07:59:58.096: INFO: (4) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 9.152225ms)
Jul 10 07:59:58.096: INFO: (4) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.69795ms)
Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 10.413691ms)
Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 10.224044ms)
Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 10.734972ms)
Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 11.110798ms)
Jul 10 07:59:58.098: INFO: (4) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 11.110823ms)
Jul 10 07:59:58.098: INFO: (4) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 11.80194ms)
Jul 10 07:59:58.103: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 4.34437ms)
Jul 10 07:59:58.103: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.396012ms)
Jul 10 07:59:58.103: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.43049ms)
Jul 10 07:59:58.106: INFO: (5) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.416272ms)
Jul 10 07:59:58.106: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.548657ms)
Jul 10 07:59:58.106: INFO: (5) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.037375ms)
Jul 10 07:59:58.110: INFO: (5) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 10.870613ms)
Jul 10 07:59:58.110: INFO: (5) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 11.364647ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.724401ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 12.095012ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 12.199559ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.221014ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 12.47843ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 11.712029ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 12.220564ms)
Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 12.861395ms)
Jul 10 07:59:58.115: INFO: (6) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 3.692887ms)
Jul 10 07:59:58.115: INFO: (6) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.220603ms)
Jul 10 07:59:58.116: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.17343ms)
Jul 10 07:59:58.118: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.999522ms)
Jul 10 07:59:58.118: INFO: (6) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.329228ms)
Jul 10 07:59:58.118: INFO: (6) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 5.920796ms)
Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.947369ms)
Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 7.762481ms)
Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 7.109542ms)
Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 7.950048ms)
Jul 10 07:59:58.122: INFO: (6) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 10.319258ms)
Jul 10 07:59:58.122: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 9.212627ms)
Jul 10 07:59:58.122: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 10.225996ms)
Jul 10 07:59:58.124: INFO: (6) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 11.267416ms)
Jul 10 07:59:58.124: INFO: (6) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 11.535991ms)
Jul 10 07:59:58.124: INFO: (6) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.864709ms)
Jul 10 07:59:58.128: INFO: (7) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 4.410596ms)
Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.808403ms)
Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.095944ms)
Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 5.739339ms)
Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.285716ms)
Jul 10 07:59:58.133: INFO: (7) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.496837ms)
Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.848772ms)
Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.943614ms)
Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 9.055347ms)
Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.331023ms)
Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 10.196166ms)
Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 10.054676ms)
Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 9.531343ms)
Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 10.62111ms)
Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 9.718482ms)
Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.489697ms)
Jul 10 07:59:58.139: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 3.848054ms)
Jul 10 07:59:58.139: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 4.061793ms)
Jul 10 07:59:58.141: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 5.190557ms)
Jul 10 07:59:58.141: INFO: (8) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 5.766793ms)
Jul 10 07:59:58.141: INFO: (8) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.326093ms)
Jul 10 07:59:58.142: INFO: (8) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 6.62221ms)
Jul 10 07:59:58.142: INFO: (8) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 7.022167ms)
Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 8.699372ms)
Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.769072ms)
Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.533877ms)
Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.011919ms)
Jul 10 07:59:58.146: INFO: (8) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.12877ms)
Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 18.04951ms)
Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 18.02107ms)
Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 18.638318ms)
Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 18.284238ms)
Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 5.352481ms)
Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.432552ms)
Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.504601ms)
Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.283391ms)
Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 5.647467ms)
Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.377863ms)
Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.995509ms)
Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.032331ms)
Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.542937ms)
Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.574607ms)
Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 7.694223ms)
Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 7.883411ms)
Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 8.334092ms)
Jul 10 07:59:58.164: INFO: (9) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.248563ms)
Jul 10 07:59:58.164: INFO: (9) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.224306ms)
Jul 10 07:59:58.165: INFO: (9) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.26189ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.676595ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.560284ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.856701ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.678728ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.778566ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.825747ms)
Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.646489ms)
Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.407708ms)
Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 7.366253ms)
Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.43505ms)
Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 7.459567ms)
Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.021451ms)
Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.74069ms)
Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.059052ms)
Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 8.875085ms)
Jul 10 07:59:58.175: INFO: (10) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.324055ms)
Jul 10 07:59:58.180: INFO: (11) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.485162ms)
Jul 10 07:59:58.180: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.057744ms)
Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 7.30553ms)
Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 7.883078ms)
Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.634876ms)
Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.698568ms)
Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.031149ms)
Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.905802ms)
Jul 10 07:59:58.184: INFO: (11) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 8.540131ms)
Jul 10 07:59:58.185: INFO: (11) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 8.633929ms)
Jul 10 07:59:58.189: INFO: (11) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 12.845792ms)
Jul 10 07:59:58.189: INFO: (11) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 13.621591ms)
Jul 10 07:59:58.190: INFO: (11) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 14.346416ms)
Jul 10 07:59:58.190: INFO: (11) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 14.68518ms)
Jul 10 07:59:58.192: INFO: (11) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 15.952659ms)
Jul 10 07:59:58.192: INFO: (11) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 16.417872ms)
Jul 10 07:59:58.198: INFO: (12) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 5.434928ms)
Jul 10 07:59:58.198: INFO: (12) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.202952ms)
Jul 10 07:59:58.198: INFO: (12) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 5.022217ms)
Jul 10 07:59:58.199: INFO: (12) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.965482ms)
Jul 10 07:59:58.201: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.418674ms)
Jul 10 07:59:58.201: INFO: (12) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.088824ms)
Jul 10 07:59:58.201: INFO: (12) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 7.080269ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.866284ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 9.313812ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 9.907489ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.829001ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.702003ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.243317ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 9.412964ms)
Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 9.318683ms)
Jul 10 07:59:58.205: INFO: (12) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.645298ms)
Jul 10 07:59:58.210: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 4.806048ms)
Jul 10 07:59:58.212: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.801165ms)
Jul 10 07:59:58.212: INFO: (13) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 5.67995ms)
Jul 10 07:59:58.212: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.688662ms)
Jul 10 07:59:58.213: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.651542ms)
Jul 10 07:59:58.213: INFO: (13) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.377488ms)
Jul 10 07:59:58.213: INFO: (13) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.410703ms)
Jul 10 07:59:58.214: INFO: (13) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 7.41988ms)
Jul 10 07:59:58.214: INFO: (13) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.4534ms)
Jul 10 07:59:58.214: INFO: (13) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 8.742807ms)
Jul 10 07:59:58.215: INFO: (13) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 9.065353ms)
Jul 10 07:59:58.215: INFO: (13) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 8.118771ms)
Jul 10 07:59:58.215: INFO: (13) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.739902ms)
Jul 10 07:59:58.216: INFO: (13) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 8.696774ms)
Jul 10 07:59:58.216: INFO: (13) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.808145ms)
Jul 10 07:59:58.216: INFO: (13) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.163142ms)
Jul 10 07:59:58.236: INFO: (14) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 19.932103ms)
Jul 10 07:59:58.239: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 21.993313ms)
Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 22.484813ms)
Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 22.291223ms)
Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 21.785554ms)
Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 21.778761ms)
Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 22.786977ms)
Jul 10 07:59:58.241: INFO: (14) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 24.442787ms)
Jul 10 07:59:58.241: INFO: (14) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 24.583011ms)
Jul 10 07:59:58.241: INFO: (14) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 24.580069ms)
Jul 10 07:59:58.242: INFO: (14) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 24.10716ms)
Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 25.252689ms)
Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 24.859907ms)
Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 26.290818ms)
Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 26.184464ms)
Jul 10 07:59:58.248: INFO: (14) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 30.649187ms)
Jul 10 07:59:58.254: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.497889ms)
Jul 10 07:59:58.254: INFO: (15) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.082094ms)
Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.535297ms)
Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.759783ms)
Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.668979ms)
Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 8.847543ms)
Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 9.313175ms)
Jul 10 07:59:58.258: INFO: (15) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.466317ms)
Jul 10 07:59:58.260: INFO: (15) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.644908ms)
Jul 10 07:59:58.260: INFO: (15) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.646117ms)
Jul 10 07:59:58.260: INFO: (15) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 11.988996ms)
Jul 10 07:59:58.267: INFO: (15) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 18.58441ms)
Jul 10 07:59:58.276: INFO: (15) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 27.664609ms)
Jul 10 07:59:58.276: INFO: (15) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 27.546723ms)
Jul 10 07:59:58.276: INFO: (15) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 27.852648ms)
Jul 10 07:59:58.281: INFO: (15) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 32.451611ms)
Jul 10 07:59:58.286: INFO: (16) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 5.032131ms)
Jul 10 07:59:58.289: INFO: (16) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.148271ms)
Jul 10 07:59:58.289: INFO: (16) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.218475ms)
Jul 10 07:59:58.289: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 8.372696ms)
Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 10.830921ms)
Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.21829ms)
Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.237901ms)
Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 11.59295ms)
Jul 10 07:59:58.293: INFO: (16) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 11.388198ms)
Jul 10 07:59:58.293: INFO: (16) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.4947ms)
Jul 10 07:59:58.293: INFO: (16) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 12.101372ms)
Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 14.758666ms)
Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 14.981189ms)
Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 14.832131ms)
Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 14.925726ms)
Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 14.897368ms)
Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.462186ms)
Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.436841ms)
Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.732672ms)
Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.23533ms)
Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.246036ms)
Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.338452ms)
Jul 10 07:59:58.305: INFO: (17) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.548523ms)
Jul 10 07:59:58.306: INFO: (17) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.536841ms)
Jul 10 07:59:58.306: INFO: (17) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 10.397783ms)
Jul 10 07:59:58.306: INFO: (17) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 10.129465ms)
Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 11.039138ms)
Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.184248ms)
Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 11.409572ms)
Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 11.176756ms)
Jul 10 07:59:58.308: INFO: (17) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.332383ms)
Jul 10 07:59:58.310: INFO: (17) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 13.43536ms)
Jul 10 07:59:58.318: INFO: (18) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.837991ms)
Jul 10 07:59:58.321: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 11.192848ms)
Jul 10 07:59:58.322: INFO: (18) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.905157ms)
Jul 10 07:59:58.322: INFO: (18) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 11.242914ms)
Jul 10 07:59:58.322: INFO: (18) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.287853ms)
Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 12.395583ms)
Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 12.921398ms)
Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 13.506265ms)
Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 13.210804ms)
Jul 10 07:59:58.324: INFO: (18) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 13.315183ms)
Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 14.250116ms)
Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 14.86052ms)
Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 15.283725ms)
Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 15.846298ms)
Jul 10 07:59:58.326: INFO: (18) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 15.505023ms)
Jul 10 07:59:58.326: INFO: (18) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 16.506619ms)
Jul 10 07:59:58.331: INFO: (19) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 4.520684ms)
Jul 10 07:59:58.331: INFO: (19) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.847707ms)
Jul 10 07:59:58.331: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.83435ms)
Jul 10 07:59:58.333: INFO: (19) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.148603ms)
Jul 10 07:59:58.333: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 5.756336ms)
Jul 10 07:59:58.333: INFO: (19) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.189422ms)
Jul 10 07:59:58.334: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.489166ms)
Jul 10 07:59:58.334: INFO: (19) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.970973ms)
Jul 10 07:59:58.335: INFO: (19) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.666502ms)
Jul 10 07:59:58.335: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 7.779512ms)
Jul 10 07:59:58.336: INFO: (19) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.955209ms)
Jul 10 07:59:58.336: INFO: (19) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.400869ms)
Jul 10 07:59:58.336: INFO: (19) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.103353ms)
Jul 10 07:59:58.337: INFO: (19) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 9.146298ms)
Jul 10 07:59:58.337: INFO: (19) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 10.446457ms)
Jul 10 07:59:58.338: INFO: (19) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 10.191321ms)
STEP: deleting ReplicationController proxy-service-l4bzw in namespace proxy-6559, will wait for the garbage collector to delete the pods 07/10/23 07:59:58.338
Jul 10 07:59:58.408: INFO: Deleting ReplicationController proxy-service-l4bzw took: 15.540504ms
Jul 10 07:59:58.609: INFO: Terminating ReplicationController proxy-service-l4bzw pods took: 201.177219ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jul 10 08:00:01.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6559" for this suite. 07/10/23 08:00:01.518
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":12,"skipped":260,"failed":0}
------------------------------
• [SLOW TEST] [6.647 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 07:59:54.888
    Jul 10 07:59:54.888: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename proxy 07/10/23 07:59:54.889
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 07:59:54.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 07:59:54.928
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 07/10/23 07:59:54.957
    STEP: creating replication controller proxy-service-l4bzw in namespace proxy-6559 07/10/23 07:59:54.957
    I0710 07:59:54.977394      21 runners.go:193] Created replication controller with name: proxy-service-l4bzw, namespace: proxy-6559, replica count: 1
    I0710 07:59:56.028795      21 runners.go:193] proxy-service-l4bzw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0710 07:59:57.028993      21 runners.go:193] proxy-service-l4bzw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0710 07:59:58.029266      21 runners.go:193] proxy-service-l4bzw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 07:59:58.034: INFO: setup took 3.102641255s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 07/10/23 07:59:58.034
    Jul 10 07:59:58.045: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 10.84127ms)
    Jul 10 07:59:58.045: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 10.787464ms)
    Jul 10 07:59:58.046: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 11.662605ms)
    Jul 10 07:59:58.046: INFO: (0) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.017701ms)
    Jul 10 07:59:58.046: INFO: (0) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 11.631466ms)
    Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 13.723411ms)
    Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 13.5435ms)
    Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 13.821432ms)
    Jul 10 07:59:58.048: INFO: (0) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 13.855929ms)
    Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 14.417884ms)
    Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 14.447154ms)
    Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 14.232682ms)
    Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 14.42792ms)
    Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 14.730769ms)
    Jul 10 07:59:58.049: INFO: (0) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 14.66336ms)
    Jul 10 07:59:58.050: INFO: (0) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 16.096317ms)
    Jul 10 07:59:58.055: INFO: (1) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.752538ms)
    Jul 10 07:59:58.056: INFO: (1) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.383335ms)
    Jul 10 07:59:58.057: INFO: (1) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.469053ms)
    Jul 10 07:59:58.057: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.526799ms)
    Jul 10 07:59:58.057: INFO: (1) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.785131ms)
    Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.561568ms)
    Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 8.584309ms)
    Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.593459ms)
    Jul 10 07:59:58.059: INFO: (1) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.802885ms)
    Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 9.18183ms)
    Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 9.347698ms)
    Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.274243ms)
    Jul 10 07:59:58.060: INFO: (1) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.959208ms)
    Jul 10 07:59:58.061: INFO: (1) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 10.242663ms)
    Jul 10 07:59:58.061: INFO: (1) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.000798ms)
    Jul 10 07:59:58.061: INFO: (1) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.066218ms)
    Jul 10 07:59:58.068: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.253717ms)
    Jul 10 07:59:58.068: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.159451ms)
    Jul 10 07:59:58.070: INFO: (2) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.865857ms)
    Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 8.466808ms)
    Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.739118ms)
    Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.631271ms)
    Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 8.044563ms)
    Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.441457ms)
    Jul 10 07:59:58.071: INFO: (2) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.042995ms)
    Jul 10 07:59:58.073: INFO: (2) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.915403ms)
    Jul 10 07:59:58.073: INFO: (2) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 10.516691ms)
    Jul 10 07:59:58.073: INFO: (2) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.808266ms)
    Jul 10 07:59:58.074: INFO: (2) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 10.502374ms)
    Jul 10 07:59:58.074: INFO: (2) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.011263ms)
    Jul 10 07:59:58.074: INFO: (2) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 12.228184ms)
    Jul 10 07:59:58.075: INFO: (2) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 12.239384ms)
    Jul 10 07:59:58.079: INFO: (3) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 3.804703ms)
    Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 3.97421ms)
    Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.442495ms)
    Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.309067ms)
    Jul 10 07:59:58.080: INFO: (3) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.683952ms)
    Jul 10 07:59:58.081: INFO: (3) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 4.077983ms)
    Jul 10 07:59:58.082: INFO: (3) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 5.293394ms)
    Jul 10 07:59:58.082: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.80475ms)
    Jul 10 07:59:58.083: INFO: (3) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 6.885496ms)
    Jul 10 07:59:58.083: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.526512ms)
    Jul 10 07:59:58.083: INFO: (3) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.103413ms)
    Jul 10 07:59:58.085: INFO: (3) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 8.819052ms)
    Jul 10 07:59:58.085: INFO: (3) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.624771ms)
    Jul 10 07:59:58.085: INFO: (3) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 8.766909ms)
    Jul 10 07:59:58.086: INFO: (3) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.534324ms)
    Jul 10 07:59:58.086: INFO: (3) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.435519ms)
    Jul 10 07:59:58.092: INFO: (4) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.368381ms)
    Jul 10 07:59:58.093: INFO: (4) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.580801ms)
    Jul 10 07:59:58.093: INFO: (4) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.80815ms)
    Jul 10 07:59:58.093: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 7.140107ms)
    Jul 10 07:59:58.094: INFO: (4) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.65877ms)
    Jul 10 07:59:58.095: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.960544ms)
    Jul 10 07:59:58.095: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.989676ms)
    Jul 10 07:59:58.095: INFO: (4) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 8.722835ms)
    Jul 10 07:59:58.096: INFO: (4) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 9.152225ms)
    Jul 10 07:59:58.096: INFO: (4) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.69795ms)
    Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 10.413691ms)
    Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 10.224044ms)
    Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 10.734972ms)
    Jul 10 07:59:58.097: INFO: (4) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 11.110798ms)
    Jul 10 07:59:58.098: INFO: (4) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 11.110823ms)
    Jul 10 07:59:58.098: INFO: (4) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 11.80194ms)
    Jul 10 07:59:58.103: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 4.34437ms)
    Jul 10 07:59:58.103: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.396012ms)
    Jul 10 07:59:58.103: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.43049ms)
    Jul 10 07:59:58.106: INFO: (5) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.416272ms)
    Jul 10 07:59:58.106: INFO: (5) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.548657ms)
    Jul 10 07:59:58.106: INFO: (5) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.037375ms)
    Jul 10 07:59:58.110: INFO: (5) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 10.870613ms)
    Jul 10 07:59:58.110: INFO: (5) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 11.364647ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.724401ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 12.095012ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 12.199559ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.221014ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 12.47843ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 11.712029ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 12.220564ms)
    Jul 10 07:59:58.111: INFO: (5) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 12.861395ms)
    Jul 10 07:59:58.115: INFO: (6) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 3.692887ms)
    Jul 10 07:59:58.115: INFO: (6) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.220603ms)
    Jul 10 07:59:58.116: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.17343ms)
    Jul 10 07:59:58.118: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.999522ms)
    Jul 10 07:59:58.118: INFO: (6) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.329228ms)
    Jul 10 07:59:58.118: INFO: (6) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 5.920796ms)
    Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.947369ms)
    Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 7.762481ms)
    Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 7.109542ms)
    Jul 10 07:59:58.119: INFO: (6) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 7.950048ms)
    Jul 10 07:59:58.122: INFO: (6) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 10.319258ms)
    Jul 10 07:59:58.122: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 9.212627ms)
    Jul 10 07:59:58.122: INFO: (6) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 10.225996ms)
    Jul 10 07:59:58.124: INFO: (6) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 11.267416ms)
    Jul 10 07:59:58.124: INFO: (6) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 11.535991ms)
    Jul 10 07:59:58.124: INFO: (6) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.864709ms)
    Jul 10 07:59:58.128: INFO: (7) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 4.410596ms)
    Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.808403ms)
    Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.095944ms)
    Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 5.739339ms)
    Jul 10 07:59:58.131: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.285716ms)
    Jul 10 07:59:58.133: INFO: (7) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.496837ms)
    Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.848772ms)
    Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.943614ms)
    Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 9.055347ms)
    Jul 10 07:59:58.134: INFO: (7) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.331023ms)
    Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 10.196166ms)
    Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 10.054676ms)
    Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 9.531343ms)
    Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 10.62111ms)
    Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 9.718482ms)
    Jul 10 07:59:58.135: INFO: (7) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.489697ms)
    Jul 10 07:59:58.139: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 3.848054ms)
    Jul 10 07:59:58.139: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 4.061793ms)
    Jul 10 07:59:58.141: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 5.190557ms)
    Jul 10 07:59:58.141: INFO: (8) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 5.766793ms)
    Jul 10 07:59:58.141: INFO: (8) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.326093ms)
    Jul 10 07:59:58.142: INFO: (8) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 6.62221ms)
    Jul 10 07:59:58.142: INFO: (8) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 7.022167ms)
    Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 8.699372ms)
    Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.769072ms)
    Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.533877ms)
    Jul 10 07:59:58.145: INFO: (8) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.011919ms)
    Jul 10 07:59:58.146: INFO: (8) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.12877ms)
    Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 18.04951ms)
    Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 18.02107ms)
    Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 18.638318ms)
    Jul 10 07:59:58.154: INFO: (8) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 18.284238ms)
    Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 5.352481ms)
    Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.432552ms)
    Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.504601ms)
    Jul 10 07:59:58.160: INFO: (9) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.283391ms)
    Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 5.647467ms)
    Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.377863ms)
    Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.995509ms)
    Jul 10 07:59:58.161: INFO: (9) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.032331ms)
    Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.542937ms)
    Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.574607ms)
    Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 7.694223ms)
    Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 7.883411ms)
    Jul 10 07:59:58.163: INFO: (9) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 8.334092ms)
    Jul 10 07:59:58.164: INFO: (9) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.248563ms)
    Jul 10 07:59:58.164: INFO: (9) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.224306ms)
    Jul 10 07:59:58.165: INFO: (9) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.26189ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.676595ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.560284ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.856701ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.678728ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.778566ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.825747ms)
    Jul 10 07:59:58.172: INFO: (10) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 6.646489ms)
    Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.407708ms)
    Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 7.366253ms)
    Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.43505ms)
    Jul 10 07:59:58.173: INFO: (10) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 7.459567ms)
    Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.021451ms)
    Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.74069ms)
    Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.059052ms)
    Jul 10 07:59:58.174: INFO: (10) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 8.875085ms)
    Jul 10 07:59:58.175: INFO: (10) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.324055ms)
    Jul 10 07:59:58.180: INFO: (11) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.485162ms)
    Jul 10 07:59:58.180: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.057744ms)
    Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 7.30553ms)
    Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 7.883078ms)
    Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 7.634876ms)
    Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.698568ms)
    Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.031149ms)
    Jul 10 07:59:58.183: INFO: (11) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.905802ms)
    Jul 10 07:59:58.184: INFO: (11) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 8.540131ms)
    Jul 10 07:59:58.185: INFO: (11) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 8.633929ms)
    Jul 10 07:59:58.189: INFO: (11) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 12.845792ms)
    Jul 10 07:59:58.189: INFO: (11) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 13.621591ms)
    Jul 10 07:59:58.190: INFO: (11) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 14.346416ms)
    Jul 10 07:59:58.190: INFO: (11) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 14.68518ms)
    Jul 10 07:59:58.192: INFO: (11) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 15.952659ms)
    Jul 10 07:59:58.192: INFO: (11) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 16.417872ms)
    Jul 10 07:59:58.198: INFO: (12) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 5.434928ms)
    Jul 10 07:59:58.198: INFO: (12) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.202952ms)
    Jul 10 07:59:58.198: INFO: (12) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 5.022217ms)
    Jul 10 07:59:58.199: INFO: (12) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.965482ms)
    Jul 10 07:59:58.201: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.418674ms)
    Jul 10 07:59:58.201: INFO: (12) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.088824ms)
    Jul 10 07:59:58.201: INFO: (12) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 7.080269ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.866284ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 9.313812ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 9.907489ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 9.829001ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.702003ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.243317ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 9.412964ms)
    Jul 10 07:59:58.203: INFO: (12) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 9.318683ms)
    Jul 10 07:59:58.205: INFO: (12) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.645298ms)
    Jul 10 07:59:58.210: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 4.806048ms)
    Jul 10 07:59:58.212: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 5.801165ms)
    Jul 10 07:59:58.212: INFO: (13) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 5.67995ms)
    Jul 10 07:59:58.212: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 5.688662ms)
    Jul 10 07:59:58.213: INFO: (13) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 6.651542ms)
    Jul 10 07:59:58.213: INFO: (13) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.377488ms)
    Jul 10 07:59:58.213: INFO: (13) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.410703ms)
    Jul 10 07:59:58.214: INFO: (13) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 7.41988ms)
    Jul 10 07:59:58.214: INFO: (13) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.4534ms)
    Jul 10 07:59:58.214: INFO: (13) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 8.742807ms)
    Jul 10 07:59:58.215: INFO: (13) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 9.065353ms)
    Jul 10 07:59:58.215: INFO: (13) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 8.118771ms)
    Jul 10 07:59:58.215: INFO: (13) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.739902ms)
    Jul 10 07:59:58.216: INFO: (13) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 8.696774ms)
    Jul 10 07:59:58.216: INFO: (13) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.808145ms)
    Jul 10 07:59:58.216: INFO: (13) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 10.163142ms)
    Jul 10 07:59:58.236: INFO: (14) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 19.932103ms)
    Jul 10 07:59:58.239: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 21.993313ms)
    Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 22.484813ms)
    Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 22.291223ms)
    Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 21.785554ms)
    Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 21.778761ms)
    Jul 10 07:59:58.240: INFO: (14) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 22.786977ms)
    Jul 10 07:59:58.241: INFO: (14) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 24.442787ms)
    Jul 10 07:59:58.241: INFO: (14) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 24.583011ms)
    Jul 10 07:59:58.241: INFO: (14) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 24.580069ms)
    Jul 10 07:59:58.242: INFO: (14) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 24.10716ms)
    Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 25.252689ms)
    Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 24.859907ms)
    Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 26.290818ms)
    Jul 10 07:59:58.243: INFO: (14) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 26.184464ms)
    Jul 10 07:59:58.248: INFO: (14) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 30.649187ms)
    Jul 10 07:59:58.254: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 5.497889ms)
    Jul 10 07:59:58.254: INFO: (15) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.082094ms)
    Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.535297ms)
    Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.759783ms)
    Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 8.668979ms)
    Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 8.847543ms)
    Jul 10 07:59:58.257: INFO: (15) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 9.313175ms)
    Jul 10 07:59:58.258: INFO: (15) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.466317ms)
    Jul 10 07:59:58.260: INFO: (15) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.644908ms)
    Jul 10 07:59:58.260: INFO: (15) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.646117ms)
    Jul 10 07:59:58.260: INFO: (15) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 11.988996ms)
    Jul 10 07:59:58.267: INFO: (15) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 18.58441ms)
    Jul 10 07:59:58.276: INFO: (15) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 27.664609ms)
    Jul 10 07:59:58.276: INFO: (15) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 27.546723ms)
    Jul 10 07:59:58.276: INFO: (15) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 27.852648ms)
    Jul 10 07:59:58.281: INFO: (15) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 32.451611ms)
    Jul 10 07:59:58.286: INFO: (16) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 5.032131ms)
    Jul 10 07:59:58.289: INFO: (16) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 8.148271ms)
    Jul 10 07:59:58.289: INFO: (16) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 8.218475ms)
    Jul 10 07:59:58.289: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 8.372696ms)
    Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 10.830921ms)
    Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.21829ms)
    Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.237901ms)
    Jul 10 07:59:58.292: INFO: (16) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 11.59295ms)
    Jul 10 07:59:58.293: INFO: (16) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 11.388198ms)
    Jul 10 07:59:58.293: INFO: (16) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 11.4947ms)
    Jul 10 07:59:58.293: INFO: (16) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 12.101372ms)
    Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 14.758666ms)
    Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 14.981189ms)
    Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 14.832131ms)
    Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 14.925726ms)
    Jul 10 07:59:58.296: INFO: (16) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 14.897368ms)
    Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.462186ms)
    Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.436841ms)
    Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 6.732672ms)
    Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 7.23533ms)
    Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 7.246036ms)
    Jul 10 07:59:58.303: INFO: (17) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.338452ms)
    Jul 10 07:59:58.305: INFO: (17) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 9.548523ms)
    Jul 10 07:59:58.306: INFO: (17) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 9.536841ms)
    Jul 10 07:59:58.306: INFO: (17) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 10.397783ms)
    Jul 10 07:59:58.306: INFO: (17) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 10.129465ms)
    Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 11.039138ms)
    Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.184248ms)
    Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 11.409572ms)
    Jul 10 07:59:58.307: INFO: (17) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 11.176756ms)
    Jul 10 07:59:58.308: INFO: (17) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 12.332383ms)
    Jul 10 07:59:58.310: INFO: (17) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 13.43536ms)
    Jul 10 07:59:58.318: INFO: (18) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.837991ms)
    Jul 10 07:59:58.321: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 11.192848ms)
    Jul 10 07:59:58.322: INFO: (18) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 11.905157ms)
    Jul 10 07:59:58.322: INFO: (18) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 11.242914ms)
    Jul 10 07:59:58.322: INFO: (18) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 11.287853ms)
    Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 12.395583ms)
    Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 12.921398ms)
    Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 13.506265ms)
    Jul 10 07:59:58.323: INFO: (18) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 13.210804ms)
    Jul 10 07:59:58.324: INFO: (18) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 13.315183ms)
    Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 14.250116ms)
    Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 14.86052ms)
    Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 15.283725ms)
    Jul 10 07:59:58.325: INFO: (18) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 15.846298ms)
    Jul 10 07:59:58.326: INFO: (18) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 15.505023ms)
    Jul 10 07:59:58.326: INFO: (18) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 16.506619ms)
    Jul 10 07:59:58.331: INFO: (19) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 4.520684ms)
    Jul 10 07:59:58.331: INFO: (19) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:462/proxy/: tls qux (200; 4.847707ms)
    Jul 10 07:59:58.331: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 4.83435ms)
    Jul 10 07:59:58.333: INFO: (19) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:162/proxy/: bar (200; 6.148603ms)
    Jul 10 07:59:58.333: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z/proxy/rewriteme">test</a> (200; 5.756336ms)
    Jul 10 07:59:58.333: INFO: (19) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:460/proxy/: tls baz (200; 6.189422ms)
    Jul 10 07:59:58.334: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:160/proxy/: foo (200; 6.489166ms)
    Jul 10 07:59:58.334: INFO: (19) /api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/https:proxy-service-l4bzw-58w7z:443/proxy/tlsrewritem... (200; 6.970973ms)
    Jul 10 07:59:58.335: INFO: (19) /api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/http:proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">... (200; 7.666502ms)
    Jul 10 07:59:58.335: INFO: (19) /api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/: <a href="/api/v1/namespaces/proxy-6559/pods/proxy-service-l4bzw-58w7z:1080/proxy/rewriteme">test<... (200; 7.779512ms)
    Jul 10 07:59:58.336: INFO: (19) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname2/proxy/: bar (200; 8.955209ms)
    Jul 10 07:59:58.336: INFO: (19) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname1/proxy/: tls baz (200; 8.400869ms)
    Jul 10 07:59:58.336: INFO: (19) /api/v1/namespaces/proxy-6559/services/http:proxy-service-l4bzw:portname1/proxy/: foo (200; 9.103353ms)
    Jul 10 07:59:58.337: INFO: (19) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname2/proxy/: bar (200; 9.146298ms)
    Jul 10 07:59:58.337: INFO: (19) /api/v1/namespaces/proxy-6559/services/https:proxy-service-l4bzw:tlsportname2/proxy/: tls qux (200; 10.446457ms)
    Jul 10 07:59:58.338: INFO: (19) /api/v1/namespaces/proxy-6559/services/proxy-service-l4bzw:portname1/proxy/: foo (200; 10.191321ms)
    STEP: deleting ReplicationController proxy-service-l4bzw in namespace proxy-6559, will wait for the garbage collector to delete the pods 07/10/23 07:59:58.338
    Jul 10 07:59:58.408: INFO: Deleting ReplicationController proxy-service-l4bzw took: 15.540504ms
    Jul 10 07:59:58.609: INFO: Terminating ReplicationController proxy-service-l4bzw pods took: 201.177219ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jul 10 08:00:01.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-6559" for this suite. 07/10/23 08:00:01.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:00:01.537
Jul 10 08:00:01.537: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:00:01.539
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:01.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:01.588
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 07/10/23 08:00:01.593
Jul 10 08:00:01.593: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Jul 10 08:00:01.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
Jul 10 08:00:02.640: INFO: stderr: ""
Jul 10 08:00:02.640: INFO: stdout: "service/agnhost-replica created\n"
Jul 10 08:00:02.640: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Jul 10 08:00:02.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
Jul 10 08:00:02.961: INFO: stderr: ""
Jul 10 08:00:02.961: INFO: stdout: "service/agnhost-primary created\n"
Jul 10 08:00:02.961: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul 10 08:00:02.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
Jul 10 08:00:03.215: INFO: stderr: ""
Jul 10 08:00:03.215: INFO: stdout: "service/frontend created\n"
Jul 10 08:00:03.216: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Jul 10 08:00:03.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
Jul 10 08:00:04.319: INFO: stderr: ""
Jul 10 08:00:04.319: INFO: stdout: "deployment.apps/frontend created\n"
Jul 10 08:00:04.319: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 10 08:00:04.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
Jul 10 08:00:05.464: INFO: stderr: ""
Jul 10 08:00:05.464: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Jul 10 08:00:05.465: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 10 08:00:05.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
Jul 10 08:00:05.785: INFO: stderr: ""
Jul 10 08:00:05.785: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 07/10/23 08:00:05.785
Jul 10 08:00:05.785: INFO: Waiting for all frontend pods to be Running.
Jul 10 08:00:10.836: INFO: Waiting for frontend to serve content.
Jul 10 08:00:10.851: INFO: Trying to add a new entry to the guestbook.
Jul 10 08:00:10.866: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 07/10/23 08:00:10.88
Jul 10 08:00:10.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
Jul 10 08:00:10.988: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:10.988: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 07/10/23 08:00:10.988
Jul 10 08:00:10.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
Jul 10 08:00:11.093: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:11.093: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 07/10/23 08:00:11.093
Jul 10 08:00:11.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
Jul 10 08:00:11.217: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:11.217: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 07/10/23 08:00:11.218
Jul 10 08:00:11.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
Jul 10 08:00:11.294: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:11.294: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 07/10/23 08:00:11.294
Jul 10 08:00:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
Jul 10 08:00:11.372: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:11.372: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 07/10/23 08:00:11.372
Jul 10 08:00:11.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
Jul 10 08:00:11.520: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:11.520: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:00:11.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6275" for this suite. 07/10/23 08:00:11.533
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":13,"skipped":288,"failed":0}
------------------------------
• [SLOW TEST] [10.018 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:00:01.537
    Jul 10 08:00:01.537: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:00:01.539
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:01.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:01.588
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 07/10/23 08:00:01.593
    Jul 10 08:00:01.593: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Jul 10 08:00:01.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
    Jul 10 08:00:02.640: INFO: stderr: ""
    Jul 10 08:00:02.640: INFO: stdout: "service/agnhost-replica created\n"
    Jul 10 08:00:02.640: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Jul 10 08:00:02.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
    Jul 10 08:00:02.961: INFO: stderr: ""
    Jul 10 08:00:02.961: INFO: stdout: "service/agnhost-primary created\n"
    Jul 10 08:00:02.961: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Jul 10 08:00:02.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
    Jul 10 08:00:03.215: INFO: stderr: ""
    Jul 10 08:00:03.215: INFO: stdout: "service/frontend created\n"
    Jul 10 08:00:03.216: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Jul 10 08:00:03.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
    Jul 10 08:00:04.319: INFO: stderr: ""
    Jul 10 08:00:04.319: INFO: stdout: "deployment.apps/frontend created\n"
    Jul 10 08:00:04.319: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Jul 10 08:00:04.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
    Jul 10 08:00:05.464: INFO: stderr: ""
    Jul 10 08:00:05.464: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Jul 10 08:00:05.465: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Jul 10 08:00:05.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 create -f -'
    Jul 10 08:00:05.785: INFO: stderr: ""
    Jul 10 08:00:05.785: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 07/10/23 08:00:05.785
    Jul 10 08:00:05.785: INFO: Waiting for all frontend pods to be Running.
    Jul 10 08:00:10.836: INFO: Waiting for frontend to serve content.
    Jul 10 08:00:10.851: INFO: Trying to add a new entry to the guestbook.
    Jul 10 08:00:10.866: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 07/10/23 08:00:10.88
    Jul 10 08:00:10.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
    Jul 10 08:00:10.988: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:10.988: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 07/10/23 08:00:10.988
    Jul 10 08:00:10.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
    Jul 10 08:00:11.093: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:11.093: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 07/10/23 08:00:11.093
    Jul 10 08:00:11.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
    Jul 10 08:00:11.217: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:11.217: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 07/10/23 08:00:11.218
    Jul 10 08:00:11.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
    Jul 10 08:00:11.294: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:11.294: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 07/10/23 08:00:11.294
    Jul 10 08:00:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
    Jul 10 08:00:11.372: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:11.372: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 07/10/23 08:00:11.372
    Jul 10 08:00:11.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6275 delete --grace-period=0 --force -f -'
    Jul 10 08:00:11.520: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:11.520: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:00:11.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6275" for this suite. 07/10/23 08:00:11.533
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:00:11.555
Jul 10 08:00:11.555: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:00:11.557
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:11.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:11.634
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-8733bec1-2c5c-4d8f-a00f-c802bc69e6c4 07/10/23 08:00:11.648
STEP: Creating a pod to test consume secrets 07/10/23 08:00:11.663
Jul 10 08:00:11.682: INFO: Waiting up to 5m0s for pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b" in namespace "secrets-3837" to be "Succeeded or Failed"
Jul 10 08:00:11.711: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.787836ms
Jul 10 08:00:13.723: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040369866s
Jul 10 08:00:15.719: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036548481s
Jul 10 08:00:17.718: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035871146s
STEP: Saw pod success 07/10/23 08:00:17.718
Jul 10 08:00:17.718: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b" satisfied condition "Succeeded or Failed"
Jul 10 08:00:17.723: INFO: Trying to get logs from node 10-62-109-102.test pod pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:00:17.755
Jul 10 08:00:17.784: INFO: Waiting for pod pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b to disappear
Jul 10 08:00:17.788: INFO: Pod pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:00:17.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3837" for this suite. 07/10/23 08:00:17.792
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":14,"skipped":289,"failed":0}
------------------------------
• [SLOW TEST] [6.253 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:00:11.555
    Jul 10 08:00:11.555: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:00:11.557
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:11.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:11.634
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-8733bec1-2c5c-4d8f-a00f-c802bc69e6c4 07/10/23 08:00:11.648
    STEP: Creating a pod to test consume secrets 07/10/23 08:00:11.663
    Jul 10 08:00:11.682: INFO: Waiting up to 5m0s for pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b" in namespace "secrets-3837" to be "Succeeded or Failed"
    Jul 10 08:00:11.711: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.787836ms
    Jul 10 08:00:13.723: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040369866s
    Jul 10 08:00:15.719: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036548481s
    Jul 10 08:00:17.718: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035871146s
    STEP: Saw pod success 07/10/23 08:00:17.718
    Jul 10 08:00:17.718: INFO: Pod "pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b" satisfied condition "Succeeded or Failed"
    Jul 10 08:00:17.723: INFO: Trying to get logs from node 10-62-109-102.test pod pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:00:17.755
    Jul 10 08:00:17.784: INFO: Waiting for pod pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b to disappear
    Jul 10 08:00:17.788: INFO: Pod pod-secrets-6ee31bfd-bfa9-466b-9713-fcd00f75888b no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:00:17.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3837" for this suite. 07/10/23 08:00:17.792
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:00:17.813
Jul 10 08:00:17.813: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:00:17.814
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:17.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:17.854
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 07/10/23 08:00:17.857
Jul 10 08:00:17.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 create -f -'
Jul 10 08:00:18.094: INFO: stderr: ""
Jul 10 08:00:18.094: INFO: stdout: "pod/pause created\n"
Jul 10 08:00:18.094: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul 10 08:00:18.094: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5810" to be "running and ready"
Jul 10 08:00:18.099: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.885342ms
Jul 10 08:00:18.099: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '' to be 'Running' but was 'Pending'
Jul 10 08:00:20.104: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009531181s
Jul 10 08:00:20.104: INFO: Pod "pause" satisfied condition "running and ready"
Jul 10 08:00:20.104: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 07/10/23 08:00:20.104
Jul 10 08:00:20.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 label pods pause testing-label=testing-label-value'
Jul 10 08:00:20.191: INFO: stderr: ""
Jul 10 08:00:20.191: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 07/10/23 08:00:20.191
Jul 10 08:00:20.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get pod pause -L testing-label'
Jul 10 08:00:20.270: INFO: stderr: ""
Jul 10 08:00:20.270: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 07/10/23 08:00:20.27
Jul 10 08:00:20.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 label pods pause testing-label-'
Jul 10 08:00:20.363: INFO: stderr: ""
Jul 10 08:00:20.363: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 07/10/23 08:00:20.363
Jul 10 08:00:20.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get pod pause -L testing-label'
Jul 10 08:00:20.436: INFO: stderr: ""
Jul 10 08:00:20.436: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 07/10/23 08:00:20.436
Jul 10 08:00:20.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 delete --grace-period=0 --force -f -'
Jul 10 08:00:20.536: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:00:20.536: INFO: stdout: "pod \"pause\" force deleted\n"
Jul 10 08:00:20.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get rc,svc -l name=pause --no-headers'
Jul 10 08:00:20.614: INFO: stderr: "No resources found in kubectl-5810 namespace.\n"
Jul 10 08:00:20.614: INFO: stdout: ""
Jul 10 08:00:20.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 10 08:00:20.677: INFO: stderr: ""
Jul 10 08:00:20.677: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:00:20.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5810" for this suite. 07/10/23 08:00:20.683
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":15,"skipped":341,"failed":0}
------------------------------
• [2.882 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:00:17.813
    Jul 10 08:00:17.813: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:00:17.814
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:17.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:17.854
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 07/10/23 08:00:17.857
    Jul 10 08:00:17.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 create -f -'
    Jul 10 08:00:18.094: INFO: stderr: ""
    Jul 10 08:00:18.094: INFO: stdout: "pod/pause created\n"
    Jul 10 08:00:18.094: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Jul 10 08:00:18.094: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5810" to be "running and ready"
    Jul 10 08:00:18.099: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.885342ms
    Jul 10 08:00:18.099: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '' to be 'Running' but was 'Pending'
    Jul 10 08:00:20.104: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009531181s
    Jul 10 08:00:20.104: INFO: Pod "pause" satisfied condition "running and ready"
    Jul 10 08:00:20.104: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 07/10/23 08:00:20.104
    Jul 10 08:00:20.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 label pods pause testing-label=testing-label-value'
    Jul 10 08:00:20.191: INFO: stderr: ""
    Jul 10 08:00:20.191: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 07/10/23 08:00:20.191
    Jul 10 08:00:20.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get pod pause -L testing-label'
    Jul 10 08:00:20.270: INFO: stderr: ""
    Jul 10 08:00:20.270: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 07/10/23 08:00:20.27
    Jul 10 08:00:20.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 label pods pause testing-label-'
    Jul 10 08:00:20.363: INFO: stderr: ""
    Jul 10 08:00:20.363: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 07/10/23 08:00:20.363
    Jul 10 08:00:20.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get pod pause -L testing-label'
    Jul 10 08:00:20.436: INFO: stderr: ""
    Jul 10 08:00:20.436: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 07/10/23 08:00:20.436
    Jul 10 08:00:20.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 delete --grace-period=0 --force -f -'
    Jul 10 08:00:20.536: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:00:20.536: INFO: stdout: "pod \"pause\" force deleted\n"
    Jul 10 08:00:20.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get rc,svc -l name=pause --no-headers'
    Jul 10 08:00:20.614: INFO: stderr: "No resources found in kubectl-5810 namespace.\n"
    Jul 10 08:00:20.614: INFO: stdout: ""
    Jul 10 08:00:20.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5810 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jul 10 08:00:20.677: INFO: stderr: ""
    Jul 10 08:00:20.677: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:00:20.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5810" for this suite. 07/10/23 08:00:20.683
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:00:20.696
Jul 10 08:00:20.696: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:00:20.697
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:20.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:20.776
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-97dd320f-b603-44b3-82d5-c1233f450b1b 07/10/23 08:00:20.784
STEP: Creating secret with name s-test-opt-upd-e8c187ca-f48b-4787-aa9e-3e8e25f3394f 07/10/23 08:00:20.8
STEP: Creating the pod 07/10/23 08:00:20.807
Jul 10 08:00:20.827: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865" in namespace "projected-1528" to be "running and ready"
Jul 10 08:00:20.841: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865": Phase="Pending", Reason="", readiness=false. Elapsed: 13.404076ms
Jul 10 08:00:20.841: INFO: The phase of Pod pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:00:22.847: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019698105s
Jul 10 08:00:22.847: INFO: The phase of Pod pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:00:24.847: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865": Phase="Running", Reason="", readiness=true. Elapsed: 4.019357486s
Jul 10 08:00:24.847: INFO: The phase of Pod pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865 is Running (Ready = true)
Jul 10 08:00:24.847: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-97dd320f-b603-44b3-82d5-c1233f450b1b 07/10/23 08:00:24.888
STEP: Updating secret s-test-opt-upd-e8c187ca-f48b-4787-aa9e-3e8e25f3394f 07/10/23 08:00:24.9
STEP: Creating secret with name s-test-opt-create-78f0bc9f-2316-4fea-80a7-6d689a139a5d 07/10/23 08:00:24.911
STEP: waiting to observe update in volume 07/10/23 08:00:24.92
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 08:01:49.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1528" for this suite. 07/10/23 08:01:49.537
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":16,"skipped":354,"failed":0}
------------------------------
• [SLOW TEST] [88.851 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:00:20.696
    Jul 10 08:00:20.696: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:00:20.697
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:00:20.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:00:20.776
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-97dd320f-b603-44b3-82d5-c1233f450b1b 07/10/23 08:00:20.784
    STEP: Creating secret with name s-test-opt-upd-e8c187ca-f48b-4787-aa9e-3e8e25f3394f 07/10/23 08:00:20.8
    STEP: Creating the pod 07/10/23 08:00:20.807
    Jul 10 08:00:20.827: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865" in namespace "projected-1528" to be "running and ready"
    Jul 10 08:00:20.841: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865": Phase="Pending", Reason="", readiness=false. Elapsed: 13.404076ms
    Jul 10 08:00:20.841: INFO: The phase of Pod pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:00:22.847: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019698105s
    Jul 10 08:00:22.847: INFO: The phase of Pod pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:00:24.847: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865": Phase="Running", Reason="", readiness=true. Elapsed: 4.019357486s
    Jul 10 08:00:24.847: INFO: The phase of Pod pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865 is Running (Ready = true)
    Jul 10 08:00:24.847: INFO: Pod "pod-projected-secrets-3bc10561-0ebe-41ca-92b0-a95ad5f11865" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-97dd320f-b603-44b3-82d5-c1233f450b1b 07/10/23 08:00:24.888
    STEP: Updating secret s-test-opt-upd-e8c187ca-f48b-4787-aa9e-3e8e25f3394f 07/10/23 08:00:24.9
    STEP: Creating secret with name s-test-opt-create-78f0bc9f-2316-4fea-80a7-6d689a139a5d 07/10/23 08:00:24.911
    STEP: waiting to observe update in volume 07/10/23 08:00:24.92
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 08:01:49.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1528" for this suite. 07/10/23 08:01:49.537
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:01:49.551
Jul 10 08:01:49.551: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename containers 07/10/23 08:01:49.552
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:49.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:49.585
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Jul 10 08:01:49.601: INFO: Waiting up to 5m0s for pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad" in namespace "containers-5585" to be "running"
Jul 10 08:01:49.604: INFO: Pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad": Phase="Pending", Reason="", readiness=false. Elapsed: 3.611046ms
Jul 10 08:01:51.613: INFO: Pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad": Phase="Running", Reason="", readiness=true. Elapsed: 2.012733819s
Jul 10 08:01:51.613: INFO: Pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jul 10 08:01:51.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5585" for this suite. 07/10/23 08:01:51.636
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":17,"skipped":415,"failed":0}
------------------------------
• [2.100 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:01:49.551
    Jul 10 08:01:49.551: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename containers 07/10/23 08:01:49.552
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:49.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:49.585
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Jul 10 08:01:49.601: INFO: Waiting up to 5m0s for pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad" in namespace "containers-5585" to be "running"
    Jul 10 08:01:49.604: INFO: Pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad": Phase="Pending", Reason="", readiness=false. Elapsed: 3.611046ms
    Jul 10 08:01:51.613: INFO: Pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad": Phase="Running", Reason="", readiness=true. Elapsed: 2.012733819s
    Jul 10 08:01:51.613: INFO: Pod "client-containers-6e91e82f-a513-4bd1-b484-49de4013a9ad" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jul 10 08:01:51.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-5585" for this suite. 07/10/23 08:01:51.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:01:51.651
Jul 10 08:01:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 08:01:51.653
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:51.682
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:51.686
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 07/10/23 08:01:51.725
STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 08:01:51.737
Jul 10 08:01:51.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 08:01:51.751: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 08:01:52.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 08:01:52.784: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 08:01:53.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul 10 08:01:53.764: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 08:01:54.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 08:01:54.763: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 07/10/23 08:01:54.767
STEP: DeleteCollection of the DaemonSets 07/10/23 08:01:54.771
STEP: Verify that ReplicaSets have been deleted 07/10/23 08:01:54.781
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Jul 10 08:01:54.801: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"70168"},"items":null}

Jul 10 08:01:54.820: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"70169"},"items":[{"metadata":{"name":"daemon-set-gvgxv","generateName":"daemon-set-","namespace":"daemonsets-6347","uid":"cd4795ab-7845-4732-b4ba-f37a800cbcad","resourceVersion":"70153","creationTimestamp":"2023-07-10T08:01:51Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"fc4b47ad19d068af26efcf8bca003adc33b05fac602c2990b8a177a2fd24c7cb","cni.projectcalico.org/podIP":"192.168.172.24/32","cni.projectcalico.org/podIPs":"192.168.172.24/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b25fad17-8877-4c89-8c88-db8f9bbb9e90","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b25fad17-8877-4c89-8c88-db8f9bbb9e90\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kgdkb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kgdkb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10-62-109-100.test","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10-62-109-100.test"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"}],"hostIP":"10.62.109.100","podIP":"192.168.172.24","podIPs":[{"ip":"192.168.172.24"}],"startTime":"2023-07-10T08:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-07-10T08:01:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://1fdf1d7f751687a6e86ce26c963c47790fcbc72baa0c9bc2e1c94a3012a79e76","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-kd8wz","generateName":"daemon-set-","namespace":"daemonsets-6347","uid":"bb6babca-c315-4575-8a7d-da40883db96e","resourceVersion":"70151","creationTimestamp":"2023-07-10T08:01:51Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"6667310fb5e0168e2592efc060f8611d55b5d5bffa439581e430796acf9dc5f7","cni.projectcalico.org/podIP":"192.168.103.73/32","cni.projectcalico.org/podIPs":"192.168.103.73/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b25fad17-8877-4c89-8c88-db8f9bbb9e90","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b25fad17-8877-4c89-8c88-db8f9bbb9e90\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.73\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-9s4jf","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-9s4jf","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10-62-109-101.test","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10-62-109-101.test"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"}],"hostIP":"10.62.109.101","podIP":"192.168.103.73","podIPs":[{"ip":"192.168.103.73"}],"startTime":"2023-07-10T08:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-07-10T08:01:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://ca820e31ca6caf17c4c69ec1009d206f590204595d37fbde152a3dce738f82ab","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-m7g8j","generateName":"daemon-set-","namespace":"daemonsets-6347","uid":"8fd763b3-2b34-4c54-8ca6-dc3154c3ebf8","resourceVersion":"70169","creationTimestamp":"2023-07-10T08:01:51Z","deletionTimestamp":"2023-07-10T08:02:24Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"1371866cc8b22e48b2c2a049d86151583429061337a87b8489a19acbd0597a69","cni.projectcalico.org/podIP":"192.168.120.21/32","cni.projectcalico.org/podIPs":"192.168.120.21/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b25fad17-8877-4c89-8c88-db8f9bbb9e90","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b25fad17-8877-4c89-8c88-db8f9bbb9e90\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6rgtv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6rgtv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10-62-109-102.test","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10-62-109-102.test"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"}],"hostIP":"10.62.109.102","podIP":"192.168.120.21","podIPs":[{"ip":"192.168.120.21"}],"startTime":"2023-07-10T08:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-07-10T08:01:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://3a15e5f5fe9f0a1a92b298034b25860be269556f6206d5b8d4df02df8456f8a6","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:01:54.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6347" for this suite. 07/10/23 08:01:54.841
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":18,"skipped":435,"failed":0}
------------------------------
• [3.204 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:01:51.651
    Jul 10 08:01:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 08:01:51.653
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:51.682
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:51.686
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 07/10/23 08:01:51.725
    STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 08:01:51.737
    Jul 10 08:01:51.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 08:01:51.751: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 08:01:52.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 08:01:52.784: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 08:01:53.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jul 10 08:01:53.764: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 08:01:54.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 08:01:54.763: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 07/10/23 08:01:54.767
    STEP: DeleteCollection of the DaemonSets 07/10/23 08:01:54.771
    STEP: Verify that ReplicaSets have been deleted 07/10/23 08:01:54.781
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Jul 10 08:01:54.801: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"70168"},"items":null}

    Jul 10 08:01:54.820: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"70169"},"items":[{"metadata":{"name":"daemon-set-gvgxv","generateName":"daemon-set-","namespace":"daemonsets-6347","uid":"cd4795ab-7845-4732-b4ba-f37a800cbcad","resourceVersion":"70153","creationTimestamp":"2023-07-10T08:01:51Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"fc4b47ad19d068af26efcf8bca003adc33b05fac602c2990b8a177a2fd24c7cb","cni.projectcalico.org/podIP":"192.168.172.24/32","cni.projectcalico.org/podIPs":"192.168.172.24/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b25fad17-8877-4c89-8c88-db8f9bbb9e90","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b25fad17-8877-4c89-8c88-db8f9bbb9e90\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kgdkb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kgdkb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10-62-109-100.test","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10-62-109-100.test"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"}],"hostIP":"10.62.109.100","podIP":"192.168.172.24","podIPs":[{"ip":"192.168.172.24"}],"startTime":"2023-07-10T08:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-07-10T08:01:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://1fdf1d7f751687a6e86ce26c963c47790fcbc72baa0c9bc2e1c94a3012a79e76","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-kd8wz","generateName":"daemon-set-","namespace":"daemonsets-6347","uid":"bb6babca-c315-4575-8a7d-da40883db96e","resourceVersion":"70151","creationTimestamp":"2023-07-10T08:01:51Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"6667310fb5e0168e2592efc060f8611d55b5d5bffa439581e430796acf9dc5f7","cni.projectcalico.org/podIP":"192.168.103.73/32","cni.projectcalico.org/podIPs":"192.168.103.73/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b25fad17-8877-4c89-8c88-db8f9bbb9e90","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b25fad17-8877-4c89-8c88-db8f9bbb9e90\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.73\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-9s4jf","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-9s4jf","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10-62-109-101.test","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10-62-109-101.test"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"}],"hostIP":"10.62.109.101","podIP":"192.168.103.73","podIPs":[{"ip":"192.168.103.73"}],"startTime":"2023-07-10T08:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-07-10T08:01:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://ca820e31ca6caf17c4c69ec1009d206f590204595d37fbde152a3dce738f82ab","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-m7g8j","generateName":"daemon-set-","namespace":"daemonsets-6347","uid":"8fd763b3-2b34-4c54-8ca6-dc3154c3ebf8","resourceVersion":"70169","creationTimestamp":"2023-07-10T08:01:51Z","deletionTimestamp":"2023-07-10T08:02:24Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"1371866cc8b22e48b2c2a049d86151583429061337a87b8489a19acbd0597a69","cni.projectcalico.org/podIP":"192.168.120.21/32","cni.projectcalico.org/podIPs":"192.168.120.21/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b25fad17-8877-4c89-8c88-db8f9bbb9e90","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b25fad17-8877-4c89-8c88-db8f9bbb9e90\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-07-10T08:01:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6rgtv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6rgtv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10-62-109-102.test","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10-62-109-102.test"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-07-10T08:01:51Z"}],"hostIP":"10.62.109.102","podIP":"192.168.120.21","podIPs":[{"ip":"192.168.120.21"}],"startTime":"2023-07-10T08:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-07-10T08:01:53Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://3a15e5f5fe9f0a1a92b298034b25860be269556f6206d5b8d4df02df8456f8a6","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:01:54.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6347" for this suite. 07/10/23 08:01:54.841
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:01:54.856
Jul 10 08:01:54.857: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:01:54.858
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:54.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:54.892
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-20cc89c8-c825-4d18-9952-6803c98dd5a9 07/10/23 08:01:54.895
STEP: Creating a pod to test consume configMaps 07/10/23 08:01:54.905
Jul 10 08:01:54.918: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa" in namespace "projected-8414" to be "Succeeded or Failed"
Jul 10 08:01:54.933: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa": Phase="Pending", Reason="", readiness=false. Elapsed: 15.26642ms
Jul 10 08:01:56.944: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025635488s
Jul 10 08:01:58.939: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021193594s
STEP: Saw pod success 07/10/23 08:01:58.939
Jul 10 08:01:58.939: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa" satisfied condition "Succeeded or Failed"
Jul 10 08:01:58.944: INFO: Trying to get logs from node 10-62-109-101.test pod pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa container projected-configmap-volume-test: <nil>
STEP: delete the pod 07/10/23 08:01:58.956
Jul 10 08:01:58.975: INFO: Waiting for pod pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa to disappear
Jul 10 08:01:58.982: INFO: Pod pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:01:58.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8414" for this suite. 07/10/23 08:01:58.987
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":19,"skipped":440,"failed":0}
------------------------------
• [4.147 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:01:54.856
    Jul 10 08:01:54.857: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:01:54.858
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:54.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:54.892
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-20cc89c8-c825-4d18-9952-6803c98dd5a9 07/10/23 08:01:54.895
    STEP: Creating a pod to test consume configMaps 07/10/23 08:01:54.905
    Jul 10 08:01:54.918: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa" in namespace "projected-8414" to be "Succeeded or Failed"
    Jul 10 08:01:54.933: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa": Phase="Pending", Reason="", readiness=false. Elapsed: 15.26642ms
    Jul 10 08:01:56.944: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025635488s
    Jul 10 08:01:58.939: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021193594s
    STEP: Saw pod success 07/10/23 08:01:58.939
    Jul 10 08:01:58.939: INFO: Pod "pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa" satisfied condition "Succeeded or Failed"
    Jul 10 08:01:58.944: INFO: Trying to get logs from node 10-62-109-101.test pod pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa container projected-configmap-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:01:58.956
    Jul 10 08:01:58.975: INFO: Waiting for pod pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa to disappear
    Jul 10 08:01:58.982: INFO: Pod pod-projected-configmaps-0d776e8e-2c5c-4c35-8c57-f6ca8a6160fa no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:01:58.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8414" for this suite. 07/10/23 08:01:58.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:01:59.009
Jul 10 08:01:59.009: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-pred 07/10/23 08:01:59.01
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:59.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:59.048
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul 10 08:01:59.051: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 10 08:01:59.060: INFO: Waiting for terminating namespaces to be deleted...
Jul 10 08:01:59.064: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-100.test before test
Jul 10 08:01:59.072: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.072: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 08:01:59.072: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.072: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:01:59.072: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
Jul 10 08:01:59.072: INFO: 	Container nfs-attacher ready: true, restart count 0
Jul 10 08:01:59.072: INFO: 	Container nfs-provisioner ready: true, restart count 0
Jul 10 08:01:59.072: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:01:59.072: INFO: 	Container snapshotter-controller ready: true, restart count 0
Jul 10 08:01:59.072: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.072: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:01:59.072: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:01:59.072: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.073: INFO: 	Container metrics-server ready: true, restart count 7
Jul 10 08:01:59.073: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.073: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 10 08:01:59.073: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.073: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:01:59.073: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 08:01:59.073: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-101.test before test
Jul 10 08:01:59.083: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.083: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 08:01:59.083: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.083: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:01:59.083: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.083: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 08:01:59.083: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.083: INFO: 	Container coredns ready: true, restart count 0
Jul 10 08:01:59.083: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.083: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:01:59.083: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:01:59.083: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:01:59.083: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 08:01:59.083: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-102.test before test
Jul 10 08:01:59.091: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.091: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:01:59.091: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.091: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 08:01:59.091: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:01:59.091: INFO: 	Container coredns ready: true, restart count 0
Jul 10 08:01:59.091: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.091: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:01:59.091: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:01:59.091: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.091: INFO: 	Container e2e ready: true, restart count 0
Jul 10 08:01:59.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:01:59.091: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:01:59.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:01:59.091: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 07/10/23 08:01:59.091
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.177072d4e945d05d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 07/10/23 08:01:59.16
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:02:00.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-955" for this suite. 07/10/23 08:02:00.158
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":20,"skipped":521,"failed":0}
------------------------------
• [1.160 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:01:59.009
    Jul 10 08:01:59.009: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-pred 07/10/23 08:01:59.01
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:01:59.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:01:59.048
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jul 10 08:01:59.051: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jul 10 08:01:59.060: INFO: Waiting for terminating namespaces to be deleted...
    Jul 10 08:01:59.064: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-100.test before test
    Jul 10 08:01:59.072: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.072: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 08:01:59.072: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.072: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
    Jul 10 08:01:59.072: INFO: 	Container nfs-attacher ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: 	Container nfs-provisioner ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: 	Container snapshotter-controller ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.072: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:01:59.072: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.073: INFO: 	Container metrics-server ready: true, restart count 7
    Jul 10 08:01:59.073: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.073: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jul 10 08:01:59.073: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.073: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:01:59.073: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 08:01:59.073: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-101.test before test
    Jul 10 08:01:59.083: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.083: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 08:01:59.083: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.083: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.083: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.083: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.083: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 08:01:59.083: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-102.test before test
    Jul 10 08:01:59.091: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.091: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.091: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:01:59.091: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.091: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.091: INFO: 	Container e2e ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:01:59.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:01:59.091: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 07/10/23 08:01:59.091
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.177072d4e945d05d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 07/10/23 08:01:59.16
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:02:00.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-955" for this suite. 07/10/23 08:02:00.158
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:00.171
Jul 10 08:02:00.171: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-runtime 07/10/23 08:02:00.172
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:00.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:00.205
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 07/10/23 08:02:00.223
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 07/10/23 08:02:15.32
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 07/10/23 08:02:15.328
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 07/10/23 08:02:15.337
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 07/10/23 08:02:15.337
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 07/10/23 08:02:15.564
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 07/10/23 08:02:18.583
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 07/10/23 08:02:20.6
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 07/10/23 08:02:20.608
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 07/10/23 08:02:20.608
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 07/10/23 08:02:20.644
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 07/10/23 08:02:21.654
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 07/10/23 08:02:24.676
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 07/10/23 08:02:24.686
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 07/10/23 08:02:24.687
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jul 10 08:02:24.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-233" for this suite. 07/10/23 08:02:24.742
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":21,"skipped":548,"failed":0}
------------------------------
• [SLOW TEST] [24.582 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:00.171
    Jul 10 08:02:00.171: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-runtime 07/10/23 08:02:00.172
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:00.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:00.205
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 07/10/23 08:02:00.223
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 07/10/23 08:02:15.32
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 07/10/23 08:02:15.328
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 07/10/23 08:02:15.337
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 07/10/23 08:02:15.337
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 07/10/23 08:02:15.564
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 07/10/23 08:02:18.583
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 07/10/23 08:02:20.6
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 07/10/23 08:02:20.608
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 07/10/23 08:02:20.608
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 07/10/23 08:02:20.644
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 07/10/23 08:02:21.654
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 07/10/23 08:02:24.676
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 07/10/23 08:02:24.686
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 07/10/23 08:02:24.687
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jul 10 08:02:24.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-233" for this suite. 07/10/23 08:02:24.742
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:24.754
Jul 10 08:02:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:02:24.755
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:24.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:24.792
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:02:24.813
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:02:25.903
STEP: Deploying the webhook pod 07/10/23 08:02:25.919
STEP: Wait for the deployment to be ready 07/10/23 08:02:26.256
Jul 10 08:02:26.286: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 25, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jul 10 08:02:28.292: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 08:02:30.292
STEP: Verifying the service has paired with the endpoint 07/10/23 08:02:30.312
Jul 10 08:02:31.312: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 07/10/23 08:02:31.318
STEP: Creating a custom resource definition that should be denied by the webhook 07/10/23 08:02:31.339
Jul 10 08:02:31.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:02:31.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2768" for this suite. 07/10/23 08:02:31.364
STEP: Destroying namespace "webhook-2768-markers" for this suite. 07/10/23 08:02:31.378
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":22,"skipped":553,"failed":0}
------------------------------
• [SLOW TEST] [6.726 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:24.754
    Jul 10 08:02:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:02:24.755
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:24.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:24.792
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:02:24.813
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:02:25.903
    STEP: Deploying the webhook pod 07/10/23 08:02:25.919
    STEP: Wait for the deployment to be ready 07/10/23 08:02:26.256
    Jul 10 08:02:26.286: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 25, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    Jul 10 08:02:28.292: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 2, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 2, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 08:02:30.292
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:02:30.312
    Jul 10 08:02:31.312: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 07/10/23 08:02:31.318
    STEP: Creating a custom resource definition that should be denied by the webhook 07/10/23 08:02:31.339
    Jul 10 08:02:31.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:02:31.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2768" for this suite. 07/10/23 08:02:31.364
    STEP: Destroying namespace "webhook-2768-markers" for this suite. 07/10/23 08:02:31.378
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:31.481
Jul 10 08:02:31.481: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename init-container 07/10/23 08:02:31.482
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:31.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:31.542
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 07/10/23 08:02:31.546
Jul 10 08:02:31.546: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 08:02:37.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8902" for this suite. 07/10/23 08:02:37.703
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":23,"skipped":566,"failed":0}
------------------------------
• [SLOW TEST] [6.234 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:31.481
    Jul 10 08:02:31.481: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename init-container 07/10/23 08:02:31.482
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:31.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:31.542
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 07/10/23 08:02:31.546
    Jul 10 08:02:31.546: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 08:02:37.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8902" for this suite. 07/10/23 08:02:37.703
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:37.715
Jul 10 08:02:37.715: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 08:02:37.716
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:37.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:37.749
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 07/10/23 08:02:37.76
STEP: watching for Pod to be ready 07/10/23 08:02:37.816
Jul 10 08:02:37.817: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions []
Jul 10 08:02:37.824: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
Jul 10 08:02:37.849: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
Jul 10 08:02:38.634: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
Jul 10 08:02:39.732: INFO: Found Pod pod-test in namespace pods-7994 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 07/10/23 08:02:39.737
STEP: getting the Pod and ensuring that it's patched 07/10/23 08:02:39.754
STEP: replacing the Pod's status Ready condition to False 07/10/23 08:02:39.759
STEP: check the Pod again to ensure its Ready conditions are False 07/10/23 08:02:39.781
STEP: deleting the Pod via a Collection with a LabelSelector 07/10/23 08:02:39.781
STEP: watching for the Pod to be deleted 07/10/23 08:02:39.806
Jul 10 08:02:39.809: INFO: observed event type MODIFIED
Jul 10 08:02:41.846: INFO: observed event type MODIFIED
Jul 10 08:02:41.889: INFO: observed event type MODIFIED
Jul 10 08:02:42.866: INFO: observed event type MODIFIED
Jul 10 08:02:42.885: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 08:02:42.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7994" for this suite. 07/10/23 08:02:42.914
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":24,"skipped":566,"failed":0}
------------------------------
• [SLOW TEST] [5.209 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:37.715
    Jul 10 08:02:37.715: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 08:02:37.716
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:37.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:37.749
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 07/10/23 08:02:37.76
    STEP: watching for Pod to be ready 07/10/23 08:02:37.816
    Jul 10 08:02:37.817: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Jul 10 08:02:37.824: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
    Jul 10 08:02:37.849: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
    Jul 10 08:02:38.634: INFO: observed Pod pod-test in namespace pods-7994 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
    Jul 10 08:02:39.732: INFO: Found Pod pod-test in namespace pods-7994 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:02:37 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 07/10/23 08:02:39.737
    STEP: getting the Pod and ensuring that it's patched 07/10/23 08:02:39.754
    STEP: replacing the Pod's status Ready condition to False 07/10/23 08:02:39.759
    STEP: check the Pod again to ensure its Ready conditions are False 07/10/23 08:02:39.781
    STEP: deleting the Pod via a Collection with a LabelSelector 07/10/23 08:02:39.781
    STEP: watching for the Pod to be deleted 07/10/23 08:02:39.806
    Jul 10 08:02:39.809: INFO: observed event type MODIFIED
    Jul 10 08:02:41.846: INFO: observed event type MODIFIED
    Jul 10 08:02:41.889: INFO: observed event type MODIFIED
    Jul 10 08:02:42.866: INFO: observed event type MODIFIED
    Jul 10 08:02:42.885: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 08:02:42.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7994" for this suite. 07/10/23 08:02:42.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:42.925
Jul 10 08:02:42.925: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename containers 07/10/23 08:02:42.926
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:42.95
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:42.954
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 07/10/23 08:02:42.957
Jul 10 08:02:42.987: INFO: Waiting up to 5m0s for pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948" in namespace "containers-1216" to be "Succeeded or Failed"
Jul 10 08:02:42.995: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948": Phase="Pending", Reason="", readiness=false. Elapsed: 8.141659ms
Jul 10 08:02:45.000: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013678198s
Jul 10 08:02:47.005: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017916061s
STEP: Saw pod success 07/10/23 08:02:47.005
Jul 10 08:02:47.005: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948" satisfied condition "Succeeded or Failed"
Jul 10 08:02:47.009: INFO: Trying to get logs from node 10-62-109-100.test pod client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:02:47.02
Jul 10 08:02:47.040: INFO: Waiting for pod client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948 to disappear
Jul 10 08:02:47.046: INFO: Pod client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jul 10 08:02:47.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1216" for this suite. 07/10/23 08:02:47.051
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":25,"skipped":581,"failed":0}
------------------------------
• [4.148 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:42.925
    Jul 10 08:02:42.925: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename containers 07/10/23 08:02:42.926
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:42.95
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:42.954
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 07/10/23 08:02:42.957
    Jul 10 08:02:42.987: INFO: Waiting up to 5m0s for pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948" in namespace "containers-1216" to be "Succeeded or Failed"
    Jul 10 08:02:42.995: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948": Phase="Pending", Reason="", readiness=false. Elapsed: 8.141659ms
    Jul 10 08:02:45.000: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013678198s
    Jul 10 08:02:47.005: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017916061s
    STEP: Saw pod success 07/10/23 08:02:47.005
    Jul 10 08:02:47.005: INFO: Pod "client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948" satisfied condition "Succeeded or Failed"
    Jul 10 08:02:47.009: INFO: Trying to get logs from node 10-62-109-100.test pod client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:02:47.02
    Jul 10 08:02:47.040: INFO: Waiting for pod client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948 to disappear
    Jul 10 08:02:47.046: INFO: Pod client-containers-eb079a8d-bfdc-44ce-a890-dad8f86e6948 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jul 10 08:02:47.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1216" for this suite. 07/10/23 08:02:47.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:47.073
Jul 10 08:02:47.073: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replication-controller 07/10/23 08:02:47.074
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:47.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:47.103
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 07/10/23 08:02:47.106
Jul 10 08:02:47.117: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-9131" to be "running and ready"
Jul 10 08:02:47.121: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 3.700456ms
Jul 10 08:02:47.121: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:02:49.127: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.010300914s
Jul 10 08:02:49.127: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Jul 10 08:02:49.127: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 07/10/23 08:02:49.132
STEP: Then the orphan pod is adopted 07/10/23 08:02:49.144
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jul 10 08:02:50.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9131" for this suite. 07/10/23 08:02:50.159
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":26,"skipped":586,"failed":0}
------------------------------
• [3.095 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:47.073
    Jul 10 08:02:47.073: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replication-controller 07/10/23 08:02:47.074
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:47.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:47.103
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 07/10/23 08:02:47.106
    Jul 10 08:02:47.117: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-9131" to be "running and ready"
    Jul 10 08:02:47.121: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 3.700456ms
    Jul 10 08:02:47.121: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:02:49.127: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.010300914s
    Jul 10 08:02:49.127: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Jul 10 08:02:49.127: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 07/10/23 08:02:49.132
    STEP: Then the orphan pod is adopted 07/10/23 08:02:49.144
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jul 10 08:02:50.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9131" for this suite. 07/10/23 08:02:50.159
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:02:50.17
Jul 10 08:02:50.170: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 08:02:50.171
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:50.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:50.209
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8679 07/10/23 08:02:50.212
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Jul 10 08:02:50.249: INFO: Found 0 stateful pods, waiting for 1
Jul 10 08:03:00.256: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 07/10/23 08:03:00.266
W0710 08:03:00.278696      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jul 10 08:03:00.290: INFO: Found 1 stateful pods, waiting for 2
Jul 10 08:03:10.297: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:03:10.297: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 07/10/23 08:03:10.305
STEP: Delete all of the StatefulSets 07/10/23 08:03:10.308
STEP: Verify that StatefulSets have been deleted 07/10/23 08:03:10.321
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 08:03:10.327: INFO: Deleting all statefulset in ns statefulset-8679
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 08:03:10.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8679" for this suite. 07/10/23 08:03:10.352
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":27,"skipped":611,"failed":0}
------------------------------
• [SLOW TEST] [20.209 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:02:50.17
    Jul 10 08:02:50.170: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 08:02:50.171
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:02:50.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:02:50.209
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8679 07/10/23 08:02:50.212
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Jul 10 08:02:50.249: INFO: Found 0 stateful pods, waiting for 1
    Jul 10 08:03:00.256: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 07/10/23 08:03:00.266
    W0710 08:03:00.278696      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jul 10 08:03:00.290: INFO: Found 1 stateful pods, waiting for 2
    Jul 10 08:03:10.297: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:03:10.297: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 07/10/23 08:03:10.305
    STEP: Delete all of the StatefulSets 07/10/23 08:03:10.308
    STEP: Verify that StatefulSets have been deleted 07/10/23 08:03:10.321
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 08:03:10.327: INFO: Deleting all statefulset in ns statefulset-8679
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 08:03:10.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8679" for this suite. 07/10/23 08:03:10.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:03:10.38
Jul 10 08:03:10.380: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:03:10.381
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:10.448
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:10.452
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:03:10.455
Jul 10 08:03:10.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5" in namespace "projected-9347" to be "Succeeded or Failed"
Jul 10 08:03:10.472: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.600212ms
Jul 10 08:03:12.478: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010724946s
Jul 10 08:03:14.477: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00984448s
Jul 10 08:03:16.477: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009960908s
STEP: Saw pod success 07/10/23 08:03:16.477
Jul 10 08:03:16.478: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5" satisfied condition "Succeeded or Failed"
Jul 10 08:03:16.482: INFO: Trying to get logs from node 10-62-109-102.test pod downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5 container client-container: <nil>
STEP: delete the pod 07/10/23 08:03:16.496
Jul 10 08:03:16.518: INFO: Waiting for pod downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5 to disappear
Jul 10 08:03:16.523: INFO: Pod downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:03:16.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9347" for this suite. 07/10/23 08:03:16.527
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":28,"skipped":629,"failed":0}
------------------------------
• [SLOW TEST] [6.157 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:03:10.38
    Jul 10 08:03:10.380: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:03:10.381
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:10.448
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:10.452
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:03:10.455
    Jul 10 08:03:10.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5" in namespace "projected-9347" to be "Succeeded or Failed"
    Jul 10 08:03:10.472: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.600212ms
    Jul 10 08:03:12.478: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010724946s
    Jul 10 08:03:14.477: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00984448s
    Jul 10 08:03:16.477: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009960908s
    STEP: Saw pod success 07/10/23 08:03:16.477
    Jul 10 08:03:16.478: INFO: Pod "downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5" satisfied condition "Succeeded or Failed"
    Jul 10 08:03:16.482: INFO: Trying to get logs from node 10-62-109-102.test pod downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5 container client-container: <nil>
    STEP: delete the pod 07/10/23 08:03:16.496
    Jul 10 08:03:16.518: INFO: Waiting for pod downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5 to disappear
    Jul 10 08:03:16.523: INFO: Pod downwardapi-volume-35cdc9d5-d548-40eb-8265-cad52705a1d5 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:03:16.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9347" for this suite. 07/10/23 08:03:16.527
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:03:16.537
Jul 10 08:03:16.537: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 08:03:16.538
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:16.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:16.57
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 07/10/23 08:03:16.573
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6381;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6381;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +notcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_udp@PTR;check="$$(dig +tcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_tcp@PTR;sleep 1; done
 07/10/23 08:03:16.619
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6381;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6381;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +notcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_udp@PTR;check="$$(dig +tcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_tcp@PTR;sleep 1; done
 07/10/23 08:03:16.619
STEP: creating a pod to probe DNS 07/10/23 08:03:16.619
STEP: submitting the pod to kubernetes 07/10/23 08:03:16.619
Jul 10 08:03:16.655: INFO: Waiting up to 15m0s for pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5" in namespace "dns-6381" to be "running"
Jul 10 08:03:16.661: INFO: Pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.974797ms
Jul 10 08:03:18.667: INFO: Pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.01180446s
Jul 10 08:03:18.667: INFO: Pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5" satisfied condition "running"
STEP: retrieving the pod 07/10/23 08:03:18.667
STEP: looking for the results for each expected name from probers 07/10/23 08:03:18.673
Jul 10 08:03:18.678: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.681: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.685: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.689: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.692: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.696: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.700: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.705: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.709: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.713: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.716: INFO: Unable to read 192.168.112.210_udp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.729: INFO: Unable to read 192.168.112.210_tcp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.734: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.758: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.764: INFO: Unable to read jessie_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.767: INFO: Unable to read jessie_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.773: INFO: Unable to read jessie_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.779: INFO: Unable to read jessie_tcp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.784: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.788: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.792: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.799: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.810: INFO: Unable to read 192.168.112.210_udp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.819: INFO: Unable to read 192.168.112.210_tcp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:18.819: INFO: Lookups using dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6381 wheezy_tcp@dns-test-service.dns-6381 wheezy_udp@dns-test-service.dns-6381.svc wheezy_tcp@dns-test-service.dns-6381.svc wheezy_udp@_http._tcp.dns-test-service.dns-6381.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6381.svc wheezy_udp@_http._tcp.test-service-2.dns-6381.svc wheezy_tcp@_http._tcp.test-service-2.dns-6381.svc 192.168.112.210_udp@PTR 192.168.112.210_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6381 jessie_tcp@dns-test-service.dns-6381 jessie_udp@dns-test-service.dns-6381.svc jessie_tcp@dns-test-service.dns-6381.svc jessie_udp@_http._tcp.dns-test-service.dns-6381.svc jessie_tcp@_http._tcp.dns-test-service.dns-6381.svc jessie_udp@_http._tcp.test-service-2.dns-6381.svc jessie_tcp@_http._tcp.test-service-2.dns-6381.svc 192.168.112.210_udp@PTR 192.168.112.210_tcp@PTR]

Jul 10 08:03:23.828: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.832: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.836: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.840: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.844: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.873: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.877: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.881: INFO: Unable to read jessie_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.885: INFO: Unable to read jessie_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.888: INFO: Unable to read jessie_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
Jul 10 08:03:23.918: INFO: Lookups using dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6381 wheezy_tcp@dns-test-service.dns-6381 wheezy_udp@dns-test-service.dns-6381.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6381 jessie_tcp@dns-test-service.dns-6381 jessie_udp@dns-test-service.dns-6381.svc]

Jul 10 08:03:28.929: INFO: DNS probes using dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5 succeeded

STEP: deleting the pod 07/10/23 08:03:28.929
STEP: deleting the test service 07/10/23 08:03:28.953
STEP: deleting the test headless service 07/10/23 08:03:29.037
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 08:03:29.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6381" for this suite. 07/10/23 08:03:29.073
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":29,"skipped":631,"failed":0}
------------------------------
• [SLOW TEST] [12.549 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:03:16.537
    Jul 10 08:03:16.537: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 08:03:16.538
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:16.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:16.57
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 07/10/23 08:03:16.573
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6381;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6381;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +notcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_udp@PTR;check="$$(dig +tcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_tcp@PTR;sleep 1; done
     07/10/23 08:03:16.619
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6381;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6381;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6381.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6381.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6381.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6381.svc;check="$$(dig +notcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_udp@PTR;check="$$(dig +tcp +noall +answer +search 210.112.168.192.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/192.168.112.210_tcp@PTR;sleep 1; done
     07/10/23 08:03:16.619
    STEP: creating a pod to probe DNS 07/10/23 08:03:16.619
    STEP: submitting the pod to kubernetes 07/10/23 08:03:16.619
    Jul 10 08:03:16.655: INFO: Waiting up to 15m0s for pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5" in namespace "dns-6381" to be "running"
    Jul 10 08:03:16.661: INFO: Pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.974797ms
    Jul 10 08:03:18.667: INFO: Pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.01180446s
    Jul 10 08:03:18.667: INFO: Pod "dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 08:03:18.667
    STEP: looking for the results for each expected name from probers 07/10/23 08:03:18.673
    Jul 10 08:03:18.678: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.681: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.685: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.689: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.692: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.696: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.700: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.705: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.709: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.713: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.716: INFO: Unable to read 192.168.112.210_udp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.729: INFO: Unable to read 192.168.112.210_tcp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.734: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.758: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.764: INFO: Unable to read jessie_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.767: INFO: Unable to read jessie_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.773: INFO: Unable to read jessie_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.779: INFO: Unable to read jessie_tcp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.784: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.788: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.792: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.799: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.810: INFO: Unable to read 192.168.112.210_udp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.819: INFO: Unable to read 192.168.112.210_tcp@PTR from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:18.819: INFO: Lookups using dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6381 wheezy_tcp@dns-test-service.dns-6381 wheezy_udp@dns-test-service.dns-6381.svc wheezy_tcp@dns-test-service.dns-6381.svc wheezy_udp@_http._tcp.dns-test-service.dns-6381.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6381.svc wheezy_udp@_http._tcp.test-service-2.dns-6381.svc wheezy_tcp@_http._tcp.test-service-2.dns-6381.svc 192.168.112.210_udp@PTR 192.168.112.210_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6381 jessie_tcp@dns-test-service.dns-6381 jessie_udp@dns-test-service.dns-6381.svc jessie_tcp@dns-test-service.dns-6381.svc jessie_udp@_http._tcp.dns-test-service.dns-6381.svc jessie_tcp@_http._tcp.dns-test-service.dns-6381.svc jessie_udp@_http._tcp.test-service-2.dns-6381.svc jessie_tcp@_http._tcp.test-service-2.dns-6381.svc 192.168.112.210_udp@PTR 192.168.112.210_tcp@PTR]

    Jul 10 08:03:23.828: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.832: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.836: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.840: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.844: INFO: Unable to read wheezy_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.873: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.877: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.881: INFO: Unable to read jessie_udp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.885: INFO: Unable to read jessie_tcp@dns-test-service.dns-6381 from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.888: INFO: Unable to read jessie_udp@dns-test-service.dns-6381.svc from pod dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5: the server could not find the requested resource (get pods dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5)
    Jul 10 08:03:23.918: INFO: Lookups using dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6381 wheezy_tcp@dns-test-service.dns-6381 wheezy_udp@dns-test-service.dns-6381.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6381 jessie_tcp@dns-test-service.dns-6381 jessie_udp@dns-test-service.dns-6381.svc]

    Jul 10 08:03:28.929: INFO: DNS probes using dns-6381/dns-test-cff0eb2b-8410-44dc-9eaf-0990fbd0fdc5 succeeded

    STEP: deleting the pod 07/10/23 08:03:28.929
    STEP: deleting the test service 07/10/23 08:03:28.953
    STEP: deleting the test headless service 07/10/23 08:03:29.037
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 08:03:29.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6381" for this suite. 07/10/23 08:03:29.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:03:29.088
Jul 10 08:03:29.089: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:03:29.09
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:29.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:29.124
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-a7b0e685-e036-4b0e-a1ac-b620d677375b 07/10/23 08:03:29.128
STEP: Creating a pod to test consume secrets 07/10/23 08:03:29.135
Jul 10 08:03:29.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d" in namespace "projected-9472" to be "Succeeded or Failed"
Jul 10 08:03:29.161: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.545745ms
Jul 10 08:03:31.167: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014385091s
Jul 10 08:03:33.170: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016955315s
Jul 10 08:03:35.167: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014221354s
STEP: Saw pod success 07/10/23 08:03:35.167
Jul 10 08:03:35.167: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d" satisfied condition "Succeeded or Failed"
Jul 10 08:03:35.171: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d container projected-secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:03:35.18
Jul 10 08:03:35.210: INFO: Waiting for pod pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d to disappear
Jul 10 08:03:35.213: INFO: Pod pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 08:03:35.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9472" for this suite. 07/10/23 08:03:35.221
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":30,"skipped":681,"failed":0}
------------------------------
• [SLOW TEST] [6.146 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:03:29.088
    Jul 10 08:03:29.089: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:03:29.09
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:29.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:29.124
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-a7b0e685-e036-4b0e-a1ac-b620d677375b 07/10/23 08:03:29.128
    STEP: Creating a pod to test consume secrets 07/10/23 08:03:29.135
    Jul 10 08:03:29.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d" in namespace "projected-9472" to be "Succeeded or Failed"
    Jul 10 08:03:29.161: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.545745ms
    Jul 10 08:03:31.167: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014385091s
    Jul 10 08:03:33.170: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016955315s
    Jul 10 08:03:35.167: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014221354s
    STEP: Saw pod success 07/10/23 08:03:35.167
    Jul 10 08:03:35.167: INFO: Pod "pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d" satisfied condition "Succeeded or Failed"
    Jul 10 08:03:35.171: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d container projected-secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:03:35.18
    Jul 10 08:03:35.210: INFO: Waiting for pod pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d to disappear
    Jul 10 08:03:35.213: INFO: Pod pod-projected-secrets-0e2b4228-5eba-4c40-870d-3e38a41b198d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 08:03:35.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9472" for this suite. 07/10/23 08:03:35.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:03:35.236
Jul 10 08:03:35.236: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:03:35.237
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:35.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:35.269
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7c53df71-1962-4588-8b63-3ea064115731 07/10/23 08:03:35.279
STEP: Creating the pod 07/10/23 08:03:35.286
Jul 10 08:03:35.303: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df" in namespace "projected-240" to be "running and ready"
Jul 10 08:03:35.308: INFO: Pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.458232ms
Jul 10 08:03:35.308: INFO: The phase of Pod pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:03:37.314: INFO: Pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df": Phase="Running", Reason="", readiness=true. Elapsed: 2.010822842s
Jul 10 08:03:37.314: INFO: The phase of Pod pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df is Running (Ready = true)
Jul 10 08:03:37.314: INFO: Pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-7c53df71-1962-4588-8b63-3ea064115731 07/10/23 08:03:37.329
STEP: waiting to observe update in volume 07/10/23 08:03:37.337
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:03:39.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-240" for this suite. 07/10/23 08:03:39.365
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":31,"skipped":692,"failed":0}
------------------------------
• [4.143 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:03:35.236
    Jul 10 08:03:35.236: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:03:35.237
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:35.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:35.269
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-7c53df71-1962-4588-8b63-3ea064115731 07/10/23 08:03:35.279
    STEP: Creating the pod 07/10/23 08:03:35.286
    Jul 10 08:03:35.303: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df" in namespace "projected-240" to be "running and ready"
    Jul 10 08:03:35.308: INFO: Pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.458232ms
    Jul 10 08:03:35.308: INFO: The phase of Pod pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:03:37.314: INFO: Pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df": Phase="Running", Reason="", readiness=true. Elapsed: 2.010822842s
    Jul 10 08:03:37.314: INFO: The phase of Pod pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df is Running (Ready = true)
    Jul 10 08:03:37.314: INFO: Pod "pod-projected-configmaps-bf6004b9-b4c9-4ca1-a8bc-bdda229f96df" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-7c53df71-1962-4588-8b63-3ea064115731 07/10/23 08:03:37.329
    STEP: waiting to observe update in volume 07/10/23 08:03:37.337
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:03:39.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-240" for this suite. 07/10/23 08:03:39.365
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:03:39.379
Jul 10 08:03:39.379: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:03:39.38
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:39.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:39.41
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-b9738c20-3d62-40b0-a632-69fc8ab9840c 07/10/23 08:03:39.413
STEP: Creating a pod to test consume configMaps 07/10/23 08:03:39.42
Jul 10 08:03:39.434: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3" in namespace "projected-5517" to be "Succeeded or Failed"
Jul 10 08:03:39.439: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.152896ms
Jul 10 08:03:41.446: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011700562s
Jul 10 08:03:43.446: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011689163s
STEP: Saw pod success 07/10/23 08:03:43.446
Jul 10 08:03:43.446: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3" satisfied condition "Succeeded or Failed"
Jul 10 08:03:43.451: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:03:43.461
Jul 10 08:03:43.536: INFO: Waiting for pod pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3 to disappear
Jul 10 08:03:43.541: INFO: Pod pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:03:43.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5517" for this suite. 07/10/23 08:03:43.546
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":32,"skipped":694,"failed":0}
------------------------------
• [4.180 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:03:39.379
    Jul 10 08:03:39.379: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:03:39.38
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:39.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:39.41
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-b9738c20-3d62-40b0-a632-69fc8ab9840c 07/10/23 08:03:39.413
    STEP: Creating a pod to test consume configMaps 07/10/23 08:03:39.42
    Jul 10 08:03:39.434: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3" in namespace "projected-5517" to be "Succeeded or Failed"
    Jul 10 08:03:39.439: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.152896ms
    Jul 10 08:03:41.446: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011700562s
    Jul 10 08:03:43.446: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011689163s
    STEP: Saw pod success 07/10/23 08:03:43.446
    Jul 10 08:03:43.446: INFO: Pod "pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3" satisfied condition "Succeeded or Failed"
    Jul 10 08:03:43.451: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:03:43.461
    Jul 10 08:03:43.536: INFO: Waiting for pod pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3 to disappear
    Jul 10 08:03:43.541: INFO: Pod pod-projected-configmaps-e710b047-9086-483a-95f5-31e123af28c3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:03:43.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5517" for this suite. 07/10/23 08:03:43.546
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:03:43.56
Jul 10 08:03:43.560: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename job 07/10/23 08:03:43.561
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:43.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:43.601
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 07/10/23 08:03:43.604
STEP: Ensuring active pods == parallelism 07/10/23 08:03:43.616
STEP: delete a job 07/10/23 08:03:45.628
STEP: deleting Job.batch foo in namespace job-5523, will wait for the garbage collector to delete the pods 07/10/23 08:03:45.628
Jul 10 08:03:45.700: INFO: Deleting Job.batch foo took: 15.596289ms
Jul 10 08:03:45.901: INFO: Terminating Job.batch foo pods took: 200.509444ms
STEP: Ensuring job was deleted 07/10/23 08:04:18.901
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jul 10 08:04:18.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5523" for this suite. 07/10/23 08:04:18.914
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":33,"skipped":717,"failed":0}
------------------------------
• [SLOW TEST] [35.368 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:03:43.56
    Jul 10 08:03:43.560: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename job 07/10/23 08:03:43.561
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:03:43.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:03:43.601
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 07/10/23 08:03:43.604
    STEP: Ensuring active pods == parallelism 07/10/23 08:03:43.616
    STEP: delete a job 07/10/23 08:03:45.628
    STEP: deleting Job.batch foo in namespace job-5523, will wait for the garbage collector to delete the pods 07/10/23 08:03:45.628
    Jul 10 08:03:45.700: INFO: Deleting Job.batch foo took: 15.596289ms
    Jul 10 08:03:45.901: INFO: Terminating Job.batch foo pods took: 200.509444ms
    STEP: Ensuring job was deleted 07/10/23 08:04:18.901
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jul 10 08:04:18.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5523" for this suite. 07/10/23 08:04:18.914
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:04:18.928
Jul 10 08:04:18.929: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:04:18.929
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:04:18.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:04:18.961
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-64ddb8c9-2359-468b-92b6-d85963906288 07/10/23 08:04:18.964
STEP: Creating a pod to test consume secrets 07/10/23 08:04:18.973
Jul 10 08:04:18.988: INFO: Waiting up to 5m0s for pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604" in namespace "secrets-2772" to be "Succeeded or Failed"
Jul 10 08:04:18.994: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604": Phase="Pending", Reason="", readiness=false. Elapsed: 5.097107ms
Jul 10 08:04:20.999: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010607156s
Jul 10 08:04:22.999: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011021867s
STEP: Saw pod success 07/10/23 08:04:23
Jul 10 08:04:23.000: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604" satisfied condition "Succeeded or Failed"
Jul 10 08:04:23.004: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604 container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:04:23.014
Jul 10 08:04:23.040: INFO: Waiting for pod pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604 to disappear
Jul 10 08:04:23.044: INFO: Pod pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:04:23.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2772" for this suite. 07/10/23 08:04:23.049
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":34,"skipped":718,"failed":0}
------------------------------
• [4.131 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:04:18.928
    Jul 10 08:04:18.929: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:04:18.929
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:04:18.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:04:18.961
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-64ddb8c9-2359-468b-92b6-d85963906288 07/10/23 08:04:18.964
    STEP: Creating a pod to test consume secrets 07/10/23 08:04:18.973
    Jul 10 08:04:18.988: INFO: Waiting up to 5m0s for pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604" in namespace "secrets-2772" to be "Succeeded or Failed"
    Jul 10 08:04:18.994: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604": Phase="Pending", Reason="", readiness=false. Elapsed: 5.097107ms
    Jul 10 08:04:20.999: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010607156s
    Jul 10 08:04:22.999: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011021867s
    STEP: Saw pod success 07/10/23 08:04:23
    Jul 10 08:04:23.000: INFO: Pod "pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604" satisfied condition "Succeeded or Failed"
    Jul 10 08:04:23.004: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604 container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:04:23.014
    Jul 10 08:04:23.040: INFO: Waiting for pod pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604 to disappear
    Jul 10 08:04:23.044: INFO: Pod pod-secrets-5667da2e-13e6-4f1c-8fee-f6a7d990f604 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:04:23.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2772" for this suite. 07/10/23 08:04:23.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:04:23.061
Jul 10 08:04:23.061: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pod-network-test 07/10/23 08:04:23.063
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:04:23.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:04:23.096
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-5371 07/10/23 08:04:23.099
STEP: creating a selector 07/10/23 08:04:23.099
STEP: Creating the service pods in kubernetes 07/10/23 08:04:23.099
Jul 10 08:04:23.099: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul 10 08:04:23.147: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5371" to be "running and ready"
Jul 10 08:04:23.277: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 130.165808ms
Jul 10 08:04:23.277: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:04:25.284: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.137185033s
Jul 10 08:04:25.284: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:04:27.284: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.137051528s
Jul 10 08:04:27.284: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:04:29.284: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.13726408s
Jul 10 08:04:29.284: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:04:31.285: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.138105995s
Jul 10 08:04:31.285: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:04:33.283: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.136049643s
Jul 10 08:04:33.283: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:04:35.283: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.135589156s
Jul 10 08:04:35.283: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jul 10 08:04:35.283: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jul 10 08:04:35.287: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5371" to be "running and ready"
Jul 10 08:04:35.292: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.439508ms
Jul 10 08:04:35.292: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Jul 10 08:04:37.298: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.011009971s
Jul 10 08:04:37.298: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Jul 10 08:04:39.299: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.011411232s
Jul 10 08:04:39.299: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Jul 10 08:04:41.299: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.011473256s
Jul 10 08:04:41.299: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Jul 10 08:04:43.298: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.01102074s
Jul 10 08:04:43.298: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Jul 10 08:04:45.297: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.010017657s
Jul 10 08:04:45.297: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jul 10 08:04:45.297: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jul 10 08:04:45.301: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5371" to be "running and ready"
Jul 10 08:04:45.306: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.489844ms
Jul 10 08:04:45.306: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jul 10 08:04:45.306: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 07/10/23 08:04:45.31
Jul 10 08:04:45.336: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5371" to be "running"
Jul 10 08:04:45.345: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.686814ms
Jul 10 08:04:47.349: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013422658s
Jul 10 08:04:47.349: INFO: Pod "test-container-pod" satisfied condition "running"
Jul 10 08:04:47.354: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5371" to be "running"
Jul 10 08:04:47.358: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.658393ms
Jul 10 08:04:47.358: INFO: Pod "host-test-container-pod" satisfied condition "running"
Jul 10 08:04:47.362: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul 10 08:04:47.362: INFO: Going to poll 192.168.172.44 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul 10 08:04:47.366: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.172.44:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:04:47.366: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:04:47.367: INFO: ExecWithOptions: Clientset creation
Jul 10 08:04:47.367: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-5371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.172.44%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 08:04:47.466: INFO: Found all 1 expected endpoints: [netserver-0]
Jul 10 08:04:47.466: INFO: Going to poll 192.168.103.76 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul 10 08:04:47.472: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.103.76:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:04:47.472: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:04:47.473: INFO: ExecWithOptions: Clientset creation
Jul 10 08:04:47.473: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-5371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.103.76%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 08:04:47.553: INFO: Found all 1 expected endpoints: [netserver-1]
Jul 10 08:04:47.553: INFO: Going to poll 192.168.120.19 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul 10 08:04:47.558: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.120.19:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:04:47.558: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:04:47.559: INFO: ExecWithOptions: Clientset creation
Jul 10 08:04:47.559: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-5371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.120.19%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 08:04:47.650: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jul 10 08:04:47.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5371" for this suite. 07/10/23 08:04:47.656
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":35,"skipped":747,"failed":0}
------------------------------
• [SLOW TEST] [24.611 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:04:23.061
    Jul 10 08:04:23.061: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pod-network-test 07/10/23 08:04:23.063
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:04:23.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:04:23.096
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-5371 07/10/23 08:04:23.099
    STEP: creating a selector 07/10/23 08:04:23.099
    STEP: Creating the service pods in kubernetes 07/10/23 08:04:23.099
    Jul 10 08:04:23.099: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jul 10 08:04:23.147: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5371" to be "running and ready"
    Jul 10 08:04:23.277: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 130.165808ms
    Jul 10 08:04:23.277: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:04:25.284: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.137185033s
    Jul 10 08:04:25.284: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:04:27.284: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.137051528s
    Jul 10 08:04:27.284: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:04:29.284: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.13726408s
    Jul 10 08:04:29.284: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:04:31.285: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.138105995s
    Jul 10 08:04:31.285: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:04:33.283: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.136049643s
    Jul 10 08:04:33.283: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:04:35.283: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.135589156s
    Jul 10 08:04:35.283: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jul 10 08:04:35.283: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jul 10 08:04:35.287: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5371" to be "running and ready"
    Jul 10 08:04:35.292: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.439508ms
    Jul 10 08:04:35.292: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Jul 10 08:04:37.298: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.011009971s
    Jul 10 08:04:37.298: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Jul 10 08:04:39.299: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.011411232s
    Jul 10 08:04:39.299: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Jul 10 08:04:41.299: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.011473256s
    Jul 10 08:04:41.299: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Jul 10 08:04:43.298: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.01102074s
    Jul 10 08:04:43.298: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Jul 10 08:04:45.297: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.010017657s
    Jul 10 08:04:45.297: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jul 10 08:04:45.297: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jul 10 08:04:45.301: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5371" to be "running and ready"
    Jul 10 08:04:45.306: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.489844ms
    Jul 10 08:04:45.306: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jul 10 08:04:45.306: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 07/10/23 08:04:45.31
    Jul 10 08:04:45.336: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5371" to be "running"
    Jul 10 08:04:45.345: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.686814ms
    Jul 10 08:04:47.349: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013422658s
    Jul 10 08:04:47.349: INFO: Pod "test-container-pod" satisfied condition "running"
    Jul 10 08:04:47.354: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5371" to be "running"
    Jul 10 08:04:47.358: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.658393ms
    Jul 10 08:04:47.358: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Jul 10 08:04:47.362: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jul 10 08:04:47.362: INFO: Going to poll 192.168.172.44 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Jul 10 08:04:47.366: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.172.44:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:04:47.366: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:04:47.367: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:04:47.367: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-5371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.172.44%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 08:04:47.466: INFO: Found all 1 expected endpoints: [netserver-0]
    Jul 10 08:04:47.466: INFO: Going to poll 192.168.103.76 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Jul 10 08:04:47.472: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.103.76:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:04:47.472: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:04:47.473: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:04:47.473: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-5371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.103.76%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 08:04:47.553: INFO: Found all 1 expected endpoints: [netserver-1]
    Jul 10 08:04:47.553: INFO: Going to poll 192.168.120.19 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Jul 10 08:04:47.558: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.120.19:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:04:47.558: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:04:47.559: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:04:47.559: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-5371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.120.19%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 08:04:47.650: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jul 10 08:04:47.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5371" for this suite. 07/10/23 08:04:47.656
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:04:47.673
Jul 10 08:04:47.673: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename watch 07/10/23 08:04:47.675
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:04:47.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:04:47.709
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 07/10/23 08:04:47.712
STEP: creating a watch on configmaps with label B 07/10/23 08:04:47.713
STEP: creating a watch on configmaps with label A or B 07/10/23 08:04:47.715
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 07/10/23 08:04:47.716
Jul 10 08:04:47.722: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71488 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:04:47.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71488 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 07/10/23 08:04:47.723
Jul 10 08:04:47.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71489 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:04:47.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71489 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 07/10/23 08:04:47.739
Jul 10 08:04:47.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71490 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:04:47.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71490 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 07/10/23 08:04:47.75
Jul 10 08:04:47.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71491 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:04:47.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71491 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 07/10/23 08:04:47.759
Jul 10 08:04:47.775: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71492 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:04:47.775: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71492 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 07/10/23 08:04:57.776
Jul 10 08:04:57.792: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71576 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:04:57.792: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71576 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jul 10 08:05:07.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9466" for this suite. 07/10/23 08:05:07.8
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":36,"skipped":757,"failed":0}
------------------------------
• [SLOW TEST] [20.142 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:04:47.673
    Jul 10 08:04:47.673: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename watch 07/10/23 08:04:47.675
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:04:47.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:04:47.709
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 07/10/23 08:04:47.712
    STEP: creating a watch on configmaps with label B 07/10/23 08:04:47.713
    STEP: creating a watch on configmaps with label A or B 07/10/23 08:04:47.715
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 07/10/23 08:04:47.716
    Jul 10 08:04:47.722: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71488 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:04:47.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71488 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 07/10/23 08:04:47.723
    Jul 10 08:04:47.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71489 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:04:47.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71489 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 07/10/23 08:04:47.739
    Jul 10 08:04:47.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71490 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:04:47.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71490 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 07/10/23 08:04:47.75
    Jul 10 08:04:47.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71491 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:04:47.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9466  81f1d8f9-8c2b-46f5-8c20-be013d659890 71491 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 07/10/23 08:04:47.759
    Jul 10 08:04:47.775: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71492 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:04:47.775: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71492 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 07/10/23 08:04:57.776
    Jul 10 08:04:57.792: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71576 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:04:57.792: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9466  a829d390-4095-4381-ba15-d73d7502c58e 71576 0 2023-07-10 08:04:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-07-10 08:04:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jul 10 08:05:07.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9466" for this suite. 07/10/23 08:05:07.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:07.816
Jul 10 08:05:07.816: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 08:05:07.818
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:07.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:07.856
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Jul 10 08:05:07.859: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:05:14.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1681" for this suite. 07/10/23 08:05:14.255
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":37,"skipped":762,"failed":0}
------------------------------
• [SLOW TEST] [6.451 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:07.816
    Jul 10 08:05:07.816: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 08:05:07.818
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:07.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:07.856
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Jul 10 08:05:07.859: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:05:14.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1681" for this suite. 07/10/23 08:05:14.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:14.269
Jul 10 08:05:14.269: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svcaccounts 07/10/23 08:05:14.27
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:14.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:14.298
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 07/10/23 08:05:14.301
STEP: watching for the ServiceAccount to be added 07/10/23 08:05:14.315
STEP: patching the ServiceAccount 07/10/23 08:05:14.316
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 07/10/23 08:05:14.324
STEP: deleting the ServiceAccount 07/10/23 08:05:14.328
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jul 10 08:05:14.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1675" for this suite. 07/10/23 08:05:14.366
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":38,"skipped":782,"failed":0}
------------------------------
• [0.106 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:14.269
    Jul 10 08:05:14.269: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svcaccounts 07/10/23 08:05:14.27
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:14.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:14.298
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 07/10/23 08:05:14.301
    STEP: watching for the ServiceAccount to be added 07/10/23 08:05:14.315
    STEP: patching the ServiceAccount 07/10/23 08:05:14.316
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 07/10/23 08:05:14.324
    STEP: deleting the ServiceAccount 07/10/23 08:05:14.328
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jul 10 08:05:14.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1675" for this suite. 07/10/23 08:05:14.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:14.379
Jul 10 08:05:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:05:14.38
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:14.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:14.426
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:05:14.429
Jul 10 08:05:14.450: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20" in namespace "downward-api-8631" to be "Succeeded or Failed"
Jul 10 08:05:14.458: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040287ms
Jul 10 08:05:16.463: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012828574s
Jul 10 08:05:18.467: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0171723s
STEP: Saw pod success 07/10/23 08:05:18.467
Jul 10 08:05:18.467: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20" satisfied condition "Succeeded or Failed"
Jul 10 08:05:18.474: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20 container client-container: <nil>
STEP: delete the pod 07/10/23 08:05:18.485
Jul 10 08:05:18.514: INFO: Waiting for pod downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20 to disappear
Jul 10 08:05:18.521: INFO: Pod downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 08:05:18.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8631" for this suite. 07/10/23 08:05:18.526
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":39,"skipped":845,"failed":0}
------------------------------
• [4.156 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:14.379
    Jul 10 08:05:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:05:14.38
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:14.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:14.426
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:05:14.429
    Jul 10 08:05:14.450: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20" in namespace "downward-api-8631" to be "Succeeded or Failed"
    Jul 10 08:05:14.458: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040287ms
    Jul 10 08:05:16.463: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012828574s
    Jul 10 08:05:18.467: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0171723s
    STEP: Saw pod success 07/10/23 08:05:18.467
    Jul 10 08:05:18.467: INFO: Pod "downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20" satisfied condition "Succeeded or Failed"
    Jul 10 08:05:18.474: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20 container client-container: <nil>
    STEP: delete the pod 07/10/23 08:05:18.485
    Jul 10 08:05:18.514: INFO: Waiting for pod downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20 to disappear
    Jul 10 08:05:18.521: INFO: Pod downwardapi-volume-0acc5a15-2ca2-4e1b-b371-09fc1f12bf20 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 08:05:18.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8631" for this suite. 07/10/23 08:05:18.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:18.536
Jul 10 08:05:18.536: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:05:18.537
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:18.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:18.582
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:05:18.605
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:05:19.426
STEP: Deploying the webhook pod 07/10/23 08:05:19.442
STEP: Wait for the deployment to be ready 07/10/23 08:05:19.467
Jul 10 08:05:19.474: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 07/10/23 08:05:21.489
STEP: Verifying the service has paired with the endpoint 07/10/23 08:05:21.513
Jul 10 08:05:22.513: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 07/10/23 08:05:22.658
STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:05:22.71
STEP: Deleting the collection of validation webhooks 07/10/23 08:05:22.738
STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:05:22.858
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:05:22.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3959" for this suite. 07/10/23 08:05:22.883
STEP: Destroying namespace "webhook-3959-markers" for this suite. 07/10/23 08:05:22.895
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":40,"skipped":853,"failed":0}
------------------------------
• [4.444 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:18.536
    Jul 10 08:05:18.536: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:05:18.537
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:18.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:18.582
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:05:18.605
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:05:19.426
    STEP: Deploying the webhook pod 07/10/23 08:05:19.442
    STEP: Wait for the deployment to be ready 07/10/23 08:05:19.467
    Jul 10 08:05:19.474: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 07/10/23 08:05:21.489
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:05:21.513
    Jul 10 08:05:22.513: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 07/10/23 08:05:22.658
    STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:05:22.71
    STEP: Deleting the collection of validation webhooks 07/10/23 08:05:22.738
    STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:05:22.858
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:05:22.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3959" for this suite. 07/10/23 08:05:22.883
    STEP: Destroying namespace "webhook-3959-markers" for this suite. 07/10/23 08:05:22.895
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:22.981
Jul 10 08:05:22.981: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:05:22.982
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:23.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:23.041
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 07/10/23 08:05:23.044
Jul 10 08:05:23.069: INFO: Waiting up to 5m0s for pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de" in namespace "emptydir-5598" to be "Succeeded or Failed"
Jul 10 08:05:23.073: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.623321ms
Jul 10 08:05:25.086: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01727773s
Jul 10 08:05:27.080: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010681353s
STEP: Saw pod success 07/10/23 08:05:27.08
Jul 10 08:05:27.080: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de" satisfied condition "Succeeded or Failed"
Jul 10 08:05:27.084: INFO: Trying to get logs from node 10-62-109-100.test pod pod-72e08f04-5d9c-4ae8-ad94-678629e286de container test-container: <nil>
STEP: delete the pod 07/10/23 08:05:27.093
Jul 10 08:05:27.127: INFO: Waiting for pod pod-72e08f04-5d9c-4ae8-ad94-678629e286de to disappear
Jul 10 08:05:27.133: INFO: Pod pod-72e08f04-5d9c-4ae8-ad94-678629e286de no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:05:27.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5598" for this suite. 07/10/23 08:05:27.138
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":41,"skipped":868,"failed":0}
------------------------------
• [4.169 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:22.981
    Jul 10 08:05:22.981: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:05:22.982
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:23.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:23.041
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 07/10/23 08:05:23.044
    Jul 10 08:05:23.069: INFO: Waiting up to 5m0s for pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de" in namespace "emptydir-5598" to be "Succeeded or Failed"
    Jul 10 08:05:23.073: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.623321ms
    Jul 10 08:05:25.086: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01727773s
    Jul 10 08:05:27.080: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010681353s
    STEP: Saw pod success 07/10/23 08:05:27.08
    Jul 10 08:05:27.080: INFO: Pod "pod-72e08f04-5d9c-4ae8-ad94-678629e286de" satisfied condition "Succeeded or Failed"
    Jul 10 08:05:27.084: INFO: Trying to get logs from node 10-62-109-100.test pod pod-72e08f04-5d9c-4ae8-ad94-678629e286de container test-container: <nil>
    STEP: delete the pod 07/10/23 08:05:27.093
    Jul 10 08:05:27.127: INFO: Waiting for pod pod-72e08f04-5d9c-4ae8-ad94-678629e286de to disappear
    Jul 10 08:05:27.133: INFO: Pod pod-72e08f04-5d9c-4ae8-ad94-678629e286de no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:05:27.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5598" for this suite. 07/10/23 08:05:27.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:27.151
Jul 10 08:05:27.151: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:05:27.152
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:27.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:27.189
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6210 07/10/23 08:05:27.193
STEP: changing the ExternalName service to type=NodePort 07/10/23 08:05:27.204
STEP: creating replication controller externalname-service in namespace services-6210 07/10/23 08:05:27.265
I0710 08:05:27.279801      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6210, replica count: 2
I0710 08:05:30.331152      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 08:05:30.331: INFO: Creating new exec pod
Jul 10 08:05:30.342: INFO: Waiting up to 5m0s for pod "execpod9b8dz" in namespace "services-6210" to be "running"
Jul 10 08:05:30.346: INFO: Pod "execpod9b8dz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.891746ms
Jul 10 08:05:32.350: INFO: Pod "execpod9b8dz": Phase="Running", Reason="", readiness=true. Elapsed: 2.008468003s
Jul 10 08:05:32.350: INFO: Pod "execpod9b8dz" satisfied condition "running"
Jul 10 08:05:33.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul 10 08:05:33.523: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul 10 08:05:33.523: INFO: stdout: "externalname-service-brlkq"
Jul 10 08:05:33.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.86.138 80'
Jul 10 08:05:33.658: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.86.138 80\nConnection to 192.168.86.138 80 port [tcp/http] succeeded!\n"
Jul 10 08:05:33.658: INFO: stdout: "externalname-service-brlkq"
Jul 10 08:05:33.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30847'
Jul 10 08:05:33.795: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30847\nConnection to 10.62.109.101 30847 port [tcp/*] succeeded!\n"
Jul 10 08:05:33.795: INFO: stdout: "externalname-service-n2b8f"
Jul 10 08:05:33.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 30847'
Jul 10 08:05:33.950: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 30847\nConnection to 10.62.109.100 30847 port [tcp/*] succeeded!\n"
Jul 10 08:05:33.950: INFO: stdout: ""
Jul 10 08:05:34.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 30847'
Jul 10 08:05:35.099: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 30847\nConnection to 10.62.109.100 30847 port [tcp/*] succeeded!\n"
Jul 10 08:05:35.099: INFO: stdout: ""
Jul 10 08:05:35.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 30847'
Jul 10 08:05:36.136: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 30847\nConnection to 10.62.109.100 30847 port [tcp/*] succeeded!\n"
Jul 10 08:05:36.136: INFO: stdout: "externalname-service-brlkq"
Jul 10 08:05:36.136: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:05:36.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6210" for this suite. 07/10/23 08:05:36.198
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":42,"skipped":875,"failed":0}
------------------------------
• [SLOW TEST] [9.061 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:27.151
    Jul 10 08:05:27.151: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:05:27.152
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:27.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:27.189
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-6210 07/10/23 08:05:27.193
    STEP: changing the ExternalName service to type=NodePort 07/10/23 08:05:27.204
    STEP: creating replication controller externalname-service in namespace services-6210 07/10/23 08:05:27.265
    I0710 08:05:27.279801      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6210, replica count: 2
    I0710 08:05:30.331152      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 08:05:30.331: INFO: Creating new exec pod
    Jul 10 08:05:30.342: INFO: Waiting up to 5m0s for pod "execpod9b8dz" in namespace "services-6210" to be "running"
    Jul 10 08:05:30.346: INFO: Pod "execpod9b8dz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.891746ms
    Jul 10 08:05:32.350: INFO: Pod "execpod9b8dz": Phase="Running", Reason="", readiness=true. Elapsed: 2.008468003s
    Jul 10 08:05:32.350: INFO: Pod "execpod9b8dz" satisfied condition "running"
    Jul 10 08:05:33.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jul 10 08:05:33.523: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jul 10 08:05:33.523: INFO: stdout: "externalname-service-brlkq"
    Jul 10 08:05:33.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.86.138 80'
    Jul 10 08:05:33.658: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.86.138 80\nConnection to 192.168.86.138 80 port [tcp/http] succeeded!\n"
    Jul 10 08:05:33.658: INFO: stdout: "externalname-service-brlkq"
    Jul 10 08:05:33.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30847'
    Jul 10 08:05:33.795: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30847\nConnection to 10.62.109.101 30847 port [tcp/*] succeeded!\n"
    Jul 10 08:05:33.795: INFO: stdout: "externalname-service-n2b8f"
    Jul 10 08:05:33.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 30847'
    Jul 10 08:05:33.950: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 30847\nConnection to 10.62.109.100 30847 port [tcp/*] succeeded!\n"
    Jul 10 08:05:33.950: INFO: stdout: ""
    Jul 10 08:05:34.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 30847'
    Jul 10 08:05:35.099: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 30847\nConnection to 10.62.109.100 30847 port [tcp/*] succeeded!\n"
    Jul 10 08:05:35.099: INFO: stdout: ""
    Jul 10 08:05:35.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6210 exec execpod9b8dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 30847'
    Jul 10 08:05:36.136: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 30847\nConnection to 10.62.109.100 30847 port [tcp/*] succeeded!\n"
    Jul 10 08:05:36.136: INFO: stdout: "externalname-service-brlkq"
    Jul 10 08:05:36.136: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:05:36.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6210" for this suite. 07/10/23 08:05:36.198
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:36.214
Jul 10 08:05:36.214: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:05:36.215
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:36.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:36.307
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 07/10/23 08:05:36.31
STEP: Creating a ResourceQuota 07/10/23 08:05:41.314
STEP: Ensuring resource quota status is calculated 07/10/23 08:05:41.326
STEP: Creating a ReplicationController 07/10/23 08:05:43.37
STEP: Ensuring resource quota status captures replication controller creation 07/10/23 08:05:43.404
STEP: Deleting a ReplicationController 07/10/23 08:05:45.411
STEP: Ensuring resource quota status released usage 07/10/23 08:05:45.426
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:05:47.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3815" for this suite. 07/10/23 08:05:47.439
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":43,"skipped":901,"failed":0}
------------------------------
• [SLOW TEST] [11.236 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:36.214
    Jul 10 08:05:36.214: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:05:36.215
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:36.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:36.307
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 07/10/23 08:05:36.31
    STEP: Creating a ResourceQuota 07/10/23 08:05:41.314
    STEP: Ensuring resource quota status is calculated 07/10/23 08:05:41.326
    STEP: Creating a ReplicationController 07/10/23 08:05:43.37
    STEP: Ensuring resource quota status captures replication controller creation 07/10/23 08:05:43.404
    STEP: Deleting a ReplicationController 07/10/23 08:05:45.411
    STEP: Ensuring resource quota status released usage 07/10/23 08:05:45.426
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:05:47.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3815" for this suite. 07/10/23 08:05:47.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:47.453
Jul 10 08:05:47.453: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:05:47.455
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:47.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:47.489
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-8ddc2c53-47b3-4c68-b632-17b728685623 07/10/23 08:05:47.492
STEP: Creating a pod to test consume configMaps 07/10/23 08:05:47.514
Jul 10 08:05:47.536: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df" in namespace "configmap-7994" to be "Succeeded or Failed"
Jul 10 08:05:47.543: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df": Phase="Pending", Reason="", readiness=false. Elapsed: 6.719857ms
Jul 10 08:05:49.549: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013062047s
Jul 10 08:05:51.551: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014439375s
STEP: Saw pod success 07/10/23 08:05:51.551
Jul 10 08:05:51.551: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df" satisfied condition "Succeeded or Failed"
Jul 10 08:05:51.555: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:05:51.565
Jul 10 08:05:51.587: INFO: Waiting for pod pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df to disappear
Jul 10 08:05:51.591: INFO: Pod pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:05:51.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7994" for this suite. 07/10/23 08:05:51.598
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":44,"skipped":951,"failed":0}
------------------------------
• [4.158 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:47.453
    Jul 10 08:05:47.453: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:05:47.455
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:47.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:47.489
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-8ddc2c53-47b3-4c68-b632-17b728685623 07/10/23 08:05:47.492
    STEP: Creating a pod to test consume configMaps 07/10/23 08:05:47.514
    Jul 10 08:05:47.536: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df" in namespace "configmap-7994" to be "Succeeded or Failed"
    Jul 10 08:05:47.543: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df": Phase="Pending", Reason="", readiness=false. Elapsed: 6.719857ms
    Jul 10 08:05:49.549: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013062047s
    Jul 10 08:05:51.551: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014439375s
    STEP: Saw pod success 07/10/23 08:05:51.551
    Jul 10 08:05:51.551: INFO: Pod "pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df" satisfied condition "Succeeded or Failed"
    Jul 10 08:05:51.555: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:05:51.565
    Jul 10 08:05:51.587: INFO: Waiting for pod pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df to disappear
    Jul 10 08:05:51.591: INFO: Pod pod-configmaps-4fd8fb57-2a13-412f-a2ad-a947805e35df no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:05:51.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7994" for this suite. 07/10/23 08:05:51.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:51.621
Jul 10 08:05:51.622: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:05:51.623
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:51.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:51.666
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 07/10/23 08:05:51.669
STEP: fetching the ConfigMap 07/10/23 08:05:51.676
STEP: patching the ConfigMap 07/10/23 08:05:51.68
STEP: listing all ConfigMaps in all namespaces with a label selector 07/10/23 08:05:51.691
STEP: deleting the ConfigMap by collection with a label selector 07/10/23 08:05:51.697
STEP: listing all ConfigMaps in test namespace 07/10/23 08:05:51.709
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:05:51.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9907" for this suite. 07/10/23 08:05:51.72
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":45,"skipped":1010,"failed":0}
------------------------------
• [0.108 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:51.621
    Jul 10 08:05:51.622: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:05:51.623
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:51.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:51.666
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 07/10/23 08:05:51.669
    STEP: fetching the ConfigMap 07/10/23 08:05:51.676
    STEP: patching the ConfigMap 07/10/23 08:05:51.68
    STEP: listing all ConfigMaps in all namespaces with a label selector 07/10/23 08:05:51.691
    STEP: deleting the ConfigMap by collection with a label selector 07/10/23 08:05:51.697
    STEP: listing all ConfigMaps in test namespace 07/10/23 08:05:51.709
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:05:51.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9907" for this suite. 07/10/23 08:05:51.72
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:51.73
Jul 10 08:05:51.730: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:05:51.731
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:51.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:51.771
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-58babcc8-e9ef-43a4-8ad1-1b46a1da4d37 07/10/23 08:05:51.774
STEP: Creating secret with name secret-projected-all-test-volume-53a93ddc-b796-459b-b295-8c8a44bf1381 07/10/23 08:05:51.78
STEP: Creating a pod to test Check all projections for projected volume plugin 07/10/23 08:05:51.788
Jul 10 08:05:51.806: INFO: Waiting up to 5m0s for pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e" in namespace "projected-9652" to be "Succeeded or Failed"
Jul 10 08:05:51.810: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.242979ms
Jul 10 08:05:53.816: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010266591s
Jul 10 08:05:55.815: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009338644s
STEP: Saw pod success 07/10/23 08:05:55.815
Jul 10 08:05:55.815: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e" satisfied condition "Succeeded or Failed"
Jul 10 08:05:55.819: INFO: Trying to get logs from node 10-62-109-100.test pod projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e container projected-all-volume-test: <nil>
STEP: delete the pod 07/10/23 08:05:55.828
Jul 10 08:05:55.847: INFO: Waiting for pod projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e to disappear
Jul 10 08:05:55.852: INFO: Pod projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Jul 10 08:05:55.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9652" for this suite. 07/10/23 08:05:55.865
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":46,"skipped":1022,"failed":0}
------------------------------
• [4.144 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:51.73
    Jul 10 08:05:51.730: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:05:51.731
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:51.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:51.771
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-58babcc8-e9ef-43a4-8ad1-1b46a1da4d37 07/10/23 08:05:51.774
    STEP: Creating secret with name secret-projected-all-test-volume-53a93ddc-b796-459b-b295-8c8a44bf1381 07/10/23 08:05:51.78
    STEP: Creating a pod to test Check all projections for projected volume plugin 07/10/23 08:05:51.788
    Jul 10 08:05:51.806: INFO: Waiting up to 5m0s for pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e" in namespace "projected-9652" to be "Succeeded or Failed"
    Jul 10 08:05:51.810: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.242979ms
    Jul 10 08:05:53.816: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010266591s
    Jul 10 08:05:55.815: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009338644s
    STEP: Saw pod success 07/10/23 08:05:55.815
    Jul 10 08:05:55.815: INFO: Pod "projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e" satisfied condition "Succeeded or Failed"
    Jul 10 08:05:55.819: INFO: Trying to get logs from node 10-62-109-100.test pod projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e container projected-all-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:05:55.828
    Jul 10 08:05:55.847: INFO: Waiting for pod projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e to disappear
    Jul 10 08:05:55.852: INFO: Pod projected-volume-763f7414-ba2a-46cd-b4d6-e3d502961b5e no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Jul 10 08:05:55.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9652" for this suite. 07/10/23 08:05:55.865
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:05:55.875
Jul 10 08:05:55.875: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:05:55.876
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:55.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:55.907
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:05:55.91
Jul 10 08:05:55.923: INFO: Waiting up to 5m0s for pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d" in namespace "projected-4350" to be "Succeeded or Failed"
Jul 10 08:05:55.928: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.8126ms
Jul 10 08:05:57.934: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010636644s
Jul 10 08:05:59.934: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011069279s
STEP: Saw pod success 07/10/23 08:05:59.934
Jul 10 08:05:59.935: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d" satisfied condition "Succeeded or Failed"
Jul 10 08:05:59.939: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d container client-container: <nil>
STEP: delete the pod 07/10/23 08:05:59.95
Jul 10 08:05:59.980: INFO: Waiting for pod downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d to disappear
Jul 10 08:05:59.984: INFO: Pod downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:05:59.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4350" for this suite. 07/10/23 08:05:59.989
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":47,"skipped":1023,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:05:55.875
    Jul 10 08:05:55.875: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:05:55.876
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:05:55.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:05:55.907
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:05:55.91
    Jul 10 08:05:55.923: INFO: Waiting up to 5m0s for pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d" in namespace "projected-4350" to be "Succeeded or Failed"
    Jul 10 08:05:55.928: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.8126ms
    Jul 10 08:05:57.934: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010636644s
    Jul 10 08:05:59.934: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011069279s
    STEP: Saw pod success 07/10/23 08:05:59.934
    Jul 10 08:05:59.935: INFO: Pod "downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d" satisfied condition "Succeeded or Failed"
    Jul 10 08:05:59.939: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d container client-container: <nil>
    STEP: delete the pod 07/10/23 08:05:59.95
    Jul 10 08:05:59.980: INFO: Waiting for pod downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d to disappear
    Jul 10 08:05:59.984: INFO: Pod downwardapi-volume-943313fa-faf7-4f34-8eb8-debdca590c3d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:05:59.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4350" for this suite. 07/10/23 08:05:59.989
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:00.001
Jul 10 08:06:00.001: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:06:00.002
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:00.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:00.034
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 07/10/23 08:06:00.037
Jul 10 08:06:00.053: INFO: Waiting up to 5m0s for pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c" in namespace "downward-api-781" to be "Succeeded or Failed"
Jul 10 08:06:00.058: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.385282ms
Jul 10 08:06:02.064: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011194417s
Jul 10 08:06:04.064: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011408102s
STEP: Saw pod success 07/10/23 08:06:04.064
Jul 10 08:06:04.064: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c" satisfied condition "Succeeded or Failed"
Jul 10 08:06:04.070: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c container dapi-container: <nil>
STEP: delete the pod 07/10/23 08:06:04.082
Jul 10 08:06:04.195: INFO: Waiting for pod downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c to disappear
Jul 10 08:06:04.202: INFO: Pod downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jul 10 08:06:04.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-781" for this suite. 07/10/23 08:06:04.209
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":48,"skipped":1023,"failed":0}
------------------------------
• [4.219 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:00.001
    Jul 10 08:06:00.001: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:06:00.002
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:00.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:00.034
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 07/10/23 08:06:00.037
    Jul 10 08:06:00.053: INFO: Waiting up to 5m0s for pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c" in namespace "downward-api-781" to be "Succeeded or Failed"
    Jul 10 08:06:00.058: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.385282ms
    Jul 10 08:06:02.064: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011194417s
    Jul 10 08:06:04.064: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011408102s
    STEP: Saw pod success 07/10/23 08:06:04.064
    Jul 10 08:06:04.064: INFO: Pod "downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c" satisfied condition "Succeeded or Failed"
    Jul 10 08:06:04.070: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c container dapi-container: <nil>
    STEP: delete the pod 07/10/23 08:06:04.082
    Jul 10 08:06:04.195: INFO: Waiting for pod downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c to disappear
    Jul 10 08:06:04.202: INFO: Pod downward-api-96d41b12-1fc9-40b7-845b-c3f3a88fac4c no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jul 10 08:06:04.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-781" for this suite. 07/10/23 08:06:04.209
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:04.221
Jul 10 08:06:04.221: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replicaset 07/10/23 08:06:04.222
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:04.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:04.258
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 07/10/23 08:06:04.332
Jul 10 08:06:04.498: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 07/10/23 08:06:04.498
Jul 10 08:06:04.498: INFO: Waiting up to 5m0s for pod "test-rs-xdw7n" in namespace "replicaset-7537" to be "running"
Jul 10 08:06:04.509: INFO: Pod "test-rs-xdw7n": Phase="Pending", Reason="", readiness=false. Elapsed: 10.486415ms
Jul 10 08:06:06.514: INFO: Pod "test-rs-xdw7n": Phase="Running", Reason="", readiness=true. Elapsed: 2.015201542s
Jul 10 08:06:06.514: INFO: Pod "test-rs-xdw7n" satisfied condition "running"
STEP: getting scale subresource 07/10/23 08:06:06.514
STEP: updating a scale subresource 07/10/23 08:06:06.518
STEP: verifying the replicaset Spec.Replicas was modified 07/10/23 08:06:06.529
STEP: Patch a scale subresource 07/10/23 08:06:06.537
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jul 10 08:06:06.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7537" for this suite. 07/10/23 08:06:06.609
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":49,"skipped":1031,"failed":0}
------------------------------
• [2.406 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:04.221
    Jul 10 08:06:04.221: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replicaset 07/10/23 08:06:04.222
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:04.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:04.258
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 07/10/23 08:06:04.332
    Jul 10 08:06:04.498: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 07/10/23 08:06:04.498
    Jul 10 08:06:04.498: INFO: Waiting up to 5m0s for pod "test-rs-xdw7n" in namespace "replicaset-7537" to be "running"
    Jul 10 08:06:04.509: INFO: Pod "test-rs-xdw7n": Phase="Pending", Reason="", readiness=false. Elapsed: 10.486415ms
    Jul 10 08:06:06.514: INFO: Pod "test-rs-xdw7n": Phase="Running", Reason="", readiness=true. Elapsed: 2.015201542s
    Jul 10 08:06:06.514: INFO: Pod "test-rs-xdw7n" satisfied condition "running"
    STEP: getting scale subresource 07/10/23 08:06:06.514
    STEP: updating a scale subresource 07/10/23 08:06:06.518
    STEP: verifying the replicaset Spec.Replicas was modified 07/10/23 08:06:06.529
    STEP: Patch a scale subresource 07/10/23 08:06:06.537
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jul 10 08:06:06.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7537" for this suite. 07/10/23 08:06:06.609
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:06.628
Jul 10 08:06:06.629: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubelet-test 07/10/23 08:06:06.629
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:06.724
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:06.731
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Jul 10 08:06:06.750: INFO: Waiting up to 5m0s for pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a" in namespace "kubelet-test-5972" to be "running and ready"
Jul 10 08:06:06.762: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.462699ms
Jul 10 08:06:06.762: INFO: The phase of Pod busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:06:08.768: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018481899s
Jul 10 08:06:08.768: INFO: The phase of Pod busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:06:10.770: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a": Phase="Running", Reason="", readiness=true. Elapsed: 4.020537949s
Jul 10 08:06:10.770: INFO: The phase of Pod busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a is Running (Ready = true)
Jul 10 08:06:10.770: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jul 10 08:06:10.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5972" for this suite. 07/10/23 08:06:10.801
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":50,"skipped":1050,"failed":0}
------------------------------
• [4.187 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:06.628
    Jul 10 08:06:06.629: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubelet-test 07/10/23 08:06:06.629
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:06.724
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:06.731
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Jul 10 08:06:06.750: INFO: Waiting up to 5m0s for pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a" in namespace "kubelet-test-5972" to be "running and ready"
    Jul 10 08:06:06.762: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.462699ms
    Jul 10 08:06:06.762: INFO: The phase of Pod busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:06:08.768: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018481899s
    Jul 10 08:06:08.768: INFO: The phase of Pod busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:06:10.770: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a": Phase="Running", Reason="", readiness=true. Elapsed: 4.020537949s
    Jul 10 08:06:10.770: INFO: The phase of Pod busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a is Running (Ready = true)
    Jul 10 08:06:10.770: INFO: Pod "busybox-scheduling-05ac76c3-84c9-424f-8c5d-3631b4ad659a" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jul 10 08:06:10.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5972" for this suite. 07/10/23 08:06:10.801
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:10.816
Jul 10 08:06:10.817: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:06:10.817
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:10.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:10.864
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-31b760a1-5db8-48b6-a009-598fb8e66831 07/10/23 08:06:10.869
STEP: Creating a pod to test consume secrets 07/10/23 08:06:10.877
Jul 10 08:06:10.894: INFO: Waiting up to 5m0s for pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1" in namespace "secrets-2569" to be "Succeeded or Failed"
Jul 10 08:06:10.898: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.319466ms
Jul 10 08:06:12.907: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012385449s
Jul 10 08:06:14.904: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009808691s
STEP: Saw pod success 07/10/23 08:06:14.904
Jul 10 08:06:14.904: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1" satisfied condition "Succeeded or Failed"
Jul 10 08:06:14.908: INFO: Trying to get logs from node 10-62-109-102.test pod pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1 container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:06:14.924
Jul 10 08:06:14.950: INFO: Waiting for pod pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1 to disappear
Jul 10 08:06:14.955: INFO: Pod pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:06:14.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2569" for this suite. 07/10/23 08:06:14.96
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":51,"skipped":1063,"failed":0}
------------------------------
• [4.157 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:10.816
    Jul 10 08:06:10.817: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:06:10.817
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:10.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:10.864
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-31b760a1-5db8-48b6-a009-598fb8e66831 07/10/23 08:06:10.869
    STEP: Creating a pod to test consume secrets 07/10/23 08:06:10.877
    Jul 10 08:06:10.894: INFO: Waiting up to 5m0s for pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1" in namespace "secrets-2569" to be "Succeeded or Failed"
    Jul 10 08:06:10.898: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.319466ms
    Jul 10 08:06:12.907: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012385449s
    Jul 10 08:06:14.904: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009808691s
    STEP: Saw pod success 07/10/23 08:06:14.904
    Jul 10 08:06:14.904: INFO: Pod "pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1" satisfied condition "Succeeded or Failed"
    Jul 10 08:06:14.908: INFO: Trying to get logs from node 10-62-109-102.test pod pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1 container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:06:14.924
    Jul 10 08:06:14.950: INFO: Waiting for pod pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1 to disappear
    Jul 10 08:06:14.955: INFO: Pod pod-secrets-0228981d-c558-4e67-aa64-0caf1ca8e0d1 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:06:14.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2569" for this suite. 07/10/23 08:06:14.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:14.975
Jul 10 08:06:14.975: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename security-context-test 07/10/23 08:06:14.976
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:15.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:15.016
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Jul 10 08:06:15.035: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d" in namespace "security-context-test-7507" to be "Succeeded or Failed"
Jul 10 08:06:15.040: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.091058ms
Jul 10 08:06:17.046: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010658342s
Jul 10 08:06:19.046: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010831107s
Jul 10 08:06:19.046: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jul 10 08:06:19.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7507" for this suite. 07/10/23 08:06:19.051
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":52,"skipped":1114,"failed":0}
------------------------------
• [4.085 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:14.975
    Jul 10 08:06:14.975: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename security-context-test 07/10/23 08:06:14.976
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:15.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:15.016
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Jul 10 08:06:15.035: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d" in namespace "security-context-test-7507" to be "Succeeded or Failed"
    Jul 10 08:06:15.040: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.091058ms
    Jul 10 08:06:17.046: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010658342s
    Jul 10 08:06:19.046: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010831107s
    Jul 10 08:06:19.046: INFO: Pod "busybox-user-65534-5d0b5232-cb22-415a-a44b-87116fb1d69d" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jul 10 08:06:19.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7507" for this suite. 07/10/23 08:06:19.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:19.061
Jul 10 08:06:19.061: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:06:19.062
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:19.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:19.097
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 07/10/23 08:06:19.1
Jul 10 08:06:19.117: INFO: Waiting up to 5m0s for pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21" in namespace "emptydir-3061" to be "Succeeded or Failed"
Jul 10 08:06:19.121: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803452ms
Jul 10 08:06:21.127: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010212274s
Jul 10 08:06:23.128: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010972162s
STEP: Saw pod success 07/10/23 08:06:23.128
Jul 10 08:06:23.128: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21" satisfied condition "Succeeded or Failed"
Jul 10 08:06:23.136: INFO: Trying to get logs from node 10-62-109-100.test pod pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21 container test-container: <nil>
STEP: delete the pod 07/10/23 08:06:23.149
Jul 10 08:06:23.171: INFO: Waiting for pod pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21 to disappear
Jul 10 08:06:23.182: INFO: Pod pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:06:23.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3061" for this suite. 07/10/23 08:06:23.188
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":53,"skipped":1123,"failed":0}
------------------------------
• [4.137 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:19.061
    Jul 10 08:06:19.061: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:06:19.062
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:19.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:19.097
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 07/10/23 08:06:19.1
    Jul 10 08:06:19.117: INFO: Waiting up to 5m0s for pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21" in namespace "emptydir-3061" to be "Succeeded or Failed"
    Jul 10 08:06:19.121: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803452ms
    Jul 10 08:06:21.127: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010212274s
    Jul 10 08:06:23.128: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010972162s
    STEP: Saw pod success 07/10/23 08:06:23.128
    Jul 10 08:06:23.128: INFO: Pod "pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21" satisfied condition "Succeeded or Failed"
    Jul 10 08:06:23.136: INFO: Trying to get logs from node 10-62-109-100.test pod pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:06:23.149
    Jul 10 08:06:23.171: INFO: Waiting for pod pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21 to disappear
    Jul 10 08:06:23.182: INFO: Pod pod-d0b89440-3e8b-4b31-bd19-c6a6f1211e21 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:06:23.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3061" for this suite. 07/10/23 08:06:23.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:06:23.199
Jul 10 08:06:23.199: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 08:06:23.2
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:23.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:23.233
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f in namespace container-probe-748 07/10/23 08:06:23.236
Jul 10 08:06:23.252: INFO: Waiting up to 5m0s for pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f" in namespace "container-probe-748" to be "not pending"
Jul 10 08:06:23.256: INFO: Pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.981413ms
Jul 10 08:06:25.557: INFO: Pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.305056857s
Jul 10 08:06:25.557: INFO: Pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f" satisfied condition "not pending"
Jul 10 08:06:25.557: INFO: Started pod liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f in namespace container-probe-748
STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 08:06:25.557
Jul 10 08:06:25.561: INFO: Initial restart count of pod liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f is 0
STEP: deleting the pod 07/10/23 08:10:26.337
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 08:10:26.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-748" for this suite. 07/10/23 08:10:26.378
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":54,"skipped":1130,"failed":0}
------------------------------
• [SLOW TEST] [243.191 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:06:23.199
    Jul 10 08:06:23.199: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 08:06:23.2
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:06:23.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:06:23.233
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f in namespace container-probe-748 07/10/23 08:06:23.236
    Jul 10 08:06:23.252: INFO: Waiting up to 5m0s for pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f" in namespace "container-probe-748" to be "not pending"
    Jul 10 08:06:23.256: INFO: Pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.981413ms
    Jul 10 08:06:25.557: INFO: Pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.305056857s
    Jul 10 08:06:25.557: INFO: Pod "liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f" satisfied condition "not pending"
    Jul 10 08:06:25.557: INFO: Started pod liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f in namespace container-probe-748
    STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 08:06:25.557
    Jul 10 08:06:25.561: INFO: Initial restart count of pod liveness-0469ffe4-765f-4ebe-96ff-f73a5a27fe6f is 0
    STEP: deleting the pod 07/10/23 08:10:26.337
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 08:10:26.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-748" for this suite. 07/10/23 08:10:26.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:10:26.391
Jul 10 08:10:26.391: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:10:26.392
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:26.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:26.427
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1246 07/10/23 08:10:26.431
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 07/10/23 08:10:26.473
STEP: creating service externalsvc in namespace services-1246 07/10/23 08:10:26.474
STEP: creating replication controller externalsvc in namespace services-1246 07/10/23 08:10:26.507
I0710 08:10:26.536670      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1246, replica count: 2
I0710 08:10:29.587159      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 07/10/23 08:10:29.591
Jul 10 08:10:29.626: INFO: Creating new exec pod
Jul 10 08:10:29.643: INFO: Waiting up to 5m0s for pod "execpod4tjmn" in namespace "services-1246" to be "running"
Jul 10 08:10:29.655: INFO: Pod "execpod4tjmn": Phase="Pending", Reason="", readiness=false. Elapsed: 11.200292ms
Jul 10 08:10:31.660: INFO: Pod "execpod4tjmn": Phase="Running", Reason="", readiness=true. Elapsed: 2.016208619s
Jul 10 08:10:31.660: INFO: Pod "execpod4tjmn" satisfied condition "running"
Jul 10 08:10:31.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1246 exec execpod4tjmn -- /bin/sh -x -c nslookup nodeport-service.services-1246.svc.cluster.local'
Jul 10 08:10:31.846: INFO: stderr: "+ nslookup nodeport-service.services-1246.svc.cluster.local\n"
Jul 10 08:10:31.846: INFO: stdout: "Server:\t\t192.168.0.2\nAddress:\t192.168.0.2#53\n\nnodeport-service.services-1246.svc.cluster.local\tcanonical name = externalsvc.services-1246.svc.cluster.local.\nName:\texternalsvc.services-1246.svc.cluster.local\nAddress: 192.168.103.128\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1246, will wait for the garbage collector to delete the pods 07/10/23 08:10:31.846
Jul 10 08:10:31.916: INFO: Deleting ReplicationController externalsvc took: 13.227228ms
Jul 10 08:10:32.016: INFO: Terminating ReplicationController externalsvc pods took: 100.522282ms
Jul 10 08:10:34.058: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:10:34.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1246" for this suite. 07/10/23 08:10:34.105
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":55,"skipped":1144,"failed":0}
------------------------------
• [SLOW TEST] [7.754 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:10:26.391
    Jul 10 08:10:26.391: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:10:26.392
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:26.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:26.427
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-1246 07/10/23 08:10:26.431
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 07/10/23 08:10:26.473
    STEP: creating service externalsvc in namespace services-1246 07/10/23 08:10:26.474
    STEP: creating replication controller externalsvc in namespace services-1246 07/10/23 08:10:26.507
    I0710 08:10:26.536670      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1246, replica count: 2
    I0710 08:10:29.587159      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 07/10/23 08:10:29.591
    Jul 10 08:10:29.626: INFO: Creating new exec pod
    Jul 10 08:10:29.643: INFO: Waiting up to 5m0s for pod "execpod4tjmn" in namespace "services-1246" to be "running"
    Jul 10 08:10:29.655: INFO: Pod "execpod4tjmn": Phase="Pending", Reason="", readiness=false. Elapsed: 11.200292ms
    Jul 10 08:10:31.660: INFO: Pod "execpod4tjmn": Phase="Running", Reason="", readiness=true. Elapsed: 2.016208619s
    Jul 10 08:10:31.660: INFO: Pod "execpod4tjmn" satisfied condition "running"
    Jul 10 08:10:31.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1246 exec execpod4tjmn -- /bin/sh -x -c nslookup nodeport-service.services-1246.svc.cluster.local'
    Jul 10 08:10:31.846: INFO: stderr: "+ nslookup nodeport-service.services-1246.svc.cluster.local\n"
    Jul 10 08:10:31.846: INFO: stdout: "Server:\t\t192.168.0.2\nAddress:\t192.168.0.2#53\n\nnodeport-service.services-1246.svc.cluster.local\tcanonical name = externalsvc.services-1246.svc.cluster.local.\nName:\texternalsvc.services-1246.svc.cluster.local\nAddress: 192.168.103.128\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1246, will wait for the garbage collector to delete the pods 07/10/23 08:10:31.846
    Jul 10 08:10:31.916: INFO: Deleting ReplicationController externalsvc took: 13.227228ms
    Jul 10 08:10:32.016: INFO: Terminating ReplicationController externalsvc pods took: 100.522282ms
    Jul 10 08:10:34.058: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:10:34.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1246" for this suite. 07/10/23 08:10:34.105
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:10:34.146
Jul 10 08:10:34.146: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 08:10:34.147
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:34.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:34.177
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 07/10/23 08:10:34.18
Jul 10 08:10:34.211: INFO: Waiting up to 5m0s for pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a" in namespace "var-expansion-3107" to be "Succeeded or Failed"
Jul 10 08:10:34.222: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.264027ms
Jul 10 08:10:36.228: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016220095s
Jul 10 08:10:38.227: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015989221s
STEP: Saw pod success 07/10/23 08:10:38.227
Jul 10 08:10:38.227: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a" satisfied condition "Succeeded or Failed"
Jul 10 08:10:38.232: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a container dapi-container: <nil>
STEP: delete the pod 07/10/23 08:10:38.247
Jul 10 08:10:38.267: INFO: Waiting for pod var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a to disappear
Jul 10 08:10:38.271: INFO: Pod var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 08:10:38.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3107" for this suite. 07/10/23 08:10:38.276
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":56,"skipped":1158,"failed":0}
------------------------------
• [4.139 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:10:34.146
    Jul 10 08:10:34.146: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 08:10:34.147
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:34.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:34.177
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 07/10/23 08:10:34.18
    Jul 10 08:10:34.211: INFO: Waiting up to 5m0s for pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a" in namespace "var-expansion-3107" to be "Succeeded or Failed"
    Jul 10 08:10:34.222: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.264027ms
    Jul 10 08:10:36.228: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016220095s
    Jul 10 08:10:38.227: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015989221s
    STEP: Saw pod success 07/10/23 08:10:38.227
    Jul 10 08:10:38.227: INFO: Pod "var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a" satisfied condition "Succeeded or Failed"
    Jul 10 08:10:38.232: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a container dapi-container: <nil>
    STEP: delete the pod 07/10/23 08:10:38.247
    Jul 10 08:10:38.267: INFO: Waiting for pod var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a to disappear
    Jul 10 08:10:38.271: INFO: Pod var-expansion-805ef3d9-be39-4ae2-bdfa-e6690692f01a no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 08:10:38.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3107" for this suite. 07/10/23 08:10:38.276
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:10:38.287
Jul 10 08:10:38.287: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:10:38.288
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:38.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:38.321
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 07/10/23 08:10:38.324
Jul 10 08:10:38.432: INFO: Waiting up to 5m0s for pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001" in namespace "projected-2793" to be "running and ready"
Jul 10 08:10:38.437: INFO: Pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001": Phase="Pending", Reason="", readiness=false. Elapsed: 4.510082ms
Jul 10 08:10:38.437: INFO: The phase of Pod labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:10:40.443: INFO: Pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001": Phase="Running", Reason="", readiness=true. Elapsed: 2.010940159s
Jul 10 08:10:40.443: INFO: The phase of Pod labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001 is Running (Ready = true)
Jul 10 08:10:40.443: INFO: Pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001" satisfied condition "running and ready"
Jul 10 08:10:40.986: INFO: Successfully updated pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:10:43.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2793" for this suite. 07/10/23 08:10:43.019
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":57,"skipped":1179,"failed":0}
------------------------------
• [4.745 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:10:38.287
    Jul 10 08:10:38.287: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:10:38.288
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:38.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:38.321
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 07/10/23 08:10:38.324
    Jul 10 08:10:38.432: INFO: Waiting up to 5m0s for pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001" in namespace "projected-2793" to be "running and ready"
    Jul 10 08:10:38.437: INFO: Pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001": Phase="Pending", Reason="", readiness=false. Elapsed: 4.510082ms
    Jul 10 08:10:38.437: INFO: The phase of Pod labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:10:40.443: INFO: Pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001": Phase="Running", Reason="", readiness=true. Elapsed: 2.010940159s
    Jul 10 08:10:40.443: INFO: The phase of Pod labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001 is Running (Ready = true)
    Jul 10 08:10:40.443: INFO: Pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001" satisfied condition "running and ready"
    Jul 10 08:10:40.986: INFO: Successfully updated pod "labelsupdate59cf3d7f-3333-437d-bbc4-c9b3dba94001"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:10:43.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2793" for this suite. 07/10/23 08:10:43.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:10:43.032
Jul 10 08:10:43.032: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename prestop 07/10/23 08:10:43.033
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:43.065
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:43.069
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-436 07/10/23 08:10:43.072
STEP: Waiting for pods to come up. 07/10/23 08:10:43.083
Jul 10 08:10:43.084: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-436" to be "running"
Jul 10 08:10:43.087: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.681489ms
Jul 10 08:10:45.092: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.008774607s
Jul 10 08:10:45.092: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-436 07/10/23 08:10:45.1
Jul 10 08:10:45.117: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-436" to be "running"
Jul 10 08:10:45.120: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.147649ms
Jul 10 08:10:47.126: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.009420505s
Jul 10 08:10:47.126: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 07/10/23 08:10:47.126
Jul 10 08:10:52.146: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 07/10/23 08:10:52.146
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Jul 10 08:10:52.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-436" for this suite. 07/10/23 08:10:52.206
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":58,"skipped":1185,"failed":0}
------------------------------
• [SLOW TEST] [9.191 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:10:43.032
    Jul 10 08:10:43.032: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename prestop 07/10/23 08:10:43.033
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:43.065
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:43.069
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-436 07/10/23 08:10:43.072
    STEP: Waiting for pods to come up. 07/10/23 08:10:43.083
    Jul 10 08:10:43.084: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-436" to be "running"
    Jul 10 08:10:43.087: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.681489ms
    Jul 10 08:10:45.092: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.008774607s
    Jul 10 08:10:45.092: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-436 07/10/23 08:10:45.1
    Jul 10 08:10:45.117: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-436" to be "running"
    Jul 10 08:10:45.120: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.147649ms
    Jul 10 08:10:47.126: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.009420505s
    Jul 10 08:10:47.126: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 07/10/23 08:10:47.126
    Jul 10 08:10:52.146: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 07/10/23 08:10:52.146
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Jul 10 08:10:52.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-436" for this suite. 07/10/23 08:10:52.206
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:10:52.223
Jul 10 08:10:52.223: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:10:52.224
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:52.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:52.252
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 08:10:52.255
Jul 10 08:10:52.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6586 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Jul 10 08:10:52.348: INFO: stderr: ""
Jul 10 08:10:52.348: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 07/10/23 08:10:52.348
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Jul 10 08:10:52.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6586 delete pods e2e-test-httpd-pod'
Jul 10 08:10:55.285: INFO: stderr: ""
Jul 10 08:10:55.285: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:10:55.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6586" for this suite. 07/10/23 08:10:55.291
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":59,"skipped":1186,"failed":0}
------------------------------
• [3.076 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:10:52.223
    Jul 10 08:10:52.223: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:10:52.224
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:52.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:52.252
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 08:10:52.255
    Jul 10 08:10:52.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6586 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Jul 10 08:10:52.348: INFO: stderr: ""
    Jul 10 08:10:52.348: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 07/10/23 08:10:52.348
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Jul 10 08:10:52.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-6586 delete pods e2e-test-httpd-pod'
    Jul 10 08:10:55.285: INFO: stderr: ""
    Jul 10 08:10:55.285: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:10:55.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6586" for this suite. 07/10/23 08:10:55.291
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:10:55.301
Jul 10 08:10:55.302: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 08:10:55.303
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:55.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:55.336
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 07/10/23 08:10:55.344
Jul 10 08:10:55.359: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7350" to be "running and ready"
Jul 10 08:10:55.363: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.760861ms
Jul 10 08:10:55.363: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:10:57.369: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.010253494s
Jul 10 08:10:57.369: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jul 10 08:10:57.369: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 07/10/23 08:10:57.373
Jul 10 08:10:57.382: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-7350" to be "running and ready"
Jul 10 08:10:57.387: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.28795ms
Jul 10 08:10:57.387: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:10:59.397: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.014553302s
Jul 10 08:10:59.397: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Jul 10 08:10:59.397: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 07/10/23 08:10:59.403
STEP: delete the pod with lifecycle hook 07/10/23 08:10:59.431
Jul 10 08:10:59.458: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 10 08:10:59.464: INFO: Pod pod-with-poststart-http-hook still exists
Jul 10 08:11:01.465: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 10 08:11:01.487: INFO: Pod pod-with-poststart-http-hook still exists
Jul 10 08:11:03.465: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 10 08:11:03.470: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jul 10 08:11:03.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7350" for this suite. 07/10/23 08:11:03.476
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":60,"skipped":1213,"failed":0}
------------------------------
• [SLOW TEST] [8.193 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:10:55.301
    Jul 10 08:10:55.302: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 08:10:55.303
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:10:55.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:10:55.336
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 07/10/23 08:10:55.344
    Jul 10 08:10:55.359: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7350" to be "running and ready"
    Jul 10 08:10:55.363: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.760861ms
    Jul 10 08:10:55.363: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:10:57.369: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.010253494s
    Jul 10 08:10:57.369: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jul 10 08:10:57.369: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 07/10/23 08:10:57.373
    Jul 10 08:10:57.382: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-7350" to be "running and ready"
    Jul 10 08:10:57.387: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.28795ms
    Jul 10 08:10:57.387: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:10:59.397: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.014553302s
    Jul 10 08:10:59.397: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Jul 10 08:10:59.397: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 07/10/23 08:10:59.403
    STEP: delete the pod with lifecycle hook 07/10/23 08:10:59.431
    Jul 10 08:10:59.458: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jul 10 08:10:59.464: INFO: Pod pod-with-poststart-http-hook still exists
    Jul 10 08:11:01.465: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jul 10 08:11:01.487: INFO: Pod pod-with-poststart-http-hook still exists
    Jul 10 08:11:03.465: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jul 10 08:11:03.470: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jul 10 08:11:03.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7350" for this suite. 07/10/23 08:11:03.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:11:03.497
Jul 10 08:11:03.497: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:11:03.498
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:03.527
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:03.531
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 07/10/23 08:11:03.534
Jul 10 08:11:03.546: INFO: Waiting up to 5m0s for pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1" in namespace "emptydir-8640" to be "Succeeded or Failed"
Jul 10 08:11:03.551: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.220517ms
Jul 10 08:11:05.558: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011967218s
Jul 10 08:11:07.558: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011873287s
STEP: Saw pod success 07/10/23 08:11:07.558
Jul 10 08:11:07.558: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1" satisfied condition "Succeeded or Failed"
Jul 10 08:11:07.566: INFO: Trying to get logs from node 10-62-109-100.test pod pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1 container test-container: <nil>
STEP: delete the pod 07/10/23 08:11:07.574
Jul 10 08:11:07.599: INFO: Waiting for pod pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1 to disappear
Jul 10 08:11:07.615: INFO: Pod pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:11:07.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8640" for this suite. 07/10/23 08:11:07.62
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":61,"skipped":1239,"failed":0}
------------------------------
• [4.137 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:11:03.497
    Jul 10 08:11:03.497: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:11:03.498
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:03.527
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:03.531
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 07/10/23 08:11:03.534
    Jul 10 08:11:03.546: INFO: Waiting up to 5m0s for pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1" in namespace "emptydir-8640" to be "Succeeded or Failed"
    Jul 10 08:11:03.551: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.220517ms
    Jul 10 08:11:05.558: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011967218s
    Jul 10 08:11:07.558: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011873287s
    STEP: Saw pod success 07/10/23 08:11:07.558
    Jul 10 08:11:07.558: INFO: Pod "pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1" satisfied condition "Succeeded or Failed"
    Jul 10 08:11:07.566: INFO: Trying to get logs from node 10-62-109-100.test pod pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:11:07.574
    Jul 10 08:11:07.599: INFO: Waiting for pod pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1 to disappear
    Jul 10 08:11:07.615: INFO: Pod pod-fd6d8c2b-d063-4efe-9347-cc6c2cac39b1 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:11:07.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8640" for this suite. 07/10/23 08:11:07.62
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:11:07.635
Jul 10 08:11:07.635: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replication-controller 07/10/23 08:11:07.636
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:07.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:07.665
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 07/10/23 08:11:07.668
STEP: When the matched label of one of its pods change 07/10/23 08:11:07.768
Jul 10 08:11:07.773: INFO: Pod name pod-release: Found 0 pods out of 1
Jul 10 08:11:12.785: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 07/10/23 08:11:12.802
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jul 10 08:11:13.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6293" for this suite. 07/10/23 08:11:13.818
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":62,"skipped":1244,"failed":0}
------------------------------
• [SLOW TEST] [6.203 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:11:07.635
    Jul 10 08:11:07.635: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replication-controller 07/10/23 08:11:07.636
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:07.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:07.665
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 07/10/23 08:11:07.668
    STEP: When the matched label of one of its pods change 07/10/23 08:11:07.768
    Jul 10 08:11:07.773: INFO: Pod name pod-release: Found 0 pods out of 1
    Jul 10 08:11:12.785: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 07/10/23 08:11:12.802
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jul 10 08:11:13.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-6293" for this suite. 07/10/23 08:11:13.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:11:13.843
Jul 10 08:11:13.843: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:11:13.845
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:13.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:13.88
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 07/10/23 08:11:13.883
Jul 10 08:11:13.899: INFO: Waiting up to 5m0s for pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b" in namespace "downward-api-8959" to be "running and ready"
Jul 10 08:11:13.903: INFO: Pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.907233ms
Jul 10 08:11:13.903: INFO: The phase of Pod labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:11:15.909: INFO: Pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010585771s
Jul 10 08:11:15.909: INFO: The phase of Pod labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b is Running (Ready = true)
Jul 10 08:11:15.909: INFO: Pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b" satisfied condition "running and ready"
Jul 10 08:11:16.461: INFO: Successfully updated pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 08:11:20.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8959" for this suite. 07/10/23 08:11:20.509
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":63,"skipped":1325,"failed":0}
------------------------------
• [SLOW TEST] [6.677 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:11:13.843
    Jul 10 08:11:13.843: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:11:13.845
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:13.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:13.88
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 07/10/23 08:11:13.883
    Jul 10 08:11:13.899: INFO: Waiting up to 5m0s for pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b" in namespace "downward-api-8959" to be "running and ready"
    Jul 10 08:11:13.903: INFO: Pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.907233ms
    Jul 10 08:11:13.903: INFO: The phase of Pod labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:11:15.909: INFO: Pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010585771s
    Jul 10 08:11:15.909: INFO: The phase of Pod labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b is Running (Ready = true)
    Jul 10 08:11:15.909: INFO: Pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b" satisfied condition "running and ready"
    Jul 10 08:11:16.461: INFO: Successfully updated pod "labelsupdate3a636745-1509-4ca4-9aaa-fe38ae7ccb5b"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 08:11:20.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8959" for this suite. 07/10/23 08:11:20.509
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:11:20.52
Jul 10 08:11:20.520: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:11:20.521
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:20.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:20.561
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-2700bbf1-5e87-4656-824e-83aafa463b77 07/10/23 08:11:20.564
STEP: Creating a pod to test consume secrets 07/10/23 08:11:20.571
Jul 10 08:11:20.584: INFO: Waiting up to 5m0s for pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a" in namespace "secrets-8579" to be "Succeeded or Failed"
Jul 10 08:11:20.588: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320426ms
Jul 10 08:11:22.593: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009173518s
Jul 10 08:11:24.595: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011109305s
Jul 10 08:11:26.597: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013026201s
STEP: Saw pod success 07/10/23 08:11:26.597
Jul 10 08:11:26.597: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a" satisfied condition "Succeeded or Failed"
Jul 10 08:11:26.602: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:11:26.612
Jul 10 08:11:26.652: INFO: Waiting for pod pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a to disappear
Jul 10 08:11:26.662: INFO: Pod pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:11:26.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8579" for this suite. 07/10/23 08:11:26.667
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":64,"skipped":1326,"failed":0}
------------------------------
• [SLOW TEST] [6.159 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:11:20.52
    Jul 10 08:11:20.520: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:11:20.521
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:20.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:20.561
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-2700bbf1-5e87-4656-824e-83aafa463b77 07/10/23 08:11:20.564
    STEP: Creating a pod to test consume secrets 07/10/23 08:11:20.571
    Jul 10 08:11:20.584: INFO: Waiting up to 5m0s for pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a" in namespace "secrets-8579" to be "Succeeded or Failed"
    Jul 10 08:11:20.588: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320426ms
    Jul 10 08:11:22.593: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009173518s
    Jul 10 08:11:24.595: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011109305s
    Jul 10 08:11:26.597: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013026201s
    STEP: Saw pod success 07/10/23 08:11:26.597
    Jul 10 08:11:26.597: INFO: Pod "pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a" satisfied condition "Succeeded or Failed"
    Jul 10 08:11:26.602: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:11:26.612
    Jul 10 08:11:26.652: INFO: Waiting for pod pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a to disappear
    Jul 10 08:11:26.662: INFO: Pod pod-secrets-83421eef-462e-46e0-9bd6-3b4a77dc0f2a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:11:26.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8579" for this suite. 07/10/23 08:11:26.667
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:11:26.68
Jul 10 08:11:26.680: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename containers 07/10/23 08:11:26.681
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:26.709
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:26.714
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 07/10/23 08:11:26.716
Jul 10 08:11:26.730: INFO: Waiting up to 5m0s for pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027" in namespace "containers-6645" to be "Succeeded or Failed"
Jul 10 08:11:26.733: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708412ms
Jul 10 08:11:28.740: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010356599s
Jul 10 08:11:30.739: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009852544s
Jul 10 08:11:32.740: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010394842s
STEP: Saw pod success 07/10/23 08:11:32.74
Jul 10 08:11:32.740: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027" satisfied condition "Succeeded or Failed"
Jul 10 08:11:32.744: INFO: Trying to get logs from node 10-62-109-100.test pod client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:11:32.755
Jul 10 08:11:32.780: INFO: Waiting for pod client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027 to disappear
Jul 10 08:11:32.788: INFO: Pod client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jul 10 08:11:32.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6645" for this suite. 07/10/23 08:11:32.793
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":65,"skipped":1333,"failed":0}
------------------------------
• [SLOW TEST] [6.133 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:11:26.68
    Jul 10 08:11:26.680: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename containers 07/10/23 08:11:26.681
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:26.709
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:26.714
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 07/10/23 08:11:26.716
    Jul 10 08:11:26.730: INFO: Waiting up to 5m0s for pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027" in namespace "containers-6645" to be "Succeeded or Failed"
    Jul 10 08:11:26.733: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708412ms
    Jul 10 08:11:28.740: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010356599s
    Jul 10 08:11:30.739: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009852544s
    Jul 10 08:11:32.740: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010394842s
    STEP: Saw pod success 07/10/23 08:11:32.74
    Jul 10 08:11:32.740: INFO: Pod "client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027" satisfied condition "Succeeded or Failed"
    Jul 10 08:11:32.744: INFO: Trying to get logs from node 10-62-109-100.test pod client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:11:32.755
    Jul 10 08:11:32.780: INFO: Waiting for pod client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027 to disappear
    Jul 10 08:11:32.788: INFO: Pod client-containers-3c49d854-6e77-4e21-b4d4-6b6bbe133027 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jul 10 08:11:32.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6645" for this suite. 07/10/23 08:11:32.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:11:32.816
Jul 10 08:11:32.816: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 08:11:32.817
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:32.853
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:32.862
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 07/10/23 08:11:32.865
Jul 10 08:11:32.867: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 07/10/23 08:11:46.043
Jul 10 08:11:46.044: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:11:50.596: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:12:03.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3503" for this suite. 07/10/23 08:12:03.295
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":66,"skipped":1383,"failed":0}
------------------------------
• [SLOW TEST] [30.490 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:11:32.816
    Jul 10 08:11:32.816: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 08:11:32.817
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:11:32.853
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:11:32.862
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 07/10/23 08:11:32.865
    Jul 10 08:11:32.867: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 07/10/23 08:11:46.043
    Jul 10 08:11:46.044: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:11:50.596: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:12:03.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3503" for this suite. 07/10/23 08:12:03.295
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:12:03.307
Jul 10 08:12:03.307: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 08:12:03.308
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:12:03.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:12:03.342
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 07/10/23 08:12:03.346
STEP: Wait for the Deployment to create new ReplicaSet 07/10/23 08:12:03.355
STEP: delete the deployment 07/10/23 08:12:03.867
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 07/10/23 08:12:03.882
STEP: Gathering metrics 07/10/23 08:12:04.447
W0710 08:12:04.455995      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul 10 08:12:04.456: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 08:12:04.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5512" for this suite. 07/10/23 08:12:04.46
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":67,"skipped":1383,"failed":0}
------------------------------
• [1.164 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:12:03.307
    Jul 10 08:12:03.307: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 08:12:03.308
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:12:03.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:12:03.342
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 07/10/23 08:12:03.346
    STEP: Wait for the Deployment to create new ReplicaSet 07/10/23 08:12:03.355
    STEP: delete the deployment 07/10/23 08:12:03.867
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 07/10/23 08:12:03.882
    STEP: Gathering metrics 07/10/23 08:12:04.447
    W0710 08:12:04.455995      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jul 10 08:12:04.456: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 08:12:04.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5512" for this suite. 07/10/23 08:12:04.46
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:12:04.472
Jul 10 08:12:04.472: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 08:12:04.474
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:12:04.559
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:12:04.562
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 07/10/23 08:12:04.593
STEP: delete the rc 07/10/23 08:12:09.645
STEP: wait for the rc to be deleted 07/10/23 08:12:09.718
Jul 10 08:12:10.768: INFO: 80 pods remaining
Jul 10 08:12:10.768: INFO: 80 pods has nil DeletionTimestamp
Jul 10 08:12:10.768: INFO: 
Jul 10 08:12:11.816: INFO: 73 pods remaining
Jul 10 08:12:11.816: INFO: 72 pods has nil DeletionTimestamp
Jul 10 08:12:11.816: INFO: 
Jul 10 08:12:12.771: INFO: 58 pods remaining
Jul 10 08:12:12.771: INFO: 58 pods has nil DeletionTimestamp
Jul 10 08:12:12.771: INFO: 
Jul 10 08:12:13.806: INFO: 40 pods remaining
Jul 10 08:12:13.806: INFO: 40 pods has nil DeletionTimestamp
Jul 10 08:12:13.806: INFO: 
Jul 10 08:12:14.786: INFO: 31 pods remaining
Jul 10 08:12:14.786: INFO: 31 pods has nil DeletionTimestamp
Jul 10 08:12:14.786: INFO: 
Jul 10 08:12:15.735: INFO: 19 pods remaining
Jul 10 08:12:15.735: INFO: 19 pods has nil DeletionTimestamp
Jul 10 08:12:15.735: INFO: 
STEP: Gathering metrics 07/10/23 08:12:16.728
W0710 08:12:16.737892      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul 10 08:12:16.737: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 08:12:16.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-808" for this suite. 07/10/23 08:12:16.749
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":68,"skipped":1395,"failed":0}
------------------------------
• [SLOW TEST] [12.309 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:12:04.472
    Jul 10 08:12:04.472: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 08:12:04.474
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:12:04.559
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:12:04.562
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 07/10/23 08:12:04.593
    STEP: delete the rc 07/10/23 08:12:09.645
    STEP: wait for the rc to be deleted 07/10/23 08:12:09.718
    Jul 10 08:12:10.768: INFO: 80 pods remaining
    Jul 10 08:12:10.768: INFO: 80 pods has nil DeletionTimestamp
    Jul 10 08:12:10.768: INFO: 
    Jul 10 08:12:11.816: INFO: 73 pods remaining
    Jul 10 08:12:11.816: INFO: 72 pods has nil DeletionTimestamp
    Jul 10 08:12:11.816: INFO: 
    Jul 10 08:12:12.771: INFO: 58 pods remaining
    Jul 10 08:12:12.771: INFO: 58 pods has nil DeletionTimestamp
    Jul 10 08:12:12.771: INFO: 
    Jul 10 08:12:13.806: INFO: 40 pods remaining
    Jul 10 08:12:13.806: INFO: 40 pods has nil DeletionTimestamp
    Jul 10 08:12:13.806: INFO: 
    Jul 10 08:12:14.786: INFO: 31 pods remaining
    Jul 10 08:12:14.786: INFO: 31 pods has nil DeletionTimestamp
    Jul 10 08:12:14.786: INFO: 
    Jul 10 08:12:15.735: INFO: 19 pods remaining
    Jul 10 08:12:15.735: INFO: 19 pods has nil DeletionTimestamp
    Jul 10 08:12:15.735: INFO: 
    STEP: Gathering metrics 07/10/23 08:12:16.728
    W0710 08:12:16.737892      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jul 10 08:12:16.737: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 08:12:16.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-808" for this suite. 07/10/23 08:12:16.749
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:12:16.785
Jul 10 08:12:16.791: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename cronjob 07/10/23 08:12:16.792
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:12:16.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:12:16.85
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 07/10/23 08:12:16.853
STEP: Ensuring no jobs are scheduled 07/10/23 08:12:16.861
STEP: Ensuring no job exists by listing jobs explicitly 07/10/23 08:17:16.87
STEP: Removing cronjob 07/10/23 08:17:16.874
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jul 10 08:17:16.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9902" for this suite. 07/10/23 08:17:16.889
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":69,"skipped":1447,"failed":0}
------------------------------
• [SLOW TEST] [300.113 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:12:16.785
    Jul 10 08:12:16.791: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename cronjob 07/10/23 08:12:16.792
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:12:16.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:12:16.85
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 07/10/23 08:12:16.853
    STEP: Ensuring no jobs are scheduled 07/10/23 08:12:16.861
    STEP: Ensuring no job exists by listing jobs explicitly 07/10/23 08:17:16.87
    STEP: Removing cronjob 07/10/23 08:17:16.874
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jul 10 08:17:16.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9902" for this suite. 07/10/23 08:17:16.889
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:17:16.903
Jul 10 08:17:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 08:17:16.905
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:16.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:16.945
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Jul 10 08:17:16.947: INFO: Creating simple deployment test-new-deployment
Jul 10 08:17:16.965: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource 07/10/23 08:17:18.985
STEP: updating a scale subresource 07/10/23 08:17:18.989
STEP: verifying the deployment Spec.Replicas was modified 07/10/23 08:17:19.003
STEP: Patch a scale subresource 07/10/23 08:17:19.008
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 08:17:19.067: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-2929  0c407e50-bd97-48e3-8b94-122386650151 76134 3 2023-07-10 08:17:16 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-07-10 08:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512028 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-07-10 08:17:18 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-07-10 08:17:18 +0000 UTC,LastTransitionTime:2023-07-10 08:17:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul 10 08:17:19.089: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-2929  74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 76142 3 2023-07-10 08:17:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 0c407e50-bd97-48e3-8b94-122386650151 0xc003512467 0xc003512468}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0c407e50-bd97-48e3-8b94-122386650151\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035124f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul 10 08:17:19.093: INFO: Pod "test-new-deployment-845c8977d9-bf5l2" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-bf5l2 test-new-deployment-845c8977d9- deployment-2929  43e7dbbc-bc96-42d1-8b94-2d9c7ac688a4 76144 0 2023-07-10 08:17:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 0xc003512927 0xc003512928}] [] [{kube-controller-manager Update v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74d8c63f-0fb5-4b5b-b870-bc2c2be0a044\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-slh4n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-slh4n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 08:17:19.094: INFO: Pod "test-new-deployment-845c8977d9-pmh66" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-pmh66 test-new-deployment-845c8977d9- deployment-2929  b587c193-26d1-458a-9e93-d79c8d7d3c00 76129 0 2023-07-10 08:17:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7ea4d932edc0f1de130f2bc6bf2b4ef73b1beab80f85e2b05233a5d44501172d cni.projectcalico.org/podIP:192.168.172.37/32 cni.projectcalico.org/podIPs:192.168.172.37/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 0xc003512a87 0xc003512a88}] [] [{kube-controller-manager Update v1 2023-07-10 08:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74d8c63f-0fb5-4b5b-b870-bc2c2be0a044\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:17:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hl8v9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hl8v9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.37,StartTime:2023-07-10 08:17:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:17:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://21be9e3f21735c5d1ee26f7c5ac7fdc1b98862932454c9887a703ba40d783588,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 08:17:19.094: INFO: Pod "test-new-deployment-845c8977d9-xw9lt" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-xw9lt test-new-deployment-845c8977d9- deployment-2929  a71ab1f7-b6c8-4db4-8b5a-4acd4f8857b5 76137 0 2023-07-10 08:17:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 0xc003512c97 0xc003512c98}] [] [{kube-controller-manager Update v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74d8c63f-0fb5-4b5b-b870-bc2c2be0a044\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4pn5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4pn5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 08:17:19.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2929" for this suite. 07/10/23 08:17:19.112
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":70,"skipped":1528,"failed":0}
------------------------------
• [2.231 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:17:16.903
    Jul 10 08:17:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 08:17:16.905
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:16.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:16.945
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Jul 10 08:17:16.947: INFO: Creating simple deployment test-new-deployment
    Jul 10 08:17:16.965: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
    STEP: getting scale subresource 07/10/23 08:17:18.985
    STEP: updating a scale subresource 07/10/23 08:17:18.989
    STEP: verifying the deployment Spec.Replicas was modified 07/10/23 08:17:19.003
    STEP: Patch a scale subresource 07/10/23 08:17:19.008
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 08:17:19.067: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-2929  0c407e50-bd97-48e3-8b94-122386650151 76134 3 2023-07-10 08:17:16 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-07-10 08:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512028 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-07-10 08:17:18 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-07-10 08:17:18 +0000 UTC,LastTransitionTime:2023-07-10 08:17:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jul 10 08:17:19.089: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-2929  74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 76142 3 2023-07-10 08:17:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 0c407e50-bd97-48e3-8b94-122386650151 0xc003512467 0xc003512468}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0c407e50-bd97-48e3-8b94-122386650151\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035124f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 08:17:19.093: INFO: Pod "test-new-deployment-845c8977d9-bf5l2" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-bf5l2 test-new-deployment-845c8977d9- deployment-2929  43e7dbbc-bc96-42d1-8b94-2d9c7ac688a4 76144 0 2023-07-10 08:17:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 0xc003512927 0xc003512928}] [] [{kube-controller-manager Update v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74d8c63f-0fb5-4b5b-b870-bc2c2be0a044\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-slh4n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-slh4n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 08:17:19.094: INFO: Pod "test-new-deployment-845c8977d9-pmh66" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-pmh66 test-new-deployment-845c8977d9- deployment-2929  b587c193-26d1-458a-9e93-d79c8d7d3c00 76129 0 2023-07-10 08:17:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7ea4d932edc0f1de130f2bc6bf2b4ef73b1beab80f85e2b05233a5d44501172d cni.projectcalico.org/podIP:192.168.172.37/32 cni.projectcalico.org/podIPs:192.168.172.37/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 0xc003512a87 0xc003512a88}] [] [{kube-controller-manager Update v1 2023-07-10 08:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74d8c63f-0fb5-4b5b-b870-bc2c2be0a044\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:17:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hl8v9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hl8v9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.37,StartTime:2023-07-10 08:17:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:17:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://21be9e3f21735c5d1ee26f7c5ac7fdc1b98862932454c9887a703ba40d783588,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 08:17:19.094: INFO: Pod "test-new-deployment-845c8977d9-xw9lt" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-xw9lt test-new-deployment-845c8977d9- deployment-2929  a71ab1f7-b6c8-4db4-8b5a-4acd4f8857b5 76137 0 2023-07-10 08:17:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 74d8c63f-0fb5-4b5b-b870-bc2c2be0a044 0xc003512c97 0xc003512c98}] [] [{kube-controller-manager Update v1 2023-07-10 08:17:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74d8c63f-0fb5-4b5b-b870-bc2c2be0a044\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4pn5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4pn5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:17:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 08:17:19.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2929" for this suite. 07/10/23 08:17:19.112
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:17:19.139
Jul 10 08:17:19.139: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:17:19.14
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:19.201
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:19.203
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:17:19.245
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:17:20.071
STEP: Deploying the webhook pod 07/10/23 08:17:20.084
STEP: Wait for the deployment to be ready 07/10/23 08:17:20.16
Jul 10 08:17:20.166: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 07/10/23 08:17:22.182
STEP: Verifying the service has paired with the endpoint 07/10/23 08:17:22.204
Jul 10 08:17:23.204: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 07/10/23 08:17:23.21
STEP: create a configmap that should be updated by the webhook 07/10/23 08:17:23.23
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:17:23.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2776" for this suite. 07/10/23 08:17:23.269
STEP: Destroying namespace "webhook-2776-markers" for this suite. 07/10/23 08:17:23.278
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":71,"skipped":1560,"failed":0}
------------------------------
• [4.224 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:17:19.139
    Jul 10 08:17:19.139: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:17:19.14
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:19.201
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:19.203
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:17:19.245
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:17:20.071
    STEP: Deploying the webhook pod 07/10/23 08:17:20.084
    STEP: Wait for the deployment to be ready 07/10/23 08:17:20.16
    Jul 10 08:17:20.166: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 07/10/23 08:17:22.182
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:17:22.204
    Jul 10 08:17:23.204: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 07/10/23 08:17:23.21
    STEP: create a configmap that should be updated by the webhook 07/10/23 08:17:23.23
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:17:23.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2776" for this suite. 07/10/23 08:17:23.269
    STEP: Destroying namespace "webhook-2776-markers" for this suite. 07/10/23 08:17:23.278
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:17:23.364
Jul 10 08:17:23.364: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 08:17:23.365
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:23.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:23.415
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Jul 10 08:17:23.466: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a1e749c4-d62e-4518-8ca1-b9a1998b6ec0", Controller:(*bool)(0xc000c5e426), BlockOwnerDeletion:(*bool)(0xc000c5e427)}}
Jul 10 08:17:23.486: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2ef86190-22b5-43a9-a1ca-d0e2123695cb", Controller:(*bool)(0xc000c5e956), BlockOwnerDeletion:(*bool)(0xc000c5e957)}}
Jul 10 08:17:23.504: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b0528b70-4517-4d08-93b4-9de7b4bc39a7", Controller:(*bool)(0xc000c5f5c6), BlockOwnerDeletion:(*bool)(0xc000c5f5c7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 08:17:28.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7419" for this suite. 07/10/23 08:17:28.53
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":72,"skipped":1580,"failed":0}
------------------------------
• [SLOW TEST] [5.184 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:17:23.364
    Jul 10 08:17:23.364: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 08:17:23.365
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:23.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:23.415
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Jul 10 08:17:23.466: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a1e749c4-d62e-4518-8ca1-b9a1998b6ec0", Controller:(*bool)(0xc000c5e426), BlockOwnerDeletion:(*bool)(0xc000c5e427)}}
    Jul 10 08:17:23.486: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2ef86190-22b5-43a9-a1ca-d0e2123695cb", Controller:(*bool)(0xc000c5e956), BlockOwnerDeletion:(*bool)(0xc000c5e957)}}
    Jul 10 08:17:23.504: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b0528b70-4517-4d08-93b4-9de7b4bc39a7", Controller:(*bool)(0xc000c5f5c6), BlockOwnerDeletion:(*bool)(0xc000c5f5c7)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 08:17:28.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7419" for this suite. 07/10/23 08:17:28.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:17:28.549
Jul 10 08:17:28.549: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-preemption 07/10/23 08:17:28.55
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:28.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:28.611
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul 10 08:17:28.730: INFO: Waiting up to 1m0s for all nodes to be ready
Jul 10 08:18:28.760: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 07/10/23 08:18:28.764
Jul 10 08:18:28.798: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jul 10 08:18:28.809: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jul 10 08:18:28.847: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jul 10 08:18:28.933: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jul 10 08:18:28.963: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jul 10 08:18:28.984: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 07/10/23 08:18:28.984
Jul 10 08:18:28.984: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2693" to be "running"
Jul 10 08:18:28.989: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197648ms
Jul 10 08:18:30.997: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012927837s
Jul 10 08:18:32.996: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011380651s
Jul 10 08:18:34.995: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010720887s
Jul 10 08:18:36.994: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009650596s
Jul 10 08:18:39.001: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.016776666s
Jul 10 08:18:39.001: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Jul 10 08:18:39.001: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
Jul 10 08:18:39.005: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.879807ms
Jul 10 08:18:39.005: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:18:39.005: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
Jul 10 08:18:39.009: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.480667ms
Jul 10 08:18:39.009: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:18:39.009: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
Jul 10 08:18:39.012: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.123508ms
Jul 10 08:18:39.012: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:18:39.012: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
Jul 10 08:18:39.015: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.376864ms
Jul 10 08:18:39.015: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:18:39.015: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
Jul 10 08:18:39.018: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.971612ms
Jul 10 08:18:39.018: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 07/10/23 08:18:39.018
Jul 10 08:18:39.034: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Jul 10 08:18:39.038: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.425279ms
Jul 10 08:18:41.044: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009506019s
Jul 10 08:18:43.046: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0118454s
Jul 10 08:18:45.043: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.008168304s
Jul 10 08:18:45.043: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:18:45.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2693" for this suite. 07/10/23 08:18:45.1
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":73,"skipped":1586,"failed":0}
------------------------------
• [SLOW TEST] [76.622 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:17:28.549
    Jul 10 08:17:28.549: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-preemption 07/10/23 08:17:28.55
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:17:28.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:17:28.611
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jul 10 08:17:28.730: INFO: Waiting up to 1m0s for all nodes to be ready
    Jul 10 08:18:28.760: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 07/10/23 08:18:28.764
    Jul 10 08:18:28.798: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Jul 10 08:18:28.809: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Jul 10 08:18:28.847: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Jul 10 08:18:28.933: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Jul 10 08:18:28.963: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Jul 10 08:18:28.984: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 07/10/23 08:18:28.984
    Jul 10 08:18:28.984: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2693" to be "running"
    Jul 10 08:18:28.989: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197648ms
    Jul 10 08:18:30.997: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012927837s
    Jul 10 08:18:32.996: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011380651s
    Jul 10 08:18:34.995: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010720887s
    Jul 10 08:18:36.994: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009650596s
    Jul 10 08:18:39.001: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.016776666s
    Jul 10 08:18:39.001: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Jul 10 08:18:39.001: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
    Jul 10 08:18:39.005: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.879807ms
    Jul 10 08:18:39.005: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:18:39.005: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
    Jul 10 08:18:39.009: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.480667ms
    Jul 10 08:18:39.009: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:18:39.009: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
    Jul 10 08:18:39.012: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.123508ms
    Jul 10 08:18:39.012: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:18:39.012: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
    Jul 10 08:18:39.015: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.376864ms
    Jul 10 08:18:39.015: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:18:39.015: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2693" to be "running"
    Jul 10 08:18:39.018: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.971612ms
    Jul 10 08:18:39.018: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 07/10/23 08:18:39.018
    Jul 10 08:18:39.034: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Jul 10 08:18:39.038: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.425279ms
    Jul 10 08:18:41.044: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009506019s
    Jul 10 08:18:43.046: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0118454s
    Jul 10 08:18:45.043: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.008168304s
    Jul 10 08:18:45.043: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:18:45.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2693" for this suite. 07/10/23 08:18:45.1
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:18:45.171
Jul 10 08:18:45.171: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 08:18:45.172
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:18:45.203
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:18:45.205
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Jul 10 08:18:45.207: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: creating the pod 07/10/23 08:18:45.208
STEP: submitting the pod to kubernetes 07/10/23 08:18:45.208
Jul 10 08:18:45.253: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84" in namespace "pods-9724" to be "running and ready"
Jul 10 08:18:45.258: INFO: Pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803677ms
Jul 10 08:18:45.258: INFO: The phase of Pod pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:18:47.263: INFO: Pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84": Phase="Running", Reason="", readiness=true. Elapsed: 2.009947054s
Jul 10 08:18:47.263: INFO: The phase of Pod pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84 is Running (Ready = true)
Jul 10 08:18:47.263: INFO: Pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 08:18:47.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9724" for this suite. 07/10/23 08:18:47.361
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":74,"skipped":1586,"failed":0}
------------------------------
• [2.204 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:18:45.171
    Jul 10 08:18:45.171: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 08:18:45.172
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:18:45.203
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:18:45.205
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Jul 10 08:18:45.207: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: creating the pod 07/10/23 08:18:45.208
    STEP: submitting the pod to kubernetes 07/10/23 08:18:45.208
    Jul 10 08:18:45.253: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84" in namespace "pods-9724" to be "running and ready"
    Jul 10 08:18:45.258: INFO: Pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803677ms
    Jul 10 08:18:45.258: INFO: The phase of Pod pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:18:47.263: INFO: Pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84": Phase="Running", Reason="", readiness=true. Elapsed: 2.009947054s
    Jul 10 08:18:47.263: INFO: The phase of Pod pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84 is Running (Ready = true)
    Jul 10 08:18:47.263: INFO: Pod "pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 08:18:47.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9724" for this suite. 07/10/23 08:18:47.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:18:47.376
Jul 10 08:18:47.376: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-pred 07/10/23 08:18:47.377
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:18:47.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:18:47.424
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul 10 08:18:47.426: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 10 08:18:47.437: INFO: Waiting for terminating namespaces to be deleted...
Jul 10 08:18:47.441: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-100.test before test
Jul 10 08:18:47.449: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 08:18:47.449: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:18:47.449: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container nfs-attacher ready: true, restart count 0
Jul 10 08:18:47.449: INFO: 	Container nfs-provisioner ready: true, restart count 0
Jul 10 08:18:47.449: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:18:47.449: INFO: 	Container snapshotter-controller ready: true, restart count 0
Jul 10 08:18:47.449: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:18:47.449: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:18:47.449: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container metrics-server ready: true, restart count 7
Jul 10 08:18:47.449: INFO: pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84 from pods-9724 started at 2023-07-10 08:18:44 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container main ready: true, restart count 0
Jul 10 08:18:47.449: INFO: pod0-1-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:36 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container pod0-1-sched-preemption-medium-priority ready: true, restart count 0
Jul 10 08:18:47.449: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 10 08:18:47.449: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.449: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:18:47.449: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 08:18:47.449: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-101.test before test
Jul 10 08:18:47.458: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 08:18:47.458: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:18:47.458: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 08:18:47.458: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container coredns ready: true, restart count 0
Jul 10 08:18:47.458: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:18:47.458: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:18:47.458: INFO: pod1-0-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:35 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container pod1-0-sched-preemption-medium-priority ready: true, restart count 0
Jul 10 08:18:47.458: INFO: pod1-1-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:35 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container pod1-1-sched-preemption-medium-priority ready: true, restart count 0
Jul 10 08:18:47.458: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.458: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:18:47.458: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 08:18:47.458: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-102.test before test
Jul 10 08:18:47.468: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:18:47.468: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 08:18:47.468: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container coredns ready: true, restart count 0
Jul 10 08:18:47.468: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:18:47.468: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:18:47.468: INFO: pod2-0-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:33 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container pod2-0-sched-preemption-medium-priority ready: true, restart count 0
Jul 10 08:18:47.468: INFO: pod2-1-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:33 +0000 UTC (1 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container pod2-1-sched-preemption-medium-priority ready: true, restart count 0
Jul 10 08:18:47.468: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container e2e ready: true, restart count 0
Jul 10 08:18:47.468: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:18:47.468: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:18:47.468: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:18:47.468: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 07/10/23 08:18:47.468
Jul 10 08:18:47.488: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8735" to be "running"
Jul 10 08:18:47.491: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.996122ms
Jul 10 08:18:49.496: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.008871347s
Jul 10 08:18:49.497: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 07/10/23 08:18:49.501
STEP: Trying to apply a random label on the found node. 07/10/23 08:18:49.533
STEP: verifying the node has the label kubernetes.io/e2e-a84e42d9-ae1d-405c-80b2-38527c272b16 95 07/10/23 08:18:49.549
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 07/10/23 08:18:49.554
Jul 10 08:18:49.562: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-8735" to be "not pending"
Jul 10 08:18:49.567: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.227876ms
Jul 10 08:18:51.572: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.010088473s
Jul 10 08:18:51.572: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.62.109.100 on the node which pod4 resides and expect not scheduled 07/10/23 08:18:51.572
Jul 10 08:18:51.583: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-8735" to be "not pending"
Jul 10 08:18:51.596: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.750778ms
Jul 10 08:18:53.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019149496s
Jul 10 08:18:55.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01759633s
Jul 10 08:18:57.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020029821s
Jul 10 08:18:59.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017625834s
Jul 10 08:19:01.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019599399s
Jul 10 08:19:03.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019527588s
Jul 10 08:19:05.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019832043s
Jul 10 08:19:07.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.021681758s
Jul 10 08:19:09.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018072246s
Jul 10 08:19:11.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.017668909s
Jul 10 08:19:13.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.017945886s
Jul 10 08:19:15.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.017455641s
Jul 10 08:19:17.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.02103192s
Jul 10 08:19:19.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.017369634s
Jul 10 08:19:21.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.018003484s
Jul 10 08:19:23.600: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.016910654s
Jul 10 08:19:25.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018984144s
Jul 10 08:19:27.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.017418953s
Jul 10 08:19:29.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.018164934s
Jul 10 08:19:31.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.017582508s
Jul 10 08:19:33.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.017567764s
Jul 10 08:19:35.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.019661786s
Jul 10 08:19:37.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.017359892s
Jul 10 08:19:39.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.017833795s
Jul 10 08:19:41.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.017391377s
Jul 10 08:19:43.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01873582s
Jul 10 08:19:45.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.01949115s
Jul 10 08:19:47.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.019491644s
Jul 10 08:19:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.01899405s
Jul 10 08:19:51.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.01996455s
Jul 10 08:19:53.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.019133857s
Jul 10 08:19:55.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.018855892s
Jul 10 08:19:57.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.019810769s
Jul 10 08:19:59.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.019845391s
Jul 10 08:20:01.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.017243038s
Jul 10 08:20:03.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.019927859s
Jul 10 08:20:05.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.018958104s
Jul 10 08:20:07.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01769559s
Jul 10 08:20:09.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.01795045s
Jul 10 08:20:11.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.019491378s
Jul 10 08:20:13.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.018688029s
Jul 10 08:20:15.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.018620573s
Jul 10 08:20:17.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.019983292s
Jul 10 08:20:19.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.020091746s
Jul 10 08:20:21.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.019134898s
Jul 10 08:20:23.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.018930981s
Jul 10 08:20:25.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.018528674s
Jul 10 08:20:27.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.018027701s
Jul 10 08:20:29.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.017519143s
Jul 10 08:20:31.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.019207758s
Jul 10 08:20:33.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.017994515s
Jul 10 08:20:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.018617565s
Jul 10 08:20:37.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02013782s
Jul 10 08:20:39.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.01737252s
Jul 10 08:20:41.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.017855504s
Jul 10 08:20:43.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.019128956s
Jul 10 08:20:45.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017719004s
Jul 10 08:20:47.600: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.016666208s
Jul 10 08:20:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.018172837s
Jul 10 08:20:51.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017507288s
Jul 10 08:20:53.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.018689242s
Jul 10 08:20:55.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.018256575s
Jul 10 08:20:57.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.01897564s
Jul 10 08:20:59.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.018774556s
Jul 10 08:21:01.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.017328417s
Jul 10 08:21:03.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.019227671s
Jul 10 08:21:05.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.017694489s
Jul 10 08:21:07.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.019508298s
Jul 10 08:21:09.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.017386765s
Jul 10 08:21:11.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.019252838s
Jul 10 08:21:13.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.019242372s
Jul 10 08:21:15.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.018610917s
Jul 10 08:21:17.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.01917014s
Jul 10 08:21:19.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.018907308s
Jul 10 08:21:21.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.01844619s
Jul 10 08:21:23.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.018477705s
Jul 10 08:21:25.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.01840508s
Jul 10 08:21:27.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.018249253s
Jul 10 08:21:29.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.017818719s
Jul 10 08:21:31.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.018502567s
Jul 10 08:21:33.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.019762041s
Jul 10 08:21:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.018236331s
Jul 10 08:21:37.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.020592296s
Jul 10 08:21:39.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.018142757s
Jul 10 08:21:41.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.018417969s
Jul 10 08:21:43.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.021343474s
Jul 10 08:21:45.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.018824618s
Jul 10 08:21:47.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.020164837s
Jul 10 08:21:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.018377448s
Jul 10 08:21:51.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.019889877s
Jul 10 08:21:53.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.018749442s
Jul 10 08:21:55.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.018380946s
Jul 10 08:21:57.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.019198843s
Jul 10 08:21:59.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.018785343s
Jul 10 08:22:01.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.019092987s
Jul 10 08:22:03.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.018540471s
Jul 10 08:22:05.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.018092237s
Jul 10 08:22:07.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.01877595s
Jul 10 08:22:09.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.018576128s
Jul 10 08:22:11.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.019633414s
Jul 10 08:22:13.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.017723423s
Jul 10 08:22:15.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.022835533s
Jul 10 08:22:17.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.021331432s
Jul 10 08:22:19.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.02368453s
Jul 10 08:22:21.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.025526551s
Jul 10 08:22:23.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.019774858s
Jul 10 08:22:25.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.0177539s
Jul 10 08:22:27.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.022029541s
Jul 10 08:22:29.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.025223825s
Jul 10 08:22:31.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.020173028s
Jul 10 08:22:33.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.018503948s
Jul 10 08:22:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.018499652s
Jul 10 08:22:37.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.018883326s
Jul 10 08:22:39.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.018467518s
Jul 10 08:22:41.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.018459682s
Jul 10 08:22:43.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.019582266s
Jul 10 08:22:45.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.024146596s
Jul 10 08:22:47.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.018624494s
Jul 10 08:22:49.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.017809601s
Jul 10 08:22:51.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.018856535s
Jul 10 08:22:53.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.018747028s
Jul 10 08:22:55.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.017405925s
Jul 10 08:22:57.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.01715286s
Jul 10 08:22:59.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.01842822s
Jul 10 08:23:01.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.018704615s
Jul 10 08:23:03.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.020163471s
Jul 10 08:23:05.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.022274207s
Jul 10 08:23:07.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.01906111s
Jul 10 08:23:09.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.018175052s
Jul 10 08:23:11.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.018318069s
Jul 10 08:23:13.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.018559432s
Jul 10 08:23:15.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.0186787s
Jul 10 08:23:17.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.01934371s
Jul 10 08:23:19.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.018105743s
Jul 10 08:23:21.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.017490038s
Jul 10 08:23:23.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.018445771s
Jul 10 08:23:25.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.017835773s
Jul 10 08:23:27.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.017497305s
Jul 10 08:23:29.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.017801731s
Jul 10 08:23:31.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.020234069s
Jul 10 08:23:33.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.019160121s
Jul 10 08:23:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.018378477s
Jul 10 08:23:37.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.018900924s
Jul 10 08:23:39.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.018429206s
Jul 10 08:23:41.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.017748033s
Jul 10 08:23:43.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.01786914s
Jul 10 08:23:45.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.018957364s
Jul 10 08:23:47.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.018165968s
Jul 10 08:23:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.018073912s
Jul 10 08:23:51.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.017971785s
Jul 10 08:23:51.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021671548s
STEP: removing the label kubernetes.io/e2e-a84e42d9-ae1d-405c-80b2-38527c272b16 off the node 10-62-109-100.test 07/10/23 08:23:51.605
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a84e42d9-ae1d-405c-80b2-38527c272b16 07/10/23 08:23:51.631
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:23:51.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8735" for this suite. 07/10/23 08:23:51.649
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":75,"skipped":1595,"failed":0}
------------------------------
• [SLOW TEST] [304.299 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:18:47.376
    Jul 10 08:18:47.376: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-pred 07/10/23 08:18:47.377
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:18:47.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:18:47.424
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jul 10 08:18:47.426: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jul 10 08:18:47.437: INFO: Waiting for terminating namespaces to be deleted...
    Jul 10 08:18:47.441: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-100.test before test
    Jul 10 08:18:47.449: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 08:18:47.449: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container nfs-attacher ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: 	Container nfs-provisioner ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: 	Container snapshotter-controller ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container metrics-server ready: true, restart count 7
    Jul 10 08:18:47.449: INFO: pod-logs-websocket-fdcd1164-791a-40aa-9aeb-5878a13f4f84 from pods-9724 started at 2023-07-10 08:18:44 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container main ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: pod0-1-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:36 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container pod0-1-sched-preemption-medium-priority ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.449: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 08:18:47.449: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-101.test before test
    Jul 10 08:18:47.458: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 08:18:47.458: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: pod1-0-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:35 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container pod1-0-sched-preemption-medium-priority ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: pod1-1-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:35 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container pod1-1-sched-preemption-medium-priority ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.458: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 08:18:47.458: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-102.test before test
    Jul 10 08:18:47.468: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: pod2-0-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:33 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container pod2-0-sched-preemption-medium-priority ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: pod2-1-sched-preemption-medium-priority from sched-preemption-2693 started at 2023-07-10 08:18:33 +0000 UTC (1 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container pod2-1-sched-preemption-medium-priority ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container e2e ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:18:47.468: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:18:47.468: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 07/10/23 08:18:47.468
    Jul 10 08:18:47.488: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8735" to be "running"
    Jul 10 08:18:47.491: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.996122ms
    Jul 10 08:18:49.496: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.008871347s
    Jul 10 08:18:49.497: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 07/10/23 08:18:49.501
    STEP: Trying to apply a random label on the found node. 07/10/23 08:18:49.533
    STEP: verifying the node has the label kubernetes.io/e2e-a84e42d9-ae1d-405c-80b2-38527c272b16 95 07/10/23 08:18:49.549
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 07/10/23 08:18:49.554
    Jul 10 08:18:49.562: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-8735" to be "not pending"
    Jul 10 08:18:49.567: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.227876ms
    Jul 10 08:18:51.572: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.010088473s
    Jul 10 08:18:51.572: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.62.109.100 on the node which pod4 resides and expect not scheduled 07/10/23 08:18:51.572
    Jul 10 08:18:51.583: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-8735" to be "not pending"
    Jul 10 08:18:51.596: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.750778ms
    Jul 10 08:18:53.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019149496s
    Jul 10 08:18:55.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01759633s
    Jul 10 08:18:57.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020029821s
    Jul 10 08:18:59.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017625834s
    Jul 10 08:19:01.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019599399s
    Jul 10 08:19:03.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019527588s
    Jul 10 08:19:05.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019832043s
    Jul 10 08:19:07.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.021681758s
    Jul 10 08:19:09.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018072246s
    Jul 10 08:19:11.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.017668909s
    Jul 10 08:19:13.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.017945886s
    Jul 10 08:19:15.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.017455641s
    Jul 10 08:19:17.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.02103192s
    Jul 10 08:19:19.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.017369634s
    Jul 10 08:19:21.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.018003484s
    Jul 10 08:19:23.600: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.016910654s
    Jul 10 08:19:25.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018984144s
    Jul 10 08:19:27.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.017418953s
    Jul 10 08:19:29.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.018164934s
    Jul 10 08:19:31.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.017582508s
    Jul 10 08:19:33.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.017567764s
    Jul 10 08:19:35.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.019661786s
    Jul 10 08:19:37.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.017359892s
    Jul 10 08:19:39.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.017833795s
    Jul 10 08:19:41.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.017391377s
    Jul 10 08:19:43.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01873582s
    Jul 10 08:19:45.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.01949115s
    Jul 10 08:19:47.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.019491644s
    Jul 10 08:19:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.01899405s
    Jul 10 08:19:51.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.01996455s
    Jul 10 08:19:53.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.019133857s
    Jul 10 08:19:55.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.018855892s
    Jul 10 08:19:57.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.019810769s
    Jul 10 08:19:59.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.019845391s
    Jul 10 08:20:01.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.017243038s
    Jul 10 08:20:03.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.019927859s
    Jul 10 08:20:05.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.018958104s
    Jul 10 08:20:07.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01769559s
    Jul 10 08:20:09.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.01795045s
    Jul 10 08:20:11.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.019491378s
    Jul 10 08:20:13.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.018688029s
    Jul 10 08:20:15.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.018620573s
    Jul 10 08:20:17.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.019983292s
    Jul 10 08:20:19.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.020091746s
    Jul 10 08:20:21.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.019134898s
    Jul 10 08:20:23.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.018930981s
    Jul 10 08:20:25.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.018528674s
    Jul 10 08:20:27.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.018027701s
    Jul 10 08:20:29.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.017519143s
    Jul 10 08:20:31.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.019207758s
    Jul 10 08:20:33.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.017994515s
    Jul 10 08:20:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.018617565s
    Jul 10 08:20:37.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02013782s
    Jul 10 08:20:39.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.01737252s
    Jul 10 08:20:41.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.017855504s
    Jul 10 08:20:43.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.019128956s
    Jul 10 08:20:45.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017719004s
    Jul 10 08:20:47.600: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.016666208s
    Jul 10 08:20:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.018172837s
    Jul 10 08:20:51.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017507288s
    Jul 10 08:20:53.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.018689242s
    Jul 10 08:20:55.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.018256575s
    Jul 10 08:20:57.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.01897564s
    Jul 10 08:20:59.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.018774556s
    Jul 10 08:21:01.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.017328417s
    Jul 10 08:21:03.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.019227671s
    Jul 10 08:21:05.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.017694489s
    Jul 10 08:21:07.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.019508298s
    Jul 10 08:21:09.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.017386765s
    Jul 10 08:21:11.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.019252838s
    Jul 10 08:21:13.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.019242372s
    Jul 10 08:21:15.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.018610917s
    Jul 10 08:21:17.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.01917014s
    Jul 10 08:21:19.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.018907308s
    Jul 10 08:21:21.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.01844619s
    Jul 10 08:21:23.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.018477705s
    Jul 10 08:21:25.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.01840508s
    Jul 10 08:21:27.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.018249253s
    Jul 10 08:21:29.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.017818719s
    Jul 10 08:21:31.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.018502567s
    Jul 10 08:21:33.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.019762041s
    Jul 10 08:21:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.018236331s
    Jul 10 08:21:37.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.020592296s
    Jul 10 08:21:39.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.018142757s
    Jul 10 08:21:41.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.018417969s
    Jul 10 08:21:43.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.021343474s
    Jul 10 08:21:45.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.018824618s
    Jul 10 08:21:47.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.020164837s
    Jul 10 08:21:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.018377448s
    Jul 10 08:21:51.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.019889877s
    Jul 10 08:21:53.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.018749442s
    Jul 10 08:21:55.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.018380946s
    Jul 10 08:21:57.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.019198843s
    Jul 10 08:21:59.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.018785343s
    Jul 10 08:22:01.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.019092987s
    Jul 10 08:22:03.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.018540471s
    Jul 10 08:22:05.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.018092237s
    Jul 10 08:22:07.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.01877595s
    Jul 10 08:22:09.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.018576128s
    Jul 10 08:22:11.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.019633414s
    Jul 10 08:22:13.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.017723423s
    Jul 10 08:22:15.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.022835533s
    Jul 10 08:22:17.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.021331432s
    Jul 10 08:22:19.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.02368453s
    Jul 10 08:22:21.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.025526551s
    Jul 10 08:22:23.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.019774858s
    Jul 10 08:22:25.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.0177539s
    Jul 10 08:22:27.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.022029541s
    Jul 10 08:22:29.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.025223825s
    Jul 10 08:22:31.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.020173028s
    Jul 10 08:22:33.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.018503948s
    Jul 10 08:22:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.018499652s
    Jul 10 08:22:37.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.018883326s
    Jul 10 08:22:39.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.018467518s
    Jul 10 08:22:41.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.018459682s
    Jul 10 08:22:43.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.019582266s
    Jul 10 08:22:45.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.024146596s
    Jul 10 08:22:47.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.018624494s
    Jul 10 08:22:49.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.017809601s
    Jul 10 08:22:51.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.018856535s
    Jul 10 08:22:53.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.018747028s
    Jul 10 08:22:55.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.017405925s
    Jul 10 08:22:57.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.01715286s
    Jul 10 08:22:59.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.01842822s
    Jul 10 08:23:01.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.018704615s
    Jul 10 08:23:03.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.020163471s
    Jul 10 08:23:05.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.022274207s
    Jul 10 08:23:07.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.01906111s
    Jul 10 08:23:09.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.018175052s
    Jul 10 08:23:11.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.018318069s
    Jul 10 08:23:13.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.018559432s
    Jul 10 08:23:15.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.0186787s
    Jul 10 08:23:17.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.01934371s
    Jul 10 08:23:19.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.018105743s
    Jul 10 08:23:21.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.017490038s
    Jul 10 08:23:23.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.018445771s
    Jul 10 08:23:25.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.017835773s
    Jul 10 08:23:27.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.017497305s
    Jul 10 08:23:29.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.017801731s
    Jul 10 08:23:31.604: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.020234069s
    Jul 10 08:23:33.603: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.019160121s
    Jul 10 08:23:35.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.018378477s
    Jul 10 08:23:37.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.018900924s
    Jul 10 08:23:39.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.018429206s
    Jul 10 08:23:41.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.017748033s
    Jul 10 08:23:43.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.01786914s
    Jul 10 08:23:45.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.018957364s
    Jul 10 08:23:47.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.018165968s
    Jul 10 08:23:49.602: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.018073912s
    Jul 10 08:23:51.601: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.017971785s
    Jul 10 08:23:51.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.021671548s
    STEP: removing the label kubernetes.io/e2e-a84e42d9-ae1d-405c-80b2-38527c272b16 off the node 10-62-109-100.test 07/10/23 08:23:51.605
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-a84e42d9-ae1d-405c-80b2-38527c272b16 07/10/23 08:23:51.631
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:23:51.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8735" for this suite. 07/10/23 08:23:51.649
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:23:51.68
Jul 10 08:23:51.680: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 08:23:51.682
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:23:51.715
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:23:51.718
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 07/10/23 08:23:51.721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 07/10/23 08:23:51.729
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 07/10/23 08:23:51.729
STEP: creating a pod to probe DNS 07/10/23 08:23:51.729
STEP: submitting the pod to kubernetes 07/10/23 08:23:51.729
Jul 10 08:23:51.760: INFO: Waiting up to 15m0s for pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4" in namespace "dns-9723" to be "running"
Jul 10 08:23:51.785: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.0616ms
Jul 10 08:23:53.790: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030231154s
Jul 10 08:23:55.790: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4": Phase="Running", Reason="", readiness=true. Elapsed: 4.030342578s
Jul 10 08:23:55.790: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4" satisfied condition "running"
STEP: retrieving the pod 07/10/23 08:23:55.79
STEP: looking for the results for each expected name from probers 07/10/23 08:23:55.794
Jul 10 08:23:55.811: INFO: DNS probes using dns-9723/dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4 succeeded

STEP: deleting the pod 07/10/23 08:23:55.811
STEP: deleting the test headless service 07/10/23 08:23:55.85
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 08:23:55.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9723" for this suite. 07/10/23 08:23:55.908
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":76,"skipped":1625,"failed":0}
------------------------------
• [4.248 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:23:51.68
    Jul 10 08:23:51.680: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 08:23:51.682
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:23:51.715
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:23:51.718
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 07/10/23 08:23:51.721
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     07/10/23 08:23:51.729
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9723.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     07/10/23 08:23:51.729
    STEP: creating a pod to probe DNS 07/10/23 08:23:51.729
    STEP: submitting the pod to kubernetes 07/10/23 08:23:51.729
    Jul 10 08:23:51.760: INFO: Waiting up to 15m0s for pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4" in namespace "dns-9723" to be "running"
    Jul 10 08:23:51.785: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.0616ms
    Jul 10 08:23:53.790: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030231154s
    Jul 10 08:23:55.790: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4": Phase="Running", Reason="", readiness=true. Elapsed: 4.030342578s
    Jul 10 08:23:55.790: INFO: Pod "dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 08:23:55.79
    STEP: looking for the results for each expected name from probers 07/10/23 08:23:55.794
    Jul 10 08:23:55.811: INFO: DNS probes using dns-9723/dns-test-047a83de-6bba-4f5a-a035-6f3d4fc66ee4 succeeded

    STEP: deleting the pod 07/10/23 08:23:55.811
    STEP: deleting the test headless service 07/10/23 08:23:55.85
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 08:23:55.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9723" for this suite. 07/10/23 08:23:55.908
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:23:55.929
Jul 10 08:23:55.929: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename events 07/10/23 08:23:55.93
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:23:55.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:23:55.969
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 07/10/23 08:23:55.971
STEP: listing events in all namespaces 07/10/23 08:23:55.985
STEP: listing events in test namespace 07/10/23 08:23:55.998
STEP: listing events with field selection filtering on source 07/10/23 08:23:56.003
STEP: listing events with field selection filtering on reportingController 07/10/23 08:23:56.007
STEP: getting the test event 07/10/23 08:23:56.011
STEP: patching the test event 07/10/23 08:23:56.014
STEP: getting the test event 07/10/23 08:23:56.036
STEP: updating the test event 07/10/23 08:23:56.04
STEP: getting the test event 07/10/23 08:23:56.057
STEP: deleting the test event 07/10/23 08:23:56.06
STEP: listing events in all namespaces 07/10/23 08:23:56.083
STEP: listing events in test namespace 07/10/23 08:23:56.095
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Jul 10 08:23:56.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8602" for this suite. 07/10/23 08:23:56.109
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":77,"skipped":1630,"failed":0}
------------------------------
• [0.193 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:23:55.929
    Jul 10 08:23:55.929: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename events 07/10/23 08:23:55.93
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:23:55.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:23:55.969
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 07/10/23 08:23:55.971
    STEP: listing events in all namespaces 07/10/23 08:23:55.985
    STEP: listing events in test namespace 07/10/23 08:23:55.998
    STEP: listing events with field selection filtering on source 07/10/23 08:23:56.003
    STEP: listing events with field selection filtering on reportingController 07/10/23 08:23:56.007
    STEP: getting the test event 07/10/23 08:23:56.011
    STEP: patching the test event 07/10/23 08:23:56.014
    STEP: getting the test event 07/10/23 08:23:56.036
    STEP: updating the test event 07/10/23 08:23:56.04
    STEP: getting the test event 07/10/23 08:23:56.057
    STEP: deleting the test event 07/10/23 08:23:56.06
    STEP: listing events in all namespaces 07/10/23 08:23:56.083
    STEP: listing events in test namespace 07/10/23 08:23:56.095
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Jul 10 08:23:56.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8602" for this suite. 07/10/23 08:23:56.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:23:56.122
Jul 10 08:23:56.122: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:23:56.123
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:23:56.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:23:56.155
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 07/10/23 08:23:56.157
Jul 10 08:23:56.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 create -f -'
Jul 10 08:23:56.846: INFO: stderr: ""
Jul 10 08:23:56.846: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 08:23:56.846
Jul 10 08:23:56.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 08:23:56.937: INFO: stderr: ""
Jul 10 08:23:56.937: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-sng49 "
Jul 10 08:23:56.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:23:57.018: INFO: stderr: ""
Jul 10 08:23:57.018: INFO: stdout: ""
Jul 10 08:23:57.018: INFO: update-demo-nautilus-f99tj is created but not running
Jul 10 08:24:02.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 08:24:02.099: INFO: stderr: ""
Jul 10 08:24:02.099: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-sng49 "
Jul 10 08:24:02.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:02.181: INFO: stderr: ""
Jul 10 08:24:02.181: INFO: stdout: "true"
Jul 10 08:24:02.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 08:24:02.262: INFO: stderr: ""
Jul 10 08:24:02.262: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 08:24:02.262: INFO: validating pod update-demo-nautilus-f99tj
Jul 10 08:24:02.272: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 08:24:02.272: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 08:24:02.272: INFO: update-demo-nautilus-f99tj is verified up and running
Jul 10 08:24:02.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-sng49 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:02.349: INFO: stderr: ""
Jul 10 08:24:02.349: INFO: stdout: "true"
Jul 10 08:24:02.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-sng49 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 08:24:02.424: INFO: stderr: ""
Jul 10 08:24:02.424: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 08:24:02.424: INFO: validating pod update-demo-nautilus-sng49
Jul 10 08:24:02.429: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 08:24:02.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 08:24:02.429: INFO: update-demo-nautilus-sng49 is verified up and running
STEP: scaling down the replication controller 07/10/23 08:24:02.429
Jul 10 08:24:02.432: INFO: scanned /root for discovery docs: <nil>
Jul 10 08:24:02.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Jul 10 08:24:03.530: INFO: stderr: ""
Jul 10 08:24:03.530: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 08:24:03.53
Jul 10 08:24:03.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 08:24:03.613: INFO: stderr: ""
Jul 10 08:24:03.613: INFO: stdout: "update-demo-nautilus-f99tj "
Jul 10 08:24:03.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:03.687: INFO: stderr: ""
Jul 10 08:24:03.687: INFO: stdout: "true"
Jul 10 08:24:03.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 08:24:03.765: INFO: stderr: ""
Jul 10 08:24:03.765: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 08:24:03.765: INFO: validating pod update-demo-nautilus-f99tj
Jul 10 08:24:03.770: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 08:24:03.770: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 08:24:03.770: INFO: update-demo-nautilus-f99tj is verified up and running
STEP: scaling up the replication controller 07/10/23 08:24:03.77
Jul 10 08:24:03.772: INFO: scanned /root for discovery docs: <nil>
Jul 10 08:24:03.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Jul 10 08:24:04.889: INFO: stderr: ""
Jul 10 08:24:04.889: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 08:24:04.889
Jul 10 08:24:04.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 08:24:04.964: INFO: stderr: ""
Jul 10 08:24:04.964: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-t2w8p "
Jul 10 08:24:04.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:05.034: INFO: stderr: ""
Jul 10 08:24:05.034: INFO: stdout: "true"
Jul 10 08:24:05.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 08:24:05.102: INFO: stderr: ""
Jul 10 08:24:05.102: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 08:24:05.102: INFO: validating pod update-demo-nautilus-f99tj
Jul 10 08:24:05.107: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 08:24:05.107: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 08:24:05.107: INFO: update-demo-nautilus-f99tj is verified up and running
Jul 10 08:24:05.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-t2w8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:05.177: INFO: stderr: ""
Jul 10 08:24:05.177: INFO: stdout: ""
Jul 10 08:24:05.177: INFO: update-demo-nautilus-t2w8p is created but not running
Jul 10 08:24:10.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 08:24:10.250: INFO: stderr: ""
Jul 10 08:24:10.250: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-t2w8p "
Jul 10 08:24:10.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:10.326: INFO: stderr: ""
Jul 10 08:24:10.326: INFO: stdout: "true"
Jul 10 08:24:10.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 08:24:10.399: INFO: stderr: ""
Jul 10 08:24:10.399: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 08:24:10.399: INFO: validating pod update-demo-nautilus-f99tj
Jul 10 08:24:10.404: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 08:24:10.405: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 08:24:10.405: INFO: update-demo-nautilus-f99tj is verified up and running
Jul 10 08:24:10.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-t2w8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 08:24:10.473: INFO: stderr: ""
Jul 10 08:24:10.473: INFO: stdout: "true"
Jul 10 08:24:10.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-t2w8p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 08:24:10.542: INFO: stderr: ""
Jul 10 08:24:10.542: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 08:24:10.542: INFO: validating pod update-demo-nautilus-t2w8p
Jul 10 08:24:10.549: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 08:24:10.549: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 08:24:10.549: INFO: update-demo-nautilus-t2w8p is verified up and running
STEP: using delete to clean up resources 07/10/23 08:24:10.549
Jul 10 08:24:10.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 delete --grace-period=0 --force -f -'
Jul 10 08:24:10.626: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 08:24:10.626: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 10 08:24:10.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get rc,svc -l name=update-demo --no-headers'
Jul 10 08:24:10.703: INFO: stderr: "No resources found in kubectl-9343 namespace.\n"
Jul 10 08:24:10.703: INFO: stdout: ""
Jul 10 08:24:10.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 10 08:24:10.777: INFO: stderr: ""
Jul 10 08:24:10.777: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:24:10.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9343" for this suite. 07/10/23 08:24:10.782
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":78,"skipped":1643,"failed":0}
------------------------------
• [SLOW TEST] [14.678 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:23:56.122
    Jul 10 08:23:56.122: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:23:56.123
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:23:56.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:23:56.155
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 07/10/23 08:23:56.157
    Jul 10 08:23:56.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 create -f -'
    Jul 10 08:23:56.846: INFO: stderr: ""
    Jul 10 08:23:56.846: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 08:23:56.846
    Jul 10 08:23:56.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 08:23:56.937: INFO: stderr: ""
    Jul 10 08:23:56.937: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-sng49 "
    Jul 10 08:23:56.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:23:57.018: INFO: stderr: ""
    Jul 10 08:23:57.018: INFO: stdout: ""
    Jul 10 08:23:57.018: INFO: update-demo-nautilus-f99tj is created but not running
    Jul 10 08:24:02.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 08:24:02.099: INFO: stderr: ""
    Jul 10 08:24:02.099: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-sng49 "
    Jul 10 08:24:02.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:02.181: INFO: stderr: ""
    Jul 10 08:24:02.181: INFO: stdout: "true"
    Jul 10 08:24:02.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 08:24:02.262: INFO: stderr: ""
    Jul 10 08:24:02.262: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 08:24:02.262: INFO: validating pod update-demo-nautilus-f99tj
    Jul 10 08:24:02.272: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 08:24:02.272: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 08:24:02.272: INFO: update-demo-nautilus-f99tj is verified up and running
    Jul 10 08:24:02.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-sng49 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:02.349: INFO: stderr: ""
    Jul 10 08:24:02.349: INFO: stdout: "true"
    Jul 10 08:24:02.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-sng49 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 08:24:02.424: INFO: stderr: ""
    Jul 10 08:24:02.424: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 08:24:02.424: INFO: validating pod update-demo-nautilus-sng49
    Jul 10 08:24:02.429: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 08:24:02.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 08:24:02.429: INFO: update-demo-nautilus-sng49 is verified up and running
    STEP: scaling down the replication controller 07/10/23 08:24:02.429
    Jul 10 08:24:02.432: INFO: scanned /root for discovery docs: <nil>
    Jul 10 08:24:02.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Jul 10 08:24:03.530: INFO: stderr: ""
    Jul 10 08:24:03.530: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 08:24:03.53
    Jul 10 08:24:03.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 08:24:03.613: INFO: stderr: ""
    Jul 10 08:24:03.613: INFO: stdout: "update-demo-nautilus-f99tj "
    Jul 10 08:24:03.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:03.687: INFO: stderr: ""
    Jul 10 08:24:03.687: INFO: stdout: "true"
    Jul 10 08:24:03.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 08:24:03.765: INFO: stderr: ""
    Jul 10 08:24:03.765: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 08:24:03.765: INFO: validating pod update-demo-nautilus-f99tj
    Jul 10 08:24:03.770: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 08:24:03.770: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 08:24:03.770: INFO: update-demo-nautilus-f99tj is verified up and running
    STEP: scaling up the replication controller 07/10/23 08:24:03.77
    Jul 10 08:24:03.772: INFO: scanned /root for discovery docs: <nil>
    Jul 10 08:24:03.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Jul 10 08:24:04.889: INFO: stderr: ""
    Jul 10 08:24:04.889: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 08:24:04.889
    Jul 10 08:24:04.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 08:24:04.964: INFO: stderr: ""
    Jul 10 08:24:04.964: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-t2w8p "
    Jul 10 08:24:04.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:05.034: INFO: stderr: ""
    Jul 10 08:24:05.034: INFO: stdout: "true"
    Jul 10 08:24:05.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 08:24:05.102: INFO: stderr: ""
    Jul 10 08:24:05.102: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 08:24:05.102: INFO: validating pod update-demo-nautilus-f99tj
    Jul 10 08:24:05.107: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 08:24:05.107: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 08:24:05.107: INFO: update-demo-nautilus-f99tj is verified up and running
    Jul 10 08:24:05.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-t2w8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:05.177: INFO: stderr: ""
    Jul 10 08:24:05.177: INFO: stdout: ""
    Jul 10 08:24:05.177: INFO: update-demo-nautilus-t2w8p is created but not running
    Jul 10 08:24:10.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 08:24:10.250: INFO: stderr: ""
    Jul 10 08:24:10.250: INFO: stdout: "update-demo-nautilus-f99tj update-demo-nautilus-t2w8p "
    Jul 10 08:24:10.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:10.326: INFO: stderr: ""
    Jul 10 08:24:10.326: INFO: stdout: "true"
    Jul 10 08:24:10.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-f99tj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 08:24:10.399: INFO: stderr: ""
    Jul 10 08:24:10.399: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 08:24:10.399: INFO: validating pod update-demo-nautilus-f99tj
    Jul 10 08:24:10.404: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 08:24:10.405: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 08:24:10.405: INFO: update-demo-nautilus-f99tj is verified up and running
    Jul 10 08:24:10.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-t2w8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 08:24:10.473: INFO: stderr: ""
    Jul 10 08:24:10.473: INFO: stdout: "true"
    Jul 10 08:24:10.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods update-demo-nautilus-t2w8p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 08:24:10.542: INFO: stderr: ""
    Jul 10 08:24:10.542: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 08:24:10.542: INFO: validating pod update-demo-nautilus-t2w8p
    Jul 10 08:24:10.549: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 08:24:10.549: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 08:24:10.549: INFO: update-demo-nautilus-t2w8p is verified up and running
    STEP: using delete to clean up resources 07/10/23 08:24:10.549
    Jul 10 08:24:10.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 delete --grace-period=0 --force -f -'
    Jul 10 08:24:10.626: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 08:24:10.626: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Jul 10 08:24:10.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get rc,svc -l name=update-demo --no-headers'
    Jul 10 08:24:10.703: INFO: stderr: "No resources found in kubectl-9343 namespace.\n"
    Jul 10 08:24:10.703: INFO: stdout: ""
    Jul 10 08:24:10.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-9343 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jul 10 08:24:10.777: INFO: stderr: ""
    Jul 10 08:24:10.777: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:24:10.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9343" for this suite. 07/10/23 08:24:10.782
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:10.801
Jul 10 08:24:10.801: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:24:10.803
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:10.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:10.838
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 07/10/23 08:24:10.84
Jul 10 08:24:10.841: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5097 proxy --unix-socket=/tmp/kubectl-proxy-unix2250557853/test'
STEP: retrieving proxy /api/ output 07/10/23 08:24:10.894
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:24:10.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5097" for this suite. 07/10/23 08:24:10.905
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":79,"skipped":1645,"failed":0}
------------------------------
• [0.119 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:10.801
    Jul 10 08:24:10.801: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:24:10.803
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:10.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:10.838
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 07/10/23 08:24:10.84
    Jul 10 08:24:10.841: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5097 proxy --unix-socket=/tmp/kubectl-proxy-unix2250557853/test'
    STEP: retrieving proxy /api/ output 07/10/23 08:24:10.894
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:24:10.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5097" for this suite. 07/10/23 08:24:10.905
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:10.922
Jul 10 08:24:10.922: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename watch 07/10/23 08:24:10.923
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:10.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:10.956
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 07/10/23 08:24:10.961
STEP: starting a background goroutine to produce watch events 07/10/23 08:24:10.969
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 07/10/23 08:24:10.969
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jul 10 08:24:13.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5222" for this suite. 07/10/23 08:24:13.781
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":80,"skipped":1657,"failed":0}
------------------------------
• [2.917 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:10.922
    Jul 10 08:24:10.922: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename watch 07/10/23 08:24:10.923
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:10.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:10.956
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 07/10/23 08:24:10.961
    STEP: starting a background goroutine to produce watch events 07/10/23 08:24:10.969
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 07/10/23 08:24:10.969
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jul 10 08:24:13.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5222" for this suite. 07/10/23 08:24:13.781
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:13.84
Jul 10 08:24:13.840: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replicaset 07/10/23 08:24:13.841
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:13.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:13.869
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Jul 10 08:24:13.910: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 10 08:24:18.919: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 07/10/23 08:24:18.919
STEP: Scaling up "test-rs" replicaset  07/10/23 08:24:18.92
Jul 10 08:24:18.938: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 07/10/23 08:24:18.938
W0710 08:24:18.963989      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jul 10 08:24:18.965: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
Jul 10 08:24:19.003: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
Jul 10 08:24:19.049: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
Jul 10 08:24:19.071: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
Jul 10 08:24:20.730: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 2, AvailableReplicas 2
Jul 10 08:24:20.848: INFO: observed Replicaset test-rs in namespace replicaset-7219 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jul 10 08:24:20.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7219" for this suite. 07/10/23 08:24:20.853
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":81,"skipped":1667,"failed":0}
------------------------------
• [SLOW TEST] [7.024 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:13.84
    Jul 10 08:24:13.840: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replicaset 07/10/23 08:24:13.841
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:13.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:13.869
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Jul 10 08:24:13.910: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jul 10 08:24:18.919: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 07/10/23 08:24:18.919
    STEP: Scaling up "test-rs" replicaset  07/10/23 08:24:18.92
    Jul 10 08:24:18.938: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 07/10/23 08:24:18.938
    W0710 08:24:18.963989      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jul 10 08:24:18.965: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
    Jul 10 08:24:19.003: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
    Jul 10 08:24:19.049: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
    Jul 10 08:24:19.071: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 1, AvailableReplicas 1
    Jul 10 08:24:20.730: INFO: observed ReplicaSet test-rs in namespace replicaset-7219 with ReadyReplicas 2, AvailableReplicas 2
    Jul 10 08:24:20.848: INFO: observed Replicaset test-rs in namespace replicaset-7219 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jul 10 08:24:20.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7219" for this suite. 07/10/23 08:24:20.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:20.865
Jul 10 08:24:20.865: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename ingress 07/10/23 08:24:20.866
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:20.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:20.959
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 07/10/23 08:24:20.962
STEP: getting /apis/networking.k8s.io 07/10/23 08:24:20.965
STEP: getting /apis/networking.k8s.iov1 07/10/23 08:24:20.966
STEP: creating 07/10/23 08:24:20.967
STEP: getting 07/10/23 08:24:20.996
STEP: listing 07/10/23 08:24:21.002
STEP: watching 07/10/23 08:24:21.007
Jul 10 08:24:21.007: INFO: starting watch
STEP: cluster-wide listing 07/10/23 08:24:21.008
STEP: cluster-wide watching 07/10/23 08:24:21.012
Jul 10 08:24:21.012: INFO: starting watch
STEP: patching 07/10/23 08:24:21.013
STEP: updating 07/10/23 08:24:21.023
Jul 10 08:24:21.035: INFO: waiting for watch events with expected annotations
Jul 10 08:24:21.035: INFO: saw patched and updated annotations
STEP: patching /status 07/10/23 08:24:21.035
STEP: updating /status 07/10/23 08:24:21.043
STEP: get /status 07/10/23 08:24:21.056
STEP: deleting 07/10/23 08:24:21.059
STEP: deleting a collection 07/10/23 08:24:21.075
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Jul 10 08:24:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-7451" for this suite. 07/10/23 08:24:21.102
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":82,"skipped":1680,"failed":0}
------------------------------
• [0.246 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:20.865
    Jul 10 08:24:20.865: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename ingress 07/10/23 08:24:20.866
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:20.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:20.959
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 07/10/23 08:24:20.962
    STEP: getting /apis/networking.k8s.io 07/10/23 08:24:20.965
    STEP: getting /apis/networking.k8s.iov1 07/10/23 08:24:20.966
    STEP: creating 07/10/23 08:24:20.967
    STEP: getting 07/10/23 08:24:20.996
    STEP: listing 07/10/23 08:24:21.002
    STEP: watching 07/10/23 08:24:21.007
    Jul 10 08:24:21.007: INFO: starting watch
    STEP: cluster-wide listing 07/10/23 08:24:21.008
    STEP: cluster-wide watching 07/10/23 08:24:21.012
    Jul 10 08:24:21.012: INFO: starting watch
    STEP: patching 07/10/23 08:24:21.013
    STEP: updating 07/10/23 08:24:21.023
    Jul 10 08:24:21.035: INFO: waiting for watch events with expected annotations
    Jul 10 08:24:21.035: INFO: saw patched and updated annotations
    STEP: patching /status 07/10/23 08:24:21.035
    STEP: updating /status 07/10/23 08:24:21.043
    STEP: get /status 07/10/23 08:24:21.056
    STEP: deleting 07/10/23 08:24:21.059
    STEP: deleting a collection 07/10/23 08:24:21.075
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Jul 10 08:24:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-7451" for this suite. 07/10/23 08:24:21.102
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:21.111
Jul 10 08:24:21.111: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename limitrange 07/10/23 08:24:21.112
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:21.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:21.139
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 07/10/23 08:24:21.141
STEP: Setting up watch 07/10/23 08:24:21.141
STEP: Submitting a LimitRange 07/10/23 08:24:21.245
STEP: Verifying LimitRange creation was observed 07/10/23 08:24:21.256
STEP: Fetching the LimitRange to ensure it has proper values 07/10/23 08:24:21.256
Jul 10 08:24:21.260: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jul 10 08:24:21.260: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 07/10/23 08:24:21.26
STEP: Ensuring Pod has resource requirements applied from LimitRange 07/10/23 08:24:21.267
Jul 10 08:24:21.272: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jul 10 08:24:21.272: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 07/10/23 08:24:21.272
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 07/10/23 08:24:21.284
Jul 10 08:24:21.292: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Jul 10 08:24:21.292: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 07/10/23 08:24:21.292
STEP: Failing to create a Pod with more than max resources 07/10/23 08:24:21.294
STEP: Updating a LimitRange 07/10/23 08:24:21.296
STEP: Verifying LimitRange updating is effective 07/10/23 08:24:21.306
STEP: Creating a Pod with less than former min resources 07/10/23 08:24:23.312
STEP: Failing to create a Pod with more than max resources 07/10/23 08:24:23.322
STEP: Deleting a LimitRange 07/10/23 08:24:23.324
STEP: Verifying the LimitRange was deleted 07/10/23 08:24:23.34
Jul 10 08:24:28.347: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 07/10/23 08:24:28.347
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Jul 10 08:24:28.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-283" for this suite. 07/10/23 08:24:28.37
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":83,"skipped":1683,"failed":0}
------------------------------
• [SLOW TEST] [7.296 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:21.111
    Jul 10 08:24:21.111: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename limitrange 07/10/23 08:24:21.112
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:21.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:21.139
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 07/10/23 08:24:21.141
    STEP: Setting up watch 07/10/23 08:24:21.141
    STEP: Submitting a LimitRange 07/10/23 08:24:21.245
    STEP: Verifying LimitRange creation was observed 07/10/23 08:24:21.256
    STEP: Fetching the LimitRange to ensure it has proper values 07/10/23 08:24:21.256
    Jul 10 08:24:21.260: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Jul 10 08:24:21.260: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 07/10/23 08:24:21.26
    STEP: Ensuring Pod has resource requirements applied from LimitRange 07/10/23 08:24:21.267
    Jul 10 08:24:21.272: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Jul 10 08:24:21.272: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 07/10/23 08:24:21.272
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 07/10/23 08:24:21.284
    Jul 10 08:24:21.292: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Jul 10 08:24:21.292: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 07/10/23 08:24:21.292
    STEP: Failing to create a Pod with more than max resources 07/10/23 08:24:21.294
    STEP: Updating a LimitRange 07/10/23 08:24:21.296
    STEP: Verifying LimitRange updating is effective 07/10/23 08:24:21.306
    STEP: Creating a Pod with less than former min resources 07/10/23 08:24:23.312
    STEP: Failing to create a Pod with more than max resources 07/10/23 08:24:23.322
    STEP: Deleting a LimitRange 07/10/23 08:24:23.324
    STEP: Verifying the LimitRange was deleted 07/10/23 08:24:23.34
    Jul 10 08:24:28.347: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 07/10/23 08:24:28.347
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Jul 10 08:24:28.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-283" for this suite. 07/10/23 08:24:28.37
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:28.408
Jul 10 08:24:28.408: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:24:28.409
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:28.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:28.453
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Jul 10 08:24:28.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-2258 version'
Jul 10 08:24:28.517: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Jul 10 08:24:28.517: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:08:36Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:24:28.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2258" for this suite. 07/10/23 08:24:28.532
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":84,"skipped":1694,"failed":0}
------------------------------
• [0.136 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:28.408
    Jul 10 08:24:28.408: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:24:28.409
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:28.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:28.453
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Jul 10 08:24:28.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-2258 version'
    Jul 10 08:24:28.517: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Jul 10 08:24:28.517: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:08:36Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:24:28.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2258" for this suite. 07/10/23 08:24:28.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:24:28.546
Jul 10 08:24:28.546: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 08:24:28.547
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:28.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:28.585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5580 07/10/23 08:24:28.587
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 07/10/23 08:24:28.598
Jul 10 08:24:28.688: INFO: Found 0 stateful pods, waiting for 3
Jul 10 08:24:38.694: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:24:38.694: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:24:38.694: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:24:38.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:24:38.858: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:24:38.858: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:24:38.858: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 07/10/23 08:24:48.883
Jul 10 08:24:48.908: INFO: Updating stateful set ss2
STEP: Creating a new revision 07/10/23 08:24:48.908
STEP: Updating Pods in reverse ordinal order 07/10/23 08:24:58.938
Jul 10 08:24:58.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:24:59.095: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:24:59.095: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:24:59.095: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:25:09.132: INFO: Waiting for StatefulSet statefulset-5580/ss2 to complete update
STEP: Rolling back to a previous revision 07/10/23 08:25:19.144
Jul 10 08:25:19.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:25:19.296: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:25:19.296: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:25:19.296: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:25:29.340: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 07/10/23 08:25:39.369
Jul 10 08:25:39.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:25:39.525: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:25:39.525: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:25:39.525: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:25:49.552: INFO: Waiting for StatefulSet statefulset-5580/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 08:25:59.562: INFO: Deleting all statefulset in ns statefulset-5580
Jul 10 08:25:59.566: INFO: Scaling statefulset ss2 to 0
Jul 10 08:26:09.594: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:26:09.598: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 08:26:09.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5580" for this suite. 07/10/23 08:26:09.629
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":85,"skipped":1721,"failed":0}
------------------------------
• [SLOW TEST] [101.093 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:24:28.546
    Jul 10 08:24:28.546: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 08:24:28.547
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:24:28.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:24:28.585
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5580 07/10/23 08:24:28.587
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 07/10/23 08:24:28.598
    Jul 10 08:24:28.688: INFO: Found 0 stateful pods, waiting for 3
    Jul 10 08:24:38.694: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:24:38.694: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:24:38.694: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:24:38.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:24:38.858: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:24:38.858: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:24:38.858: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 07/10/23 08:24:48.883
    Jul 10 08:24:48.908: INFO: Updating stateful set ss2
    STEP: Creating a new revision 07/10/23 08:24:48.908
    STEP: Updating Pods in reverse ordinal order 07/10/23 08:24:58.938
    Jul 10 08:24:58.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:24:59.095: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:24:59.095: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:24:59.095: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:25:09.132: INFO: Waiting for StatefulSet statefulset-5580/ss2 to complete update
    STEP: Rolling back to a previous revision 07/10/23 08:25:19.144
    Jul 10 08:25:19.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:25:19.296: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:25:19.296: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:25:19.296: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:25:29.340: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 07/10/23 08:25:39.369
    Jul 10 08:25:39.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-5580 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:25:39.525: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:25:39.525: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:25:39.525: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:25:49.552: INFO: Waiting for StatefulSet statefulset-5580/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 08:25:59.562: INFO: Deleting all statefulset in ns statefulset-5580
    Jul 10 08:25:59.566: INFO: Scaling statefulset ss2 to 0
    Jul 10 08:26:09.594: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:26:09.598: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 08:26:09.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5580" for this suite. 07/10/23 08:26:09.629
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:26:09.64
Jul 10 08:26:09.640: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:26:09.641
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:09.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:09.672
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 07/10/23 08:26:09.674
Jul 10 08:26:09.687: INFO: Waiting up to 5m0s for pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f" in namespace "downward-api-6708" to be "running and ready"
Jul 10 08:26:09.691: INFO: Pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05613ms
Jul 10 08:26:09.691: INFO: The phase of Pod annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:26:11.696: INFO: Pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.009115499s
Jul 10 08:26:11.696: INFO: The phase of Pod annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f is Running (Ready = true)
Jul 10 08:26:11.696: INFO: Pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f" satisfied condition "running and ready"
Jul 10 08:26:12.236: INFO: Successfully updated pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 08:26:16.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6708" for this suite. 07/10/23 08:26:16.277
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":86,"skipped":1722,"failed":0}
------------------------------
• [SLOW TEST] [6.655 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:26:09.64
    Jul 10 08:26:09.640: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:26:09.641
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:09.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:09.672
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 07/10/23 08:26:09.674
    Jul 10 08:26:09.687: INFO: Waiting up to 5m0s for pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f" in namespace "downward-api-6708" to be "running and ready"
    Jul 10 08:26:09.691: INFO: Pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05613ms
    Jul 10 08:26:09.691: INFO: The phase of Pod annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:26:11.696: INFO: Pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.009115499s
    Jul 10 08:26:11.696: INFO: The phase of Pod annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f is Running (Ready = true)
    Jul 10 08:26:11.696: INFO: Pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f" satisfied condition "running and ready"
    Jul 10 08:26:12.236: INFO: Successfully updated pod "annotationupdate343fc414-7b27-4246-89d6-1cef71eb1d1f"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 08:26:16.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6708" for this suite. 07/10/23 08:26:16.277
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:26:16.299
Jul 10 08:26:16.299: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 07/10/23 08:26:16.3
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:16.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:16.347
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 07/10/23 08:26:16.349
STEP: Creating hostNetwork=false pod 07/10/23 08:26:16.349
Jul 10 08:26:16.363: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-315" to be "running and ready"
Jul 10 08:26:16.366: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667364ms
Jul 10 08:26:16.366: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:26:18.372: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009342637s
Jul 10 08:26:18.372: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:26:20.372: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009872143s
Jul 10 08:26:20.372: INFO: The phase of Pod test-pod is Running (Ready = true)
Jul 10 08:26:20.372: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 07/10/23 08:26:20.377
Jul 10 08:26:20.389: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-315" to be "running and ready"
Jul 10 08:26:20.393: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.975905ms
Jul 10 08:26:20.394: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:26:22.399: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009385312s
Jul 10 08:26:22.399: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Jul 10 08:26:22.399: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 07/10/23 08:26:22.403
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 07/10/23 08:26:22.403
Jul 10 08:26:22.404: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.404: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.405: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.405: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul 10 08:26:22.500: INFO: Exec stderr: ""
Jul 10 08:26:22.500: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.500: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.501: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.501: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul 10 08:26:22.588: INFO: Exec stderr: ""
Jul 10 08:26:22.588: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.588: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.589: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.589: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul 10 08:26:22.669: INFO: Exec stderr: ""
Jul 10 08:26:22.669: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.670: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.670: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul 10 08:26:22.749: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 07/10/23 08:26:22.749
Jul 10 08:26:22.749: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.749: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.750: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.750: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jul 10 08:26:22.837: INFO: Exec stderr: ""
Jul 10 08:26:22.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.837: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.838: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.838: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jul 10 08:26:22.914: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 07/10/23 08:26:22.914
Jul 10 08:26:22.915: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.915: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.915: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.916: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul 10 08:26:22.984: INFO: Exec stderr: ""
Jul 10 08:26:22.984: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:22.984: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:22.985: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:22.985: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul 10 08:26:23.077: INFO: Exec stderr: ""
Jul 10 08:26:23.077: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:23.077: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:23.078: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:23.078: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul 10 08:26:23.149: INFO: Exec stderr: ""
Jul 10 08:26:23.149: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 08:26:23.149: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:26:23.150: INFO: ExecWithOptions: Clientset creation
Jul 10 08:26:23.150: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul 10 08:26:23.214: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Jul 10 08:26:23.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-315" for this suite. 07/10/23 08:26:23.22
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":87,"skipped":1754,"failed":0}
------------------------------
• [SLOW TEST] [7.195 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:26:16.299
    Jul 10 08:26:16.299: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 07/10/23 08:26:16.3
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:16.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:16.347
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 07/10/23 08:26:16.349
    STEP: Creating hostNetwork=false pod 07/10/23 08:26:16.349
    Jul 10 08:26:16.363: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-315" to be "running and ready"
    Jul 10 08:26:16.366: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667364ms
    Jul 10 08:26:16.366: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:26:18.372: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009342637s
    Jul 10 08:26:18.372: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:26:20.372: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009872143s
    Jul 10 08:26:20.372: INFO: The phase of Pod test-pod is Running (Ready = true)
    Jul 10 08:26:20.372: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 07/10/23 08:26:20.377
    Jul 10 08:26:20.389: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-315" to be "running and ready"
    Jul 10 08:26:20.393: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.975905ms
    Jul 10 08:26:20.394: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:26:22.399: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009385312s
    Jul 10 08:26:22.399: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Jul 10 08:26:22.399: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 07/10/23 08:26:22.403
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 07/10/23 08:26:22.403
    Jul 10 08:26:22.404: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.404: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.405: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.405: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jul 10 08:26:22.500: INFO: Exec stderr: ""
    Jul 10 08:26:22.500: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.500: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.501: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.501: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jul 10 08:26:22.588: INFO: Exec stderr: ""
    Jul 10 08:26:22.588: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.588: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.589: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.589: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jul 10 08:26:22.669: INFO: Exec stderr: ""
    Jul 10 08:26:22.669: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.670: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.670: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jul 10 08:26:22.749: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 07/10/23 08:26:22.749
    Jul 10 08:26:22.749: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.749: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.750: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.750: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Jul 10 08:26:22.837: INFO: Exec stderr: ""
    Jul 10 08:26:22.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.837: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.838: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.838: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Jul 10 08:26:22.914: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 07/10/23 08:26:22.914
    Jul 10 08:26:22.915: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.915: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.915: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.916: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jul 10 08:26:22.984: INFO: Exec stderr: ""
    Jul 10 08:26:22.984: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:22.984: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:22.985: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:22.985: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jul 10 08:26:23.077: INFO: Exec stderr: ""
    Jul 10 08:26:23.077: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:23.077: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:23.078: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:23.078: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jul 10 08:26:23.149: INFO: Exec stderr: ""
    Jul 10 08:26:23.149: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-315 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 08:26:23.149: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:26:23.150: INFO: ExecWithOptions: Clientset creation
    Jul 10 08:26:23.150: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-315/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jul 10 08:26:23.214: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Jul 10 08:26:23.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-315" for this suite. 07/10/23 08:26:23.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:26:23.495
Jul 10 08:26:23.495: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:26:23.496
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:23.53
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:23.533
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-458d52b8-b869-477c-997f-7b752e0964e8 07/10/23 08:26:23.535
STEP: Creating a pod to test consume configMaps 07/10/23 08:26:23.549
Jul 10 08:26:23.563: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f" in namespace "projected-3478" to be "Succeeded or Failed"
Jul 10 08:26:23.566: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.17972ms
Jul 10 08:26:25.571: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008746798s
Jul 10 08:26:27.572: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009702848s
STEP: Saw pod success 07/10/23 08:26:27.572
Jul 10 08:26:27.573: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f" satisfied condition "Succeeded or Failed"
Jul 10 08:26:27.581: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:26:27.614
Jul 10 08:26:27.635: INFO: Waiting for pod pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f to disappear
Jul 10 08:26:27.641: INFO: Pod pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:26:27.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3478" for this suite. 07/10/23 08:26:27.646
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":88,"skipped":1773,"failed":0}
------------------------------
• [4.160 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:26:23.495
    Jul 10 08:26:23.495: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:26:23.496
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:23.53
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:23.533
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-458d52b8-b869-477c-997f-7b752e0964e8 07/10/23 08:26:23.535
    STEP: Creating a pod to test consume configMaps 07/10/23 08:26:23.549
    Jul 10 08:26:23.563: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f" in namespace "projected-3478" to be "Succeeded or Failed"
    Jul 10 08:26:23.566: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.17972ms
    Jul 10 08:26:25.571: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008746798s
    Jul 10 08:26:27.572: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009702848s
    STEP: Saw pod success 07/10/23 08:26:27.572
    Jul 10 08:26:27.573: INFO: Pod "pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f" satisfied condition "Succeeded or Failed"
    Jul 10 08:26:27.581: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:26:27.614
    Jul 10 08:26:27.635: INFO: Waiting for pod pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f to disappear
    Jul 10 08:26:27.641: INFO: Pod pod-projected-configmaps-17356fc5-69e8-4844-b200-d986e075692f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:26:27.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3478" for this suite. 07/10/23 08:26:27.646
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:26:27.656
Jul 10 08:26:27.657: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename events 07/10/23 08:26:27.658
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:27.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:27.682
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 07/10/23 08:26:27.689
STEP: listing all events in all namespaces 07/10/23 08:26:27.712
STEP: patching the test event 07/10/23 08:26:27.722
STEP: fetching the test event 07/10/23 08:26:27.734
STEP: updating the test event 07/10/23 08:26:27.739
STEP: getting the test event 07/10/23 08:26:27.753
STEP: deleting the test event 07/10/23 08:26:27.757
STEP: listing all events in all namespaces 07/10/23 08:26:27.769
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Jul 10 08:26:27.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-78" for this suite. 07/10/23 08:26:27.785
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":89,"skipped":1774,"failed":0}
------------------------------
• [0.141 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:26:27.656
    Jul 10 08:26:27.657: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename events 07/10/23 08:26:27.658
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:27.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:27.682
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 07/10/23 08:26:27.689
    STEP: listing all events in all namespaces 07/10/23 08:26:27.712
    STEP: patching the test event 07/10/23 08:26:27.722
    STEP: fetching the test event 07/10/23 08:26:27.734
    STEP: updating the test event 07/10/23 08:26:27.739
    STEP: getting the test event 07/10/23 08:26:27.753
    STEP: deleting the test event 07/10/23 08:26:27.757
    STEP: listing all events in all namespaces 07/10/23 08:26:27.769
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Jul 10 08:26:27.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-78" for this suite. 07/10/23 08:26:27.785
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:26:27.802
Jul 10 08:26:27.802: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:26:27.803
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:27.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:27.841
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-ec0ab83b-663c-42cb-aeb5-f792043b0b57 07/10/23 08:26:27.848
STEP: Creating configMap with name cm-test-opt-upd-a6d4df17-009c-4568-8f6b-e7df7d1122dd 07/10/23 08:26:27.856
STEP: Creating the pod 07/10/23 08:26:27.867
Jul 10 08:26:27.881: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d" in namespace "projected-1459" to be "running and ready"
Jul 10 08:26:27.885: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.917995ms
Jul 10 08:26:27.885: INFO: The phase of Pod pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:26:29.891: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009896218s
Jul 10 08:26:29.891: INFO: The phase of Pod pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:26:31.893: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d": Phase="Running", Reason="", readiness=true. Elapsed: 4.011428396s
Jul 10 08:26:31.893: INFO: The phase of Pod pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d is Running (Ready = true)
Jul 10 08:26:31.893: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-ec0ab83b-663c-42cb-aeb5-f792043b0b57 07/10/23 08:26:31.932
STEP: Updating configmap cm-test-opt-upd-a6d4df17-009c-4568-8f6b-e7df7d1122dd 07/10/23 08:26:31.942
STEP: Creating configMap with name cm-test-opt-create-baf79026-ef97-4616-8b27-f94303993872 07/10/23 08:26:31.972
STEP: waiting to observe update in volume 07/10/23 08:26:31.98
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:28:02.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1459" for this suite. 07/10/23 08:28:02.645
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":90,"skipped":1852,"failed":0}
------------------------------
• [SLOW TEST] [94.858 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:26:27.802
    Jul 10 08:26:27.802: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:26:27.803
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:26:27.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:26:27.841
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-ec0ab83b-663c-42cb-aeb5-f792043b0b57 07/10/23 08:26:27.848
    STEP: Creating configMap with name cm-test-opt-upd-a6d4df17-009c-4568-8f6b-e7df7d1122dd 07/10/23 08:26:27.856
    STEP: Creating the pod 07/10/23 08:26:27.867
    Jul 10 08:26:27.881: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d" in namespace "projected-1459" to be "running and ready"
    Jul 10 08:26:27.885: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.917995ms
    Jul 10 08:26:27.885: INFO: The phase of Pod pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:26:29.891: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009896218s
    Jul 10 08:26:29.891: INFO: The phase of Pod pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:26:31.893: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d": Phase="Running", Reason="", readiness=true. Elapsed: 4.011428396s
    Jul 10 08:26:31.893: INFO: The phase of Pod pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d is Running (Ready = true)
    Jul 10 08:26:31.893: INFO: Pod "pod-projected-configmaps-82bcd988-50d3-4eb3-8533-5fe02a08259d" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-ec0ab83b-663c-42cb-aeb5-f792043b0b57 07/10/23 08:26:31.932
    STEP: Updating configmap cm-test-opt-upd-a6d4df17-009c-4568-8f6b-e7df7d1122dd 07/10/23 08:26:31.942
    STEP: Creating configMap with name cm-test-opt-create-baf79026-ef97-4616-8b27-f94303993872 07/10/23 08:26:31.972
    STEP: waiting to observe update in volume 07/10/23 08:26:31.98
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:28:02.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1459" for this suite. 07/10/23 08:28:02.645
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:02.663
Jul 10 08:28:02.664: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename watch 07/10/23 08:28:02.666
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:02.699
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:02.702
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 07/10/23 08:28:02.704
STEP: modifying the configmap once 07/10/23 08:28:02.712
STEP: modifying the configmap a second time 07/10/23 08:28:02.723
STEP: deleting the configmap 07/10/23 08:28:02.733
STEP: creating a watch on configmaps from the resource version returned by the first update 07/10/23 08:28:02.743
STEP: Expecting to observe notifications for all changes to the configmap after the first update 07/10/23 08:28:02.744
Jul 10 08:28:02.744: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4688  d6a37e89-a799-484d-a972-7674a8422557 79173 0 2023-07-10 08:28:02 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-07-10 08:28:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 08:28:02.745: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4688  d6a37e89-a799-484d-a972-7674a8422557 79174 0 2023-07-10 08:28:02 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-07-10 08:28:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jul 10 08:28:02.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4688" for this suite. 07/10/23 08:28:02.749
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":91,"skipped":1879,"failed":0}
------------------------------
• [0.095 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:02.663
    Jul 10 08:28:02.664: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename watch 07/10/23 08:28:02.666
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:02.699
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:02.702
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 07/10/23 08:28:02.704
    STEP: modifying the configmap once 07/10/23 08:28:02.712
    STEP: modifying the configmap a second time 07/10/23 08:28:02.723
    STEP: deleting the configmap 07/10/23 08:28:02.733
    STEP: creating a watch on configmaps from the resource version returned by the first update 07/10/23 08:28:02.743
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 07/10/23 08:28:02.744
    Jul 10 08:28:02.744: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4688  d6a37e89-a799-484d-a972-7674a8422557 79173 0 2023-07-10 08:28:02 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-07-10 08:28:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 08:28:02.745: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4688  d6a37e89-a799-484d-a972-7674a8422557 79174 0 2023-07-10 08:28:02 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-07-10 08:28:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jul 10 08:28:02.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4688" for this suite. 07/10/23 08:28:02.749
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:02.76
Jul 10 08:28:02.760: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename discovery 07/10/23 08:28:02.761
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:02.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:02.792
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 07/10/23 08:28:02.796
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Jul 10 08:28:03.418: INFO: Checking APIGroup: apiregistration.k8s.io
Jul 10 08:28:03.419: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Jul 10 08:28:03.419: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Jul 10 08:28:03.419: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Jul 10 08:28:03.419: INFO: Checking APIGroup: apps
Jul 10 08:28:03.420: INFO: PreferredVersion.GroupVersion: apps/v1
Jul 10 08:28:03.420: INFO: Versions found [{apps/v1 v1}]
Jul 10 08:28:03.420: INFO: apps/v1 matches apps/v1
Jul 10 08:28:03.420: INFO: Checking APIGroup: events.k8s.io
Jul 10 08:28:03.421: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Jul 10 08:28:03.421: INFO: Versions found [{events.k8s.io/v1 v1}]
Jul 10 08:28:03.421: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Jul 10 08:28:03.421: INFO: Checking APIGroup: authentication.k8s.io
Jul 10 08:28:03.421: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Jul 10 08:28:03.421: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Jul 10 08:28:03.421: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Jul 10 08:28:03.421: INFO: Checking APIGroup: authorization.k8s.io
Jul 10 08:28:03.422: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Jul 10 08:28:03.422: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Jul 10 08:28:03.422: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Jul 10 08:28:03.422: INFO: Checking APIGroup: autoscaling
Jul 10 08:28:03.423: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Jul 10 08:28:03.423: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Jul 10 08:28:03.423: INFO: autoscaling/v2 matches autoscaling/v2
Jul 10 08:28:03.423: INFO: Checking APIGroup: batch
Jul 10 08:28:03.424: INFO: PreferredVersion.GroupVersion: batch/v1
Jul 10 08:28:03.424: INFO: Versions found [{batch/v1 v1}]
Jul 10 08:28:03.424: INFO: batch/v1 matches batch/v1
Jul 10 08:28:03.424: INFO: Checking APIGroup: certificates.k8s.io
Jul 10 08:28:03.425: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Jul 10 08:28:03.425: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Jul 10 08:28:03.425: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Jul 10 08:28:03.425: INFO: Checking APIGroup: networking.k8s.io
Jul 10 08:28:03.425: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Jul 10 08:28:03.425: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1alpha1 v1alpha1}]
Jul 10 08:28:03.425: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Jul 10 08:28:03.425: INFO: Checking APIGroup: policy
Jul 10 08:28:03.426: INFO: PreferredVersion.GroupVersion: policy/v1
Jul 10 08:28:03.426: INFO: Versions found [{policy/v1 v1}]
Jul 10 08:28:03.426: INFO: policy/v1 matches policy/v1
Jul 10 08:28:03.426: INFO: Checking APIGroup: rbac.authorization.k8s.io
Jul 10 08:28:03.427: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Jul 10 08:28:03.427: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Jul 10 08:28:03.427: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Jul 10 08:28:03.427: INFO: Checking APIGroup: storage.k8s.io
Jul 10 08:28:03.428: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Jul 10 08:28:03.428: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Jul 10 08:28:03.428: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Jul 10 08:28:03.428: INFO: Checking APIGroup: admissionregistration.k8s.io
Jul 10 08:28:03.429: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Jul 10 08:28:03.429: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Jul 10 08:28:03.429: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Jul 10 08:28:03.429: INFO: Checking APIGroup: apiextensions.k8s.io
Jul 10 08:28:03.429: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Jul 10 08:28:03.429: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Jul 10 08:28:03.429: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Jul 10 08:28:03.429: INFO: Checking APIGroup: scheduling.k8s.io
Jul 10 08:28:03.430: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Jul 10 08:28:03.430: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Jul 10 08:28:03.430: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Jul 10 08:28:03.430: INFO: Checking APIGroup: coordination.k8s.io
Jul 10 08:28:03.431: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Jul 10 08:28:03.431: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Jul 10 08:28:03.431: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Jul 10 08:28:03.431: INFO: Checking APIGroup: node.k8s.io
Jul 10 08:28:03.432: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Jul 10 08:28:03.432: INFO: Versions found [{node.k8s.io/v1 v1}]
Jul 10 08:28:03.432: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Jul 10 08:28:03.432: INFO: Checking APIGroup: discovery.k8s.io
Jul 10 08:28:03.433: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Jul 10 08:28:03.433: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Jul 10 08:28:03.433: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Jul 10 08:28:03.433: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Jul 10 08:28:03.434: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Jul 10 08:28:03.434: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Jul 10 08:28:03.434: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Jul 10 08:28:03.434: INFO: Checking APIGroup: internal.apiserver.k8s.io
Jul 10 08:28:03.434: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
Jul 10 08:28:03.434: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
Jul 10 08:28:03.434: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
Jul 10 08:28:03.434: INFO: Checking APIGroup: crd.projectcalico.org
Jul 10 08:28:03.435: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Jul 10 08:28:03.435: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Jul 10 08:28:03.435: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Jul 10 08:28:03.435: INFO: Checking APIGroup: snapshot.storage.k8s.io
Jul 10 08:28:03.436: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Jul 10 08:28:03.436: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
Jul 10 08:28:03.436: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Jul 10 08:28:03.436: INFO: Checking APIGroup: metrics.k8s.io
Jul 10 08:28:03.437: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Jul 10 08:28:03.437: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Jul 10 08:28:03.437: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Jul 10 08:28:03.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-3136" for this suite. 07/10/23 08:28:03.442
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":92,"skipped":1910,"failed":0}
------------------------------
• [0.692 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:02.76
    Jul 10 08:28:02.760: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename discovery 07/10/23 08:28:02.761
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:02.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:02.792
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 07/10/23 08:28:02.796
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Jul 10 08:28:03.418: INFO: Checking APIGroup: apiregistration.k8s.io
    Jul 10 08:28:03.419: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Jul 10 08:28:03.419: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Jul 10 08:28:03.419: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Jul 10 08:28:03.419: INFO: Checking APIGroup: apps
    Jul 10 08:28:03.420: INFO: PreferredVersion.GroupVersion: apps/v1
    Jul 10 08:28:03.420: INFO: Versions found [{apps/v1 v1}]
    Jul 10 08:28:03.420: INFO: apps/v1 matches apps/v1
    Jul 10 08:28:03.420: INFO: Checking APIGroup: events.k8s.io
    Jul 10 08:28:03.421: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Jul 10 08:28:03.421: INFO: Versions found [{events.k8s.io/v1 v1}]
    Jul 10 08:28:03.421: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Jul 10 08:28:03.421: INFO: Checking APIGroup: authentication.k8s.io
    Jul 10 08:28:03.421: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Jul 10 08:28:03.421: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Jul 10 08:28:03.421: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Jul 10 08:28:03.421: INFO: Checking APIGroup: authorization.k8s.io
    Jul 10 08:28:03.422: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Jul 10 08:28:03.422: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Jul 10 08:28:03.422: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Jul 10 08:28:03.422: INFO: Checking APIGroup: autoscaling
    Jul 10 08:28:03.423: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Jul 10 08:28:03.423: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Jul 10 08:28:03.423: INFO: autoscaling/v2 matches autoscaling/v2
    Jul 10 08:28:03.423: INFO: Checking APIGroup: batch
    Jul 10 08:28:03.424: INFO: PreferredVersion.GroupVersion: batch/v1
    Jul 10 08:28:03.424: INFO: Versions found [{batch/v1 v1}]
    Jul 10 08:28:03.424: INFO: batch/v1 matches batch/v1
    Jul 10 08:28:03.424: INFO: Checking APIGroup: certificates.k8s.io
    Jul 10 08:28:03.425: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Jul 10 08:28:03.425: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Jul 10 08:28:03.425: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Jul 10 08:28:03.425: INFO: Checking APIGroup: networking.k8s.io
    Jul 10 08:28:03.425: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Jul 10 08:28:03.425: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1alpha1 v1alpha1}]
    Jul 10 08:28:03.425: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Jul 10 08:28:03.425: INFO: Checking APIGroup: policy
    Jul 10 08:28:03.426: INFO: PreferredVersion.GroupVersion: policy/v1
    Jul 10 08:28:03.426: INFO: Versions found [{policy/v1 v1}]
    Jul 10 08:28:03.426: INFO: policy/v1 matches policy/v1
    Jul 10 08:28:03.426: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Jul 10 08:28:03.427: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Jul 10 08:28:03.427: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Jul 10 08:28:03.427: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Jul 10 08:28:03.427: INFO: Checking APIGroup: storage.k8s.io
    Jul 10 08:28:03.428: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Jul 10 08:28:03.428: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Jul 10 08:28:03.428: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Jul 10 08:28:03.428: INFO: Checking APIGroup: admissionregistration.k8s.io
    Jul 10 08:28:03.429: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Jul 10 08:28:03.429: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Jul 10 08:28:03.429: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Jul 10 08:28:03.429: INFO: Checking APIGroup: apiextensions.k8s.io
    Jul 10 08:28:03.429: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Jul 10 08:28:03.429: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Jul 10 08:28:03.429: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Jul 10 08:28:03.429: INFO: Checking APIGroup: scheduling.k8s.io
    Jul 10 08:28:03.430: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Jul 10 08:28:03.430: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Jul 10 08:28:03.430: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Jul 10 08:28:03.430: INFO: Checking APIGroup: coordination.k8s.io
    Jul 10 08:28:03.431: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Jul 10 08:28:03.431: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Jul 10 08:28:03.431: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Jul 10 08:28:03.431: INFO: Checking APIGroup: node.k8s.io
    Jul 10 08:28:03.432: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Jul 10 08:28:03.432: INFO: Versions found [{node.k8s.io/v1 v1}]
    Jul 10 08:28:03.432: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Jul 10 08:28:03.432: INFO: Checking APIGroup: discovery.k8s.io
    Jul 10 08:28:03.433: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Jul 10 08:28:03.433: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Jul 10 08:28:03.433: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Jul 10 08:28:03.433: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Jul 10 08:28:03.434: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Jul 10 08:28:03.434: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Jul 10 08:28:03.434: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Jul 10 08:28:03.434: INFO: Checking APIGroup: internal.apiserver.k8s.io
    Jul 10 08:28:03.434: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
    Jul 10 08:28:03.434: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
    Jul 10 08:28:03.434: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
    Jul 10 08:28:03.434: INFO: Checking APIGroup: crd.projectcalico.org
    Jul 10 08:28:03.435: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Jul 10 08:28:03.435: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Jul 10 08:28:03.435: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Jul 10 08:28:03.435: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Jul 10 08:28:03.436: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Jul 10 08:28:03.436: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
    Jul 10 08:28:03.436: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Jul 10 08:28:03.436: INFO: Checking APIGroup: metrics.k8s.io
    Jul 10 08:28:03.437: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Jul 10 08:28:03.437: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Jul 10 08:28:03.437: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Jul 10 08:28:03.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-3136" for this suite. 07/10/23 08:28:03.442
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:03.453
Jul 10 08:28:03.453: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:28:03.454
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:03.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:03.488
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:28:03.509
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:28:04.105
STEP: Deploying the webhook pod 07/10/23 08:28:04.118
STEP: Wait for the deployment to be ready 07/10/23 08:28:04.248
Jul 10 08:28:04.271: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jul 10 08:28:06.291: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 08:28:08.342
STEP: Verifying the service has paired with the endpoint 07/10/23 08:28:08.362
Jul 10 08:28:09.362: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 07/10/23 08:28:09.367
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 07/10/23 08:28:09.391
STEP: Creating a dummy validating-webhook-configuration object 07/10/23 08:28:09.411
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 07/10/23 08:28:09.424
STEP: Creating a dummy mutating-webhook-configuration object 07/10/23 08:28:09.439
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 07/10/23 08:28:09.457
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:28:09.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7483" for this suite. 07/10/23 08:28:09.486
STEP: Destroying namespace "webhook-7483-markers" for this suite. 07/10/23 08:28:09.504
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":93,"skipped":1913,"failed":0}
------------------------------
• [SLOW TEST] [6.133 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:03.453
    Jul 10 08:28:03.453: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:28:03.454
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:03.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:03.488
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:28:03.509
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:28:04.105
    STEP: Deploying the webhook pod 07/10/23 08:28:04.118
    STEP: Wait for the deployment to be ready 07/10/23 08:28:04.248
    Jul 10 08:28:04.271: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jul 10 08:28:06.291: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 28, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 08:28:08.342
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:28:08.362
    Jul 10 08:28:09.362: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 07/10/23 08:28:09.367
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 07/10/23 08:28:09.391
    STEP: Creating a dummy validating-webhook-configuration object 07/10/23 08:28:09.411
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 07/10/23 08:28:09.424
    STEP: Creating a dummy mutating-webhook-configuration object 07/10/23 08:28:09.439
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 07/10/23 08:28:09.457
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:28:09.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7483" for this suite. 07/10/23 08:28:09.486
    STEP: Destroying namespace "webhook-7483-markers" for this suite. 07/10/23 08:28:09.504
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:09.587
Jul 10 08:28:09.587: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename events 07/10/23 08:28:09.588
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:09.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:09.631
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 07/10/23 08:28:09.633
Jul 10 08:28:09.652: INFO: created test-event-1
Jul 10 08:28:09.661: INFO: created test-event-2
Jul 10 08:28:09.667: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 07/10/23 08:28:09.667
STEP: delete collection of events 07/10/23 08:28:09.678
Jul 10 08:28:09.678: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 07/10/23 08:28:09.721
Jul 10 08:28:09.721: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Jul 10 08:28:09.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4389" for this suite. 07/10/23 08:28:09.728
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":94,"skipped":1931,"failed":0}
------------------------------
• [0.152 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:09.587
    Jul 10 08:28:09.587: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename events 07/10/23 08:28:09.588
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:09.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:09.631
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 07/10/23 08:28:09.633
    Jul 10 08:28:09.652: INFO: created test-event-1
    Jul 10 08:28:09.661: INFO: created test-event-2
    Jul 10 08:28:09.667: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 07/10/23 08:28:09.667
    STEP: delete collection of events 07/10/23 08:28:09.678
    Jul 10 08:28:09.678: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 07/10/23 08:28:09.721
    Jul 10 08:28:09.721: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Jul 10 08:28:09.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4389" for this suite. 07/10/23 08:28:09.728
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:09.739
Jul 10 08:28:09.739: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:28:09.74
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:09.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:09.792
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 07/10/23 08:28:09.794
STEP: Creating a ResourceQuota 07/10/23 08:28:14.8
STEP: Ensuring resource quota status is calculated 07/10/23 08:28:14.808
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:28:16.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4591" for this suite. 07/10/23 08:28:16.82
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":95,"skipped":1941,"failed":0}
------------------------------
• [SLOW TEST] [7.091 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:09.739
    Jul 10 08:28:09.739: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:28:09.74
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:09.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:09.792
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 07/10/23 08:28:09.794
    STEP: Creating a ResourceQuota 07/10/23 08:28:14.8
    STEP: Ensuring resource quota status is calculated 07/10/23 08:28:14.808
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:28:16.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4591" for this suite. 07/10/23 08:28:16.82
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:16.83
Jul 10 08:28:16.831: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:28:16.832
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:16.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:16.864
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-7647/configmap-test-78fbfe48-ea9c-47db-aae7-f30cb4f83f4c 07/10/23 08:28:16.866
STEP: Creating a pod to test consume configMaps 07/10/23 08:28:16.873
Jul 10 08:28:16.892: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078" in namespace "configmap-7647" to be "Succeeded or Failed"
Jul 10 08:28:16.895: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115937ms
Jul 10 08:28:18.900: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007879852s
Jul 10 08:28:20.904: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011967825s
STEP: Saw pod success 07/10/23 08:28:20.904
Jul 10 08:28:20.904: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078" satisfied condition "Succeeded or Failed"
Jul 10 08:28:20.908: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078 container env-test: <nil>
STEP: delete the pod 07/10/23 08:28:20.924
Jul 10 08:28:20.948: INFO: Waiting for pod pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078 to disappear
Jul 10 08:28:20.951: INFO: Pod pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:28:20.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7647" for this suite. 07/10/23 08:28:20.956
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":96,"skipped":1945,"failed":0}
------------------------------
• [4.135 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:16.83
    Jul 10 08:28:16.831: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:28:16.832
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:16.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:16.864
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-7647/configmap-test-78fbfe48-ea9c-47db-aae7-f30cb4f83f4c 07/10/23 08:28:16.866
    STEP: Creating a pod to test consume configMaps 07/10/23 08:28:16.873
    Jul 10 08:28:16.892: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078" in namespace "configmap-7647" to be "Succeeded or Failed"
    Jul 10 08:28:16.895: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115937ms
    Jul 10 08:28:18.900: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007879852s
    Jul 10 08:28:20.904: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011967825s
    STEP: Saw pod success 07/10/23 08:28:20.904
    Jul 10 08:28:20.904: INFO: Pod "pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078" satisfied condition "Succeeded or Failed"
    Jul 10 08:28:20.908: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078 container env-test: <nil>
    STEP: delete the pod 07/10/23 08:28:20.924
    Jul 10 08:28:20.948: INFO: Waiting for pod pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078 to disappear
    Jul 10 08:28:20.951: INFO: Pod pod-configmaps-7ae2b772-8b3a-45c1-a95d-3a6197745078 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:28:20.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7647" for this suite. 07/10/23 08:28:20.956
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:20.968
Jul 10 08:28:20.968: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:28:20.969
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:20.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:20.997
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
STEP: creating service in namespace services-4213 07/10/23 08:28:20.999
STEP: creating service affinity-nodeport in namespace services-4213 07/10/23 08:28:20.999
STEP: creating replication controller affinity-nodeport in namespace services-4213 07/10/23 08:28:21.032
I0710 08:28:21.050746      21 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4213, replica count: 3
I0710 08:28:24.101426      21 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 08:28:24.115: INFO: Creating new exec pod
Jul 10 08:28:24.126: INFO: Waiting up to 5m0s for pod "execpod-affinityl854n" in namespace "services-4213" to be "running"
Jul 10 08:28:24.129: INFO: Pod "execpod-affinityl854n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627857ms
Jul 10 08:28:26.140: INFO: Pod "execpod-affinityl854n": Phase="Running", Reason="", readiness=true. Elapsed: 2.014032002s
Jul 10 08:28:26.140: INFO: Pod "execpod-affinityl854n" satisfied condition "running"
Jul 10 08:28:27.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Jul 10 08:28:27.311: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Jul 10 08:28:27.311: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:28:27.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.47.95 80'
Jul 10 08:28:27.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.47.95 80\nConnection to 192.168.47.95 80 port [tcp/http] succeeded!\n"
Jul 10 08:28:27.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:28:27.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 31486'
Jul 10 08:28:27.628: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 31486\nConnection to 10.62.109.101 31486 port [tcp/*] succeeded!\n"
Jul 10 08:28:27.628: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:28:27.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 31486'
Jul 10 08:28:27.768: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 31486\nConnection to 10.62.109.100 31486 port [tcp/*] succeeded!\n"
Jul 10 08:28:27.768: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:28:27.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.62.109.100:31486/ ; done'
Jul 10 08:28:27.963: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n"
Jul 10 08:28:27.963: INFO: stdout: "\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv"
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
Jul 10 08:28:27.963: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4213, will wait for the garbage collector to delete the pods 07/10/23 08:28:27.984
Jul 10 08:28:28.054: INFO: Deleting ReplicationController affinity-nodeport took: 13.025792ms
Jul 10 08:28:28.154: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.160942ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:28:30.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4213" for this suite. 07/10/23 08:28:30.698
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":97,"skipped":1997,"failed":0}
------------------------------
• [SLOW TEST] [9.741 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:20.968
    Jul 10 08:28:20.968: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:28:20.969
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:20.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:20.997
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2194
    STEP: creating service in namespace services-4213 07/10/23 08:28:20.999
    STEP: creating service affinity-nodeport in namespace services-4213 07/10/23 08:28:20.999
    STEP: creating replication controller affinity-nodeport in namespace services-4213 07/10/23 08:28:21.032
    I0710 08:28:21.050746      21 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4213, replica count: 3
    I0710 08:28:24.101426      21 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 08:28:24.115: INFO: Creating new exec pod
    Jul 10 08:28:24.126: INFO: Waiting up to 5m0s for pod "execpod-affinityl854n" in namespace "services-4213" to be "running"
    Jul 10 08:28:24.129: INFO: Pod "execpod-affinityl854n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627857ms
    Jul 10 08:28:26.140: INFO: Pod "execpod-affinityl854n": Phase="Running", Reason="", readiness=true. Elapsed: 2.014032002s
    Jul 10 08:28:26.140: INFO: Pod "execpod-affinityl854n" satisfied condition "running"
    Jul 10 08:28:27.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Jul 10 08:28:27.311: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Jul 10 08:28:27.311: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:28:27.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.47.95 80'
    Jul 10 08:28:27.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.47.95 80\nConnection to 192.168.47.95 80 port [tcp/http] succeeded!\n"
    Jul 10 08:28:27.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:28:27.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 31486'
    Jul 10 08:28:27.628: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 31486\nConnection to 10.62.109.101 31486 port [tcp/*] succeeded!\n"
    Jul 10 08:28:27.628: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:28:27.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.100 31486'
    Jul 10 08:28:27.768: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.100 31486\nConnection to 10.62.109.100 31486 port [tcp/*] succeeded!\n"
    Jul 10 08:28:27.768: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:28:27.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-4213 exec execpod-affinityl854n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.62.109.100:31486/ ; done'
    Jul 10 08:28:27.963: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:31486/\n"
    Jul 10 08:28:27.963: INFO: stdout: "\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv\naffinity-nodeport-pcbrv"
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Received response from host: affinity-nodeport-pcbrv
    Jul 10 08:28:27.963: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4213, will wait for the garbage collector to delete the pods 07/10/23 08:28:27.984
    Jul 10 08:28:28.054: INFO: Deleting ReplicationController affinity-nodeport took: 13.025792ms
    Jul 10 08:28:28.154: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.160942ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:28:30.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4213" for this suite. 07/10/23 08:28:30.698
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:30.71
Jul 10 08:28:30.710: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replication-controller 07/10/23 08:28:30.711
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:30.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:30.764
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Jul 10 08:28:30.766: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 07/10/23 08:28:31.782
STEP: Checking rc "condition-test" has the desired failure condition set 07/10/23 08:28:31.798
STEP: Scaling down rc "condition-test" to satisfy pod quota 07/10/23 08:28:32.811
Jul 10 08:28:32.823: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 07/10/23 08:28:32.823
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jul 10 08:28:33.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9098" for this suite. 07/10/23 08:28:33.84
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":98,"skipped":2005,"failed":0}
------------------------------
• [3.142 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:30.71
    Jul 10 08:28:30.710: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replication-controller 07/10/23 08:28:30.711
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:30.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:30.764
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Jul 10 08:28:30.766: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 07/10/23 08:28:31.782
    STEP: Checking rc "condition-test" has the desired failure condition set 07/10/23 08:28:31.798
    STEP: Scaling down rc "condition-test" to satisfy pod quota 07/10/23 08:28:32.811
    Jul 10 08:28:32.823: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 07/10/23 08:28:32.823
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jul 10 08:28:33.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9098" for this suite. 07/10/23 08:28:33.84
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:33.854
Jul 10 08:28:33.854: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 08:28:33.855
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:33.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:33.887
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Jul 10 08:28:33.919: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul 10 08:28:38.926: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 07/10/23 08:28:38.926
Jul 10 08:28:38.927: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 07/10/23 08:28:38.949
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 08:28:38.971: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4403  2678fe86-a512-4a6f-8cb9-f4d6535ca7e2 79654 1 2023-07-10 08:28:38 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-07-10 08:28:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d224d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Jul 10 08:28:38.981: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-4403  7a52fee2-1eb4-4cb8-a306-19d4bcb71ee0 79658 1 2023-07-10 08:28:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 2678fe86-a512-4a6f-8cb9-f4d6535ca7e2 0xc004a8a557 0xc004a8a558}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:28:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2678fe86-a512-4a6f-8cb9-f4d6535ca7e2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8a5e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 08:28:38.981: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jul 10 08:28:38.981: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-4403  3db88ba1-17e5-4faa-9445-4d2f2c4f87b9 79657 1 2023-07-10 08:28:33 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 2678fe86-a512-4a6f-8cb9-f4d6535ca7e2 0xc004a8a427 0xc004a8a428}] [] [{e2e.test Update apps/v1 2023-07-10 08:28:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:28:34 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-07-10 08:28:38 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"2678fe86-a512-4a6f-8cb9-f4d6535ca7e2\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004a8a4e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul 10 08:28:38.987: INFO: Pod "test-cleanup-controller-scmvg" is available:
&Pod{ObjectMeta:{test-cleanup-controller-scmvg test-cleanup-controller- deployment-4403  0810fbf8-258b-4f56-b4b6-907cb1d9fbeb 79610 0 2023-07-10 08:28:33 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:11c14d6e2e1e03b3af8334be290eb36dda54ed7cf39aea3962936e3fcd1cf8d8 cni.projectcalico.org/podIP:192.168.172.58/32 cni.projectcalico.org/podIPs:192.168.172.58/32] [{apps/v1 ReplicaSet test-cleanup-controller 3db88ba1-17e5-4faa-9445-4d2f2c4f87b9 0xc003d22827 0xc003d22828}] [] [{kube-controller-manager Update v1 2023-07-10 08:28:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3db88ba1-17e5-4faa-9445-4d2f2c4f87b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:28:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:28:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ftsz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ftsz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.58,StartTime:2023-07-10 08:28:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:28:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://be7f5b2e7a225e03618f78da4a7826603e1fa2551637fb186cc37a72f25ea92f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 08:28:38.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4403" for this suite. 07/10/23 08:28:38.994
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":99,"skipped":2049,"failed":0}
------------------------------
• [SLOW TEST] [5.163 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:33.854
    Jul 10 08:28:33.854: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 08:28:33.855
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:33.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:33.887
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Jul 10 08:28:33.919: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Jul 10 08:28:38.926: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 07/10/23 08:28:38.926
    Jul 10 08:28:38.927: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 07/10/23 08:28:38.949
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 08:28:38.971: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4403  2678fe86-a512-4a6f-8cb9-f4d6535ca7e2 79654 1 2023-07-10 08:28:38 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-07-10 08:28:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d224d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Jul 10 08:28:38.981: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-4403  7a52fee2-1eb4-4cb8-a306-19d4bcb71ee0 79658 1 2023-07-10 08:28:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 2678fe86-a512-4a6f-8cb9-f4d6535ca7e2 0xc004a8a557 0xc004a8a558}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:28:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2678fe86-a512-4a6f-8cb9-f4d6535ca7e2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8a5e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 08:28:38.981: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Jul 10 08:28:38.981: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-4403  3db88ba1-17e5-4faa-9445-4d2f2c4f87b9 79657 1 2023-07-10 08:28:33 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 2678fe86-a512-4a6f-8cb9-f4d6535ca7e2 0xc004a8a427 0xc004a8a428}] [] [{e2e.test Update apps/v1 2023-07-10 08:28:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:28:34 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-07-10 08:28:38 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"2678fe86-a512-4a6f-8cb9-f4d6535ca7e2\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004a8a4e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 08:28:38.987: INFO: Pod "test-cleanup-controller-scmvg" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-scmvg test-cleanup-controller- deployment-4403  0810fbf8-258b-4f56-b4b6-907cb1d9fbeb 79610 0 2023-07-10 08:28:33 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:11c14d6e2e1e03b3af8334be290eb36dda54ed7cf39aea3962936e3fcd1cf8d8 cni.projectcalico.org/podIP:192.168.172.58/32 cni.projectcalico.org/podIPs:192.168.172.58/32] [{apps/v1 ReplicaSet test-cleanup-controller 3db88ba1-17e5-4faa-9445-4d2f2c4f87b9 0xc003d22827 0xc003d22828}] [] [{kube-controller-manager Update v1 2023-07-10 08:28:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3db88ba1-17e5-4faa-9445-4d2f2c4f87b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:28:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:28:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ftsz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ftsz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:28:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.58,StartTime:2023-07-10 08:28:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:28:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://be7f5b2e7a225e03618f78da4a7826603e1fa2551637fb186cc37a72f25ea92f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 08:28:38.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4403" for this suite. 07/10/23 08:28:38.994
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:39.017
Jul 10 08:28:39.018: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename conformance-tests 07/10/23 08:28:39.018
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:39.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:39.064
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 07/10/23 08:28:39.066
Jul 10 08:28:39.066: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Jul 10 08:28:39.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-7204" for this suite. 07/10/23 08:28:39.084
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":100,"skipped":2053,"failed":0}
------------------------------
• [0.074 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:39.017
    Jul 10 08:28:39.018: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename conformance-tests 07/10/23 08:28:39.018
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:39.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:39.064
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 07/10/23 08:28:39.066
    Jul 10 08:28:39.066: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Jul 10 08:28:39.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-7204" for this suite. 07/10/23 08:28:39.084
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:39.092
Jul 10 08:28:39.092: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-pred 07/10/23 08:28:39.093
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:39.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:39.131
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul 10 08:28:39.133: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 10 08:28:39.141: INFO: Waiting for terminating namespaces to be deleted...
Jul 10 08:28:39.144: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-100.test before test
Jul 10 08:28:39.152: INFO: test-cleanup-controller-scmvg from deployment-4403 started at 2023-07-10 08:28:33 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container httpd ready: true, restart count 0
Jul 10 08:28:39.152: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 08:28:39.152: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:28:39.152: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container nfs-attacher ready: true, restart count 0
Jul 10 08:28:39.152: INFO: 	Container nfs-provisioner ready: true, restart count 0
Jul 10 08:28:39.152: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:28:39.152: INFO: 	Container snapshotter-controller ready: true, restart count 0
Jul 10 08:28:39.152: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:28:39.152: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:28:39.152: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container metrics-server ready: true, restart count 7
Jul 10 08:28:39.152: INFO: condition-test-dmc56 from replication-controller-9098 started at 2023-07-10 08:28:31 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container httpd ready: true, restart count 0
Jul 10 08:28:39.152: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 10 08:28:39.152: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.152: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:28:39.152: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 08:28:39.152: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-101.test before test
Jul 10 08:28:39.159: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 08:28:39.159: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:28:39.159: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 08:28:39.159: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container coredns ready: true, restart count 0
Jul 10 08:28:39.159: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:28:39.159: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:28:39.159: INFO: condition-test-k99mp from replication-controller-9098 started at 2023-07-10 08:28:31 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container httpd ready: true, restart count 0
Jul 10 08:28:39.159: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.159: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:28:39.159: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 08:28:39.159: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-102.test before test
Jul 10 08:28:39.167: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.167: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 08:28:39.167: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.167: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 08:28:39.167: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 08:28:39.167: INFO: 	Container coredns ready: true, restart count 0
Jul 10 08:28:39.167: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.167: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 08:28:39.167: INFO: 	Container plugin ready: true, restart count 0
Jul 10 08:28:39.167: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.167: INFO: 	Container e2e ready: true, restart count 0
Jul 10 08:28:39.167: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:28:39.167: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 08:28:39.167: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 08:28:39.167: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 07/10/23 08:28:39.167
Jul 10 08:28:39.182: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2929" to be "running"
Jul 10 08:28:39.190: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.598398ms
Jul 10 08:28:41.197: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015247021s
Jul 10 08:28:43.209: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.026765932s
Jul 10 08:28:43.209: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 07/10/23 08:28:43.218
STEP: Trying to apply a random label on the found node. 07/10/23 08:28:43.242
STEP: verifying the node has the label kubernetes.io/e2e-9d184827-6edd-43e2-a017-7ddd8be08faa 42 07/10/23 08:28:43.26
STEP: Trying to relaunch the pod, now with labels. 07/10/23 08:28:43.267
Jul 10 08:28:43.277: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-2929" to be "not pending"
Jul 10 08:28:43.280: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 3.193182ms
Jul 10 08:28:45.285: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00848543s
Jul 10 08:28:47.286: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.008948968s
Jul 10 08:28:47.286: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-9d184827-6edd-43e2-a017-7ddd8be08faa off the node 10-62-109-100.test 07/10/23 08:28:47.29
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9d184827-6edd-43e2-a017-7ddd8be08faa 07/10/23 08:28:47.366
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:28:47.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2929" for this suite. 07/10/23 08:28:47.38
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":101,"skipped":2055,"failed":0}
------------------------------
• [SLOW TEST] [8.297 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:39.092
    Jul 10 08:28:39.092: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-pred 07/10/23 08:28:39.093
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:39.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:39.131
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jul 10 08:28:39.133: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jul 10 08:28:39.141: INFO: Waiting for terminating namespaces to be deleted...
    Jul 10 08:28:39.144: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-100.test before test
    Jul 10 08:28:39.152: INFO: test-cleanup-controller-scmvg from deployment-4403 started at 2023-07-10 08:28:33 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container httpd ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 08:28:39.152: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container nfs-attacher ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: 	Container nfs-provisioner ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: 	Container snapshotter-controller ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container metrics-server ready: true, restart count 7
    Jul 10 08:28:39.152: INFO: condition-test-dmc56 from replication-controller-9098 started at 2023-07-10 08:28:31 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container httpd ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.152: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 08:28:39.152: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-101.test before test
    Jul 10 08:28:39.159: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 08:28:39.159: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: condition-test-k99mp from replication-controller-9098 started at 2023-07-10 08:28:31 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container httpd ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.159: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 08:28:39.159: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-102.test before test
    Jul 10 08:28:39.167: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.167: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.167: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 08:28:39.167: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.167: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.167: INFO: 	Container e2e ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 08:28:39.167: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 08:28:39.167: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 07/10/23 08:28:39.167
    Jul 10 08:28:39.182: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2929" to be "running"
    Jul 10 08:28:39.190: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.598398ms
    Jul 10 08:28:41.197: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015247021s
    Jul 10 08:28:43.209: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.026765932s
    Jul 10 08:28:43.209: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 07/10/23 08:28:43.218
    STEP: Trying to apply a random label on the found node. 07/10/23 08:28:43.242
    STEP: verifying the node has the label kubernetes.io/e2e-9d184827-6edd-43e2-a017-7ddd8be08faa 42 07/10/23 08:28:43.26
    STEP: Trying to relaunch the pod, now with labels. 07/10/23 08:28:43.267
    Jul 10 08:28:43.277: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-2929" to be "not pending"
    Jul 10 08:28:43.280: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 3.193182ms
    Jul 10 08:28:45.285: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00848543s
    Jul 10 08:28:47.286: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.008948968s
    Jul 10 08:28:47.286: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-9d184827-6edd-43e2-a017-7ddd8be08faa off the node 10-62-109-100.test 07/10/23 08:28:47.29
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-9d184827-6edd-43e2-a017-7ddd8be08faa 07/10/23 08:28:47.366
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:28:47.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2929" for this suite. 07/10/23 08:28:47.38
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:47.391
Jul 10 08:28:47.391: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:28:47.393
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:47.423
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:47.425
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-f924e083-4a31-48ff-8951-80e7dc1710ab 07/10/23 08:28:47.427
STEP: Creating a pod to test consume configMaps 07/10/23 08:28:47.435
Jul 10 08:28:47.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8" in namespace "configmap-72" to be "Succeeded or Failed"
Jul 10 08:28:47.457: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.285853ms
Jul 10 08:28:49.470: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016937757s
Jul 10 08:28:51.463: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009946416s
Jul 10 08:28:53.463: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009923948s
STEP: Saw pod success 07/10/23 08:28:53.463
Jul 10 08:28:53.463: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8" satisfied condition "Succeeded or Failed"
Jul 10 08:28:53.466: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:28:53.476
Jul 10 08:28:53.508: INFO: Waiting for pod pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8 to disappear
Jul 10 08:28:53.514: INFO: Pod pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:28:53.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-72" for this suite. 07/10/23 08:28:53.518
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":102,"skipped":2087,"failed":0}
------------------------------
• [SLOW TEST] [6.143 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:47.391
    Jul 10 08:28:47.391: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:28:47.393
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:47.423
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:47.425
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-f924e083-4a31-48ff-8951-80e7dc1710ab 07/10/23 08:28:47.427
    STEP: Creating a pod to test consume configMaps 07/10/23 08:28:47.435
    Jul 10 08:28:47.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8" in namespace "configmap-72" to be "Succeeded or Failed"
    Jul 10 08:28:47.457: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.285853ms
    Jul 10 08:28:49.470: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016937757s
    Jul 10 08:28:51.463: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009946416s
    Jul 10 08:28:53.463: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009923948s
    STEP: Saw pod success 07/10/23 08:28:53.463
    Jul 10 08:28:53.463: INFO: Pod "pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8" satisfied condition "Succeeded or Failed"
    Jul 10 08:28:53.466: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:28:53.476
    Jul 10 08:28:53.508: INFO: Waiting for pod pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8 to disappear
    Jul 10 08:28:53.514: INFO: Pod pod-configmaps-db359716-9cd1-494f-b0d6-327b730fcbb8 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:28:53.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-72" for this suite. 07/10/23 08:28:53.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:53.535
Jul 10 08:28:53.536: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-runtime 07/10/23 08:28:53.537
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:53.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:53.572
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 07/10/23 08:28:53.574
STEP: wait for the container to reach Failed 07/10/23 08:28:53.586
STEP: get the container status 07/10/23 08:28:57.624
STEP: the container should be terminated 07/10/23 08:28:57.628
STEP: the termination message should be set 07/10/23 08:28:57.628
Jul 10 08:28:57.629: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 07/10/23 08:28:57.629
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jul 10 08:28:57.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2237" for this suite. 07/10/23 08:28:57.668
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":103,"skipped":2092,"failed":0}
------------------------------
• [4.146 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:53.535
    Jul 10 08:28:53.536: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-runtime 07/10/23 08:28:53.537
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:53.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:53.572
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 07/10/23 08:28:53.574
    STEP: wait for the container to reach Failed 07/10/23 08:28:53.586
    STEP: get the container status 07/10/23 08:28:57.624
    STEP: the container should be terminated 07/10/23 08:28:57.628
    STEP: the termination message should be set 07/10/23 08:28:57.628
    Jul 10 08:28:57.629: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 07/10/23 08:28:57.629
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jul 10 08:28:57.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-2237" for this suite. 07/10/23 08:28:57.668
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:28:57.681
Jul 10 08:28:57.682: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 08:28:57.683
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:57.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:57.723
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 07/10/23 08:28:57.73
Jul 10 08:28:57.745: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2508" to be "running and ready"
Jul 10 08:28:57.749: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.558967ms
Jul 10 08:28:57.749: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:28:59.753: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008402468s
Jul 10 08:28:59.753: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jul 10 08:28:59.753: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 07/10/23 08:28:59.758
Jul 10 08:28:59.765: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-2508" to be "running and ready"
Jul 10 08:28:59.770: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.721654ms
Jul 10 08:28:59.770: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:29:01.774: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.008862158s
Jul 10 08:29:01.774: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Jul 10 08:29:01.774: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 07/10/23 08:29:01.779
Jul 10 08:29:01.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 10 08:29:01.801: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 10 08:29:03.802: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 10 08:29:03.807: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 10 08:29:05.802: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 10 08:29:05.807: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 07/10/23 08:29:05.807
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jul 10 08:29:05.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2508" for this suite. 07/10/23 08:29:05.827
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":104,"skipped":2094,"failed":0}
------------------------------
• [SLOW TEST] [8.155 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:28:57.681
    Jul 10 08:28:57.682: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 08:28:57.683
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:28:57.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:28:57.723
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 07/10/23 08:28:57.73
    Jul 10 08:28:57.745: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2508" to be "running and ready"
    Jul 10 08:28:57.749: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.558967ms
    Jul 10 08:28:57.749: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:28:59.753: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008402468s
    Jul 10 08:28:59.753: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jul 10 08:28:59.753: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 07/10/23 08:28:59.758
    Jul 10 08:28:59.765: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-2508" to be "running and ready"
    Jul 10 08:28:59.770: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.721654ms
    Jul 10 08:28:59.770: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:29:01.774: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.008862158s
    Jul 10 08:29:01.774: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Jul 10 08:29:01.774: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 07/10/23 08:29:01.779
    Jul 10 08:29:01.794: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jul 10 08:29:01.801: INFO: Pod pod-with-prestop-exec-hook still exists
    Jul 10 08:29:03.802: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jul 10 08:29:03.807: INFO: Pod pod-with-prestop-exec-hook still exists
    Jul 10 08:29:05.802: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jul 10 08:29:05.807: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 07/10/23 08:29:05.807
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jul 10 08:29:05.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2508" for this suite. 07/10/23 08:29:05.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:29:05.838
Jul 10 08:29:05.838: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:29:05.839
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:29:05.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:29:05.879
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-a1ee5dfc-f5e0-4b4b-9167-10c54a4073e4 07/10/23 08:29:05.882
STEP: Creating a pod to test consume secrets 07/10/23 08:29:05.888
Jul 10 08:29:05.907: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444" in namespace "projected-9776" to be "Succeeded or Failed"
Jul 10 08:29:05.912: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705928ms
Jul 10 08:29:07.917: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009759092s
Jul 10 08:29:09.917: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009782813s
STEP: Saw pod success 07/10/23 08:29:09.917
Jul 10 08:29:09.917: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444" satisfied condition "Succeeded or Failed"
Jul 10 08:29:09.920: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444 container projected-secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:29:09.934
Jul 10 08:29:09.969: INFO: Waiting for pod pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444 to disappear
Jul 10 08:29:09.973: INFO: Pod pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 08:29:09.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9776" for this suite. 07/10/23 08:29:09.977
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":105,"skipped":2107,"failed":0}
------------------------------
• [4.148 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:29:05.838
    Jul 10 08:29:05.838: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:29:05.839
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:29:05.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:29:05.879
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-a1ee5dfc-f5e0-4b4b-9167-10c54a4073e4 07/10/23 08:29:05.882
    STEP: Creating a pod to test consume secrets 07/10/23 08:29:05.888
    Jul 10 08:29:05.907: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444" in namespace "projected-9776" to be "Succeeded or Failed"
    Jul 10 08:29:05.912: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705928ms
    Jul 10 08:29:07.917: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009759092s
    Jul 10 08:29:09.917: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009782813s
    STEP: Saw pod success 07/10/23 08:29:09.917
    Jul 10 08:29:09.917: INFO: Pod "pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444" satisfied condition "Succeeded or Failed"
    Jul 10 08:29:09.920: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444 container projected-secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:29:09.934
    Jul 10 08:29:09.969: INFO: Waiting for pod pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444 to disappear
    Jul 10 08:29:09.973: INFO: Pod pod-projected-secrets-9d910108-0be6-4542-b909-bf544ca36444 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 08:29:09.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9776" for this suite. 07/10/23 08:29:09.977
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:29:09.986
Jul 10 08:29:09.986: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:29:09.987
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:29:10.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:29:10.03
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-7031/configmap-test-9f062dd5-59f0-4f83-b66b-6222d83d1e9c 07/10/23 08:29:10.032
STEP: Creating a pod to test consume configMaps 07/10/23 08:29:10.039
Jul 10 08:29:10.052: INFO: Waiting up to 5m0s for pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55" in namespace "configmap-7031" to be "Succeeded or Failed"
Jul 10 08:29:10.057: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.584255ms
Jul 10 08:29:12.061: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00929776s
Jul 10 08:29:14.063: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011101879s
STEP: Saw pod success 07/10/23 08:29:14.063
Jul 10 08:29:14.063: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55" satisfied condition "Succeeded or Failed"
Jul 10 08:29:14.069: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55 container env-test: <nil>
STEP: delete the pod 07/10/23 08:29:14.079
Jul 10 08:29:14.096: INFO: Waiting for pod pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55 to disappear
Jul 10 08:29:14.099: INFO: Pod pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:29:14.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7031" for this suite. 07/10/23 08:29:14.104
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":106,"skipped":2108,"failed":0}
------------------------------
• [4.126 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:29:09.986
    Jul 10 08:29:09.986: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:29:09.987
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:29:10.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:29:10.03
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-7031/configmap-test-9f062dd5-59f0-4f83-b66b-6222d83d1e9c 07/10/23 08:29:10.032
    STEP: Creating a pod to test consume configMaps 07/10/23 08:29:10.039
    Jul 10 08:29:10.052: INFO: Waiting up to 5m0s for pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55" in namespace "configmap-7031" to be "Succeeded or Failed"
    Jul 10 08:29:10.057: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.584255ms
    Jul 10 08:29:12.061: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00929776s
    Jul 10 08:29:14.063: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011101879s
    STEP: Saw pod success 07/10/23 08:29:14.063
    Jul 10 08:29:14.063: INFO: Pod "pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55" satisfied condition "Succeeded or Failed"
    Jul 10 08:29:14.069: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55 container env-test: <nil>
    STEP: delete the pod 07/10/23 08:29:14.079
    Jul 10 08:29:14.096: INFO: Waiting for pod pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55 to disappear
    Jul 10 08:29:14.099: INFO: Pod pod-configmaps-51d7b587-d357-4b3a-96b9-0d91d2a3da55 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:29:14.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7031" for this suite. 07/10/23 08:29:14.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:29:14.114
Jul 10 08:29:14.114: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 08:29:14.115
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:29:14.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:29:14.147
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7219 07/10/23 08:29:14.149
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-7219 07/10/23 08:29:14.156
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7219 07/10/23 08:29:14.168
Jul 10 08:29:14.180: INFO: Found 0 stateful pods, waiting for 1
Jul 10 08:29:24.186: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 07/10/23 08:29:24.186
Jul 10 08:29:24.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:29:24.343: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:29:24.343: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:29:24.343: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:29:24.348: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 10 08:29:34.355: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:29:34.355: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:29:34.377: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Jul 10 08:29:34.377: INFO: ss-0  10-62-109-100.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:14 +0000 UTC  }]
Jul 10 08:29:34.377: INFO: 
Jul 10 08:29:34.377: INFO: StatefulSet ss has not reached scale 3, at 1
Jul 10 08:29:35.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993953474s
Jul 10 08:29:36.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989174796s
Jul 10 08:29:37.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983852489s
Jul 10 08:29:38.401: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976913346s
Jul 10 08:29:39.411: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971502269s
Jul 10 08:29:40.416: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962036468s
Jul 10 08:29:41.422: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955964327s
Jul 10 08:29:42.429: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949437812s
Jul 10 08:29:43.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.704566ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7219 07/10/23 08:29:44.436
Jul 10 08:29:44.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:29:44.573: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:29:44.573: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:29:44.573: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:29:44.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:29:44.723: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 10 08:29:44.723: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:29:44.723: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:29:44.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:29:44.878: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul 10 08:29:44.878: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:29:44.878: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:29:44.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jul 10 08:29:54.890: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:29:54.890: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:29:54.890: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 07/10/23 08:29:54.89
Jul 10 08:29:54.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:29:55.043: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:29:55.043: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:29:55.043: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:29:55.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:29:55.185: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:29:55.185: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:29:55.185: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:29:55.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:29:55.337: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:29:55.337: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:29:55.337: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:29:55.337: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:29:55.342: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul 10 08:30:05.354: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:30:05.354: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:30:05.354: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:30:05.384: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Jul 10 08:30:05.384: INFO: ss-0  10-62-109-100.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:14 +0000 UTC  }]
Jul 10 08:30:05.384: INFO: ss-1  10-62-109-101.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
Jul 10 08:30:05.384: INFO: ss-2  10-62-109-102.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
Jul 10 08:30:05.384: INFO: 
Jul 10 08:30:05.384: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 10 08:30:06.394: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Jul 10 08:30:06.394: INFO: ss-0  10-62-109-100.test  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:14 +0000 UTC  }]
Jul 10 08:30:06.394: INFO: ss-1  10-62-109-101.test  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
Jul 10 08:30:06.394: INFO: ss-2  10-62-109-102.test  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
Jul 10 08:30:06.394: INFO: 
Jul 10 08:30:06.394: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 10 08:30:07.402: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.981279798s
Jul 10 08:30:08.407: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.972750018s
Jul 10 08:30:09.412: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.968048751s
Jul 10 08:30:10.416: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.963447936s
Jul 10 08:30:11.421: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.958759432s
Jul 10 08:30:12.426: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.954199732s
Jul 10 08:30:13.431: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.948914658s
Jul 10 08:30:14.436: INFO: Verifying statefulset ss doesn't scale past 0 for another 943.279359ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7219 07/10/23 08:30:15.437
Jul 10 08:30:15.442: INFO: Scaling statefulset ss to 0
Jul 10 08:30:15.454: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 08:30:15.457: INFO: Deleting all statefulset in ns statefulset-7219
Jul 10 08:30:15.461: INFO: Scaling statefulset ss to 0
Jul 10 08:30:15.472: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:30:15.476: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 08:30:15.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7219" for this suite. 07/10/23 08:30:15.5
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":107,"skipped":2115,"failed":0}
------------------------------
• [SLOW TEST] [61.396 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:29:14.114
    Jul 10 08:29:14.114: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 08:29:14.115
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:29:14.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:29:14.147
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7219 07/10/23 08:29:14.149
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-7219 07/10/23 08:29:14.156
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7219 07/10/23 08:29:14.168
    Jul 10 08:29:14.180: INFO: Found 0 stateful pods, waiting for 1
    Jul 10 08:29:24.186: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 07/10/23 08:29:24.186
    Jul 10 08:29:24.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:29:24.343: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:29:24.343: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:29:24.343: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:29:24.348: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Jul 10 08:29:34.355: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:29:34.355: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:29:34.377: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
    Jul 10 08:29:34.377: INFO: ss-0  10-62-109-100.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:14 +0000 UTC  }]
    Jul 10 08:29:34.377: INFO: 
    Jul 10 08:29:34.377: INFO: StatefulSet ss has not reached scale 3, at 1
    Jul 10 08:29:35.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993953474s
    Jul 10 08:29:36.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989174796s
    Jul 10 08:29:37.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983852489s
    Jul 10 08:29:38.401: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976913346s
    Jul 10 08:29:39.411: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971502269s
    Jul 10 08:29:40.416: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962036468s
    Jul 10 08:29:41.422: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955964327s
    Jul 10 08:29:42.429: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949437812s
    Jul 10 08:29:43.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.704566ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7219 07/10/23 08:29:44.436
    Jul 10 08:29:44.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:29:44.573: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:29:44.573: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:29:44.573: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:29:44.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:29:44.723: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Jul 10 08:29:44.723: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:29:44.723: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:29:44.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:29:44.878: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Jul 10 08:29:44.878: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:29:44.878: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:29:44.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Jul 10 08:29:54.890: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:29:54.890: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:29:54.890: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 07/10/23 08:29:54.89
    Jul 10 08:29:54.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:29:55.043: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:29:55.043: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:29:55.043: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:29:55.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:29:55.185: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:29:55.185: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:29:55.185: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:29:55.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-7219 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:29:55.337: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:29:55.337: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:29:55.337: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:29:55.337: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:29:55.342: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Jul 10 08:30:05.354: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:30:05.354: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:30:05.354: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:30:05.384: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
    Jul 10 08:30:05.384: INFO: ss-0  10-62-109-100.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:14 +0000 UTC  }]
    Jul 10 08:30:05.384: INFO: ss-1  10-62-109-101.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
    Jul 10 08:30:05.384: INFO: ss-2  10-62-109-102.test  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
    Jul 10 08:30:05.384: INFO: 
    Jul 10 08:30:05.384: INFO: StatefulSet ss has not reached scale 0, at 3
    Jul 10 08:30:06.394: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
    Jul 10 08:30:06.394: INFO: ss-0  10-62-109-100.test  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:14 +0000 UTC  }]
    Jul 10 08:30:06.394: INFO: ss-1  10-62-109-101.test  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
    Jul 10 08:30:06.394: INFO: ss-2  10-62-109-102.test  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:29:34 +0000 UTC  }]
    Jul 10 08:30:06.394: INFO: 
    Jul 10 08:30:06.394: INFO: StatefulSet ss has not reached scale 0, at 3
    Jul 10 08:30:07.402: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.981279798s
    Jul 10 08:30:08.407: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.972750018s
    Jul 10 08:30:09.412: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.968048751s
    Jul 10 08:30:10.416: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.963447936s
    Jul 10 08:30:11.421: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.958759432s
    Jul 10 08:30:12.426: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.954199732s
    Jul 10 08:30:13.431: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.948914658s
    Jul 10 08:30:14.436: INFO: Verifying statefulset ss doesn't scale past 0 for another 943.279359ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7219 07/10/23 08:30:15.437
    Jul 10 08:30:15.442: INFO: Scaling statefulset ss to 0
    Jul 10 08:30:15.454: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 08:30:15.457: INFO: Deleting all statefulset in ns statefulset-7219
    Jul 10 08:30:15.461: INFO: Scaling statefulset ss to 0
    Jul 10 08:30:15.472: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:30:15.476: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 08:30:15.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7219" for this suite. 07/10/23 08:30:15.5
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:30:15.511
Jul 10 08:30:15.511: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 08:30:15.512
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:30:15.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:30:15.553
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 07/10/23 08:30:15.561
STEP: create the rc2 07/10/23 08:30:15.57
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 07/10/23 08:30:20.631
STEP: delete the rc simpletest-rc-to-be-deleted 07/10/23 08:30:23.511
STEP: wait for the rc to be deleted 07/10/23 08:30:23.547
Jul 10 08:30:28.622: INFO: 73 pods remaining
Jul 10 08:30:28.622: INFO: 73 pods has nil DeletionTimestamp
Jul 10 08:30:28.622: INFO: 
STEP: Gathering metrics 07/10/23 08:30:33.573
W0710 08:30:33.593505      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul 10 08:30:33.593: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jul 10 08:30:33.593: INFO: Deleting pod "simpletest-rc-to-be-deleted-2crlc" in namespace "gc-468"
Jul 10 08:30:33.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tz6n" in namespace "gc-468"
Jul 10 08:30:33.766: INFO: Deleting pod "simpletest-rc-to-be-deleted-44ztj" in namespace "gc-468"
Jul 10 08:30:33.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-4b8p5" in namespace "gc-468"
Jul 10 08:30:33.972: INFO: Deleting pod "simpletest-rc-to-be-deleted-4bvrc" in namespace "gc-468"
Jul 10 08:30:34.022: INFO: Deleting pod "simpletest-rc-to-be-deleted-4flfz" in namespace "gc-468"
Jul 10 08:30:34.081: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qsxn" in namespace "gc-468"
Jul 10 08:30:34.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-4szvd" in namespace "gc-468"
Jul 10 08:30:34.358: INFO: Deleting pod "simpletest-rc-to-be-deleted-4trkv" in namespace "gc-468"
Jul 10 08:30:34.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-5spms" in namespace "gc-468"
Jul 10 08:30:34.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tdlw" in namespace "gc-468"
Jul 10 08:30:34.589: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cr6c" in namespace "gc-468"
Jul 10 08:30:34.672: INFO: Deleting pod "simpletest-rc-to-be-deleted-76xvr" in namespace "gc-468"
Jul 10 08:30:34.768: INFO: Deleting pod "simpletest-rc-to-be-deleted-779qr" in namespace "gc-468"
Jul 10 08:30:34.825: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zqk6" in namespace "gc-468"
Jul 10 08:30:34.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-855jp" in namespace "gc-468"
Jul 10 08:30:34.972: INFO: Deleting pod "simpletest-rc-to-be-deleted-887vk" in namespace "gc-468"
Jul 10 08:30:35.026: INFO: Deleting pod "simpletest-rc-to-be-deleted-88szh" in namespace "gc-468"
Jul 10 08:30:35.178: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qgrr" in namespace "gc-468"
Jul 10 08:30:35.238: INFO: Deleting pod "simpletest-rc-to-be-deleted-8r55m" in namespace "gc-468"
Jul 10 08:30:35.287: INFO: Deleting pod "simpletest-rc-to-be-deleted-9557m" in namespace "gc-468"
Jul 10 08:30:35.359: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nnfm" in namespace "gc-468"
Jul 10 08:30:35.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-9p8kr" in namespace "gc-468"
Jul 10 08:30:35.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rpz4" in namespace "gc-468"
Jul 10 08:30:35.570: INFO: Deleting pod "simpletest-rc-to-be-deleted-b5n7c" in namespace "gc-468"
Jul 10 08:30:35.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8mv7" in namespace "gc-468"
Jul 10 08:30:35.759: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbbpx" in namespace "gc-468"
Jul 10 08:30:35.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-bngst" in namespace "gc-468"
Jul 10 08:30:35.886: INFO: Deleting pod "simpletest-rc-to-be-deleted-bpvh6" in namespace "gc-468"
Jul 10 08:30:35.987: INFO: Deleting pod "simpletest-rc-to-be-deleted-cffr9" in namespace "gc-468"
Jul 10 08:30:36.045: INFO: Deleting pod "simpletest-rc-to-be-deleted-chldd" in namespace "gc-468"
Jul 10 08:30:36.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-cssl5" in namespace "gc-468"
Jul 10 08:30:36.156: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6cc5" in namespace "gc-468"
Jul 10 08:30:36.213: INFO: Deleting pod "simpletest-rc-to-be-deleted-dc6bs" in namespace "gc-468"
Jul 10 08:30:36.365: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkmjz" in namespace "gc-468"
Jul 10 08:30:36.407: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkt4t" in namespace "gc-468"
Jul 10 08:30:36.466: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnr4x" in namespace "gc-468"
Jul 10 08:30:36.554: INFO: Deleting pod "simpletest-rc-to-be-deleted-ds5mm" in namespace "gc-468"
Jul 10 08:30:36.598: INFO: Deleting pod "simpletest-rc-to-be-deleted-dt5c7" in namespace "gc-468"
Jul 10 08:30:36.643: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkt8p" in namespace "gc-468"
Jul 10 08:30:36.698: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5d2q" in namespace "gc-468"
Jul 10 08:30:36.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-g6kbd" in namespace "gc-468"
Jul 10 08:30:36.921: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9cbr" in namespace "gc-468"
Jul 10 08:30:36.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-ghkfl" in namespace "gc-468"
Jul 10 08:30:37.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6tnr" in namespace "gc-468"
Jul 10 08:30:37.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp8gw" in namespace "gc-468"
Jul 10 08:30:37.135: INFO: Deleting pod "simpletest-rc-to-be-deleted-jqnnt" in namespace "gc-468"
Jul 10 08:30:37.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-js8tf" in namespace "gc-468"
Jul 10 08:30:37.418: INFO: Deleting pod "simpletest-rc-to-be-deleted-k6989" in namespace "gc-468"
Jul 10 08:30:37.549: INFO: Deleting pod "simpletest-rc-to-be-deleted-kklgl" in namespace "gc-468"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 08:30:37.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-468" for this suite. 07/10/23 08:30:37.641
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":108,"skipped":2124,"failed":0}
------------------------------
• [SLOW TEST] [22.169 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:30:15.511
    Jul 10 08:30:15.511: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 08:30:15.512
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:30:15.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:30:15.553
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 07/10/23 08:30:15.561
    STEP: create the rc2 07/10/23 08:30:15.57
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 07/10/23 08:30:20.631
    STEP: delete the rc simpletest-rc-to-be-deleted 07/10/23 08:30:23.511
    STEP: wait for the rc to be deleted 07/10/23 08:30:23.547
    Jul 10 08:30:28.622: INFO: 73 pods remaining
    Jul 10 08:30:28.622: INFO: 73 pods has nil DeletionTimestamp
    Jul 10 08:30:28.622: INFO: 
    STEP: Gathering metrics 07/10/23 08:30:33.573
    W0710 08:30:33.593505      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jul 10 08:30:33.593: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Jul 10 08:30:33.593: INFO: Deleting pod "simpletest-rc-to-be-deleted-2crlc" in namespace "gc-468"
    Jul 10 08:30:33.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tz6n" in namespace "gc-468"
    Jul 10 08:30:33.766: INFO: Deleting pod "simpletest-rc-to-be-deleted-44ztj" in namespace "gc-468"
    Jul 10 08:30:33.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-4b8p5" in namespace "gc-468"
    Jul 10 08:30:33.972: INFO: Deleting pod "simpletest-rc-to-be-deleted-4bvrc" in namespace "gc-468"
    Jul 10 08:30:34.022: INFO: Deleting pod "simpletest-rc-to-be-deleted-4flfz" in namespace "gc-468"
    Jul 10 08:30:34.081: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qsxn" in namespace "gc-468"
    Jul 10 08:30:34.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-4szvd" in namespace "gc-468"
    Jul 10 08:30:34.358: INFO: Deleting pod "simpletest-rc-to-be-deleted-4trkv" in namespace "gc-468"
    Jul 10 08:30:34.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-5spms" in namespace "gc-468"
    Jul 10 08:30:34.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tdlw" in namespace "gc-468"
    Jul 10 08:30:34.589: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cr6c" in namespace "gc-468"
    Jul 10 08:30:34.672: INFO: Deleting pod "simpletest-rc-to-be-deleted-76xvr" in namespace "gc-468"
    Jul 10 08:30:34.768: INFO: Deleting pod "simpletest-rc-to-be-deleted-779qr" in namespace "gc-468"
    Jul 10 08:30:34.825: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zqk6" in namespace "gc-468"
    Jul 10 08:30:34.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-855jp" in namespace "gc-468"
    Jul 10 08:30:34.972: INFO: Deleting pod "simpletest-rc-to-be-deleted-887vk" in namespace "gc-468"
    Jul 10 08:30:35.026: INFO: Deleting pod "simpletest-rc-to-be-deleted-88szh" in namespace "gc-468"
    Jul 10 08:30:35.178: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qgrr" in namespace "gc-468"
    Jul 10 08:30:35.238: INFO: Deleting pod "simpletest-rc-to-be-deleted-8r55m" in namespace "gc-468"
    Jul 10 08:30:35.287: INFO: Deleting pod "simpletest-rc-to-be-deleted-9557m" in namespace "gc-468"
    Jul 10 08:30:35.359: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nnfm" in namespace "gc-468"
    Jul 10 08:30:35.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-9p8kr" in namespace "gc-468"
    Jul 10 08:30:35.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rpz4" in namespace "gc-468"
    Jul 10 08:30:35.570: INFO: Deleting pod "simpletest-rc-to-be-deleted-b5n7c" in namespace "gc-468"
    Jul 10 08:30:35.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8mv7" in namespace "gc-468"
    Jul 10 08:30:35.759: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbbpx" in namespace "gc-468"
    Jul 10 08:30:35.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-bngst" in namespace "gc-468"
    Jul 10 08:30:35.886: INFO: Deleting pod "simpletest-rc-to-be-deleted-bpvh6" in namespace "gc-468"
    Jul 10 08:30:35.987: INFO: Deleting pod "simpletest-rc-to-be-deleted-cffr9" in namespace "gc-468"
    Jul 10 08:30:36.045: INFO: Deleting pod "simpletest-rc-to-be-deleted-chldd" in namespace "gc-468"
    Jul 10 08:30:36.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-cssl5" in namespace "gc-468"
    Jul 10 08:30:36.156: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6cc5" in namespace "gc-468"
    Jul 10 08:30:36.213: INFO: Deleting pod "simpletest-rc-to-be-deleted-dc6bs" in namespace "gc-468"
    Jul 10 08:30:36.365: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkmjz" in namespace "gc-468"
    Jul 10 08:30:36.407: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkt4t" in namespace "gc-468"
    Jul 10 08:30:36.466: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnr4x" in namespace "gc-468"
    Jul 10 08:30:36.554: INFO: Deleting pod "simpletest-rc-to-be-deleted-ds5mm" in namespace "gc-468"
    Jul 10 08:30:36.598: INFO: Deleting pod "simpletest-rc-to-be-deleted-dt5c7" in namespace "gc-468"
    Jul 10 08:30:36.643: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkt8p" in namespace "gc-468"
    Jul 10 08:30:36.698: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5d2q" in namespace "gc-468"
    Jul 10 08:30:36.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-g6kbd" in namespace "gc-468"
    Jul 10 08:30:36.921: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9cbr" in namespace "gc-468"
    Jul 10 08:30:36.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-ghkfl" in namespace "gc-468"
    Jul 10 08:30:37.031: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6tnr" in namespace "gc-468"
    Jul 10 08:30:37.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp8gw" in namespace "gc-468"
    Jul 10 08:30:37.135: INFO: Deleting pod "simpletest-rc-to-be-deleted-jqnnt" in namespace "gc-468"
    Jul 10 08:30:37.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-js8tf" in namespace "gc-468"
    Jul 10 08:30:37.418: INFO: Deleting pod "simpletest-rc-to-be-deleted-k6989" in namespace "gc-468"
    Jul 10 08:30:37.549: INFO: Deleting pod "simpletest-rc-to-be-deleted-kklgl" in namespace "gc-468"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 08:30:37.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-468" for this suite. 07/10/23 08:30:37.641
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:30:37.683
Jul 10 08:30:37.683: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:30:37.684
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:30:37.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:30:37.833
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 07/10/23 08:30:37.835
Jul 10 08:30:37.855: INFO: Waiting up to 5m0s for pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f" in namespace "downward-api-2644" to be "Succeeded or Failed"
Jul 10 08:30:37.865: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.971563ms
Jul 10 08:30:39.870: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014348323s
Jul 10 08:30:41.871: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015631579s
Jul 10 08:30:43.872: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016796225s
STEP: Saw pod success 07/10/23 08:30:43.872
Jul 10 08:30:43.872: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f" satisfied condition "Succeeded or Failed"
Jul 10 08:30:43.888: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-1647544b-94a9-4941-a58b-494d6289920f container dapi-container: <nil>
STEP: delete the pod 07/10/23 08:30:43.904
Jul 10 08:30:43.934: INFO: Waiting for pod downward-api-1647544b-94a9-4941-a58b-494d6289920f to disappear
Jul 10 08:30:43.939: INFO: Pod downward-api-1647544b-94a9-4941-a58b-494d6289920f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jul 10 08:30:43.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2644" for this suite. 07/10/23 08:30:43.944
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":109,"skipped":2162,"failed":0}
------------------------------
• [SLOW TEST] [6.270 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:30:37.683
    Jul 10 08:30:37.683: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:30:37.684
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:30:37.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:30:37.833
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 07/10/23 08:30:37.835
    Jul 10 08:30:37.855: INFO: Waiting up to 5m0s for pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f" in namespace "downward-api-2644" to be "Succeeded or Failed"
    Jul 10 08:30:37.865: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.971563ms
    Jul 10 08:30:39.870: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014348323s
    Jul 10 08:30:41.871: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015631579s
    Jul 10 08:30:43.872: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016796225s
    STEP: Saw pod success 07/10/23 08:30:43.872
    Jul 10 08:30:43.872: INFO: Pod "downward-api-1647544b-94a9-4941-a58b-494d6289920f" satisfied condition "Succeeded or Failed"
    Jul 10 08:30:43.888: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-1647544b-94a9-4941-a58b-494d6289920f container dapi-container: <nil>
    STEP: delete the pod 07/10/23 08:30:43.904
    Jul 10 08:30:43.934: INFO: Waiting for pod downward-api-1647544b-94a9-4941-a58b-494d6289920f to disappear
    Jul 10 08:30:43.939: INFO: Pod downward-api-1647544b-94a9-4941-a58b-494d6289920f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jul 10 08:30:43.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2644" for this suite. 07/10/23 08:30:43.944
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:30:43.955
Jul 10 08:30:43.955: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename subpath 07/10/23 08:30:43.956
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:30:43.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:30:43.996
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 07/10/23 08:30:43.998
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-ppz5 07/10/23 08:30:44.016
STEP: Creating a pod to test atomic-volume-subpath 07/10/23 08:30:44.016
Jul 10 08:30:44.033: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ppz5" in namespace "subpath-4052" to be "Succeeded or Failed"
Jul 10 08:30:44.037: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338337ms
Jul 10 08:30:46.049: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015745121s
Jul 10 08:30:48.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 4.008197475s
Jul 10 08:30:50.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 6.008651097s
Jul 10 08:30:52.041: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 8.008013791s
Jul 10 08:30:54.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 10.009160329s
Jul 10 08:30:56.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 12.010027537s
Jul 10 08:30:58.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 14.009126319s
Jul 10 08:31:00.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 16.009813517s
Jul 10 08:31:02.045: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 18.011769329s
Jul 10 08:31:04.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 20.008759019s
Jul 10 08:31:06.044: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 22.010410166s
Jul 10 08:31:08.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=false. Elapsed: 24.009634129s
Jul 10 08:31:10.044: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.010207845s
STEP: Saw pod success 07/10/23 08:31:10.044
Jul 10 08:31:10.044: INFO: Pod "pod-subpath-test-configmap-ppz5" satisfied condition "Succeeded or Failed"
Jul 10 08:31:10.048: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-configmap-ppz5 container test-container-subpath-configmap-ppz5: <nil>
STEP: delete the pod 07/10/23 08:31:10.058
Jul 10 08:31:10.087: INFO: Waiting for pod pod-subpath-test-configmap-ppz5 to disappear
Jul 10 08:31:10.091: INFO: Pod pod-subpath-test-configmap-ppz5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ppz5 07/10/23 08:31:10.091
Jul 10 08:31:10.091: INFO: Deleting pod "pod-subpath-test-configmap-ppz5" in namespace "subpath-4052"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jul 10 08:31:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4052" for this suite. 07/10/23 08:31:10.099
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":110,"skipped":2183,"failed":0}
------------------------------
• [SLOW TEST] [26.240 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:30:43.955
    Jul 10 08:30:43.955: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename subpath 07/10/23 08:30:43.956
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:30:43.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:30:43.996
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 07/10/23 08:30:43.998
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-ppz5 07/10/23 08:30:44.016
    STEP: Creating a pod to test atomic-volume-subpath 07/10/23 08:30:44.016
    Jul 10 08:30:44.033: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ppz5" in namespace "subpath-4052" to be "Succeeded or Failed"
    Jul 10 08:30:44.037: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338337ms
    Jul 10 08:30:46.049: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015745121s
    Jul 10 08:30:48.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 4.008197475s
    Jul 10 08:30:50.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 6.008651097s
    Jul 10 08:30:52.041: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 8.008013791s
    Jul 10 08:30:54.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 10.009160329s
    Jul 10 08:30:56.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 12.010027537s
    Jul 10 08:30:58.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 14.009126319s
    Jul 10 08:31:00.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 16.009813517s
    Jul 10 08:31:02.045: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 18.011769329s
    Jul 10 08:31:04.042: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 20.008759019s
    Jul 10 08:31:06.044: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=true. Elapsed: 22.010410166s
    Jul 10 08:31:08.043: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Running", Reason="", readiness=false. Elapsed: 24.009634129s
    Jul 10 08:31:10.044: INFO: Pod "pod-subpath-test-configmap-ppz5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.010207845s
    STEP: Saw pod success 07/10/23 08:31:10.044
    Jul 10 08:31:10.044: INFO: Pod "pod-subpath-test-configmap-ppz5" satisfied condition "Succeeded or Failed"
    Jul 10 08:31:10.048: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-configmap-ppz5 container test-container-subpath-configmap-ppz5: <nil>
    STEP: delete the pod 07/10/23 08:31:10.058
    Jul 10 08:31:10.087: INFO: Waiting for pod pod-subpath-test-configmap-ppz5 to disappear
    Jul 10 08:31:10.091: INFO: Pod pod-subpath-test-configmap-ppz5 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-ppz5 07/10/23 08:31:10.091
    Jul 10 08:31:10.091: INFO: Deleting pod "pod-subpath-test-configmap-ppz5" in namespace "subpath-4052"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jul 10 08:31:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4052" for this suite. 07/10/23 08:31:10.099
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:10.195
Jul 10 08:31:10.196: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:31:10.197
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:10.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:10.237
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 07/10/23 08:31:10.239
Jul 10 08:31:10.253: INFO: Waiting up to 5m0s for pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840" in namespace "emptydir-883" to be "Succeeded or Failed"
Jul 10 08:31:10.257: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549838ms
Jul 10 08:31:12.262: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008325423s
Jul 10 08:31:14.263: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009513293s
STEP: Saw pod success 07/10/23 08:31:14.263
Jul 10 08:31:14.263: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840" satisfied condition "Succeeded or Failed"
Jul 10 08:31:14.268: INFO: Trying to get logs from node 10-62-109-100.test pod pod-6abcbc6c-50ff-4651-b36c-b555a9404840 container test-container: <nil>
STEP: delete the pod 07/10/23 08:31:14.277
Jul 10 08:31:14.337: INFO: Waiting for pod pod-6abcbc6c-50ff-4651-b36c-b555a9404840 to disappear
Jul 10 08:31:14.340: INFO: Pod pod-6abcbc6c-50ff-4651-b36c-b555a9404840 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:31:14.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-883" for this suite. 07/10/23 08:31:14.345
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":111,"skipped":2188,"failed":0}
------------------------------
• [4.160 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:10.195
    Jul 10 08:31:10.196: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:31:10.197
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:10.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:10.237
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 07/10/23 08:31:10.239
    Jul 10 08:31:10.253: INFO: Waiting up to 5m0s for pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840" in namespace "emptydir-883" to be "Succeeded or Failed"
    Jul 10 08:31:10.257: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549838ms
    Jul 10 08:31:12.262: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008325423s
    Jul 10 08:31:14.263: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009513293s
    STEP: Saw pod success 07/10/23 08:31:14.263
    Jul 10 08:31:14.263: INFO: Pod "pod-6abcbc6c-50ff-4651-b36c-b555a9404840" satisfied condition "Succeeded or Failed"
    Jul 10 08:31:14.268: INFO: Trying to get logs from node 10-62-109-100.test pod pod-6abcbc6c-50ff-4651-b36c-b555a9404840 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:31:14.277
    Jul 10 08:31:14.337: INFO: Waiting for pod pod-6abcbc6c-50ff-4651-b36c-b555a9404840 to disappear
    Jul 10 08:31:14.340: INFO: Pod pod-6abcbc6c-50ff-4651-b36c-b555a9404840 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:31:14.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-883" for this suite. 07/10/23 08:31:14.345
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:14.355
Jul 10 08:31:14.355: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:31:14.356
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:14.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:14.386
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 07/10/23 08:31:14.389
Jul 10 08:31:14.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-3017 create -f -'
Jul 10 08:31:14.637: INFO: stderr: ""
Jul 10 08:31:14.637: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 07/10/23 08:31:14.637
Jul 10 08:31:15.646: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:31:15.646: INFO: Found 0 / 1
Jul 10 08:31:16.643: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:31:16.643: INFO: Found 0 / 1
Jul 10 08:31:17.642: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:31:17.642: INFO: Found 1 / 1
Jul 10 08:31:17.642: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 07/10/23 08:31:17.642
Jul 10 08:31:17.645: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:31:17.645: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 10 08:31:17.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-3017 patch pod agnhost-primary-2n7db -p {"metadata":{"annotations":{"x":"y"}}}'
Jul 10 08:31:17.735: INFO: stderr: ""
Jul 10 08:31:17.735: INFO: stdout: "pod/agnhost-primary-2n7db patched\n"
STEP: checking annotations 07/10/23 08:31:17.735
Jul 10 08:31:17.740: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:31:17.740: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:31:17.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3017" for this suite. 07/10/23 08:31:17.745
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":112,"skipped":2188,"failed":0}
------------------------------
• [3.403 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:14.355
    Jul 10 08:31:14.355: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:31:14.356
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:14.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:14.386
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 07/10/23 08:31:14.389
    Jul 10 08:31:14.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-3017 create -f -'
    Jul 10 08:31:14.637: INFO: stderr: ""
    Jul 10 08:31:14.637: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 07/10/23 08:31:14.637
    Jul 10 08:31:15.646: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:31:15.646: INFO: Found 0 / 1
    Jul 10 08:31:16.643: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:31:16.643: INFO: Found 0 / 1
    Jul 10 08:31:17.642: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:31:17.642: INFO: Found 1 / 1
    Jul 10 08:31:17.642: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 07/10/23 08:31:17.642
    Jul 10 08:31:17.645: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:31:17.645: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jul 10 08:31:17.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-3017 patch pod agnhost-primary-2n7db -p {"metadata":{"annotations":{"x":"y"}}}'
    Jul 10 08:31:17.735: INFO: stderr: ""
    Jul 10 08:31:17.735: INFO: stdout: "pod/agnhost-primary-2n7db patched\n"
    STEP: checking annotations 07/10/23 08:31:17.735
    Jul 10 08:31:17.740: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:31:17.740: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:31:17.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3017" for this suite. 07/10/23 08:31:17.745
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:17.762
Jul 10 08:31:17.762: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:31:17.763
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:17.797
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:17.799
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
STEP: creating an Endpoint 07/10/23 08:31:17.805
STEP: waiting for available Endpoint 07/10/23 08:31:17.814
STEP: listing all Endpoints 07/10/23 08:31:17.815
STEP: updating the Endpoint 07/10/23 08:31:17.818
STEP: fetching the Endpoint 07/10/23 08:31:17.827
STEP: patching the Endpoint 07/10/23 08:31:17.83
STEP: fetching the Endpoint 07/10/23 08:31:17.843
STEP: deleting the Endpoint by Collection 07/10/23 08:31:17.847
STEP: waiting for Endpoint deletion 07/10/23 08:31:17.865
STEP: fetching the Endpoint 07/10/23 08:31:17.866
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:31:17.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-949" for this suite. 07/10/23 08:31:17.879
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":113,"skipped":2257,"failed":0}
------------------------------
• [0.128 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:17.762
    Jul 10 08:31:17.762: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:31:17.763
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:17.797
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:17.799
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3210
    STEP: creating an Endpoint 07/10/23 08:31:17.805
    STEP: waiting for available Endpoint 07/10/23 08:31:17.814
    STEP: listing all Endpoints 07/10/23 08:31:17.815
    STEP: updating the Endpoint 07/10/23 08:31:17.818
    STEP: fetching the Endpoint 07/10/23 08:31:17.827
    STEP: patching the Endpoint 07/10/23 08:31:17.83
    STEP: fetching the Endpoint 07/10/23 08:31:17.843
    STEP: deleting the Endpoint by Collection 07/10/23 08:31:17.847
    STEP: waiting for Endpoint deletion 07/10/23 08:31:17.865
    STEP: fetching the Endpoint 07/10/23 08:31:17.866
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:31:17.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-949" for this suite. 07/10/23 08:31:17.879
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:17.89
Jul 10 08:31:17.890: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sysctl 07/10/23 08:31:17.891
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:17.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:17.929
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 07/10/23 08:31:17.932
STEP: Watching for error events or started pod 07/10/23 08:31:17.945
STEP: Waiting for pod completion 07/10/23 08:31:19.951
Jul 10 08:31:19.951: INFO: Waiting up to 3m0s for pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5" in namespace "sysctl-9877" to be "completed"
Jul 10 08:31:19.954: INFO: Pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.284215ms
Jul 10 08:31:21.961: INFO: Pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010106705s
Jul 10 08:31:21.961: INFO: Pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5" satisfied condition "completed"
STEP: Checking that the pod succeeded 07/10/23 08:31:21.965
STEP: Getting logs from the pod 07/10/23 08:31:21.965
STEP: Checking that the sysctl is actually updated 07/10/23 08:31:21.975
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 08:31:21.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-9877" for this suite. 07/10/23 08:31:21.979
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":114,"skipped":2257,"failed":0}
------------------------------
• [4.098 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:17.89
    Jul 10 08:31:17.890: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sysctl 07/10/23 08:31:17.891
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:17.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:17.929
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 07/10/23 08:31:17.932
    STEP: Watching for error events or started pod 07/10/23 08:31:17.945
    STEP: Waiting for pod completion 07/10/23 08:31:19.951
    Jul 10 08:31:19.951: INFO: Waiting up to 3m0s for pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5" in namespace "sysctl-9877" to be "completed"
    Jul 10 08:31:19.954: INFO: Pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.284215ms
    Jul 10 08:31:21.961: INFO: Pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010106705s
    Jul 10 08:31:21.961: INFO: Pod "sysctl-06a767c8-ae05-46ec-810b-68f708157cf5" satisfied condition "completed"
    STEP: Checking that the pod succeeded 07/10/23 08:31:21.965
    STEP: Getting logs from the pod 07/10/23 08:31:21.965
    STEP: Checking that the sysctl is actually updated 07/10/23 08:31:21.975
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 08:31:21.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-9877" for this suite. 07/10/23 08:31:21.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:21.989
Jul 10 08:31:21.990: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:31:21.991
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:22.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:22.021
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
STEP: creating a collection of services 07/10/23 08:31:22.024
Jul 10 08:31:22.024: INFO: Creating e2e-svc-a-tgl2f
Jul 10 08:31:22.042: INFO: Creating e2e-svc-b-g4hct
Jul 10 08:31:22.065: INFO: Creating e2e-svc-c-8bqm8
STEP: deleting service collection 07/10/23 08:31:22.094
Jul 10 08:31:22.147: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:31:22.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9702" for this suite. 07/10/23 08:31:22.151
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":115,"skipped":2265,"failed":0}
------------------------------
• [0.252 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:21.989
    Jul 10 08:31:21.990: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:31:21.991
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:22.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:22.021
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3620
    STEP: creating a collection of services 07/10/23 08:31:22.024
    Jul 10 08:31:22.024: INFO: Creating e2e-svc-a-tgl2f
    Jul 10 08:31:22.042: INFO: Creating e2e-svc-b-g4hct
    Jul 10 08:31:22.065: INFO: Creating e2e-svc-c-8bqm8
    STEP: deleting service collection 07/10/23 08:31:22.094
    Jul 10 08:31:22.147: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:31:22.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9702" for this suite. 07/10/23 08:31:22.151
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:22.242
Jul 10 08:31:22.242: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 08:31:22.244
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:22.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:22.272
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 07/10/23 08:31:22.275
Jul 10 08:31:22.288: INFO: created test-pod-1
Jul 10 08:31:22.296: INFO: created test-pod-2
Jul 10 08:31:22.308: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 07/10/23 08:31:22.308
Jul 10 08:31:22.308: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-4891' to be running and ready
Jul 10 08:31:22.369: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul 10 08:31:22.369: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul 10 08:31:22.369: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul 10 08:31:22.369: INFO: 0 / 3 pods in namespace 'pods-4891' are running and ready (0 seconds elapsed)
Jul 10 08:31:22.369: INFO: expected 0 pod replicas in namespace 'pods-4891', 0 are Running and Ready.
Jul 10 08:31:22.369: INFO: POD         NODE                PHASE    GRACE  CONDITIONS
Jul 10 08:31:22.369: INFO: test-pod-1  10-62-109-100.test  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:21 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:21 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
Jul 10 08:31:22.369: INFO: test-pod-2  10-62-109-101.test  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
Jul 10 08:31:22.369: INFO: test-pod-3  10-62-109-102.test  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
Jul 10 08:31:22.369: INFO: 
Jul 10 08:31:24.383: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul 10 08:31:24.383: INFO: 2 / 3 pods in namespace 'pods-4891' are running and ready (2 seconds elapsed)
Jul 10 08:31:24.383: INFO: expected 0 pod replicas in namespace 'pods-4891', 0 are Running and Ready.
Jul 10 08:31:24.383: INFO: POD         NODE                PHASE    GRACE  CONDITIONS
Jul 10 08:31:24.383: INFO: test-pod-2  10-62-109-101.test  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
Jul 10 08:31:24.383: INFO: 
Jul 10 08:31:26.383: INFO: 3 / 3 pods in namespace 'pods-4891' are running and ready (4 seconds elapsed)
Jul 10 08:31:26.383: INFO: expected 0 pod replicas in namespace 'pods-4891', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 07/10/23 08:31:26.437
Jul 10 08:31:26.441: INFO: Pod quantity 3 is different from expected quantity 0
Jul 10 08:31:27.451: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 08:31:28.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4891" for this suite. 07/10/23 08:31:28.452
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":116,"skipped":2266,"failed":0}
------------------------------
• [SLOW TEST] [6.222 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:22.242
    Jul 10 08:31:22.242: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 08:31:22.244
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:22.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:22.272
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 07/10/23 08:31:22.275
    Jul 10 08:31:22.288: INFO: created test-pod-1
    Jul 10 08:31:22.296: INFO: created test-pod-2
    Jul 10 08:31:22.308: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 07/10/23 08:31:22.308
    Jul 10 08:31:22.308: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-4891' to be running and ready
    Jul 10 08:31:22.369: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jul 10 08:31:22.369: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jul 10 08:31:22.369: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jul 10 08:31:22.369: INFO: 0 / 3 pods in namespace 'pods-4891' are running and ready (0 seconds elapsed)
    Jul 10 08:31:22.369: INFO: expected 0 pod replicas in namespace 'pods-4891', 0 are Running and Ready.
    Jul 10 08:31:22.369: INFO: POD         NODE                PHASE    GRACE  CONDITIONS
    Jul 10 08:31:22.369: INFO: test-pod-1  10-62-109-100.test  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:21 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:21 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
    Jul 10 08:31:22.369: INFO: test-pod-2  10-62-109-101.test  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
    Jul 10 08:31:22.369: INFO: test-pod-3  10-62-109-102.test  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
    Jul 10 08:31:22.369: INFO: 
    Jul 10 08:31:24.383: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jul 10 08:31:24.383: INFO: 2 / 3 pods in namespace 'pods-4891' are running and ready (2 seconds elapsed)
    Jul 10 08:31:24.383: INFO: expected 0 pod replicas in namespace 'pods-4891', 0 are Running and Ready.
    Jul 10 08:31:24.383: INFO: POD         NODE                PHASE    GRACE  CONDITIONS
    Jul 10 08:31:24.383: INFO: test-pod-2  10-62-109-101.test  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-07-10 08:31:22 +0000 UTC  }]
    Jul 10 08:31:24.383: INFO: 
    Jul 10 08:31:26.383: INFO: 3 / 3 pods in namespace 'pods-4891' are running and ready (4 seconds elapsed)
    Jul 10 08:31:26.383: INFO: expected 0 pod replicas in namespace 'pods-4891', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 07/10/23 08:31:26.437
    Jul 10 08:31:26.441: INFO: Pod quantity 3 is different from expected quantity 0
    Jul 10 08:31:27.451: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 08:31:28.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4891" for this suite. 07/10/23 08:31:28.452
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:28.466
Jul 10 08:31:28.466: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:31:28.467
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:28.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:28.55
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:31:28.553
Jul 10 08:31:28.567: INFO: Waiting up to 5m0s for pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d" in namespace "downward-api-7911" to be "Succeeded or Failed"
Jul 10 08:31:28.570: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.038807ms
Jul 10 08:31:30.575: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007906664s
Jul 10 08:31:32.577: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009920645s
STEP: Saw pod success 07/10/23 08:31:32.577
Jul 10 08:31:32.577: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d" satisfied condition "Succeeded or Failed"
Jul 10 08:31:32.582: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d container client-container: <nil>
STEP: delete the pod 07/10/23 08:31:32.595
Jul 10 08:31:32.633: INFO: Waiting for pod downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d to disappear
Jul 10 08:31:32.637: INFO: Pod downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 08:31:32.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7911" for this suite. 07/10/23 08:31:32.651
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":117,"skipped":2297,"failed":0}
------------------------------
• [4.195 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:28.466
    Jul 10 08:31:28.466: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:31:28.467
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:28.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:28.55
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:31:28.553
    Jul 10 08:31:28.567: INFO: Waiting up to 5m0s for pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d" in namespace "downward-api-7911" to be "Succeeded or Failed"
    Jul 10 08:31:28.570: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.038807ms
    Jul 10 08:31:30.575: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007906664s
    Jul 10 08:31:32.577: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009920645s
    STEP: Saw pod success 07/10/23 08:31:32.577
    Jul 10 08:31:32.577: INFO: Pod "downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d" satisfied condition "Succeeded or Failed"
    Jul 10 08:31:32.582: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d container client-container: <nil>
    STEP: delete the pod 07/10/23 08:31:32.595
    Jul 10 08:31:32.633: INFO: Waiting for pod downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d to disappear
    Jul 10 08:31:32.637: INFO: Pod downwardapi-volume-382724da-40ac-41c5-aea9-c33c2a549f2d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 08:31:32.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7911" for this suite. 07/10/23 08:31:32.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:32.663
Jul 10 08:31:32.663: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 08:31:32.664
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:32.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:32.703
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 07/10/23 08:31:32.705
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 07/10/23 08:31:32.705
STEP: creating a pod to probe DNS 07/10/23 08:31:32.705
STEP: submitting the pod to kubernetes 07/10/23 08:31:32.705
Jul 10 08:31:32.718: INFO: Waiting up to 15m0s for pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5" in namespace "dns-4746" to be "running"
Jul 10 08:31:32.723: INFO: Pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.561348ms
Jul 10 08:31:34.729: INFO: Pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5": Phase="Running", Reason="", readiness=true. Elapsed: 2.011118138s
Jul 10 08:31:34.729: INFO: Pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5" satisfied condition "running"
STEP: retrieving the pod 07/10/23 08:31:34.73
STEP: looking for the results for each expected name from probers 07/10/23 08:31:34.733
Jul 10 08:31:34.749: INFO: DNS probes using dns-4746/dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5 succeeded

STEP: deleting the pod 07/10/23 08:31:34.749
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 08:31:34.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4746" for this suite. 07/10/23 08:31:34.785
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":118,"skipped":2336,"failed":0}
------------------------------
• [2.133 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:32.663
    Jul 10 08:31:32.663: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 08:31:32.664
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:32.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:32.703
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     07/10/23 08:31:32.705
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     07/10/23 08:31:32.705
    STEP: creating a pod to probe DNS 07/10/23 08:31:32.705
    STEP: submitting the pod to kubernetes 07/10/23 08:31:32.705
    Jul 10 08:31:32.718: INFO: Waiting up to 15m0s for pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5" in namespace "dns-4746" to be "running"
    Jul 10 08:31:32.723: INFO: Pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.561348ms
    Jul 10 08:31:34.729: INFO: Pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5": Phase="Running", Reason="", readiness=true. Elapsed: 2.011118138s
    Jul 10 08:31:34.729: INFO: Pod "dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 08:31:34.73
    STEP: looking for the results for each expected name from probers 07/10/23 08:31:34.733
    Jul 10 08:31:34.749: INFO: DNS probes using dns-4746/dns-test-92add93c-f28e-4a8b-a403-0e57a17936e5 succeeded

    STEP: deleting the pod 07/10/23 08:31:34.749
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 08:31:34.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4746" for this suite. 07/10/23 08:31:34.785
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:31:34.799
Jul 10 08:31:34.799: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 08:31:34.8
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:34.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:34.829
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 in namespace container-probe-4848 07/10/23 08:31:34.832
Jul 10 08:31:34.842: INFO: Waiting up to 5m0s for pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1" in namespace "container-probe-4848" to be "not pending"
Jul 10 08:31:34.850: INFO: Pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.356191ms
Jul 10 08:31:36.856: INFO: Pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013880469s
Jul 10 08:31:36.856: INFO: Pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1" satisfied condition "not pending"
Jul 10 08:31:36.856: INFO: Started pod liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 in namespace container-probe-4848
STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 08:31:36.856
Jul 10 08:31:36.860: INFO: Initial restart count of pod liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is 0
Jul 10 08:31:56.923: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 1 (20.063358071s elapsed)
Jul 10 08:32:16.978: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 2 (40.118957078s elapsed)
Jul 10 08:32:37.040: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 3 (1m0.180724639s elapsed)
Jul 10 08:32:57.098: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 4 (1m20.238822935s elapsed)
Jul 10 08:34:09.311: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 5 (2m32.451733675s elapsed)
STEP: deleting the pod 07/10/23 08:34:09.311
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 08:34:09.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4848" for this suite. 07/10/23 08:34:09.339
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":119,"skipped":2351,"failed":0}
------------------------------
• [SLOW TEST] [154.551 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:31:34.799
    Jul 10 08:31:34.799: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 08:31:34.8
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:31:34.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:31:34.829
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 in namespace container-probe-4848 07/10/23 08:31:34.832
    Jul 10 08:31:34.842: INFO: Waiting up to 5m0s for pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1" in namespace "container-probe-4848" to be "not pending"
    Jul 10 08:31:34.850: INFO: Pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.356191ms
    Jul 10 08:31:36.856: INFO: Pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013880469s
    Jul 10 08:31:36.856: INFO: Pod "liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1" satisfied condition "not pending"
    Jul 10 08:31:36.856: INFO: Started pod liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 in namespace container-probe-4848
    STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 08:31:36.856
    Jul 10 08:31:36.860: INFO: Initial restart count of pod liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is 0
    Jul 10 08:31:56.923: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 1 (20.063358071s elapsed)
    Jul 10 08:32:16.978: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 2 (40.118957078s elapsed)
    Jul 10 08:32:37.040: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 3 (1m0.180724639s elapsed)
    Jul 10 08:32:57.098: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 4 (1m20.238822935s elapsed)
    Jul 10 08:34:09.311: INFO: Restart count of pod container-probe-4848/liveness-f2fd3789-16b3-4b20-aad1-45549a569cb1 is now 5 (2m32.451733675s elapsed)
    STEP: deleting the pod 07/10/23 08:34:09.311
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 08:34:09.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4848" for this suite. 07/10/23 08:34:09.339
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:34:09.352
Jul 10 08:34:09.352: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 08:34:09.355
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:09.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:09.395
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 07/10/23 08:34:09.404
Jul 10 08:34:09.419: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3410" to be "running and ready"
Jul 10 08:34:09.424: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.100985ms
Jul 10 08:34:09.424: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:34:11.431: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011516576s
Jul 10 08:34:11.431: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:34:13.433: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.014115111s
Jul 10 08:34:13.433: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jul 10 08:34:13.433: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 07/10/23 08:34:13.437
Jul 10 08:34:13.448: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-3410" to be "running and ready"
Jul 10 08:34:13.452: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.512152ms
Jul 10 08:34:13.452: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:34:15.457: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008844259s
Jul 10 08:34:15.457: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:34:17.458: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.009816934s
Jul 10 08:34:17.458: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Jul 10 08:34:17.458: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 07/10/23 08:34:17.465
Jul 10 08:34:17.480: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 10 08:34:17.484: INFO: Pod pod-with-prestop-http-hook still exists
Jul 10 08:34:19.485: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 10 08:34:19.490: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 07/10/23 08:34:19.49
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jul 10 08:34:19.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3410" for this suite. 07/10/23 08:34:19.515
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":120,"skipped":2362,"failed":0}
------------------------------
• [SLOW TEST] [10.238 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:34:09.352
    Jul 10 08:34:09.352: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 08:34:09.355
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:09.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:09.395
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 07/10/23 08:34:09.404
    Jul 10 08:34:09.419: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3410" to be "running and ready"
    Jul 10 08:34:09.424: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.100985ms
    Jul 10 08:34:09.424: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:34:11.431: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011516576s
    Jul 10 08:34:11.431: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:34:13.433: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.014115111s
    Jul 10 08:34:13.433: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jul 10 08:34:13.433: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 07/10/23 08:34:13.437
    Jul 10 08:34:13.448: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-3410" to be "running and ready"
    Jul 10 08:34:13.452: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.512152ms
    Jul 10 08:34:13.452: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:34:15.457: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008844259s
    Jul 10 08:34:15.457: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:34:17.458: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.009816934s
    Jul 10 08:34:17.458: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Jul 10 08:34:17.458: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 07/10/23 08:34:17.465
    Jul 10 08:34:17.480: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jul 10 08:34:17.484: INFO: Pod pod-with-prestop-http-hook still exists
    Jul 10 08:34:19.485: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jul 10 08:34:19.490: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 07/10/23 08:34:19.49
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jul 10 08:34:19.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3410" for this suite. 07/10/23 08:34:19.515
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:34:19.59
Jul 10 08:34:19.591: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:34:19.592
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:19.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:19.629
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 07/10/23 08:34:19.631
Jul 10 08:34:19.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Jul 10 08:34:19.722: INFO: stderr: ""
Jul 10 08:34:19.722: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 07/10/23 08:34:19.722
Jul 10 08:34:19.722: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jul 10 08:34:19.722: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8216" to be "running and ready, or succeeded"
Jul 10 08:34:19.725: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940544ms
Jul 10 08:34:19.725: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10-62-109-100.test' to be 'Running' but was 'Pending'
Jul 10 08:34:21.730: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008438326s
Jul 10 08:34:21.730: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jul 10 08:34:21.731: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 07/10/23 08:34:21.731
Jul 10 08:34:21.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator'
Jul 10 08:34:21.818: INFO: stderr: ""
Jul 10 08:34:21.818: INFO: stdout: "I0710 08:34:20.384055       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/bcrg 215\nI0710 08:34:20.584212       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/qq6 497\nI0710 08:34:20.784857       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/tg8 363\nI0710 08:34:20.984163       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/zsrx 445\nI0710 08:34:21.184628       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/9mf2 322\nI0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\n"
STEP: limiting log lines 07/10/23 08:34:21.818
Jul 10 08:34:21.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --tail=1'
Jul 10 08:34:21.919: INFO: stderr: ""
Jul 10 08:34:21.919: INFO: stdout: "I0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\n"
Jul 10 08:34:21.919: INFO: got output "I0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\n"
STEP: limiting log bytes 07/10/23 08:34:21.919
Jul 10 08:34:21.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --limit-bytes=1'
Jul 10 08:34:22.006: INFO: stderr: ""
Jul 10 08:34:22.006: INFO: stdout: "I"
Jul 10 08:34:22.006: INFO: got output "I"
STEP: exposing timestamps 07/10/23 08:34:22.006
Jul 10 08:34:22.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --tail=1 --timestamps'
Jul 10 08:34:22.093: INFO: stderr: ""
Jul 10 08:34:22.093: INFO: stdout: "2023-07-10T08:34:21.584750126Z I0710 08:34:21.584485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/259p 528\n"
Jul 10 08:34:22.093: INFO: got output "2023-07-10T08:34:21.584750126Z I0710 08:34:21.584485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/259p 528\n"
STEP: restricting to a time range 07/10/23 08:34:22.094
Jul 10 08:34:24.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --since=1s'
Jul 10 08:34:24.675: INFO: stderr: ""
Jul 10 08:34:24.675: INFO: stdout: "I0710 08:34:23.384141       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/68f6 534\nI0710 08:34:23.584514       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/4z7x 530\nI0710 08:34:23.784965       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/nc5 540\nI0710 08:34:23.984195       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/dzr 215\nI0710 08:34:24.184613       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/j4ch 272\n"
Jul 10 08:34:24.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --since=24h'
Jul 10 08:34:24.768: INFO: stderr: ""
Jul 10 08:34:24.768: INFO: stdout: "I0710 08:34:20.384055       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/bcrg 215\nI0710 08:34:20.584212       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/qq6 497\nI0710 08:34:20.784857       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/tg8 363\nI0710 08:34:20.984163       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/zsrx 445\nI0710 08:34:21.184628       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/9mf2 322\nI0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\nI0710 08:34:21.584485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/259p 528\nI0710 08:34:21.784889       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/ggw 239\nI0710 08:34:21.985150       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/lzdq 495\nI0710 08:34:22.185037       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/k882 515\nI0710 08:34:22.384503       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/4qz 555\nI0710 08:34:22.584944       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/k5kc 584\nI0710 08:34:22.784170       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/f45l 542\nI0710 08:34:22.984367       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/4hh 496\nI0710 08:34:23.184847       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/wh8q 234\nI0710 08:34:23.384141       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/68f6 534\nI0710 08:34:23.584514       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/4z7x 530\nI0710 08:34:23.784965       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/nc5 540\nI0710 08:34:23.984195       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/dzr 215\nI0710 08:34:24.184613       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/j4ch 272\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Jul 10 08:34:24.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 delete pod logs-generator'
Jul 10 08:34:26.343: INFO: stderr: ""
Jul 10 08:34:26.343: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:34:26.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8216" for this suite. 07/10/23 08:34:26.348
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":121,"skipped":2364,"failed":0}
------------------------------
• [SLOW TEST] [6.769 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:34:19.59
    Jul 10 08:34:19.591: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:34:19.592
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:19.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:19.629
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 07/10/23 08:34:19.631
    Jul 10 08:34:19.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Jul 10 08:34:19.722: INFO: stderr: ""
    Jul 10 08:34:19.722: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 07/10/23 08:34:19.722
    Jul 10 08:34:19.722: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Jul 10 08:34:19.722: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8216" to be "running and ready, or succeeded"
    Jul 10 08:34:19.725: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940544ms
    Jul 10 08:34:19.725: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10-62-109-100.test' to be 'Running' but was 'Pending'
    Jul 10 08:34:21.730: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008438326s
    Jul 10 08:34:21.730: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Jul 10 08:34:21.731: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 07/10/23 08:34:21.731
    Jul 10 08:34:21.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator'
    Jul 10 08:34:21.818: INFO: stderr: ""
    Jul 10 08:34:21.818: INFO: stdout: "I0710 08:34:20.384055       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/bcrg 215\nI0710 08:34:20.584212       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/qq6 497\nI0710 08:34:20.784857       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/tg8 363\nI0710 08:34:20.984163       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/zsrx 445\nI0710 08:34:21.184628       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/9mf2 322\nI0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\n"
    STEP: limiting log lines 07/10/23 08:34:21.818
    Jul 10 08:34:21.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --tail=1'
    Jul 10 08:34:21.919: INFO: stderr: ""
    Jul 10 08:34:21.919: INFO: stdout: "I0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\n"
    Jul 10 08:34:21.919: INFO: got output "I0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\n"
    STEP: limiting log bytes 07/10/23 08:34:21.919
    Jul 10 08:34:21.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --limit-bytes=1'
    Jul 10 08:34:22.006: INFO: stderr: ""
    Jul 10 08:34:22.006: INFO: stdout: "I"
    Jul 10 08:34:22.006: INFO: got output "I"
    STEP: exposing timestamps 07/10/23 08:34:22.006
    Jul 10 08:34:22.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --tail=1 --timestamps'
    Jul 10 08:34:22.093: INFO: stderr: ""
    Jul 10 08:34:22.093: INFO: stdout: "2023-07-10T08:34:21.584750126Z I0710 08:34:21.584485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/259p 528\n"
    Jul 10 08:34:22.093: INFO: got output "2023-07-10T08:34:21.584750126Z I0710 08:34:21.584485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/259p 528\n"
    STEP: restricting to a time range 07/10/23 08:34:22.094
    Jul 10 08:34:24.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --since=1s'
    Jul 10 08:34:24.675: INFO: stderr: ""
    Jul 10 08:34:24.675: INFO: stdout: "I0710 08:34:23.384141       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/68f6 534\nI0710 08:34:23.584514       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/4z7x 530\nI0710 08:34:23.784965       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/nc5 540\nI0710 08:34:23.984195       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/dzr 215\nI0710 08:34:24.184613       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/j4ch 272\n"
    Jul 10 08:34:24.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 logs logs-generator logs-generator --since=24h'
    Jul 10 08:34:24.768: INFO: stderr: ""
    Jul 10 08:34:24.768: INFO: stdout: "I0710 08:34:20.384055       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/bcrg 215\nI0710 08:34:20.584212       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/qq6 497\nI0710 08:34:20.784857       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/tg8 363\nI0710 08:34:20.984163       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/zsrx 445\nI0710 08:34:21.184628       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/9mf2 322\nI0710 08:34:21.385067       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/pv8 339\nI0710 08:34:21.584485       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/259p 528\nI0710 08:34:21.784889       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/ggw 239\nI0710 08:34:21.985150       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/lzdq 495\nI0710 08:34:22.185037       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/k882 515\nI0710 08:34:22.384503       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/4qz 555\nI0710 08:34:22.584944       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/k5kc 584\nI0710 08:34:22.784170       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/f45l 542\nI0710 08:34:22.984367       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/4hh 496\nI0710 08:34:23.184847       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/wh8q 234\nI0710 08:34:23.384141       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/68f6 534\nI0710 08:34:23.584514       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/4z7x 530\nI0710 08:34:23.784965       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/nc5 540\nI0710 08:34:23.984195       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/dzr 215\nI0710 08:34:24.184613       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/j4ch 272\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Jul 10 08:34:24.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8216 delete pod logs-generator'
    Jul 10 08:34:26.343: INFO: stderr: ""
    Jul 10 08:34:26.343: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:34:26.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8216" for this suite. 07/10/23 08:34:26.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:34:26.36
Jul 10 08:34:26.360: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename init-container 07/10/23 08:34:26.361
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:26.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:26.406
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 07/10/23 08:34:26.409
Jul 10 08:34:26.409: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 08:34:31.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8617" for this suite. 07/10/23 08:34:31.506
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":122,"skipped":2372,"failed":0}
------------------------------
• [SLOW TEST] [5.157 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:34:26.36
    Jul 10 08:34:26.360: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename init-container 07/10/23 08:34:26.361
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:26.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:26.406
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 07/10/23 08:34:26.409
    Jul 10 08:34:26.409: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 08:34:31.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8617" for this suite. 07/10/23 08:34:31.506
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:34:31.518
Jul 10 08:34:31.518: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:34:31.519
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:31.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:31.55
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 07/10/23 08:34:31.553
Jul 10 08:34:31.553: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4555 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 07/10/23 08:34:31.602
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:34:31.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4555" for this suite. 07/10/23 08:34:31.616
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":123,"skipped":2394,"failed":0}
------------------------------
• [0.107 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:34:31.518
    Jul 10 08:34:31.518: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:34:31.519
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:31.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:31.55
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 07/10/23 08:34:31.553
    Jul 10 08:34:31.553: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4555 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 07/10/23 08:34:31.602
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:34:31.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4555" for this suite. 07/10/23 08:34:31.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:34:31.628
Jul 10 08:34:31.628: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-preemption 07/10/23 08:34:31.629
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:31.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:31.7
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul 10 08:34:31.723: INFO: Waiting up to 1m0s for all nodes to be ready
Jul 10 08:35:31.757: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:35:31.761
Jul 10 08:35:31.761: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-preemption-path 07/10/23 08:35:31.762
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:31.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:31.858
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Jul 10 08:35:31.884: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Jul 10 08:35:31.887: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Jul 10 08:35:31.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7014" for this suite. 07/10/23 08:35:31.916
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:35:31.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4060" for this suite. 07/10/23 08:35:31.947
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":124,"skipped":2433,"failed":0}
------------------------------
• [SLOW TEST] [60.406 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:34:31.628
    Jul 10 08:34:31.628: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-preemption 07/10/23 08:34:31.629
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:34:31.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:34:31.7
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jul 10 08:34:31.723: INFO: Waiting up to 1m0s for all nodes to be ready
    Jul 10 08:35:31.757: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:35:31.761
    Jul 10 08:35:31.761: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-preemption-path 07/10/23 08:35:31.762
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:31.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:31.858
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Jul 10 08:35:31.884: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Jul 10 08:35:31.887: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Jul 10 08:35:31.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7014" for this suite. 07/10/23 08:35:31.916
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:35:31.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4060" for this suite. 07/10/23 08:35:31.947
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:35:32.035
Jul 10 08:35:32.035: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename lease-test 07/10/23 08:35:32.036
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:32.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:32.073
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Jul 10 08:35:32.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3967" for this suite. 07/10/23 08:35:32.173
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":125,"skipped":2439,"failed":0}
------------------------------
• [0.151 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:35:32.035
    Jul 10 08:35:32.035: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename lease-test 07/10/23 08:35:32.036
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:32.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:32.073
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Jul 10 08:35:32.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-3967" for this suite. 07/10/23 08:35:32.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:35:32.187
Jul 10 08:35:32.187: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:35:32.188
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:32.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:32.215
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:35:32.237
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:35:32.879
STEP: Deploying the webhook pod 07/10/23 08:35:32.892
STEP: Wait for the deployment to be ready 07/10/23 08:35:32.926
Jul 10 08:35:32.932: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jul 10 08:35:34.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 08:35:36.957
STEP: Verifying the service has paired with the endpoint 07/10/23 08:35:36.981
Jul 10 08:35:37.981: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 07/10/23 08:35:37.986
STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:37.986
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 07/10/23 08:35:38.012
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 07/10/23 08:35:39.027
STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:39.027
STEP: Having no error when timeout is longer than webhook latency 07/10/23 08:35:40.071
STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:40.071
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 07/10/23 08:35:45.13
STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:45.13
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:35:50.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7203" for this suite. 07/10/23 08:35:50.189
STEP: Destroying namespace "webhook-7203-markers" for this suite. 07/10/23 08:35:50.198
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":126,"skipped":2450,"failed":0}
------------------------------
• [SLOW TEST] [18.103 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:35:32.187
    Jul 10 08:35:32.187: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:35:32.188
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:32.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:32.215
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:35:32.237
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:35:32.879
    STEP: Deploying the webhook pod 07/10/23 08:35:32.892
    STEP: Wait for the deployment to be ready 07/10/23 08:35:32.926
    Jul 10 08:35:32.932: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jul 10 08:35:34.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 35, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 08:35:36.957
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:35:36.981
    Jul 10 08:35:37.981: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 07/10/23 08:35:37.986
    STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:37.986
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 07/10/23 08:35:38.012
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 07/10/23 08:35:39.027
    STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:39.027
    STEP: Having no error when timeout is longer than webhook latency 07/10/23 08:35:40.071
    STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:40.071
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 07/10/23 08:35:45.13
    STEP: Registering slow webhook via the AdmissionRegistration API 07/10/23 08:35:45.13
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:35:50.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7203" for this suite. 07/10/23 08:35:50.189
    STEP: Destroying namespace "webhook-7203-markers" for this suite. 07/10/23 08:35:50.198
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:35:50.293
Jul 10 08:35:50.293: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:35:50.294
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:50.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:50.345
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 07/10/23 08:35:50.347
Jul 10 08:35:50.361: INFO: Waiting up to 5m0s for pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03" in namespace "emptydir-8832" to be "Succeeded or Failed"
Jul 10 08:35:50.365: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03": Phase="Pending", Reason="", readiness=false. Elapsed: 3.519822ms
Jul 10 08:35:52.371: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009756653s
Jul 10 08:35:54.371: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009536715s
STEP: Saw pod success 07/10/23 08:35:54.371
Jul 10 08:35:54.371: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03" satisfied condition "Succeeded or Failed"
Jul 10 08:35:54.375: INFO: Trying to get logs from node 10-62-109-100.test pod pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03 container test-container: <nil>
STEP: delete the pod 07/10/23 08:35:54.389
Jul 10 08:35:54.616: INFO: Waiting for pod pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03 to disappear
Jul 10 08:35:54.635: INFO: Pod pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:35:54.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8832" for this suite. 07/10/23 08:35:54.646
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":127,"skipped":2486,"failed":0}
------------------------------
• [4.366 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:35:50.293
    Jul 10 08:35:50.293: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:35:50.294
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:50.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:50.345
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 07/10/23 08:35:50.347
    Jul 10 08:35:50.361: INFO: Waiting up to 5m0s for pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03" in namespace "emptydir-8832" to be "Succeeded or Failed"
    Jul 10 08:35:50.365: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03": Phase="Pending", Reason="", readiness=false. Elapsed: 3.519822ms
    Jul 10 08:35:52.371: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009756653s
    Jul 10 08:35:54.371: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009536715s
    STEP: Saw pod success 07/10/23 08:35:54.371
    Jul 10 08:35:54.371: INFO: Pod "pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03" satisfied condition "Succeeded or Failed"
    Jul 10 08:35:54.375: INFO: Trying to get logs from node 10-62-109-100.test pod pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:35:54.389
    Jul 10 08:35:54.616: INFO: Waiting for pod pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03 to disappear
    Jul 10 08:35:54.635: INFO: Pod pod-6c1bf49d-5032-4677-8a29-d8f0ccf03e03 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:35:54.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8832" for this suite. 07/10/23 08:35:54.646
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:35:54.661
Jul 10 08:35:54.661: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:35:54.662
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:54.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:54.692
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:35:54.694
Jul 10 08:35:54.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee" in namespace "projected-4976" to be "Succeeded or Failed"
Jul 10 08:35:54.712: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.346359ms
Jul 10 08:35:56.718: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009542467s
Jul 10 08:35:58.732: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023725976s
STEP: Saw pod success 07/10/23 08:35:58.732
Jul 10 08:35:58.732: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee" satisfied condition "Succeeded or Failed"
Jul 10 08:35:58.736: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee container client-container: <nil>
STEP: delete the pod 07/10/23 08:35:58.746
Jul 10 08:35:58.767: INFO: Waiting for pod downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee to disappear
Jul 10 08:35:58.772: INFO: Pod downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:35:58.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4976" for this suite. 07/10/23 08:35:58.777
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":128,"skipped":2502,"failed":0}
------------------------------
• [4.128 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:35:54.661
    Jul 10 08:35:54.661: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:35:54.662
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:54.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:54.692
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:35:54.694
    Jul 10 08:35:54.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee" in namespace "projected-4976" to be "Succeeded or Failed"
    Jul 10 08:35:54.712: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.346359ms
    Jul 10 08:35:56.718: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009542467s
    Jul 10 08:35:58.732: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023725976s
    STEP: Saw pod success 07/10/23 08:35:58.732
    Jul 10 08:35:58.732: INFO: Pod "downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee" satisfied condition "Succeeded or Failed"
    Jul 10 08:35:58.736: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee container client-container: <nil>
    STEP: delete the pod 07/10/23 08:35:58.746
    Jul 10 08:35:58.767: INFO: Waiting for pod downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee to disappear
    Jul 10 08:35:58.772: INFO: Pod downwardapi-volume-14a3622c-ffdf-46cf-9f91-1c9b798ae1ee no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:35:58.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4976" for this suite. 07/10/23 08:35:58.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:35:58.789
Jul 10 08:35:58.789: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-webhook 07/10/23 08:35:58.79
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:58.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:58.827
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 07/10/23 08:35:58.83
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 07/10/23 08:35:59.244
STEP: Deploying the custom resource conversion webhook pod 07/10/23 08:35:59.253
STEP: Wait for the deployment to be ready 07/10/23 08:35:59.275
Jul 10 08:35:59.282: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 07/10/23 08:36:01.304
STEP: Verifying the service has paired with the endpoint 07/10/23 08:36:01.332
Jul 10 08:36:02.333: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Jul 10 08:36:02.338: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Creating a v1 custom resource 07/10/23 08:36:04.943
STEP: v2 custom resource should be converted 07/10/23 08:36:04.951
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:36:05.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4641" for this suite. 07/10/23 08:36:05.486
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":129,"skipped":2510,"failed":0}
------------------------------
• [SLOW TEST] [6.814 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:35:58.789
    Jul 10 08:35:58.789: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-webhook 07/10/23 08:35:58.79
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:35:58.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:35:58.827
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 07/10/23 08:35:58.83
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 07/10/23 08:35:59.244
    STEP: Deploying the custom resource conversion webhook pod 07/10/23 08:35:59.253
    STEP: Wait for the deployment to be ready 07/10/23 08:35:59.275
    Jul 10 08:35:59.282: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 07/10/23 08:36:01.304
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:36:01.332
    Jul 10 08:36:02.333: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Jul 10 08:36:02.338: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Creating a v1 custom resource 07/10/23 08:36:04.943
    STEP: v2 custom resource should be converted 07/10/23 08:36:04.951
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:36:05.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-4641" for this suite. 07/10/23 08:36:05.486
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:05.603
Jul 10 08:36:05.604: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 08:36:05.605
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:05.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:05.826
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Jul 10 08:36:05.852: INFO: Waiting up to 2m0s for pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" in namespace "var-expansion-3456" to be "container 0 failed with reason CreateContainerConfigError"
Jul 10 08:36:05.856: INFO: Pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.916286ms
Jul 10 08:36:07.868: INFO: Pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015535208s
Jul 10 08:36:07.868: INFO: Pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Jul 10 08:36:07.868: INFO: Deleting pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" in namespace "var-expansion-3456"
Jul 10 08:36:07.879: INFO: Wait up to 5m0s for pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 08:36:11.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3456" for this suite. 07/10/23 08:36:11.897
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":130,"skipped":2515,"failed":0}
------------------------------
• [SLOW TEST] [6.303 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:05.603
    Jul 10 08:36:05.604: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 08:36:05.605
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:05.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:05.826
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Jul 10 08:36:05.852: INFO: Waiting up to 2m0s for pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" in namespace "var-expansion-3456" to be "container 0 failed with reason CreateContainerConfigError"
    Jul 10 08:36:05.856: INFO: Pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.916286ms
    Jul 10 08:36:07.868: INFO: Pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015535208s
    Jul 10 08:36:07.868: INFO: Pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Jul 10 08:36:07.868: INFO: Deleting pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" in namespace "var-expansion-3456"
    Jul 10 08:36:07.879: INFO: Wait up to 5m0s for pod "var-expansion-d72230bc-c908-4317-aebd-37f9788ba0d9" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 08:36:11.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3456" for this suite. 07/10/23 08:36:11.897
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:11.907
Jul 10 08:36:11.907: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:36:11.908
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:11.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:11.948
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 07/10/23 08:36:11.95
Jul 10 08:36:11.962: INFO: Waiting up to 5m0s for pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4" in namespace "downward-api-3380" to be "Succeeded or Failed"
Jul 10 08:36:11.967: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.668887ms
Jul 10 08:36:14.022: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059813677s
Jul 10 08:36:15.972: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009588549s
STEP: Saw pod success 07/10/23 08:36:15.972
Jul 10 08:36:15.972: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4" satisfied condition "Succeeded or Failed"
Jul 10 08:36:15.986: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4 container dapi-container: <nil>
STEP: delete the pod 07/10/23 08:36:16.002
Jul 10 08:36:16.048: INFO: Waiting for pod downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4 to disappear
Jul 10 08:36:16.052: INFO: Pod downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jul 10 08:36:16.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3380" for this suite. 07/10/23 08:36:16.056
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":131,"skipped":2525,"failed":0}
------------------------------
• [4.160 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:11.907
    Jul 10 08:36:11.907: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:36:11.908
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:11.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:11.948
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 07/10/23 08:36:11.95
    Jul 10 08:36:11.962: INFO: Waiting up to 5m0s for pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4" in namespace "downward-api-3380" to be "Succeeded or Failed"
    Jul 10 08:36:11.967: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.668887ms
    Jul 10 08:36:14.022: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059813677s
    Jul 10 08:36:15.972: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009588549s
    STEP: Saw pod success 07/10/23 08:36:15.972
    Jul 10 08:36:15.972: INFO: Pod "downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4" satisfied condition "Succeeded or Failed"
    Jul 10 08:36:15.986: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4 container dapi-container: <nil>
    STEP: delete the pod 07/10/23 08:36:16.002
    Jul 10 08:36:16.048: INFO: Waiting for pod downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4 to disappear
    Jul 10 08:36:16.052: INFO: Pod downward-api-f2803a56-9a80-4c0f-9b14-1d54a498f6a4 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jul 10 08:36:16.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3380" for this suite. 07/10/23 08:36:16.056
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:16.068
Jul 10 08:36:16.068: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:36:16.069
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:16.109
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:16.112
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-57797d18-929e-4cd1-9220-109a91a1b43e 07/10/23 08:36:16.114
STEP: Creating a pod to test consume secrets 07/10/23 08:36:16.123
Jul 10 08:36:16.136: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336" in namespace "projected-6072" to be "Succeeded or Failed"
Jul 10 08:36:16.139: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336": Phase="Pending", Reason="", readiness=false. Elapsed: 3.434268ms
Jul 10 08:36:18.147: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011168039s
Jul 10 08:36:20.145: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009144946s
STEP: Saw pod success 07/10/23 08:36:20.145
Jul 10 08:36:20.145: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336" satisfied condition "Succeeded or Failed"
Jul 10 08:36:20.150: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336 container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:36:20.159
Jul 10 08:36:20.183: INFO: Waiting for pod pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336 to disappear
Jul 10 08:36:20.191: INFO: Pod pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 08:36:20.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6072" for this suite. 07/10/23 08:36:20.196
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":132,"skipped":2525,"failed":0}
------------------------------
• [4.139 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:16.068
    Jul 10 08:36:16.068: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:36:16.069
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:16.109
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:16.112
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-57797d18-929e-4cd1-9220-109a91a1b43e 07/10/23 08:36:16.114
    STEP: Creating a pod to test consume secrets 07/10/23 08:36:16.123
    Jul 10 08:36:16.136: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336" in namespace "projected-6072" to be "Succeeded or Failed"
    Jul 10 08:36:16.139: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336": Phase="Pending", Reason="", readiness=false. Elapsed: 3.434268ms
    Jul 10 08:36:18.147: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011168039s
    Jul 10 08:36:20.145: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009144946s
    STEP: Saw pod success 07/10/23 08:36:20.145
    Jul 10 08:36:20.145: INFO: Pod "pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336" satisfied condition "Succeeded or Failed"
    Jul 10 08:36:20.150: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336 container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:36:20.159
    Jul 10 08:36:20.183: INFO: Waiting for pod pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336 to disappear
    Jul 10 08:36:20.191: INFO: Pod pod-projected-secrets-f2e41f06-cde4-45a9-a606-6bf16d854336 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 08:36:20.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6072" for this suite. 07/10/23 08:36:20.196
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:20.207
Jul 10 08:36:20.207: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:36:20.208
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:20.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:20.286
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 07/10/23 08:36:20.288
Jul 10 08:36:20.310: INFO: Waiting up to 5m0s for pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da" in namespace "emptydir-6773" to be "Succeeded or Failed"
Jul 10 08:36:20.315: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.338324ms
Jul 10 08:36:22.321: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010815094s
Jul 10 08:36:24.320: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010522531s
STEP: Saw pod success 07/10/23 08:36:24.32
Jul 10 08:36:24.321: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da" satisfied condition "Succeeded or Failed"
Jul 10 08:36:24.338: INFO: Trying to get logs from node 10-62-109-100.test pod pod-f882515a-ebc9-4277-9ae2-6d4bb11303da container test-container: <nil>
STEP: delete the pod 07/10/23 08:36:24.348
Jul 10 08:36:24.431: INFO: Waiting for pod pod-f882515a-ebc9-4277-9ae2-6d4bb11303da to disappear
Jul 10 08:36:24.435: INFO: Pod pod-f882515a-ebc9-4277-9ae2-6d4bb11303da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:36:24.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6773" for this suite. 07/10/23 08:36:24.441
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":133,"skipped":2528,"failed":0}
------------------------------
• [4.250 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:20.207
    Jul 10 08:36:20.207: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:36:20.208
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:20.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:20.286
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 07/10/23 08:36:20.288
    Jul 10 08:36:20.310: INFO: Waiting up to 5m0s for pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da" in namespace "emptydir-6773" to be "Succeeded or Failed"
    Jul 10 08:36:20.315: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.338324ms
    Jul 10 08:36:22.321: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010815094s
    Jul 10 08:36:24.320: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010522531s
    STEP: Saw pod success 07/10/23 08:36:24.32
    Jul 10 08:36:24.321: INFO: Pod "pod-f882515a-ebc9-4277-9ae2-6d4bb11303da" satisfied condition "Succeeded or Failed"
    Jul 10 08:36:24.338: INFO: Trying to get logs from node 10-62-109-100.test pod pod-f882515a-ebc9-4277-9ae2-6d4bb11303da container test-container: <nil>
    STEP: delete the pod 07/10/23 08:36:24.348
    Jul 10 08:36:24.431: INFO: Waiting for pod pod-f882515a-ebc9-4277-9ae2-6d4bb11303da to disappear
    Jul 10 08:36:24.435: INFO: Pod pod-f882515a-ebc9-4277-9ae2-6d4bb11303da no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:36:24.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6773" for this suite. 07/10/23 08:36:24.441
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:24.458
Jul 10 08:36:24.458: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:36:24.459
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:24.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:24.494
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-9172 07/10/23 08:36:24.497
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[] 07/10/23 08:36:24.526
Jul 10 08:36:24.547: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9172 07/10/23 08:36:24.547
Jul 10 08:36:24.563: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9172" to be "running and ready"
Jul 10 08:36:24.567: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.644259ms
Jul 10 08:36:24.567: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:36:26.572: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009471372s
Jul 10 08:36:26.572: INFO: The phase of Pod pod1 is Running (Ready = true)
Jul 10 08:36:26.572: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[pod1:[80]] 07/10/23 08:36:26.576
Jul 10 08:36:26.587: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 07/10/23 08:36:26.587
Jul 10 08:36:26.587: INFO: Creating new exec pod
Jul 10 08:36:26.597: INFO: Waiting up to 5m0s for pod "execpodgxn2w" in namespace "services-9172" to be "running"
Jul 10 08:36:26.605: INFO: Pod "execpodgxn2w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.892555ms
Jul 10 08:36:28.611: INFO: Pod "execpodgxn2w": Phase="Running", Reason="", readiness=true. Elapsed: 2.013101201s
Jul 10 08:36:28.611: INFO: Pod "execpodgxn2w" satisfied condition "running"
Jul 10 08:36:29.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul 10 08:36:29.770: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul 10 08:36:29.770: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:36:29.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.92.136 80'
Jul 10 08:36:29.929: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.92.136 80\nConnection to 192.168.92.136 80 port [tcp/http] succeeded!\n"
Jul 10 08:36:29.929: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-9172 07/10/23 08:36:29.929
Jul 10 08:36:29.939: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9172" to be "running and ready"
Jul 10 08:36:29.943: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.914106ms
Jul 10 08:36:29.943: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:36:31.950: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010414992s
Jul 10 08:36:31.950: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:36:33.949: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.00933026s
Jul 10 08:36:33.949: INFO: The phase of Pod pod2 is Running (Ready = true)
Jul 10 08:36:33.949: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[pod1:[80] pod2:[80]] 07/10/23 08:36:33.953
Jul 10 08:36:33.967: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 07/10/23 08:36:33.967
Jul 10 08:36:34.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul 10 08:36:35.120: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul 10 08:36:35.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:36:35.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.92.136 80'
Jul 10 08:36:35.259: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.92.136 80\nConnection to 192.168.92.136 80 port [tcp/http] succeeded!\n"
Jul 10 08:36:35.259: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9172 07/10/23 08:36:35.259
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[pod2:[80]] 07/10/23 08:36:35.294
Jul 10 08:36:35.312: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 07/10/23 08:36:35.312
Jul 10 08:36:36.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul 10 08:36:36.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul 10 08:36:36.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:36:36.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.92.136 80'
Jul 10 08:36:36.596: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.92.136 80\nConnection to 192.168.92.136 80 port [tcp/http] succeeded!\n"
Jul 10 08:36:36.597: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-9172 07/10/23 08:36:36.597
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[] 07/10/23 08:36:36.627
Jul 10 08:36:37.654: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:36:37.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9172" for this suite. 07/10/23 08:36:37.727
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":134,"skipped":2537,"failed":0}
------------------------------
• [SLOW TEST] [13.279 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:24.458
    Jul 10 08:36:24.458: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:36:24.459
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:24.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:24.494
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-9172 07/10/23 08:36:24.497
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[] 07/10/23 08:36:24.526
    Jul 10 08:36:24.547: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-9172 07/10/23 08:36:24.547
    Jul 10 08:36:24.563: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9172" to be "running and ready"
    Jul 10 08:36:24.567: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.644259ms
    Jul 10 08:36:24.567: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:36:26.572: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009471372s
    Jul 10 08:36:26.572: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jul 10 08:36:26.572: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[pod1:[80]] 07/10/23 08:36:26.576
    Jul 10 08:36:26.587: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 07/10/23 08:36:26.587
    Jul 10 08:36:26.587: INFO: Creating new exec pod
    Jul 10 08:36:26.597: INFO: Waiting up to 5m0s for pod "execpodgxn2w" in namespace "services-9172" to be "running"
    Jul 10 08:36:26.605: INFO: Pod "execpodgxn2w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.892555ms
    Jul 10 08:36:28.611: INFO: Pod "execpodgxn2w": Phase="Running", Reason="", readiness=true. Elapsed: 2.013101201s
    Jul 10 08:36:28.611: INFO: Pod "execpodgxn2w" satisfied condition "running"
    Jul 10 08:36:29.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jul 10 08:36:29.770: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jul 10 08:36:29.770: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:36:29.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.92.136 80'
    Jul 10 08:36:29.929: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.92.136 80\nConnection to 192.168.92.136 80 port [tcp/http] succeeded!\n"
    Jul 10 08:36:29.929: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-9172 07/10/23 08:36:29.929
    Jul 10 08:36:29.939: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9172" to be "running and ready"
    Jul 10 08:36:29.943: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.914106ms
    Jul 10 08:36:29.943: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:36:31.950: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010414992s
    Jul 10 08:36:31.950: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:36:33.949: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.00933026s
    Jul 10 08:36:33.949: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jul 10 08:36:33.949: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[pod1:[80] pod2:[80]] 07/10/23 08:36:33.953
    Jul 10 08:36:33.967: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 07/10/23 08:36:33.967
    Jul 10 08:36:34.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jul 10 08:36:35.120: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jul 10 08:36:35.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:36:35.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.92.136 80'
    Jul 10 08:36:35.259: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.92.136 80\nConnection to 192.168.92.136 80 port [tcp/http] succeeded!\n"
    Jul 10 08:36:35.259: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-9172 07/10/23 08:36:35.259
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[pod2:[80]] 07/10/23 08:36:35.294
    Jul 10 08:36:35.312: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 07/10/23 08:36:35.312
    Jul 10 08:36:36.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jul 10 08:36:36.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jul 10 08:36:36.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:36:36.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-9172 exec execpodgxn2w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.92.136 80'
    Jul 10 08:36:36.596: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.92.136 80\nConnection to 192.168.92.136 80 port [tcp/http] succeeded!\n"
    Jul 10 08:36:36.597: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-9172 07/10/23 08:36:36.597
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9172 to expose endpoints map[] 07/10/23 08:36:36.627
    Jul 10 08:36:37.654: INFO: successfully validated that service endpoint-test2 in namespace services-9172 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:36:37.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9172" for this suite. 07/10/23 08:36:37.727
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:37.74
Jul 10 08:36:37.740: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:36:37.741
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:37.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:37.77
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:36:37.791
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:36:38.177
STEP: Deploying the webhook pod 07/10/23 08:36:38.191
STEP: Wait for the deployment to be ready 07/10/23 08:36:38.221
Jul 10 08:36:38.238: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jul 10 08:36:40.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 08:36:42.264
STEP: Verifying the service has paired with the endpoint 07/10/23 08:36:42.286
Jul 10 08:36:43.286: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Jul 10 08:36:43.292: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4896-crds.webhook.example.com via the AdmissionRegistration API 07/10/23 08:36:43.805
STEP: Creating a custom resource that should be mutated by the webhook 07/10/23 08:36:43.827
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:36:46.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8229" for this suite. 07/10/23 08:36:46.437
STEP: Destroying namespace "webhook-8229-markers" for this suite. 07/10/23 08:36:46.45
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":135,"skipped":2568,"failed":0}
------------------------------
• [SLOW TEST] [8.801 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:37.74
    Jul 10 08:36:37.740: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:36:37.741
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:37.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:37.77
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:36:37.791
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:36:38.177
    STEP: Deploying the webhook pod 07/10/23 08:36:38.191
    STEP: Wait for the deployment to be ready 07/10/23 08:36:38.221
    Jul 10 08:36:38.238: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jul 10 08:36:40.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 36, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 08:36:42.264
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:36:42.286
    Jul 10 08:36:43.286: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Jul 10 08:36:43.292: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4896-crds.webhook.example.com via the AdmissionRegistration API 07/10/23 08:36:43.805
    STEP: Creating a custom resource that should be mutated by the webhook 07/10/23 08:36:43.827
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:36:46.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8229" for this suite. 07/10/23 08:36:46.437
    STEP: Destroying namespace "webhook-8229-markers" for this suite. 07/10/23 08:36:46.45
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:46.544
Jul 10 08:36:46.544: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:36:46.545
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:46.602
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:46.604
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:36:46.607
Jul 10 08:36:46.623: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd" in namespace "downward-api-1960" to be "Succeeded or Failed"
Jul 10 08:36:46.628: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.877423ms
Jul 10 08:36:48.634: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010835162s
Jul 10 08:36:50.634: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010788292s
STEP: Saw pod success 07/10/23 08:36:50.634
Jul 10 08:36:50.634: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd" satisfied condition "Succeeded or Failed"
Jul 10 08:36:50.638: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd container client-container: <nil>
STEP: delete the pod 07/10/23 08:36:50.648
Jul 10 08:36:50.677: INFO: Waiting for pod downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd to disappear
Jul 10 08:36:50.680: INFO: Pod downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 08:36:50.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1960" for this suite. 07/10/23 08:36:50.684
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":136,"skipped":2616,"failed":0}
------------------------------
• [4.148 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:46.544
    Jul 10 08:36:46.544: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:36:46.545
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:46.602
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:46.604
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:36:46.607
    Jul 10 08:36:46.623: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd" in namespace "downward-api-1960" to be "Succeeded or Failed"
    Jul 10 08:36:46.628: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.877423ms
    Jul 10 08:36:48.634: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010835162s
    Jul 10 08:36:50.634: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010788292s
    STEP: Saw pod success 07/10/23 08:36:50.634
    Jul 10 08:36:50.634: INFO: Pod "downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd" satisfied condition "Succeeded or Failed"
    Jul 10 08:36:50.638: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd container client-container: <nil>
    STEP: delete the pod 07/10/23 08:36:50.648
    Jul 10 08:36:50.677: INFO: Waiting for pod downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd to disappear
    Jul 10 08:36:50.680: INFO: Pod downwardapi-volume-a5b175e4-ce55-4478-b4f3-e93d1653dedd no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 08:36:50.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1960" for this suite. 07/10/23 08:36:50.684
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:50.693
Jul 10 08:36:50.694: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:36:50.695
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:50.724
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:50.726
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 08:36:50.728
Jul 10 08:36:50.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-1660 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jul 10 08:36:50.816: INFO: stderr: ""
Jul 10 08:36:50.816: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 07/10/23 08:36:50.816
Jul 10 08:36:50.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-1660 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Jul 10 08:36:51.908: INFO: stderr: ""
Jul 10 08:36:51.908: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 08:36:51.908
Jul 10 08:36:51.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-1660 delete pods e2e-test-httpd-pod'
Jul 10 08:36:54.694: INFO: stderr: ""
Jul 10 08:36:54.694: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:36:54.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1660" for this suite. 07/10/23 08:36:54.699
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":137,"skipped":2627,"failed":0}
------------------------------
• [4.015 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:50.693
    Jul 10 08:36:50.694: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:36:50.695
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:50.724
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:50.726
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 08:36:50.728
    Jul 10 08:36:50.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-1660 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Jul 10 08:36:50.816: INFO: stderr: ""
    Jul 10 08:36:50.816: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 07/10/23 08:36:50.816
    Jul 10 08:36:50.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-1660 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Jul 10 08:36:51.908: INFO: stderr: ""
    Jul 10 08:36:51.908: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 08:36:51.908
    Jul 10 08:36:51.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-1660 delete pods e2e-test-httpd-pod'
    Jul 10 08:36:54.694: INFO: stderr: ""
    Jul 10 08:36:54.694: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:36:54.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1660" for this suite. 07/10/23 08:36:54.699
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:54.711
Jul 10 08:36:54.711: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:36:54.712
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:54.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:54.746
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-5490/secret-test-4afdfcda-192b-40dc-910a-eae162fa32b7 07/10/23 08:36:54.748
STEP: Creating a pod to test consume secrets 07/10/23 08:36:54.756
Jul 10 08:36:54.771: INFO: Waiting up to 5m0s for pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a" in namespace "secrets-5490" to be "Succeeded or Failed"
Jul 10 08:36:54.780: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.727077ms
Jul 10 08:36:56.784: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013231873s
Jul 10 08:36:58.785: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013841132s
STEP: Saw pod success 07/10/23 08:36:58.785
Jul 10 08:36:58.785: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a" satisfied condition "Succeeded or Failed"
Jul 10 08:36:58.788: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a container env-test: <nil>
STEP: delete the pod 07/10/23 08:36:58.798
Jul 10 08:36:58.835: INFO: Waiting for pod pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a to disappear
Jul 10 08:36:58.838: INFO: Pod pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:36:58.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5490" for this suite. 07/10/23 08:36:58.842
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":138,"skipped":2664,"failed":0}
------------------------------
• [4.140 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:54.711
    Jul 10 08:36:54.711: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:36:54.712
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:54.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:54.746
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-5490/secret-test-4afdfcda-192b-40dc-910a-eae162fa32b7 07/10/23 08:36:54.748
    STEP: Creating a pod to test consume secrets 07/10/23 08:36:54.756
    Jul 10 08:36:54.771: INFO: Waiting up to 5m0s for pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a" in namespace "secrets-5490" to be "Succeeded or Failed"
    Jul 10 08:36:54.780: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.727077ms
    Jul 10 08:36:56.784: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013231873s
    Jul 10 08:36:58.785: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013841132s
    STEP: Saw pod success 07/10/23 08:36:58.785
    Jul 10 08:36:58.785: INFO: Pod "pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a" satisfied condition "Succeeded or Failed"
    Jul 10 08:36:58.788: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a container env-test: <nil>
    STEP: delete the pod 07/10/23 08:36:58.798
    Jul 10 08:36:58.835: INFO: Waiting for pod pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a to disappear
    Jul 10 08:36:58.838: INFO: Pod pod-configmaps-50bd22e0-f4ce-4003-8557-31207b8a135a no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:36:58.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5490" for this suite. 07/10/23 08:36:58.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:58.852
Jul 10 08:36:58.852: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 08:36:58.853
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:58.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:58.889
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 07/10/23 08:36:58.891
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 07/10/23 08:36:58.892
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 07/10/23 08:36:58.892
STEP: fetching the /apis/apiextensions.k8s.io discovery document 07/10/23 08:36:58.892
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 07/10/23 08:36:58.893
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 07/10/23 08:36:58.893
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 07/10/23 08:36:58.894
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:36:58.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9975" for this suite. 07/10/23 08:36:58.9
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":139,"skipped":2679,"failed":0}
------------------------------
• [0.057 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:58.852
    Jul 10 08:36:58.852: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 08:36:58.853
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:58.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:58.889
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 07/10/23 08:36:58.891
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 07/10/23 08:36:58.892
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 07/10/23 08:36:58.892
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 07/10/23 08:36:58.892
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 07/10/23 08:36:58.893
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 07/10/23 08:36:58.893
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 07/10/23 08:36:58.894
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:36:58.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9975" for this suite. 07/10/23 08:36:58.9
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:36:58.91
Jul 10 08:36:58.910: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:36:58.911
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:58.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:58.947
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-1bbb4eae-1146-4598-b7b8-a27a682eefeb 07/10/23 08:36:58.949
STEP: Creating a pod to test consume configMaps 07/10/23 08:36:58.957
Jul 10 08:36:58.972: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b" in namespace "projected-4399" to be "Succeeded or Failed"
Jul 10 08:36:58.976: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069864ms
Jul 10 08:37:00.982: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009183162s
Jul 10 08:37:02.984: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011352741s
STEP: Saw pod success 07/10/23 08:37:02.984
Jul 10 08:37:02.984: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b" satisfied condition "Succeeded or Failed"
Jul 10 08:37:02.988: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:37:02.998
Jul 10 08:37:03.026: INFO: Waiting for pod pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b to disappear
Jul 10 08:37:03.030: INFO: Pod pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:37:03.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4399" for this suite. 07/10/23 08:37:03.035
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":140,"skipped":2679,"failed":0}
------------------------------
• [4.148 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:36:58.91
    Jul 10 08:36:58.910: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:36:58.911
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:36:58.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:36:58.947
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-1bbb4eae-1146-4598-b7b8-a27a682eefeb 07/10/23 08:36:58.949
    STEP: Creating a pod to test consume configMaps 07/10/23 08:36:58.957
    Jul 10 08:36:58.972: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b" in namespace "projected-4399" to be "Succeeded or Failed"
    Jul 10 08:36:58.976: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069864ms
    Jul 10 08:37:00.982: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009183162s
    Jul 10 08:37:02.984: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011352741s
    STEP: Saw pod success 07/10/23 08:37:02.984
    Jul 10 08:37:02.984: INFO: Pod "pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b" satisfied condition "Succeeded or Failed"
    Jul 10 08:37:02.988: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:37:02.998
    Jul 10 08:37:03.026: INFO: Waiting for pod pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b to disappear
    Jul 10 08:37:03.030: INFO: Pod pod-projected-configmaps-0d95b6e5-f3c5-41c8-9345-3b723c086a2b no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:37:03.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4399" for this suite. 07/10/23 08:37:03.035
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:03.069
Jul 10 08:37:03.069: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:37:03.071
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:03.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:03.106
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
STEP: creating service in namespace services-3199 07/10/23 08:37:03.115
STEP: creating service affinity-clusterip-transition in namespace services-3199 07/10/23 08:37:03.115
STEP: creating replication controller affinity-clusterip-transition in namespace services-3199 07/10/23 08:37:03.145
I0710 08:37:03.161863      21 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3199, replica count: 3
I0710 08:37:06.213454      21 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 08:37:06.223: INFO: Creating new exec pod
Jul 10 08:37:06.235: INFO: Waiting up to 5m0s for pod "execpod-affinity8z8pw" in namespace "services-3199" to be "running"
Jul 10 08:37:06.253: INFO: Pod "execpod-affinity8z8pw": Phase="Pending", Reason="", readiness=false. Elapsed: 17.893359ms
Jul 10 08:37:08.257: INFO: Pod "execpod-affinity8z8pw": Phase="Running", Reason="", readiness=true. Elapsed: 2.022583464s
Jul 10 08:37:08.257: INFO: Pod "execpod-affinity8z8pw" satisfied condition "running"
Jul 10 08:37:09.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Jul 10 08:37:09.412: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Jul 10 08:37:09.412: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:37:09.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.110.78 80'
Jul 10 08:37:09.560: INFO: stderr: "+ nc -v -t -w 2 192.168.110.78 80\n+ echo hostName\nConnection to 192.168.110.78 80 port [tcp/http] succeeded!\n"
Jul 10 08:37:09.560: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:37:09.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.110.78:80/ ; done'
Jul 10 08:37:09.811: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n"
Jul 10 08:37:09.811: INFO: stdout: "\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-bdblf"
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
Jul 10 08:37:09.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.110.78:80/ ; done'
Jul 10 08:37:10.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n"
Jul 10 08:37:10.189: INFO: stdout: "\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc"
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
Jul 10 08:37:10.189: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3199, will wait for the garbage collector to delete the pods 07/10/23 08:37:10.212
Jul 10 08:37:10.287: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.76612ms
Jul 10 08:37:10.488: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.939589ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:37:13.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3199" for this suite. 07/10/23 08:37:13.224
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":141,"skipped":2713,"failed":0}
------------------------------
• [SLOW TEST] [10.163 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:03.069
    Jul 10 08:37:03.069: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:37:03.071
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:03.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:03.106
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2179
    STEP: creating service in namespace services-3199 07/10/23 08:37:03.115
    STEP: creating service affinity-clusterip-transition in namespace services-3199 07/10/23 08:37:03.115
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3199 07/10/23 08:37:03.145
    I0710 08:37:03.161863      21 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3199, replica count: 3
    I0710 08:37:06.213454      21 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 08:37:06.223: INFO: Creating new exec pod
    Jul 10 08:37:06.235: INFO: Waiting up to 5m0s for pod "execpod-affinity8z8pw" in namespace "services-3199" to be "running"
    Jul 10 08:37:06.253: INFO: Pod "execpod-affinity8z8pw": Phase="Pending", Reason="", readiness=false. Elapsed: 17.893359ms
    Jul 10 08:37:08.257: INFO: Pod "execpod-affinity8z8pw": Phase="Running", Reason="", readiness=true. Elapsed: 2.022583464s
    Jul 10 08:37:08.257: INFO: Pod "execpod-affinity8z8pw" satisfied condition "running"
    Jul 10 08:37:09.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Jul 10 08:37:09.412: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Jul 10 08:37:09.412: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:37:09.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.110.78 80'
    Jul 10 08:37:09.560: INFO: stderr: "+ nc -v -t -w 2 192.168.110.78 80\n+ echo hostName\nConnection to 192.168.110.78 80 port [tcp/http] succeeded!\n"
    Jul 10 08:37:09.560: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:37:09.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.110.78:80/ ; done'
    Jul 10 08:37:09.811: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n"
    Jul 10 08:37:09.811: INFO: stdout: "\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-55sgn\naffinity-clusterip-transition-bdblf\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-bdblf"
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-55sgn
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:09.811: INFO: Received response from host: affinity-clusterip-transition-bdblf
    Jul 10 08:37:09.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3199 exec execpod-affinity8z8pw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.110.78:80/ ; done'
    Jul 10 08:37:10.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.110.78:80/\n"
    Jul 10 08:37:10.189: INFO: stdout: "\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc\naffinity-clusterip-transition-chphc"
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Received response from host: affinity-clusterip-transition-chphc
    Jul 10 08:37:10.189: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3199, will wait for the garbage collector to delete the pods 07/10/23 08:37:10.212
    Jul 10 08:37:10.287: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.76612ms
    Jul 10 08:37:10.488: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.939589ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:37:13.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3199" for this suite. 07/10/23 08:37:13.224
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:13.233
Jul 10 08:37:13.233: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename runtimeclass 07/10/23 08:37:13.234
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:13.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:13.264
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-7015-delete-me 07/10/23 08:37:13.276
STEP: Waiting for the RuntimeClass to disappear 07/10/23 08:37:13.285
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jul 10 08:37:13.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7015" for this suite. 07/10/23 08:37:13.299
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":142,"skipped":2718,"failed":0}
------------------------------
• [0.075 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:13.233
    Jul 10 08:37:13.233: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename runtimeclass 07/10/23 08:37:13.234
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:13.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:13.264
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-7015-delete-me 07/10/23 08:37:13.276
    STEP: Waiting for the RuntimeClass to disappear 07/10/23 08:37:13.285
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jul 10 08:37:13.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7015" for this suite. 07/10/23 08:37:13.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:13.31
Jul 10 08:37:13.310: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:37:13.311
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:13.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:13.347
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-5c199f4e-943d-4d80-badd-744dd042d69b 07/10/23 08:37:13.349
STEP: Creating a pod to test consume secrets 07/10/23 08:37:13.357
Jul 10 08:37:13.370: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3" in namespace "projected-936" to be "Succeeded or Failed"
Jul 10 08:37:13.378: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.856302ms
Jul 10 08:37:15.383: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013452516s
Jul 10 08:37:17.385: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015380316s
STEP: Saw pod success 07/10/23 08:37:17.385
Jul 10 08:37:17.385: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3" satisfied condition "Succeeded or Failed"
Jul 10 08:37:17.389: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3 container projected-secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:37:17.399
Jul 10 08:37:17.437: INFO: Waiting for pod pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3 to disappear
Jul 10 08:37:17.442: INFO: Pod pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 08:37:17.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-936" for this suite. 07/10/23 08:37:17.449
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":143,"skipped":2755,"failed":0}
------------------------------
• [4.155 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:13.31
    Jul 10 08:37:13.310: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:37:13.311
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:13.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:13.347
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-5c199f4e-943d-4d80-badd-744dd042d69b 07/10/23 08:37:13.349
    STEP: Creating a pod to test consume secrets 07/10/23 08:37:13.357
    Jul 10 08:37:13.370: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3" in namespace "projected-936" to be "Succeeded or Failed"
    Jul 10 08:37:13.378: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.856302ms
    Jul 10 08:37:15.383: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013452516s
    Jul 10 08:37:17.385: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015380316s
    STEP: Saw pod success 07/10/23 08:37:17.385
    Jul 10 08:37:17.385: INFO: Pod "pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3" satisfied condition "Succeeded or Failed"
    Jul 10 08:37:17.389: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3 container projected-secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:37:17.399
    Jul 10 08:37:17.437: INFO: Waiting for pod pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3 to disappear
    Jul 10 08:37:17.442: INFO: Pod pod-projected-secrets-45299e66-d8c7-4211-9364-f1427bb2f6d3 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 08:37:17.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-936" for this suite. 07/10/23 08:37:17.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:17.473
Jul 10 08:37:17.473: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:37:17.475
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:17.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:17.529
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-591eba7b-3f3e-4ecc-b274-3ed5378c070a 07/10/23 08:37:17.535
STEP: Creating a pod to test consume configMaps 07/10/23 08:37:17.546
Jul 10 08:37:17.565: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65" in namespace "projected-6145" to be "Succeeded or Failed"
Jul 10 08:37:17.569: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65": Phase="Pending", Reason="", readiness=false. Elapsed: 3.859126ms
Jul 10 08:37:19.574: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008941999s
Jul 10 08:37:21.576: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011511638s
STEP: Saw pod success 07/10/23 08:37:21.576
Jul 10 08:37:21.576: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65" satisfied condition "Succeeded or Failed"
Jul 10 08:37:21.580: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:37:21.589
Jul 10 08:37:21.615: INFO: Waiting for pod pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65 to disappear
Jul 10 08:37:21.618: INFO: Pod pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:37:21.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6145" for this suite. 07/10/23 08:37:21.622
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":144,"skipped":2806,"failed":0}
------------------------------
• [4.167 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:17.473
    Jul 10 08:37:17.473: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:37:17.475
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:17.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:17.529
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-591eba7b-3f3e-4ecc-b274-3ed5378c070a 07/10/23 08:37:17.535
    STEP: Creating a pod to test consume configMaps 07/10/23 08:37:17.546
    Jul 10 08:37:17.565: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65" in namespace "projected-6145" to be "Succeeded or Failed"
    Jul 10 08:37:17.569: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65": Phase="Pending", Reason="", readiness=false. Elapsed: 3.859126ms
    Jul 10 08:37:19.574: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008941999s
    Jul 10 08:37:21.576: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011511638s
    STEP: Saw pod success 07/10/23 08:37:21.576
    Jul 10 08:37:21.576: INFO: Pod "pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65" satisfied condition "Succeeded or Failed"
    Jul 10 08:37:21.580: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:37:21.589
    Jul 10 08:37:21.615: INFO: Waiting for pod pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65 to disappear
    Jul 10 08:37:21.618: INFO: Pod pod-projected-configmaps-43ab2a30-0816-413f-9178-2091aece1d65 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:37:21.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6145" for this suite. 07/10/23 08:37:21.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:21.641
Jul 10 08:37:21.641: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replicaset 07/10/23 08:37:21.642
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:21.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:21.673
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 07/10/23 08:37:21.675
STEP: Verify that the required pods have come up 07/10/23 08:37:21.689
Jul 10 08:37:21.694: INFO: Pod name sample-pod: Found 0 pods out of 3
Jul 10 08:37:26.699: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 07/10/23 08:37:26.699
Jul 10 08:37:26.702: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 07/10/23 08:37:26.702
STEP: DeleteCollection of the ReplicaSets 07/10/23 08:37:26.712
STEP: After DeleteCollection verify that ReplicaSets have been deleted 07/10/23 08:37:26.733
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jul 10 08:37:26.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-373" for this suite. 07/10/23 08:37:26.749
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":145,"skipped":2815,"failed":0}
------------------------------
• [SLOW TEST] [5.161 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:21.641
    Jul 10 08:37:21.641: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replicaset 07/10/23 08:37:21.642
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:21.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:21.673
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 07/10/23 08:37:21.675
    STEP: Verify that the required pods have come up 07/10/23 08:37:21.689
    Jul 10 08:37:21.694: INFO: Pod name sample-pod: Found 0 pods out of 3
    Jul 10 08:37:26.699: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 07/10/23 08:37:26.699
    Jul 10 08:37:26.702: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 07/10/23 08:37:26.702
    STEP: DeleteCollection of the ReplicaSets 07/10/23 08:37:26.712
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 07/10/23 08:37:26.733
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jul 10 08:37:26.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-373" for this suite. 07/10/23 08:37:26.749
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:26.802
Jul 10 08:37:26.802: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replication-controller 07/10/23 08:37:26.803
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:26.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:26.88
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da 07/10/23 08:37:26.883
Jul 10 08:37:26.907: INFO: Pod name my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da: Found 0 pods out of 1
Jul 10 08:37:31.913: INFO: Pod name my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da: Found 1 pods out of 1
Jul 10 08:37:31.913: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da" are running
Jul 10 08:37:31.913: INFO: Waiting up to 5m0s for pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l" in namespace "replication-controller-9214" to be "running"
Jul 10 08:37:31.920: INFO: Pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l": Phase="Running", Reason="", readiness=true. Elapsed: 7.019243ms
Jul 10 08:37:31.920: INFO: Pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l" satisfied condition "running"
Jul 10 08:37:31.920: INFO: Pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:26 +0000 UTC Reason: Message:}])
Jul 10 08:37:31.920: INFO: Trying to dial the pod
Jul 10 08:37:36.935: INFO: Controller my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da: Got expected result from replica 1 [my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l]: "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jul 10 08:37:36.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9214" for this suite. 07/10/23 08:37:36.94
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":146,"skipped":2818,"failed":0}
------------------------------
• [SLOW TEST] [10.148 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:26.802
    Jul 10 08:37:26.802: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replication-controller 07/10/23 08:37:26.803
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:26.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:26.88
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da 07/10/23 08:37:26.883
    Jul 10 08:37:26.907: INFO: Pod name my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da: Found 0 pods out of 1
    Jul 10 08:37:31.913: INFO: Pod name my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da: Found 1 pods out of 1
    Jul 10 08:37:31.913: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da" are running
    Jul 10 08:37:31.913: INFO: Waiting up to 5m0s for pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l" in namespace "replication-controller-9214" to be "running"
    Jul 10 08:37:31.920: INFO: Pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l": Phase="Running", Reason="", readiness=true. Elapsed: 7.019243ms
    Jul 10 08:37:31.920: INFO: Pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l" satisfied condition "running"
    Jul 10 08:37:31.920: INFO: Pod "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 08:37:26 +0000 UTC Reason: Message:}])
    Jul 10 08:37:31.920: INFO: Trying to dial the pod
    Jul 10 08:37:36.935: INFO: Controller my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da: Got expected result from replica 1 [my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l]: "my-hostname-basic-dc2a3d31-4748-46d9-a6b3-595be72f60da-vgl7l", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jul 10 08:37:36.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9214" for this suite. 07/10/23 08:37:36.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:36.952
Jul 10 08:37:36.952: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:37:36.953
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:36.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:36.99
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-fbd98e74-1710-4a82-9cea-c654baaaecc8 07/10/23 08:37:36.992
STEP: Creating a pod to test consume configMaps 07/10/23 08:37:37.002
Jul 10 08:37:37.021: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1" in namespace "projected-9880" to be "Succeeded or Failed"
Jul 10 08:37:37.026: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.733009ms
Jul 10 08:37:39.032: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010637079s
Jul 10 08:37:41.033: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011531512s
STEP: Saw pod success 07/10/23 08:37:41.033
Jul 10 08:37:41.033: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1" satisfied condition "Succeeded or Failed"
Jul 10 08:37:41.037: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:37:41.047
Jul 10 08:37:41.067: INFO: Waiting for pod pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1 to disappear
Jul 10 08:37:41.071: INFO: Pod pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 08:37:41.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9880" for this suite. 07/10/23 08:37:41.076
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":147,"skipped":2831,"failed":0}
------------------------------
• [4.134 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:36.952
    Jul 10 08:37:36.952: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:37:36.953
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:36.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:36.99
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-fbd98e74-1710-4a82-9cea-c654baaaecc8 07/10/23 08:37:36.992
    STEP: Creating a pod to test consume configMaps 07/10/23 08:37:37.002
    Jul 10 08:37:37.021: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1" in namespace "projected-9880" to be "Succeeded or Failed"
    Jul 10 08:37:37.026: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.733009ms
    Jul 10 08:37:39.032: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010637079s
    Jul 10 08:37:41.033: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011531512s
    STEP: Saw pod success 07/10/23 08:37:41.033
    Jul 10 08:37:41.033: INFO: Pod "pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1" satisfied condition "Succeeded or Failed"
    Jul 10 08:37:41.037: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:37:41.047
    Jul 10 08:37:41.067: INFO: Waiting for pod pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1 to disappear
    Jul 10 08:37:41.071: INFO: Pod pod-projected-configmaps-b381cb1f-29ab-4666-8f9d-bd903ed85ad1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 08:37:41.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9880" for this suite. 07/10/23 08:37:41.076
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:41.087
Jul 10 08:37:41.087: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename namespaces 07/10/23 08:37:41.088
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:41.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:41.121
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 07/10/23 08:37:41.124
Jul 10 08:37:41.139: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 07/10/23 08:37:41.139
Jul 10 08:37:41.150: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 07/10/23 08:37:41.15
Jul 10 08:37:41.165: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:37:41.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3822" for this suite. 07/10/23 08:37:41.169
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":148,"skipped":2844,"failed":0}
------------------------------
• [0.094 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:41.087
    Jul 10 08:37:41.087: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename namespaces 07/10/23 08:37:41.088
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:41.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:41.121
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 07/10/23 08:37:41.124
    Jul 10 08:37:41.139: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 07/10/23 08:37:41.139
    Jul 10 08:37:41.150: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 07/10/23 08:37:41.15
    Jul 10 08:37:41.165: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:37:41.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3822" for this suite. 07/10/23 08:37:41.169
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:41.181
Jul 10 08:37:41.181: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-webhook 07/10/23 08:37:41.182
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:41.209
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:41.212
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 07/10/23 08:37:41.214
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 07/10/23 08:37:41.737
STEP: Deploying the custom resource conversion webhook pod 07/10/23 08:37:41.749
STEP: Wait for the deployment to be ready 07/10/23 08:37:41.772
Jul 10 08:37:41.787: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Jul 10 08:37:43.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 08:37:45.808
STEP: Verifying the service has paired with the endpoint 07/10/23 08:37:45.833
Jul 10 08:37:46.833: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Jul 10 08:37:46.838: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Creating a v1 custom resource 07/10/23 08:37:49.541
STEP: Create a v2 custom resource 07/10/23 08:37:49.578
STEP: List CRs in v1 07/10/23 08:37:49.643
STEP: List CRs in v2 07/10/23 08:37:49.649
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:37:50.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1417" for this suite. 07/10/23 08:37:50.189
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":149,"skipped":2852,"failed":0}
------------------------------
• [SLOW TEST] [9.123 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:41.181
    Jul 10 08:37:41.181: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-webhook 07/10/23 08:37:41.182
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:41.209
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:41.212
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 07/10/23 08:37:41.214
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 07/10/23 08:37:41.737
    STEP: Deploying the custom resource conversion webhook pod 07/10/23 08:37:41.749
    STEP: Wait for the deployment to be ready 07/10/23 08:37:41.772
    Jul 10 08:37:41.787: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Jul 10 08:37:43.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 37, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 08:37:45.808
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:37:45.833
    Jul 10 08:37:46.833: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Jul 10 08:37:46.838: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Creating a v1 custom resource 07/10/23 08:37:49.541
    STEP: Create a v2 custom resource 07/10/23 08:37:49.578
    STEP: List CRs in v1 07/10/23 08:37:49.643
    STEP: List CRs in v2 07/10/23 08:37:49.649
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:37:50.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-1417" for this suite. 07/10/23 08:37:50.189
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:50.305
Jul 10 08:37:50.305: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:37:50.306
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:50.348
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:50.351
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:37:50.428
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:37:51.137
STEP: Deploying the webhook pod 07/10/23 08:37:51.146
STEP: Wait for the deployment to be ready 07/10/23 08:37:51.169
Jul 10 08:37:51.188: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 07/10/23 08:37:53.259
STEP: Verifying the service has paired with the endpoint 07/10/23 08:37:53.284
Jul 10 08:37:54.285: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 07/10/23 08:37:54.289
STEP: Updating a mutating webhook configuration's rules to not include the create operation 07/10/23 08:37:54.32
STEP: Creating a configMap that should not be mutated 07/10/23 08:37:54.33
STEP: Patching a mutating webhook configuration's rules to include the create operation 07/10/23 08:37:54.348
STEP: Creating a configMap that should be mutated 07/10/23 08:37:54.361
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:37:54.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2830" for this suite. 07/10/23 08:37:54.399
STEP: Destroying namespace "webhook-2830-markers" for this suite. 07/10/23 08:37:54.533
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":150,"skipped":2854,"failed":0}
------------------------------
• [4.326 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:50.305
    Jul 10 08:37:50.305: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:37:50.306
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:50.348
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:50.351
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:37:50.428
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:37:51.137
    STEP: Deploying the webhook pod 07/10/23 08:37:51.146
    STEP: Wait for the deployment to be ready 07/10/23 08:37:51.169
    Jul 10 08:37:51.188: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 07/10/23 08:37:53.259
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:37:53.284
    Jul 10 08:37:54.285: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 07/10/23 08:37:54.289
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 07/10/23 08:37:54.32
    STEP: Creating a configMap that should not be mutated 07/10/23 08:37:54.33
    STEP: Patching a mutating webhook configuration's rules to include the create operation 07/10/23 08:37:54.348
    STEP: Creating a configMap that should be mutated 07/10/23 08:37:54.361
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:37:54.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2830" for this suite. 07/10/23 08:37:54.399
    STEP: Destroying namespace "webhook-2830-markers" for this suite. 07/10/23 08:37:54.533
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:54.631
Jul 10 08:37:54.632: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubelet-test 07/10/23 08:37:54.632
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:54.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:54.666
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jul 10 08:37:54.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4880" for this suite. 07/10/23 08:37:54.741
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":151,"skipped":2874,"failed":0}
------------------------------
• [0.122 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:54.631
    Jul 10 08:37:54.632: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubelet-test 07/10/23 08:37:54.632
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:54.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:54.666
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jul 10 08:37:54.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4880" for this suite. 07/10/23 08:37:54.741
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:54.755
Jul 10 08:37:54.755: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replication-controller 07/10/23 08:37:54.756
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:54.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:54.783
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 07/10/23 08:37:54.836
STEP: waiting for RC to be added 07/10/23 08:37:54.846
STEP: waiting for available Replicas 07/10/23 08:37:54.846
STEP: patching ReplicationController 07/10/23 08:37:56.198
STEP: waiting for RC to be modified 07/10/23 08:37:56.213
STEP: patching ReplicationController status 07/10/23 08:37:56.218
STEP: waiting for RC to be modified 07/10/23 08:37:56.234
STEP: waiting for available Replicas 07/10/23 08:37:56.234
STEP: fetching ReplicationController status 07/10/23 08:37:56.34
STEP: patching ReplicationController scale 07/10/23 08:37:56.349
STEP: waiting for RC to be modified 07/10/23 08:37:56.358
STEP: waiting for ReplicationController's scale to be the max amount 07/10/23 08:37:56.361
STEP: fetching ReplicationController; ensuring that it's patched 07/10/23 08:37:58.782
STEP: updating ReplicationController status 07/10/23 08:37:58.787
STEP: waiting for RC to be modified 07/10/23 08:37:58.796
STEP: listing all ReplicationControllers 07/10/23 08:37:58.797
STEP: checking that ReplicationController has expected values 07/10/23 08:37:58.8
STEP: deleting ReplicationControllers by collection 07/10/23 08:37:58.8
STEP: waiting for ReplicationController to have a DELETED watchEvent 07/10/23 08:37:58.821
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jul 10 08:37:58.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7414" for this suite. 07/10/23 08:37:58.91
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":152,"skipped":2889,"failed":0}
------------------------------
• [4.164 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:54.755
    Jul 10 08:37:54.755: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replication-controller 07/10/23 08:37:54.756
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:54.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:54.783
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 07/10/23 08:37:54.836
    STEP: waiting for RC to be added 07/10/23 08:37:54.846
    STEP: waiting for available Replicas 07/10/23 08:37:54.846
    STEP: patching ReplicationController 07/10/23 08:37:56.198
    STEP: waiting for RC to be modified 07/10/23 08:37:56.213
    STEP: patching ReplicationController status 07/10/23 08:37:56.218
    STEP: waiting for RC to be modified 07/10/23 08:37:56.234
    STEP: waiting for available Replicas 07/10/23 08:37:56.234
    STEP: fetching ReplicationController status 07/10/23 08:37:56.34
    STEP: patching ReplicationController scale 07/10/23 08:37:56.349
    STEP: waiting for RC to be modified 07/10/23 08:37:56.358
    STEP: waiting for ReplicationController's scale to be the max amount 07/10/23 08:37:56.361
    STEP: fetching ReplicationController; ensuring that it's patched 07/10/23 08:37:58.782
    STEP: updating ReplicationController status 07/10/23 08:37:58.787
    STEP: waiting for RC to be modified 07/10/23 08:37:58.796
    STEP: listing all ReplicationControllers 07/10/23 08:37:58.797
    STEP: checking that ReplicationController has expected values 07/10/23 08:37:58.8
    STEP: deleting ReplicationControllers by collection 07/10/23 08:37:58.8
    STEP: waiting for ReplicationController to have a DELETED watchEvent 07/10/23 08:37:58.821
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jul 10 08:37:58.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7414" for this suite. 07/10/23 08:37:58.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:37:58.92
Jul 10 08:37:58.920: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename job 07/10/23 08:37:58.921
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:58.951
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:58.954
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 07/10/23 08:37:58.959
STEP: Patching the Job 07/10/23 08:37:58.973
STEP: Watching for Job to be patched 07/10/23 08:37:59.007
Jul 10 08:37:59.009: INFO: Event ADDED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm] and annotations: map[batch.kubernetes.io/job-tracking:]
Jul 10 08:37:59.009: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm] and annotations: map[batch.kubernetes.io/job-tracking:]
Jul 10 08:37:59.009: INFO: Event MODIFIED found for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 07/10/23 08:37:59.009
STEP: Watching for Job to be updated 07/10/23 08:37:59.024
Jul 10 08:37:59.026: INFO: Event MODIFIED found for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jul 10 08:37:59.026: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 07/10/23 08:37:59.026
Jul 10 08:37:59.030: INFO: Job: e2e-zn7hm as labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched]
STEP: Waiting for job to complete 07/10/23 08:37:59.03
STEP: Delete a job collection with a labelselector 07/10/23 08:38:09.034
STEP: Watching for Job to be deleted 07/10/23 08:38:09.048
Jul 10 08:38:09.050: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jul 10 08:38:09.050: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jul 10 08:38:09.050: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jul 10 08:38:09.051: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jul 10 08:38:09.056: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jul 10 08:38:09.056: INFO: Event DELETED found for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 07/10/23 08:38:09.056
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jul 10 08:38:09.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-989" for this suite. 07/10/23 08:38:09.102
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":153,"skipped":2922,"failed":0}
------------------------------
• [SLOW TEST] [10.207 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:37:58.92
    Jul 10 08:37:58.920: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename job 07/10/23 08:37:58.921
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:37:58.951
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:37:58.954
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 07/10/23 08:37:58.959
    STEP: Patching the Job 07/10/23 08:37:58.973
    STEP: Watching for Job to be patched 07/10/23 08:37:59.007
    Jul 10 08:37:59.009: INFO: Event ADDED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm] and annotations: map[batch.kubernetes.io/job-tracking:]
    Jul 10 08:37:59.009: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm] and annotations: map[batch.kubernetes.io/job-tracking:]
    Jul 10 08:37:59.009: INFO: Event MODIFIED found for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 07/10/23 08:37:59.009
    STEP: Watching for Job to be updated 07/10/23 08:37:59.024
    Jul 10 08:37:59.026: INFO: Event MODIFIED found for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jul 10 08:37:59.026: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 07/10/23 08:37:59.026
    Jul 10 08:37:59.030: INFO: Job: e2e-zn7hm as labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched]
    STEP: Waiting for job to complete 07/10/23 08:37:59.03
    STEP: Delete a job collection with a labelselector 07/10/23 08:38:09.034
    STEP: Watching for Job to be deleted 07/10/23 08:38:09.048
    Jul 10 08:38:09.050: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jul 10 08:38:09.050: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jul 10 08:38:09.050: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jul 10 08:38:09.051: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jul 10 08:38:09.056: INFO: Event MODIFIED observed for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jul 10 08:38:09.056: INFO: Event DELETED found for Job e2e-zn7hm in namespace job-989 with labels: map[e2e-job-label:e2e-zn7hm e2e-zn7hm:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 07/10/23 08:38:09.056
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jul 10 08:38:09.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-989" for this suite. 07/10/23 08:38:09.102
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:38:09.13
Jul 10 08:38:09.130: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename init-container 07/10/23 08:38:09.131
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:09.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:09.16
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 07/10/23 08:38:09.162
Jul 10 08:38:09.163: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 08:38:12.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9341" for this suite. 07/10/23 08:38:12.976
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":154,"skipped":2967,"failed":0}
------------------------------
• [3.859 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:38:09.13
    Jul 10 08:38:09.130: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename init-container 07/10/23 08:38:09.131
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:09.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:09.16
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 07/10/23 08:38:09.162
    Jul 10 08:38:09.163: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 08:38:12.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9341" for this suite. 07/10/23 08:38:12.976
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:38:12.991
Jul 10 08:38:12.991: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 08:38:12.993
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:13.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:13.022
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7881 07/10/23 08:38:13.024
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-7881 07/10/23 08:38:13.035
Jul 10 08:38:13.063: INFO: Found 0 stateful pods, waiting for 1
Jul 10 08:38:23.068: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 07/10/23 08:38:23.076
STEP: Getting /status 07/10/23 08:38:23.089
Jul 10 08:38:23.095: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 07/10/23 08:38:23.095
Jul 10 08:38:23.115: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 07/10/23 08:38:23.115
Jul 10 08:38:23.116: INFO: Observed &StatefulSet event: ADDED
Jul 10 08:38:23.116: INFO: Found Statefulset ss in namespace statefulset-7881 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul 10 08:38:23.116: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 07/10/23 08:38:23.116
Jul 10 08:38:23.116: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul 10 08:38:23.129: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 07/10/23 08:38:23.129
Jul 10 08:38:23.130: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 08:38:23.130: INFO: Deleting all statefulset in ns statefulset-7881
Jul 10 08:38:23.134: INFO: Scaling statefulset ss to 0
Jul 10 08:38:33.159: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:38:33.163: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 08:38:33.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7881" for this suite. 07/10/23 08:38:33.194
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":155,"skipped":3017,"failed":0}
------------------------------
• [SLOW TEST] [20.217 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:38:12.991
    Jul 10 08:38:12.991: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 08:38:12.993
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:13.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:13.022
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7881 07/10/23 08:38:13.024
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-7881 07/10/23 08:38:13.035
    Jul 10 08:38:13.063: INFO: Found 0 stateful pods, waiting for 1
    Jul 10 08:38:23.068: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 07/10/23 08:38:23.076
    STEP: Getting /status 07/10/23 08:38:23.089
    Jul 10 08:38:23.095: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 07/10/23 08:38:23.095
    Jul 10 08:38:23.115: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 07/10/23 08:38:23.115
    Jul 10 08:38:23.116: INFO: Observed &StatefulSet event: ADDED
    Jul 10 08:38:23.116: INFO: Found Statefulset ss in namespace statefulset-7881 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jul 10 08:38:23.116: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 07/10/23 08:38:23.116
    Jul 10 08:38:23.116: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jul 10 08:38:23.129: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 07/10/23 08:38:23.129
    Jul 10 08:38:23.130: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 08:38:23.130: INFO: Deleting all statefulset in ns statefulset-7881
    Jul 10 08:38:23.134: INFO: Scaling statefulset ss to 0
    Jul 10 08:38:33.159: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:38:33.163: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 08:38:33.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7881" for this suite. 07/10/23 08:38:33.194
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:38:33.209
Jul 10 08:38:33.209: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename subpath 07/10/23 08:38:33.21
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:33.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:33.245
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 07/10/23 08:38:33.248
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-jk4c 07/10/23 08:38:33.265
STEP: Creating a pod to test atomic-volume-subpath 07/10/23 08:38:33.265
Jul 10 08:38:33.280: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jk4c" in namespace "subpath-96" to be "Succeeded or Failed"
Jul 10 08:38:33.283: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.086259ms
Jul 10 08:38:35.365: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.085448344s
Jul 10 08:38:37.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.008435515s
Jul 10 08:38:39.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.008356666s
Jul 10 08:38:41.289: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 8.008630178s
Jul 10 08:38:43.289: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 10.00903231s
Jul 10 08:38:45.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 12.008085616s
Jul 10 08:38:47.290: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 14.010056406s
Jul 10 08:38:49.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 16.008355601s
Jul 10 08:38:51.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 18.008579633s
Jul 10 08:38:53.291: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 20.011025578s
Jul 10 08:38:55.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 22.007700492s
Jul 10 08:38:57.290: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=false. Elapsed: 24.010155092s
Jul 10 08:38:59.294: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.013772284s
STEP: Saw pod success 07/10/23 08:38:59.294
Jul 10 08:38:59.294: INFO: Pod "pod-subpath-test-secret-jk4c" satisfied condition "Succeeded or Failed"
Jul 10 08:38:59.298: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-secret-jk4c container test-container-subpath-secret-jk4c: <nil>
STEP: delete the pod 07/10/23 08:38:59.309
Jul 10 08:38:59.342: INFO: Waiting for pod pod-subpath-test-secret-jk4c to disappear
Jul 10 08:38:59.345: INFO: Pod pod-subpath-test-secret-jk4c no longer exists
STEP: Deleting pod pod-subpath-test-secret-jk4c 07/10/23 08:38:59.345
Jul 10 08:38:59.345: INFO: Deleting pod "pod-subpath-test-secret-jk4c" in namespace "subpath-96"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jul 10 08:38:59.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-96" for this suite. 07/10/23 08:38:59.354
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":156,"skipped":3024,"failed":0}
------------------------------
• [SLOW TEST] [26.154 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:38:33.209
    Jul 10 08:38:33.209: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename subpath 07/10/23 08:38:33.21
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:33.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:33.245
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 07/10/23 08:38:33.248
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-jk4c 07/10/23 08:38:33.265
    STEP: Creating a pod to test atomic-volume-subpath 07/10/23 08:38:33.265
    Jul 10 08:38:33.280: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jk4c" in namespace "subpath-96" to be "Succeeded or Failed"
    Jul 10 08:38:33.283: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.086259ms
    Jul 10 08:38:35.365: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.085448344s
    Jul 10 08:38:37.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 4.008435515s
    Jul 10 08:38:39.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.008356666s
    Jul 10 08:38:41.289: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 8.008630178s
    Jul 10 08:38:43.289: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 10.00903231s
    Jul 10 08:38:45.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 12.008085616s
    Jul 10 08:38:47.290: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 14.010056406s
    Jul 10 08:38:49.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 16.008355601s
    Jul 10 08:38:51.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 18.008579633s
    Jul 10 08:38:53.291: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 20.011025578s
    Jul 10 08:38:55.288: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=true. Elapsed: 22.007700492s
    Jul 10 08:38:57.290: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Running", Reason="", readiness=false. Elapsed: 24.010155092s
    Jul 10 08:38:59.294: INFO: Pod "pod-subpath-test-secret-jk4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.013772284s
    STEP: Saw pod success 07/10/23 08:38:59.294
    Jul 10 08:38:59.294: INFO: Pod "pod-subpath-test-secret-jk4c" satisfied condition "Succeeded or Failed"
    Jul 10 08:38:59.298: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-secret-jk4c container test-container-subpath-secret-jk4c: <nil>
    STEP: delete the pod 07/10/23 08:38:59.309
    Jul 10 08:38:59.342: INFO: Waiting for pod pod-subpath-test-secret-jk4c to disappear
    Jul 10 08:38:59.345: INFO: Pod pod-subpath-test-secret-jk4c no longer exists
    STEP: Deleting pod pod-subpath-test-secret-jk4c 07/10/23 08:38:59.345
    Jul 10 08:38:59.345: INFO: Deleting pod "pod-subpath-test-secret-jk4c" in namespace "subpath-96"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jul 10 08:38:59.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-96" for this suite. 07/10/23 08:38:59.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:38:59.364
Jul 10 08:38:59.364: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:38:59.365
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:59.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:59.391
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 07/10/23 08:38:59.394
Jul 10 08:38:59.407: INFO: Waiting up to 5m0s for pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0" in namespace "emptydir-4319" to be "Succeeded or Failed"
Jul 10 08:38:59.410: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.410382ms
Jul 10 08:39:01.416: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009022871s
Jul 10 08:39:03.416: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008580364s
Jul 10 08:39:05.417: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009543175s
STEP: Saw pod success 07/10/23 08:39:05.417
Jul 10 08:39:05.417: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0" satisfied condition "Succeeded or Failed"
Jul 10 08:39:05.420: INFO: Trying to get logs from node 10-62-109-100.test pod pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0 container test-container: <nil>
STEP: delete the pod 07/10/23 08:39:05.429
Jul 10 08:39:05.466: INFO: Waiting for pod pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0 to disappear
Jul 10 08:39:05.474: INFO: Pod pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:39:05.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4319" for this suite. 07/10/23 08:39:05.479
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":157,"skipped":3040,"failed":0}
------------------------------
• [SLOW TEST] [6.130 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:38:59.364
    Jul 10 08:38:59.364: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:38:59.365
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:38:59.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:38:59.391
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 07/10/23 08:38:59.394
    Jul 10 08:38:59.407: INFO: Waiting up to 5m0s for pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0" in namespace "emptydir-4319" to be "Succeeded or Failed"
    Jul 10 08:38:59.410: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.410382ms
    Jul 10 08:39:01.416: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009022871s
    Jul 10 08:39:03.416: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008580364s
    Jul 10 08:39:05.417: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009543175s
    STEP: Saw pod success 07/10/23 08:39:05.417
    Jul 10 08:39:05.417: INFO: Pod "pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0" satisfied condition "Succeeded or Failed"
    Jul 10 08:39:05.420: INFO: Trying to get logs from node 10-62-109-100.test pod pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:39:05.429
    Jul 10 08:39:05.466: INFO: Waiting for pod pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0 to disappear
    Jul 10 08:39:05.474: INFO: Pod pod-5064fe20-2e4e-4f1a-bc89-bea3d3d8aef0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:39:05.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4319" for this suite. 07/10/23 08:39:05.479
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:39:05.496
Jul 10 08:39:05.496: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:39:05.497
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:05.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:05.539
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 07/10/23 08:39:05.541
Jul 10 08:39:05.559: INFO: Waiting up to 5m0s for pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2" in namespace "emptydir-3502" to be "Succeeded or Failed"
Jul 10 08:39:05.565: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.690492ms
Jul 10 08:39:07.572: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012723457s
Jul 10 08:39:09.570: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010701704s
Jul 10 08:39:11.570: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010607461s
STEP: Saw pod success 07/10/23 08:39:11.57
Jul 10 08:39:11.570: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2" satisfied condition "Succeeded or Failed"
Jul 10 08:39:11.574: INFO: Trying to get logs from node 10-62-109-100.test pod pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2 container test-container: <nil>
STEP: delete the pod 07/10/23 08:39:11.583
Jul 10 08:39:11.601: INFO: Waiting for pod pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2 to disappear
Jul 10 08:39:11.604: INFO: Pod pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:39:11.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3502" for this suite. 07/10/23 08:39:11.608
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":158,"skipped":3084,"failed":0}
------------------------------
• [SLOW TEST] [6.120 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:39:05.496
    Jul 10 08:39:05.496: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:39:05.497
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:05.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:05.539
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 07/10/23 08:39:05.541
    Jul 10 08:39:05.559: INFO: Waiting up to 5m0s for pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2" in namespace "emptydir-3502" to be "Succeeded or Failed"
    Jul 10 08:39:05.565: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.690492ms
    Jul 10 08:39:07.572: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012723457s
    Jul 10 08:39:09.570: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010701704s
    Jul 10 08:39:11.570: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010607461s
    STEP: Saw pod success 07/10/23 08:39:11.57
    Jul 10 08:39:11.570: INFO: Pod "pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2" satisfied condition "Succeeded or Failed"
    Jul 10 08:39:11.574: INFO: Trying to get logs from node 10-62-109-100.test pod pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:39:11.583
    Jul 10 08:39:11.601: INFO: Waiting for pod pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2 to disappear
    Jul 10 08:39:11.604: INFO: Pod pod-403f223f-7c4d-4ea3-b0c4-a9de5fa7efe2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:39:11.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3502" for this suite. 07/10/23 08:39:11.608
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:39:11.625
Jul 10 08:39:11.625: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:39:11.626
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:11.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:11.66
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 07/10/23 08:39:11.662
Jul 10 08:39:11.678: INFO: Waiting up to 5m0s for pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea" in namespace "emptydir-2100" to be "Succeeded or Failed"
Jul 10 08:39:11.686: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.135674ms
Jul 10 08:39:13.693: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014823337s
Jul 10 08:39:15.692: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01366797s
Jul 10 08:39:17.695: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016514903s
STEP: Saw pod success 07/10/23 08:39:17.695
Jul 10 08:39:17.695: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea" satisfied condition "Succeeded or Failed"
Jul 10 08:39:17.698: INFO: Trying to get logs from node 10-62-109-100.test pod pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea container test-container: <nil>
STEP: delete the pod 07/10/23 08:39:17.71
Jul 10 08:39:17.734: INFO: Waiting for pod pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea to disappear
Jul 10 08:39:17.738: INFO: Pod pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:39:17.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2100" for this suite. 07/10/23 08:39:17.743
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":159,"skipped":3181,"failed":0}
------------------------------
• [SLOW TEST] [6.128 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:39:11.625
    Jul 10 08:39:11.625: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:39:11.626
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:11.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:11.66
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 07/10/23 08:39:11.662
    Jul 10 08:39:11.678: INFO: Waiting up to 5m0s for pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea" in namespace "emptydir-2100" to be "Succeeded or Failed"
    Jul 10 08:39:11.686: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.135674ms
    Jul 10 08:39:13.693: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014823337s
    Jul 10 08:39:15.692: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01366797s
    Jul 10 08:39:17.695: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016514903s
    STEP: Saw pod success 07/10/23 08:39:17.695
    Jul 10 08:39:17.695: INFO: Pod "pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea" satisfied condition "Succeeded or Failed"
    Jul 10 08:39:17.698: INFO: Trying to get logs from node 10-62-109-100.test pod pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea container test-container: <nil>
    STEP: delete the pod 07/10/23 08:39:17.71
    Jul 10 08:39:17.734: INFO: Waiting for pod pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea to disappear
    Jul 10 08:39:17.738: INFO: Pod pod-b0170a6b-3a2d-4580-b6b1-8e899ffeb5ea no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:39:17.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2100" for this suite. 07/10/23 08:39:17.743
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:39:17.753
Jul 10 08:39:17.753: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:39:17.754
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:17.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:17.785
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 07/10/23 08:39:34.794
STEP: Creating a ResourceQuota 07/10/23 08:39:39.8
STEP: Ensuring resource quota status is calculated 07/10/23 08:39:39.813
STEP: Creating a ConfigMap 07/10/23 08:39:41.818
STEP: Ensuring resource quota status captures configMap creation 07/10/23 08:39:41.843
STEP: Deleting a ConfigMap 07/10/23 08:39:43.85
STEP: Ensuring resource quota status released usage 07/10/23 08:39:43.865
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:39:45.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5598" for this suite. 07/10/23 08:39:45.876
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":160,"skipped":3184,"failed":0}
------------------------------
• [SLOW TEST] [28.132 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:39:17.753
    Jul 10 08:39:17.753: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:39:17.754
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:17.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:17.785
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 07/10/23 08:39:34.794
    STEP: Creating a ResourceQuota 07/10/23 08:39:39.8
    STEP: Ensuring resource quota status is calculated 07/10/23 08:39:39.813
    STEP: Creating a ConfigMap 07/10/23 08:39:41.818
    STEP: Ensuring resource quota status captures configMap creation 07/10/23 08:39:41.843
    STEP: Deleting a ConfigMap 07/10/23 08:39:43.85
    STEP: Ensuring resource quota status released usage 07/10/23 08:39:43.865
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:39:45.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5598" for this suite. 07/10/23 08:39:45.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:39:45.887
Jul 10 08:39:45.887: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 08:39:45.888
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:45.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:45.923
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7 in namespace container-probe-5584 07/10/23 08:39:45.926
Jul 10 08:39:45.966: INFO: Waiting up to 5m0s for pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7" in namespace "container-probe-5584" to be "not pending"
Jul 10 08:39:45.970: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.747563ms
Jul 10 08:39:47.975: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00871979s
Jul 10 08:39:49.975: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7": Phase="Running", Reason="", readiness=true. Elapsed: 4.008959159s
Jul 10 08:39:49.975: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7" satisfied condition "not pending"
Jul 10 08:39:49.975: INFO: Started pod test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7 in namespace container-probe-5584
STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 08:39:49.975
Jul 10 08:39:49.979: INFO: Initial restart count of pod test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7 is 0
STEP: deleting the pod 07/10/23 08:43:50.808
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 08:43:50.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5584" for this suite. 07/10/23 08:43:50.851
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":161,"skipped":3200,"failed":0}
------------------------------
• [SLOW TEST] [244.985 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:39:45.887
    Jul 10 08:39:45.887: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 08:39:45.888
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:39:45.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:39:45.923
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7 in namespace container-probe-5584 07/10/23 08:39:45.926
    Jul 10 08:39:45.966: INFO: Waiting up to 5m0s for pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7" in namespace "container-probe-5584" to be "not pending"
    Jul 10 08:39:45.970: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.747563ms
    Jul 10 08:39:47.975: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00871979s
    Jul 10 08:39:49.975: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7": Phase="Running", Reason="", readiness=true. Elapsed: 4.008959159s
    Jul 10 08:39:49.975: INFO: Pod "test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7" satisfied condition "not pending"
    Jul 10 08:39:49.975: INFO: Started pod test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7 in namespace container-probe-5584
    STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 08:39:49.975
    Jul 10 08:39:49.979: INFO: Initial restart count of pod test-webserver-7956e15f-8e77-4c08-925f-9f924f7cffe7 is 0
    STEP: deleting the pod 07/10/23 08:43:50.808
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 08:43:50.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5584" for this suite. 07/10/23 08:43:50.851
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:43:50.872
Jul 10 08:43:50.872: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:43:50.874
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:43:50.918
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:43:50.921
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-ca740db7-2411-40db-aeb5-548e8749d705 07/10/23 08:43:50.924
STEP: Creating a pod to test consume secrets 07/10/23 08:43:51.053
Jul 10 08:43:51.101: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9" in namespace "projected-653" to be "Succeeded or Failed"
Jul 10 08:43:51.109: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.951884ms
Jul 10 08:43:53.116: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014575617s
Jul 10 08:43:55.115: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013394274s
STEP: Saw pod success 07/10/23 08:43:55.115
Jul 10 08:43:55.115: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9" satisfied condition "Succeeded or Failed"
Jul 10 08:43:55.120: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9 container projected-secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:43:55.137
Jul 10 08:43:55.162: INFO: Waiting for pod pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9 to disappear
Jul 10 08:43:55.166: INFO: Pod pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 08:43:55.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-653" for this suite. 07/10/23 08:43:55.169
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":162,"skipped":3203,"failed":0}
------------------------------
• [4.307 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:43:50.872
    Jul 10 08:43:50.872: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:43:50.874
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:43:50.918
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:43:50.921
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-ca740db7-2411-40db-aeb5-548e8749d705 07/10/23 08:43:50.924
    STEP: Creating a pod to test consume secrets 07/10/23 08:43:51.053
    Jul 10 08:43:51.101: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9" in namespace "projected-653" to be "Succeeded or Failed"
    Jul 10 08:43:51.109: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.951884ms
    Jul 10 08:43:53.116: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014575617s
    Jul 10 08:43:55.115: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013394274s
    STEP: Saw pod success 07/10/23 08:43:55.115
    Jul 10 08:43:55.115: INFO: Pod "pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9" satisfied condition "Succeeded or Failed"
    Jul 10 08:43:55.120: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9 container projected-secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:43:55.137
    Jul 10 08:43:55.162: INFO: Waiting for pod pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9 to disappear
    Jul 10 08:43:55.166: INFO: Pod pod-projected-secrets-951ebf42-ba5f-4c08-853e-4202dcc02ac9 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 08:43:55.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-653" for this suite. 07/10/23 08:43:55.169
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:43:55.181
Jul 10 08:43:55.181: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 08:43:55.182
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:43:55.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:43:55.256
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 07/10/23 08:43:55.265
STEP: waiting for Deployment to be created 07/10/23 08:43:55.334
STEP: waiting for all Replicas to be Ready 07/10/23 08:43:55.339
Jul 10 08:43:55.341: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.341: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.372: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.372: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.406: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.406: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.456: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:55.456: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul 10 08:43:57.134: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jul 10 08:43:57.134: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jul 10 08:43:57.586: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 07/10/23 08:43:57.586
W0710 08:43:57.605336      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jul 10 08:43:57.606: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 07/10/23 08:43:57.607
Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.638: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.639: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.689: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.689: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.739: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.739: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:57.754: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:43:57.754: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:43:59.655: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:59.655: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:43:59.719: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
STEP: listing Deployments 07/10/23 08:43:59.719
Jul 10 08:43:59.725: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 07/10/23 08:43:59.725
Jul 10 08:43:59.754: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 07/10/23 08:43:59.754
Jul 10 08:43:59.762: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:43:59.795: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:43:59.858: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:43:59.887: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:43:59.903: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:44:01.292: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:44:01.898: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:44:01.977: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:44:01.989: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul 10 08:44:03.719: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 07/10/23 08:44:03.868
STEP: fetching the DeploymentStatus 07/10/23 08:44:03.875
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3
Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3
Jul 10 08:44:03.881: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
Jul 10 08:44:03.881: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3
STEP: deleting the Deployment 07/10/23 08:44:03.881
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.898: INFO: observed event type MODIFIED
Jul 10 08:44:03.899: INFO: observed event type MODIFIED
Jul 10 08:44:03.899: INFO: observed event type MODIFIED
Jul 10 08:44:03.899: INFO: observed event type MODIFIED
Jul 10 08:44:03.899: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 08:44:03.902: INFO: Log out all the ReplicaSets if there is no deployment created
Jul 10 08:44:03.907: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8349  d3d8b252-a296-453f-b49e-037ad4e1e2a2 86949 4 2023-07-10 08:43:57 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 19602775-5542-4297-90c5-2617dbcd1759 0xc003958b87 0xc003958b88}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19602775-5542-4297-90c5-2617dbcd1759\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003958c10 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jul 10 08:44:03.913: INFO: pod: "test-deployment-54cc775c4b-cfnjp":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-cfnjp test-deployment-54cc775c4b- deployment-8349  5e273b8f-85c9-4b17-a2a1-e466df854ecf 86936 0 2023-07-10 08:43:59 +0000 UTC 2023-07-10 08:44:02 +0000 UTC 0xc00412c0f8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:8fa14b6b8d1db3d3b40b0aa4f7c8cb633cf5bc8c9b0ee4417db48868288d62e8 cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet test-deployment-54cc775c4b d3d8b252-a296-453f-b49e-037ad4e1e2a2 0xc00412c127 0xc00412c128}] [] [{kube-controller-manager Update v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3d8b252-a296-453f-b49e-037ad4e1e2a2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.117\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status} {calico Update v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rcx9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rcx9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:192.168.103.117,StartTime:2023-07-10 08:43:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:44:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:docker-pullable://registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:docker://0051d00a6ac54b8d662df313911e746fe334c0769ffe633cfabd967b357bbd03,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.103.117,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul 10 08:44:03.914: INFO: pod: "test-deployment-54cc775c4b-wv59w":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-wv59w test-deployment-54cc775c4b- deployment-8349  2e41be92-8f8d-44ac-9ad4-256f0ed59e62 86945 0 2023-07-10 08:43:57 +0000 UTC 2023-07-10 08:44:04 +0000 UTC 0xc00412c310 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:3782c8372ee0a7e0c3494980d8883997a466cd38a74ba4d44c86945ce51e714d cni.projectcalico.org/podIP:192.168.172.23/32 cni.projectcalico.org/podIPs:192.168.172.23/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b d3d8b252-a296-453f-b49e-037ad4e1e2a2 0xc00412c347 0xc00412c348}] [] [{kube-controller-manager Update v1 2023-07-10 08:43:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3d8b252-a296-453f-b49e-037ad4e1e2a2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:43:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m9txq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m9txq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.23,StartTime:2023-07-10 08:43:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:43:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:docker-pullable://registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:docker://65642eebebd90e8ebc270949f6428c3f84f777cb1af4e91d2227942f22cc587b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul 10 08:44:03.914: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8349  3a35420e-e2e1-45d7-b592-2f659eabd794 86941 2 2023-07-10 08:43:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 19602775-5542-4297-90c5-2617dbcd1759 0xc003958c77 0xc003958c78}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19602775-5542-4297-90c5-2617dbcd1759\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003958d00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Jul 10 08:44:03.918: INFO: pod: "test-deployment-7c7d8d58c8-8jgtf":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-8jgtf test-deployment-7c7d8d58c8- deployment-8349  372734f0-23e2-4698-bb25-24c79489a0b6 86940 0 2023-07-10 08:44:01 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:5684424ea48369264e0b2ffc6f6245907227f2f29af6893bfd3154ca0495826d cni.projectcalico.org/podIP:192.168.172.61/32 cni.projectcalico.org/podIPs:192.168.172.61/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3a35420e-e2e1-45d7-b592-2f659eabd794 0xc003981c67 0xc003981c68}] [] [{kube-controller-manager Update v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a35420e-e2e1-45d7-b592-2f659eabd794\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:44:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dvz88,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dvz88,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.61,StartTime:2023-07-10 08:44:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:44:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://d3474b101ffaa05770f8ba5bdcb78b64a78f20026c674f1cb6649a62ea4e1bfd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul 10 08:44:03.918: INFO: pod: "test-deployment-7c7d8d58c8-h7n6g":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-h7n6g test-deployment-7c7d8d58c8- deployment-8349  661b0e0d-7d7c-4187-a2fc-7fb1c44da337 86904 0 2023-07-10 08:43:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:f98579afcaa49b7e067298a7de6e1f306eaac39466d792fc423ffcd136eb81e3 cni.projectcalico.org/podIP:192.168.120.62/32 cni.projectcalico.org/podIPs:192.168.120.62/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3a35420e-e2e1-45d7-b592-2f659eabd794 0xc003981e67 0xc003981e68}] [] [{kube-controller-manager Update v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a35420e-e2e1-45d7-b592-2f659eabd794\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:44:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29b8n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29b8n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.62,StartTime:2023-07-10 08:43:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:44:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://705114976b3e54df19305bde764fded3a608d21cc2002ebdb0e373727f30d42a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul 10 08:44:03.918: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8349  6b73c714-cf4f-4574-87fa-87225149bdc3 86835 3 2023-07-10 08:43:55 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 19602775-5542-4297-90c5-2617dbcd1759 0xc003958d67 0xc003958d68}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19602775-5542-4297-90c5-2617dbcd1759\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003958df0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 08:44:03.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8349" for this suite. 07/10/23 08:44:03.928
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":163,"skipped":3232,"failed":0}
------------------------------
• [SLOW TEST] [8.772 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:43:55.181
    Jul 10 08:43:55.181: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 08:43:55.182
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:43:55.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:43:55.256
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 07/10/23 08:43:55.265
    STEP: waiting for Deployment to be created 07/10/23 08:43:55.334
    STEP: waiting for all Replicas to be Ready 07/10/23 08:43:55.339
    Jul 10 08:43:55.341: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.341: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.372: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.372: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.406: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.406: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.456: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:55.456: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jul 10 08:43:57.134: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Jul 10 08:43:57.134: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Jul 10 08:43:57.586: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 07/10/23 08:43:57.586
    W0710 08:43:57.605336      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jul 10 08:43:57.606: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 07/10/23 08:43:57.607
    Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.608: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 0
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.609: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.638: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.639: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.689: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.689: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.739: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.739: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:57.754: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:43:57.754: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:43:59.655: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:59.655: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:43:59.719: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    STEP: listing Deployments 07/10/23 08:43:59.719
    Jul 10 08:43:59.725: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 07/10/23 08:43:59.725
    Jul 10 08:43:59.754: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 07/10/23 08:43:59.754
    Jul 10 08:43:59.762: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:43:59.795: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:43:59.858: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:43:59.887: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:43:59.903: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:44:01.292: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:44:01.898: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:44:01.977: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:44:01.989: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jul 10 08:44:03.719: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 07/10/23 08:44:03.868
    STEP: fetching the DeploymentStatus 07/10/23 08:44:03.875
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 1
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3
    Jul 10 08:44:03.880: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3
    Jul 10 08:44:03.881: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 2
    Jul 10 08:44:03.881: INFO: observed Deployment test-deployment in namespace deployment-8349 with ReadyReplicas 3
    STEP: deleting the Deployment 07/10/23 08:44:03.881
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.898: INFO: observed event type MODIFIED
    Jul 10 08:44:03.899: INFO: observed event type MODIFIED
    Jul 10 08:44:03.899: INFO: observed event type MODIFIED
    Jul 10 08:44:03.899: INFO: observed event type MODIFIED
    Jul 10 08:44:03.899: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 08:44:03.902: INFO: Log out all the ReplicaSets if there is no deployment created
    Jul 10 08:44:03.907: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8349  d3d8b252-a296-453f-b49e-037ad4e1e2a2 86949 4 2023-07-10 08:43:57 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 19602775-5542-4297-90c5-2617dbcd1759 0xc003958b87 0xc003958b88}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19602775-5542-4297-90c5-2617dbcd1759\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003958c10 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Jul 10 08:44:03.913: INFO: pod: "test-deployment-54cc775c4b-cfnjp":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-cfnjp test-deployment-54cc775c4b- deployment-8349  5e273b8f-85c9-4b17-a2a1-e466df854ecf 86936 0 2023-07-10 08:43:59 +0000 UTC 2023-07-10 08:44:02 +0000 UTC 0xc00412c0f8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:8fa14b6b8d1db3d3b40b0aa4f7c8cb633cf5bc8c9b0ee4417db48868288d62e8 cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet test-deployment-54cc775c4b d3d8b252-a296-453f-b49e-037ad4e1e2a2 0xc00412c127 0xc00412c128}] [] [{kube-controller-manager Update v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3d8b252-a296-453f-b49e-037ad4e1e2a2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.117\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status} {calico Update v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rcx9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rcx9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:192.168.103.117,StartTime:2023-07-10 08:43:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:44:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:docker-pullable://registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:docker://0051d00a6ac54b8d662df313911e746fe334c0769ffe633cfabd967b357bbd03,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.103.117,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jul 10 08:44:03.914: INFO: pod: "test-deployment-54cc775c4b-wv59w":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-wv59w test-deployment-54cc775c4b- deployment-8349  2e41be92-8f8d-44ac-9ad4-256f0ed59e62 86945 0 2023-07-10 08:43:57 +0000 UTC 2023-07-10 08:44:04 +0000 UTC 0xc00412c310 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:3782c8372ee0a7e0c3494980d8883997a466cd38a74ba4d44c86945ce51e714d cni.projectcalico.org/podIP:192.168.172.23/32 cni.projectcalico.org/podIPs:192.168.172.23/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b d3d8b252-a296-453f-b49e-037ad4e1e2a2 0xc00412c347 0xc00412c348}] [] [{kube-controller-manager Update v1 2023-07-10 08:43:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d3d8b252-a296-453f-b49e-037ad4e1e2a2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:43:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m9txq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m9txq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.23,StartTime:2023-07-10 08:43:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:43:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:docker-pullable://registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:docker://65642eebebd90e8ebc270949f6428c3f84f777cb1af4e91d2227942f22cc587b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jul 10 08:44:03.914: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8349  3a35420e-e2e1-45d7-b592-2f659eabd794 86941 2 2023-07-10 08:43:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 19602775-5542-4297-90c5-2617dbcd1759 0xc003958c77 0xc003958c78}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19602775-5542-4297-90c5-2617dbcd1759\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003958d00 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Jul 10 08:44:03.918: INFO: pod: "test-deployment-7c7d8d58c8-8jgtf":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-8jgtf test-deployment-7c7d8d58c8- deployment-8349  372734f0-23e2-4698-bb25-24c79489a0b6 86940 0 2023-07-10 08:44:01 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:5684424ea48369264e0b2ffc6f6245907227f2f29af6893bfd3154ca0495826d cni.projectcalico.org/podIP:192.168.172.61/32 cni.projectcalico.org/podIPs:192.168.172.61/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3a35420e-e2e1-45d7-b592-2f659eabd794 0xc003981c67 0xc003981c68}] [] [{kube-controller-manager Update v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a35420e-e2e1-45d7-b592-2f659eabd794\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:44:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:44:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dvz88,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dvz88,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.61,StartTime:2023-07-10 08:44:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:44:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://d3474b101ffaa05770f8ba5bdcb78b64a78f20026c674f1cb6649a62ea4e1bfd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jul 10 08:44:03.918: INFO: pod: "test-deployment-7c7d8d58c8-h7n6g":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-h7n6g test-deployment-7c7d8d58c8- deployment-8349  661b0e0d-7d7c-4187-a2fc-7fb1c44da337 86904 0 2023-07-10 08:43:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:f98579afcaa49b7e067298a7de6e1f306eaac39466d792fc423ffcd136eb81e3 cni.projectcalico.org/podIP:192.168.120.62/32 cni.projectcalico.org/podIPs:192.168.120.62/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 3a35420e-e2e1-45d7-b592-2f659eabd794 0xc003981e67 0xc003981e68}] [] [{kube-controller-manager Update v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a35420e-e2e1-45d7-b592-2f659eabd794\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 08:44:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 08:44:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29b8n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29b8n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:44:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 08:43:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.62,StartTime:2023-07-10 08:43:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 08:44:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://705114976b3e54df19305bde764fded3a608d21cc2002ebdb0e373727f30d42a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jul 10 08:44:03.918: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8349  6b73c714-cf4f-4574-87fa-87225149bdc3 86835 3 2023-07-10 08:43:55 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 19602775-5542-4297-90c5-2617dbcd1759 0xc003958d67 0xc003958d68}] [] [{kube-controller-manager Update apps/v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19602775-5542-4297-90c5-2617dbcd1759\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 08:43:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003958df0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 08:44:03.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8349" for this suite. 07/10/23 08:44:03.928
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:03.955
Jul 10 08:44:03.956: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename runtimeclass 07/10/23 08:44:03.957
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:04.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:04.033
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 07/10/23 08:44:04.037
STEP: getting /apis/node.k8s.io 07/10/23 08:44:04.039
STEP: getting /apis/node.k8s.io/v1 07/10/23 08:44:04.04
STEP: creating 07/10/23 08:44:04.041
STEP: watching 07/10/23 08:44:04.081
Jul 10 08:44:04.081: INFO: starting watch
STEP: getting 07/10/23 08:44:04.091
STEP: listing 07/10/23 08:44:04.094
STEP: patching 07/10/23 08:44:04.098
STEP: updating 07/10/23 08:44:04.106
Jul 10 08:44:04.113: INFO: waiting for watch events with expected annotations
STEP: deleting 07/10/23 08:44:04.113
STEP: deleting a collection 07/10/23 08:44:04.17
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jul 10 08:44:04.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5343" for this suite. 07/10/23 08:44:04.221
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":164,"skipped":3246,"failed":0}
------------------------------
• [0.275 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:03.955
    Jul 10 08:44:03.956: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename runtimeclass 07/10/23 08:44:03.957
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:04.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:04.033
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 07/10/23 08:44:04.037
    STEP: getting /apis/node.k8s.io 07/10/23 08:44:04.039
    STEP: getting /apis/node.k8s.io/v1 07/10/23 08:44:04.04
    STEP: creating 07/10/23 08:44:04.041
    STEP: watching 07/10/23 08:44:04.081
    Jul 10 08:44:04.081: INFO: starting watch
    STEP: getting 07/10/23 08:44:04.091
    STEP: listing 07/10/23 08:44:04.094
    STEP: patching 07/10/23 08:44:04.098
    STEP: updating 07/10/23 08:44:04.106
    Jul 10 08:44:04.113: INFO: waiting for watch events with expected annotations
    STEP: deleting 07/10/23 08:44:04.113
    STEP: deleting a collection 07/10/23 08:44:04.17
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jul 10 08:44:04.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5343" for this suite. 07/10/23 08:44:04.221
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:04.232
Jul 10 08:44:04.232: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:44:04.234
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:04.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:04.28
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:44:04.303
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:44:04.924
STEP: Deploying the webhook pod 07/10/23 08:44:04.935
STEP: Wait for the deployment to be ready 07/10/23 08:44:04.993
Jul 10 08:44:05.017: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 07/10/23 08:44:07.03
STEP: Verifying the service has paired with the endpoint 07/10/23 08:44:07.064
Jul 10 08:44:08.065: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 07/10/23 08:44:08.07
STEP: create a pod that should be updated by the webhook 07/10/23 08:44:08.092
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:44:08.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6218" for this suite. 07/10/23 08:44:08.152
STEP: Destroying namespace "webhook-6218-markers" for this suite. 07/10/23 08:44:08.162
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":165,"skipped":3250,"failed":0}
------------------------------
• [4.028 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:04.232
    Jul 10 08:44:04.232: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:44:04.234
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:04.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:04.28
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:44:04.303
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:44:04.924
    STEP: Deploying the webhook pod 07/10/23 08:44:04.935
    STEP: Wait for the deployment to be ready 07/10/23 08:44:04.993
    Jul 10 08:44:05.017: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 07/10/23 08:44:07.03
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:44:07.064
    Jul 10 08:44:08.065: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 07/10/23 08:44:08.07
    STEP: create a pod that should be updated by the webhook 07/10/23 08:44:08.092
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:44:08.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6218" for this suite. 07/10/23 08:44:08.152
    STEP: Destroying namespace "webhook-6218-markers" for this suite. 07/10/23 08:44:08.162
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:08.264
Jul 10 08:44:08.264: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:44:08.265
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:08.306
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:08.309
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-da27a12c-1b04-47f3-9b51-8731b4124a80 07/10/23 08:44:08.392
STEP: Creating a pod to test consume secrets 07/10/23 08:44:08.403
Jul 10 08:44:08.418: INFO: Waiting up to 5m0s for pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73" in namespace "secrets-475" to be "Succeeded or Failed"
Jul 10 08:44:08.422: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73": Phase="Pending", Reason="", readiness=false. Elapsed: 4.374466ms
Jul 10 08:44:10.428: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009784946s
Jul 10 08:44:12.428: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010640006s
STEP: Saw pod success 07/10/23 08:44:12.429
Jul 10 08:44:12.429: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73" satisfied condition "Succeeded or Failed"
Jul 10 08:44:12.433: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73 container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:44:12.455
Jul 10 08:44:12.476: INFO: Waiting for pod pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73 to disappear
Jul 10 08:44:12.479: INFO: Pod pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:44:12.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-475" for this suite. 07/10/23 08:44:12.484
STEP: Destroying namespace "secret-namespace-7997" for this suite. 07/10/23 08:44:12.493
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":166,"skipped":3295,"failed":0}
------------------------------
• [4.240 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:08.264
    Jul 10 08:44:08.264: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:44:08.265
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:08.306
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:08.309
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-da27a12c-1b04-47f3-9b51-8731b4124a80 07/10/23 08:44:08.392
    STEP: Creating a pod to test consume secrets 07/10/23 08:44:08.403
    Jul 10 08:44:08.418: INFO: Waiting up to 5m0s for pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73" in namespace "secrets-475" to be "Succeeded or Failed"
    Jul 10 08:44:08.422: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73": Phase="Pending", Reason="", readiness=false. Elapsed: 4.374466ms
    Jul 10 08:44:10.428: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009784946s
    Jul 10 08:44:12.428: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010640006s
    STEP: Saw pod success 07/10/23 08:44:12.429
    Jul 10 08:44:12.429: INFO: Pod "pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73" satisfied condition "Succeeded or Failed"
    Jul 10 08:44:12.433: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73 container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:44:12.455
    Jul 10 08:44:12.476: INFO: Waiting for pod pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73 to disappear
    Jul 10 08:44:12.479: INFO: Pod pod-secrets-dd4c996d-6e48-4cc1-9ce9-f0427e238b73 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:44:12.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-475" for this suite. 07/10/23 08:44:12.484
    STEP: Destroying namespace "secret-namespace-7997" for this suite. 07/10/23 08:44:12.493
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:12.504
Jul 10 08:44:12.505: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:44:12.505
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:12.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:12.537
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:44:12.539
Jul 10 08:44:12.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4" in namespace "projected-9247" to be "Succeeded or Failed"
Jul 10 08:44:12.561: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.537908ms
Jul 10 08:44:14.570: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013778371s
Jul 10 08:44:16.566: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0097125s
STEP: Saw pod success 07/10/23 08:44:16.566
Jul 10 08:44:16.566: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4" satisfied condition "Succeeded or Failed"
Jul 10 08:44:16.570: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4 container client-container: <nil>
STEP: delete the pod 07/10/23 08:44:16.579
Jul 10 08:44:16.603: INFO: Waiting for pod downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4 to disappear
Jul 10 08:44:16.607: INFO: Pod downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:44:16.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9247" for this suite. 07/10/23 08:44:16.618
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":167,"skipped":3295,"failed":0}
------------------------------
• [4.124 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:12.504
    Jul 10 08:44:12.505: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:44:12.505
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:12.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:12.537
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:44:12.539
    Jul 10 08:44:12.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4" in namespace "projected-9247" to be "Succeeded or Failed"
    Jul 10 08:44:12.561: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.537908ms
    Jul 10 08:44:14.570: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013778371s
    Jul 10 08:44:16.566: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0097125s
    STEP: Saw pod success 07/10/23 08:44:16.566
    Jul 10 08:44:16.566: INFO: Pod "downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4" satisfied condition "Succeeded or Failed"
    Jul 10 08:44:16.570: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4 container client-container: <nil>
    STEP: delete the pod 07/10/23 08:44:16.579
    Jul 10 08:44:16.603: INFO: Waiting for pod downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4 to disappear
    Jul 10 08:44:16.607: INFO: Pod downwardapi-volume-5ecc9065-1375-41a9-a1a4-fc81e98607c4 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:44:16.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9247" for this suite. 07/10/23 08:44:16.618
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:16.628
Jul 10 08:44:16.629: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename disruption 07/10/23 08:44:16.631
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:16.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:16.669
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 07/10/23 08:44:16.671
STEP: Waiting for the pdb to be processed 07/10/23 08:44:16.687
STEP: First trying to evict a pod which shouldn't be evictable 07/10/23 08:44:18.71
STEP: Waiting for all pods to be running 07/10/23 08:44:18.711
Jul 10 08:44:18.715: INFO: pods: 0 < 3
Jul 10 08:44:20.720: INFO: running pods: 2 < 3
STEP: locating a running pod 07/10/23 08:44:22.722
STEP: Updating the pdb to allow a pod to be evicted 07/10/23 08:44:22.733
STEP: Waiting for the pdb to be processed 07/10/23 08:44:22.745
STEP: Trying to evict the same pod we tried earlier which should now be evictable 07/10/23 08:44:24.753
STEP: Waiting for all pods to be running 07/10/23 08:44:24.754
STEP: Waiting for the pdb to observed all healthy pods 07/10/23 08:44:24.761
STEP: Patching the pdb to disallow a pod to be evicted 07/10/23 08:44:24.803
STEP: Waiting for the pdb to be processed 07/10/23 08:44:24.849
STEP: Waiting for all pods to be running 07/10/23 08:44:26.861
STEP: locating a running pod 07/10/23 08:44:26.865
STEP: Deleting the pdb to allow a pod to be evicted 07/10/23 08:44:26.879
STEP: Waiting for the pdb to be deleted 07/10/23 08:44:26.892
STEP: Trying to evict the same pod we tried earlier which should now be evictable 07/10/23 08:44:26.896
STEP: Waiting for all pods to be running 07/10/23 08:44:26.896
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jul 10 08:44:26.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-428" for this suite. 07/10/23 08:44:26.934
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":168,"skipped":3296,"failed":0}
------------------------------
• [SLOW TEST] [10.343 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:16.628
    Jul 10 08:44:16.629: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename disruption 07/10/23 08:44:16.631
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:16.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:16.669
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 07/10/23 08:44:16.671
    STEP: Waiting for the pdb to be processed 07/10/23 08:44:16.687
    STEP: First trying to evict a pod which shouldn't be evictable 07/10/23 08:44:18.71
    STEP: Waiting for all pods to be running 07/10/23 08:44:18.711
    Jul 10 08:44:18.715: INFO: pods: 0 < 3
    Jul 10 08:44:20.720: INFO: running pods: 2 < 3
    STEP: locating a running pod 07/10/23 08:44:22.722
    STEP: Updating the pdb to allow a pod to be evicted 07/10/23 08:44:22.733
    STEP: Waiting for the pdb to be processed 07/10/23 08:44:22.745
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 07/10/23 08:44:24.753
    STEP: Waiting for all pods to be running 07/10/23 08:44:24.754
    STEP: Waiting for the pdb to observed all healthy pods 07/10/23 08:44:24.761
    STEP: Patching the pdb to disallow a pod to be evicted 07/10/23 08:44:24.803
    STEP: Waiting for the pdb to be processed 07/10/23 08:44:24.849
    STEP: Waiting for all pods to be running 07/10/23 08:44:26.861
    STEP: locating a running pod 07/10/23 08:44:26.865
    STEP: Deleting the pdb to allow a pod to be evicted 07/10/23 08:44:26.879
    STEP: Waiting for the pdb to be deleted 07/10/23 08:44:26.892
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 07/10/23 08:44:26.896
    STEP: Waiting for all pods to be running 07/10/23 08:44:26.896
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jul 10 08:44:26.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-428" for this suite. 07/10/23 08:44:26.934
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:26.973
Jul 10 08:44:26.973: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:44:26.974
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:27.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:27.017
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-e50b5334-33b2-4649-9d8b-1483dc984ba0 07/10/23 08:44:27.021
STEP: Creating a pod to test consume secrets 07/10/23 08:44:27.033
Jul 10 08:44:27.051: INFO: Waiting up to 5m0s for pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338" in namespace "secrets-9852" to be "Succeeded or Failed"
Jul 10 08:44:27.055: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338": Phase="Pending", Reason="", readiness=false. Elapsed: 3.215059ms
Jul 10 08:44:29.060: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00828345s
Jul 10 08:44:31.061: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009449693s
STEP: Saw pod success 07/10/23 08:44:31.061
Jul 10 08:44:31.061: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338" satisfied condition "Succeeded or Failed"
Jul 10 08:44:31.071: INFO: Trying to get logs from node 10-62-109-101.test pod pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338 container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 08:44:31.09
Jul 10 08:44:31.108: INFO: Waiting for pod pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338 to disappear
Jul 10 08:44:31.112: INFO: Pod pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:44:31.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9852" for this suite. 07/10/23 08:44:31.12
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":169,"skipped":3326,"failed":0}
------------------------------
• [4.155 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:26.973
    Jul 10 08:44:26.973: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:44:26.974
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:27.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:27.017
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-e50b5334-33b2-4649-9d8b-1483dc984ba0 07/10/23 08:44:27.021
    STEP: Creating a pod to test consume secrets 07/10/23 08:44:27.033
    Jul 10 08:44:27.051: INFO: Waiting up to 5m0s for pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338" in namespace "secrets-9852" to be "Succeeded or Failed"
    Jul 10 08:44:27.055: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338": Phase="Pending", Reason="", readiness=false. Elapsed: 3.215059ms
    Jul 10 08:44:29.060: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00828345s
    Jul 10 08:44:31.061: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009449693s
    STEP: Saw pod success 07/10/23 08:44:31.061
    Jul 10 08:44:31.061: INFO: Pod "pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338" satisfied condition "Succeeded or Failed"
    Jul 10 08:44:31.071: INFO: Trying to get logs from node 10-62-109-101.test pod pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338 container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 08:44:31.09
    Jul 10 08:44:31.108: INFO: Waiting for pod pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338 to disappear
    Jul 10 08:44:31.112: INFO: Pod pod-secrets-32f799bd-dcf5-4eab-8351-917bfd68e338 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:44:31.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9852" for this suite. 07/10/23 08:44:31.12
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:31.13
Jul 10 08:44:31.130: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:44:31.131
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:31.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:31.167
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:44:31.169
Jul 10 08:44:31.183: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297" in namespace "projected-4676" to be "Succeeded or Failed"
Jul 10 08:44:31.190: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297": Phase="Pending", Reason="", readiness=false. Elapsed: 6.105706ms
Jul 10 08:44:33.194: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010703734s
Jul 10 08:44:35.195: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011174694s
STEP: Saw pod success 07/10/23 08:44:35.195
Jul 10 08:44:35.195: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297" satisfied condition "Succeeded or Failed"
Jul 10 08:44:35.198: INFO: Trying to get logs from node 10-62-109-101.test pod downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297 container client-container: <nil>
STEP: delete the pod 07/10/23 08:44:35.207
Jul 10 08:44:35.234: INFO: Waiting for pod downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297 to disappear
Jul 10 08:44:35.237: INFO: Pod downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:44:35.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4676" for this suite. 07/10/23 08:44:35.241
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":170,"skipped":3340,"failed":0}
------------------------------
• [4.121 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:31.13
    Jul 10 08:44:31.130: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:44:31.131
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:31.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:31.167
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:44:31.169
    Jul 10 08:44:31.183: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297" in namespace "projected-4676" to be "Succeeded or Failed"
    Jul 10 08:44:31.190: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297": Phase="Pending", Reason="", readiness=false. Elapsed: 6.105706ms
    Jul 10 08:44:33.194: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010703734s
    Jul 10 08:44:35.195: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011174694s
    STEP: Saw pod success 07/10/23 08:44:35.195
    Jul 10 08:44:35.195: INFO: Pod "downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297" satisfied condition "Succeeded or Failed"
    Jul 10 08:44:35.198: INFO: Trying to get logs from node 10-62-109-101.test pod downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297 container client-container: <nil>
    STEP: delete the pod 07/10/23 08:44:35.207
    Jul 10 08:44:35.234: INFO: Waiting for pod downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297 to disappear
    Jul 10 08:44:35.237: INFO: Pod downwardapi-volume-b0754c2b-7cf9-45a2-a8bf-f7bcb269b297 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:44:35.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4676" for this suite. 07/10/23 08:44:35.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:44:35.252
Jul 10 08:44:35.252: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename cronjob 07/10/23 08:44:35.253
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:35.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:35.284
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 07/10/23 08:44:35.286
STEP: Ensuring a job is scheduled 07/10/23 08:44:35.294
STEP: Ensuring exactly one is scheduled 07/10/23 08:45:01.301
STEP: Ensuring exactly one running job exists by listing jobs explicitly 07/10/23 08:45:01.331
STEP: Ensuring no more jobs are scheduled 07/10/23 08:45:01.34
STEP: Removing cronjob 07/10/23 08:50:01.35
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jul 10 08:50:01.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9860" for this suite. 07/10/23 08:50:01.371
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":171,"skipped":3380,"failed":0}
------------------------------
• [SLOW TEST] [326.128 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:44:35.252
    Jul 10 08:44:35.252: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename cronjob 07/10/23 08:44:35.253
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:44:35.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:44:35.284
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 07/10/23 08:44:35.286
    STEP: Ensuring a job is scheduled 07/10/23 08:44:35.294
    STEP: Ensuring exactly one is scheduled 07/10/23 08:45:01.301
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 07/10/23 08:45:01.331
    STEP: Ensuring no more jobs are scheduled 07/10/23 08:45:01.34
    STEP: Removing cronjob 07/10/23 08:50:01.35
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jul 10 08:50:01.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9860" for this suite. 07/10/23 08:50:01.371
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:01.383
Jul 10 08:50:01.383: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:50:01.385
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:01.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:01.464
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 07/10/23 08:50:01.466
STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:50:01.474
STEP: Creating a ResourceQuota with not terminating scope 07/10/23 08:50:03.479
STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:50:03.488
STEP: Creating a long running pod 07/10/23 08:50:05.494
STEP: Ensuring resource quota with not terminating scope captures the pod usage 07/10/23 08:50:05.558
STEP: Ensuring resource quota with terminating scope ignored the pod usage 07/10/23 08:50:07.564
STEP: Deleting the pod 07/10/23 08:50:09.57
STEP: Ensuring resource quota status released the pod usage 07/10/23 08:50:09.601
STEP: Creating a terminating pod 07/10/23 08:50:11.608
STEP: Ensuring resource quota with terminating scope captures the pod usage 07/10/23 08:50:11.629
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 07/10/23 08:50:13.634
STEP: Deleting the pod 07/10/23 08:50:15.639
STEP: Ensuring resource quota status released the pod usage 07/10/23 08:50:15.671
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:50:17.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8209" for this suite. 07/10/23 08:50:17.684
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":172,"skipped":3406,"failed":0}
------------------------------
• [SLOW TEST] [16.313 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:01.383
    Jul 10 08:50:01.383: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:50:01.385
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:01.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:01.464
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 07/10/23 08:50:01.466
    STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:50:01.474
    STEP: Creating a ResourceQuota with not terminating scope 07/10/23 08:50:03.479
    STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:50:03.488
    STEP: Creating a long running pod 07/10/23 08:50:05.494
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 07/10/23 08:50:05.558
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 07/10/23 08:50:07.564
    STEP: Deleting the pod 07/10/23 08:50:09.57
    STEP: Ensuring resource quota status released the pod usage 07/10/23 08:50:09.601
    STEP: Creating a terminating pod 07/10/23 08:50:11.608
    STEP: Ensuring resource quota with terminating scope captures the pod usage 07/10/23 08:50:11.629
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 07/10/23 08:50:13.634
    STEP: Deleting the pod 07/10/23 08:50:15.639
    STEP: Ensuring resource quota status released the pod usage 07/10/23 08:50:15.671
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:50:17.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8209" for this suite. 07/10/23 08:50:17.684
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:17.697
Jul 10 08:50:17.697: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:50:17.698
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:17.727
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:17.729
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-011d0517-9139-4f4b-be4b-9dd0806d1c63 07/10/23 08:50:17.737
STEP: Creating the pod 07/10/23 08:50:17.752
Jul 10 08:50:17.766: INFO: Waiting up to 5m0s for pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201" in namespace "configmap-6623" to be "running"
Jul 10 08:50:17.771: INFO: Pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201": Phase="Pending", Reason="", readiness=false. Elapsed: 5.785823ms
Jul 10 08:50:19.777: INFO: Pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201": Phase="Running", Reason="", readiness=false. Elapsed: 2.011157443s
Jul 10 08:50:19.777: INFO: Pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201" satisfied condition "running"
STEP: Waiting for pod with text data 07/10/23 08:50:19.777
STEP: Waiting for pod with binary data 07/10/23 08:50:19.793
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:50:19.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6623" for this suite. 07/10/23 08:50:19.808
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":173,"skipped":3410,"failed":0}
------------------------------
• [2.124 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:17.697
    Jul 10 08:50:17.697: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:50:17.698
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:17.727
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:17.729
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-011d0517-9139-4f4b-be4b-9dd0806d1c63 07/10/23 08:50:17.737
    STEP: Creating the pod 07/10/23 08:50:17.752
    Jul 10 08:50:17.766: INFO: Waiting up to 5m0s for pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201" in namespace "configmap-6623" to be "running"
    Jul 10 08:50:17.771: INFO: Pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201": Phase="Pending", Reason="", readiness=false. Elapsed: 5.785823ms
    Jul 10 08:50:19.777: INFO: Pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201": Phase="Running", Reason="", readiness=false. Elapsed: 2.011157443s
    Jul 10 08:50:19.777: INFO: Pod "pod-configmaps-4282fc49-5a9e-4265-b6b6-0c6c02da4201" satisfied condition "running"
    STEP: Waiting for pod with text data 07/10/23 08:50:19.777
    STEP: Waiting for pod with binary data 07/10/23 08:50:19.793
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:50:19.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6623" for this suite. 07/10/23 08:50:19.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:19.825
Jul 10 08:50:19.825: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename tables 07/10/23 08:50:19.826
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:19.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:19.858
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Jul 10 08:50:19.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2617" for this suite. 07/10/23 08:50:19.869
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":174,"skipped":3454,"failed":0}
------------------------------
• [0.054 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:19.825
    Jul 10 08:50:19.825: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename tables 07/10/23 08:50:19.826
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:19.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:19.858
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Jul 10 08:50:19.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-2617" for this suite. 07/10/23 08:50:19.869
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:19.88
Jul 10 08:50:19.880: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 08:50:19.881
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:19.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:19.927
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-8a3b5390-697d-4793-9e20-5ba3e42db492 07/10/23 08:50:19.93
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jul 10 08:50:19.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3541" for this suite. 07/10/23 08:50:19.936
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":175,"skipped":3458,"failed":0}
------------------------------
• [0.068 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:19.88
    Jul 10 08:50:19.880: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 08:50:19.881
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:19.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:19.927
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-8a3b5390-697d-4793-9e20-5ba3e42db492 07/10/23 08:50:19.93
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 08:50:19.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3541" for this suite. 07/10/23 08:50:19.936
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:19.949
Jul 10 08:50:19.949: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:50:19.95
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:19.989
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:19.997
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 07/10/23 08:50:20
STEP: Getting a ResourceQuota 07/10/23 08:50:20.008
STEP: Listing all ResourceQuotas with LabelSelector 07/10/23 08:50:20.011
STEP: Patching the ResourceQuota 07/10/23 08:50:20.056
STEP: Deleting a Collection of ResourceQuotas 07/10/23 08:50:20.072
STEP: Verifying the deleted ResourceQuota 07/10/23 08:50:20.097
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:50:20.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7845" for this suite. 07/10/23 08:50:20.105
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":176,"skipped":3473,"failed":0}
------------------------------
• [0.165 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:19.949
    Jul 10 08:50:19.949: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:50:19.95
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:19.989
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:19.997
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 07/10/23 08:50:20
    STEP: Getting a ResourceQuota 07/10/23 08:50:20.008
    STEP: Listing all ResourceQuotas with LabelSelector 07/10/23 08:50:20.011
    STEP: Patching the ResourceQuota 07/10/23 08:50:20.056
    STEP: Deleting a Collection of ResourceQuotas 07/10/23 08:50:20.072
    STEP: Verifying the deleted ResourceQuota 07/10/23 08:50:20.097
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:50:20.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7845" for this suite. 07/10/23 08:50:20.105
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:20.115
Jul 10 08:50:20.115: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:50:20.116
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:20.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:20.15
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-de6b52aa-c6ed-46e2-8cf9-0680d4265a93 07/10/23 08:50:20.152
STEP: Creating a pod to test consume configMaps 07/10/23 08:50:20.18
Jul 10 08:50:20.196: INFO: Waiting up to 5m0s for pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab" in namespace "configmap-6901" to be "Succeeded or Failed"
Jul 10 08:50:20.200: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Pending", Reason="", readiness=false. Elapsed: 3.738192ms
Jul 10 08:50:22.206: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009107696s
Jul 10 08:50:24.212: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015737113s
Jul 10 08:50:26.207: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010647393s
STEP: Saw pod success 07/10/23 08:50:26.207
Jul 10 08:50:26.207: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab" satisfied condition "Succeeded or Failed"
Jul 10 08:50:26.217: INFO: Trying to get logs from node 10-62-109-101.test pod pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:50:26.237
Jul 10 08:50:26.345: INFO: Waiting for pod pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab to disappear
Jul 10 08:50:26.348: INFO: Pod pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:50:26.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6901" for this suite. 07/10/23 08:50:26.353
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":177,"skipped":3485,"failed":0}
------------------------------
• [SLOW TEST] [6.250 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:20.115
    Jul 10 08:50:20.115: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:50:20.116
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:20.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:20.15
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-de6b52aa-c6ed-46e2-8cf9-0680d4265a93 07/10/23 08:50:20.152
    STEP: Creating a pod to test consume configMaps 07/10/23 08:50:20.18
    Jul 10 08:50:20.196: INFO: Waiting up to 5m0s for pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab" in namespace "configmap-6901" to be "Succeeded or Failed"
    Jul 10 08:50:20.200: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Pending", Reason="", readiness=false. Elapsed: 3.738192ms
    Jul 10 08:50:22.206: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009107696s
    Jul 10 08:50:24.212: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015737113s
    Jul 10 08:50:26.207: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010647393s
    STEP: Saw pod success 07/10/23 08:50:26.207
    Jul 10 08:50:26.207: INFO: Pod "pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab" satisfied condition "Succeeded or Failed"
    Jul 10 08:50:26.217: INFO: Trying to get logs from node 10-62-109-101.test pod pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:50:26.237
    Jul 10 08:50:26.345: INFO: Waiting for pod pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab to disappear
    Jul 10 08:50:26.348: INFO: Pod pod-configmaps-4476319a-c86e-4d4e-bbab-ec3788abffab no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:50:26.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6901" for this suite. 07/10/23 08:50:26.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:26.366
Jul 10 08:50:26.366: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 08:50:26.367
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:26.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:26.399
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 07/10/23 08:50:26.401
Jul 10 08:50:26.402: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 08:50:29.703: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:50:42.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6339" for this suite. 07/10/23 08:50:42.499
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":178,"skipped":3499,"failed":0}
------------------------------
• [SLOW TEST] [16.143 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:26.366
    Jul 10 08:50:26.366: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 08:50:26.367
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:26.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:26.399
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 07/10/23 08:50:26.401
    Jul 10 08:50:26.402: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 08:50:29.703: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:50:42.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6339" for this suite. 07/10/23 08:50:42.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:50:42.511
Jul 10 08:50:42.511: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 08:50:42.512
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:42.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:42.545
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 07/10/23 08:50:42.548
Jul 10 08:50:42.566: INFO: Waiting up to 2m0s for pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" in namespace "var-expansion-3337" to be "running"
Jul 10 08:50:42.572: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 5.441219ms
Jul 10 08:50:44.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011287289s
Jul 10 08:50:46.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012689101s
Jul 10 08:50:48.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011301214s
Jul 10 08:50:50.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012752879s
Jul 10 08:50:52.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012436666s
Jul 10 08:50:54.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009939292s
Jul 10 08:50:56.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 14.01160095s
Jul 10 08:50:58.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012236623s
Jul 10 08:51:00.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 18.011419359s
Jul 10 08:51:02.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 20.013485019s
Jul 10 08:51:04.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 22.012884937s
Jul 10 08:51:06.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 24.010936213s
Jul 10 08:51:08.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 26.013759577s
Jul 10 08:51:10.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 28.011518872s
Jul 10 08:51:12.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 30.011882385s
Jul 10 08:51:14.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 32.01010187s
Jul 10 08:51:16.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 34.012918575s
Jul 10 08:51:18.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 36.013581518s
Jul 10 08:51:20.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011870035s
Jul 10 08:51:22.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 40.012515598s
Jul 10 08:51:24.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011316489s
Jul 10 08:51:26.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 44.012243436s
Jul 10 08:51:28.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 46.012725673s
Jul 10 08:51:30.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 48.010818085s
Jul 10 08:51:32.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013054117s
Jul 10 08:51:34.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01195611s
Jul 10 08:51:36.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 54.012439284s
Jul 10 08:51:38.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 56.01273146s
Jul 10 08:51:40.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 58.010813306s
Jul 10 08:51:42.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.011027323s
Jul 10 08:51:44.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.01114919s
Jul 10 08:51:46.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.011909783s
Jul 10 08:51:48.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.012669972s
Jul 10 08:51:50.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.011233625s
Jul 10 08:51:52.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.013344413s
Jul 10 08:51:54.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.012638246s
Jul 10 08:51:56.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013647001s
Jul 10 08:51:58.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.011431448s
Jul 10 08:52:00.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.012474946s
Jul 10 08:52:02.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.012186692s
Jul 10 08:52:04.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.011082767s
Jul 10 08:52:06.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012384706s
Jul 10 08:52:08.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.012819549s
Jul 10 08:52:10.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010563657s
Jul 10 08:52:12.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013795569s
Jul 10 08:52:14.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.012099476s
Jul 10 08:52:16.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.011549326s
Jul 10 08:52:18.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.009983514s
Jul 10 08:52:20.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.013062845s
Jul 10 08:52:22.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.011768914s
Jul 10 08:52:24.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.011465249s
Jul 10 08:52:26.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.011607908s
Jul 10 08:52:28.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.011192516s
Jul 10 08:52:30.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.011909764s
Jul 10 08:52:32.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.012149116s
Jul 10 08:52:34.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.012034241s
Jul 10 08:52:36.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.014005628s
Jul 10 08:52:38.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.012766622s
Jul 10 08:52:40.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.010250196s
Jul 10 08:52:42.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.012139684s
Jul 10 08:52:42.584: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017356214s
STEP: updating the pod 07/10/23 08:52:42.584
Jul 10 08:52:43.112: INFO: Successfully updated pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168"
STEP: waiting for pod running 07/10/23 08:52:43.112
Jul 10 08:52:43.112: INFO: Waiting up to 2m0s for pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" in namespace "var-expansion-3337" to be "running"
Jul 10 08:52:43.117: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 4.789366ms
Jul 10 08:52:45.123: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Running", Reason="", readiness=true. Elapsed: 2.011103254s
Jul 10 08:52:45.123: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" satisfied condition "running"
STEP: deleting the pod gracefully 07/10/23 08:52:45.123
Jul 10 08:52:45.123: INFO: Deleting pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" in namespace "var-expansion-3337"
Jul 10 08:52:45.138: INFO: Wait up to 5m0s for pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 08:53:17.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3337" for this suite. 07/10/23 08:53:17.175
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":179,"skipped":3528,"failed":0}
------------------------------
• [SLOW TEST] [154.678 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:50:42.511
    Jul 10 08:50:42.511: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 08:50:42.512
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:50:42.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:50:42.545
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 07/10/23 08:50:42.548
    Jul 10 08:50:42.566: INFO: Waiting up to 2m0s for pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" in namespace "var-expansion-3337" to be "running"
    Jul 10 08:50:42.572: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 5.441219ms
    Jul 10 08:50:44.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011287289s
    Jul 10 08:50:46.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012689101s
    Jul 10 08:50:48.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011301214s
    Jul 10 08:50:50.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012752879s
    Jul 10 08:50:52.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012436666s
    Jul 10 08:50:54.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009939292s
    Jul 10 08:50:56.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 14.01160095s
    Jul 10 08:50:58.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012236623s
    Jul 10 08:51:00.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 18.011419359s
    Jul 10 08:51:02.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 20.013485019s
    Jul 10 08:51:04.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 22.012884937s
    Jul 10 08:51:06.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 24.010936213s
    Jul 10 08:51:08.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 26.013759577s
    Jul 10 08:51:10.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 28.011518872s
    Jul 10 08:51:12.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 30.011882385s
    Jul 10 08:51:14.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 32.01010187s
    Jul 10 08:51:16.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 34.012918575s
    Jul 10 08:51:18.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 36.013581518s
    Jul 10 08:51:20.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011870035s
    Jul 10 08:51:22.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 40.012515598s
    Jul 10 08:51:24.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011316489s
    Jul 10 08:51:26.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 44.012243436s
    Jul 10 08:51:28.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 46.012725673s
    Jul 10 08:51:30.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 48.010818085s
    Jul 10 08:51:32.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013054117s
    Jul 10 08:51:34.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01195611s
    Jul 10 08:51:36.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 54.012439284s
    Jul 10 08:51:38.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 56.01273146s
    Jul 10 08:51:40.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 58.010813306s
    Jul 10 08:51:42.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.011027323s
    Jul 10 08:51:44.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.01114919s
    Jul 10 08:51:46.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.011909783s
    Jul 10 08:51:48.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.012669972s
    Jul 10 08:51:50.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.011233625s
    Jul 10 08:51:52.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.013344413s
    Jul 10 08:51:54.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.012638246s
    Jul 10 08:51:56.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013647001s
    Jul 10 08:51:58.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.011431448s
    Jul 10 08:52:00.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.012474946s
    Jul 10 08:52:02.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.012186692s
    Jul 10 08:52:04.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.011082767s
    Jul 10 08:52:06.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012384706s
    Jul 10 08:52:08.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.012819549s
    Jul 10 08:52:10.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010563657s
    Jul 10 08:52:12.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013795569s
    Jul 10 08:52:14.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.012099476s
    Jul 10 08:52:16.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.011549326s
    Jul 10 08:52:18.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.009983514s
    Jul 10 08:52:20.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.013062845s
    Jul 10 08:52:22.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.011768914s
    Jul 10 08:52:24.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.011465249s
    Jul 10 08:52:26.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.011607908s
    Jul 10 08:52:28.577: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.011192516s
    Jul 10 08:52:30.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.011909764s
    Jul 10 08:52:32.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.012149116s
    Jul 10 08:52:34.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.012034241s
    Jul 10 08:52:36.580: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.014005628s
    Jul 10 08:52:38.579: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.012766622s
    Jul 10 08:52:40.576: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.010250196s
    Jul 10 08:52:42.578: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.012139684s
    Jul 10 08:52:42.584: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017356214s
    STEP: updating the pod 07/10/23 08:52:42.584
    Jul 10 08:52:43.112: INFO: Successfully updated pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168"
    STEP: waiting for pod running 07/10/23 08:52:43.112
    Jul 10 08:52:43.112: INFO: Waiting up to 2m0s for pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" in namespace "var-expansion-3337" to be "running"
    Jul 10 08:52:43.117: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Pending", Reason="", readiness=false. Elapsed: 4.789366ms
    Jul 10 08:52:45.123: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168": Phase="Running", Reason="", readiness=true. Elapsed: 2.011103254s
    Jul 10 08:52:45.123: INFO: Pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" satisfied condition "running"
    STEP: deleting the pod gracefully 07/10/23 08:52:45.123
    Jul 10 08:52:45.123: INFO: Deleting pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" in namespace "var-expansion-3337"
    Jul 10 08:52:45.138: INFO: Wait up to 5m0s for pod "var-expansion-ba1dd78c-62fe-4c61-ab8a-8cf2280ac168" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 08:53:17.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3337" for this suite. 07/10/23 08:53:17.175
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:17.19
Jul 10 08:53:17.190: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svcaccounts 07/10/23 08:53:17.191
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:17.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:17.22
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Jul 10 08:53:17.225: INFO: Got root ca configmap in namespace "svcaccounts-81"
Jul 10 08:53:17.238: INFO: Deleted root ca configmap in namespace "svcaccounts-81"
STEP: waiting for a new root ca configmap created 07/10/23 08:53:17.738
Jul 10 08:53:17.744: INFO: Recreated root ca configmap in namespace "svcaccounts-81"
Jul 10 08:53:17.809: INFO: Updated root ca configmap in namespace "svcaccounts-81"
STEP: waiting for the root ca configmap reconciled 07/10/23 08:53:18.31
Jul 10 08:53:18.315: INFO: Reconciled root ca configmap in namespace "svcaccounts-81"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jul 10 08:53:18.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-81" for this suite. 07/10/23 08:53:18.322
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":180,"skipped":3532,"failed":0}
------------------------------
• [1.150 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:17.19
    Jul 10 08:53:17.190: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svcaccounts 07/10/23 08:53:17.191
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:17.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:17.22
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Jul 10 08:53:17.225: INFO: Got root ca configmap in namespace "svcaccounts-81"
    Jul 10 08:53:17.238: INFO: Deleted root ca configmap in namespace "svcaccounts-81"
    STEP: waiting for a new root ca configmap created 07/10/23 08:53:17.738
    Jul 10 08:53:17.744: INFO: Recreated root ca configmap in namespace "svcaccounts-81"
    Jul 10 08:53:17.809: INFO: Updated root ca configmap in namespace "svcaccounts-81"
    STEP: waiting for the root ca configmap reconciled 07/10/23 08:53:18.31
    Jul 10 08:53:18.315: INFO: Reconciled root ca configmap in namespace "svcaccounts-81"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jul 10 08:53:18.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-81" for this suite. 07/10/23 08:53:18.322
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:18.34
Jul 10 08:53:18.340: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename podtemplate 07/10/23 08:53:18.341
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:18.357
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:18.36
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jul 10 08:53:18.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-770" for this suite. 07/10/23 08:53:18.458
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":181,"skipped":3534,"failed":0}
------------------------------
• [0.131 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:18.34
    Jul 10 08:53:18.340: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename podtemplate 07/10/23 08:53:18.341
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:18.357
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:18.36
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jul 10 08:53:18.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-770" for this suite. 07/10/23 08:53:18.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:18.473
Jul 10 08:53:18.473: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:53:18.474
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:18.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:18.506
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:53:18.533
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:53:19.118
STEP: Deploying the webhook pod 07/10/23 08:53:19.134
STEP: Wait for the deployment to be ready 07/10/23 08:53:19.167
Jul 10 08:53:19.186: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 07/10/23 08:53:21.223
STEP: Verifying the service has paired with the endpoint 07/10/23 08:53:21.246
Jul 10 08:53:22.246: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 07/10/23 08:53:22.25
STEP: create a namespace for the webhook 07/10/23 08:53:22.272
STEP: create a configmap should be unconditionally rejected by the webhook 07/10/23 08:53:22.307
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:53:22.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4276" for this suite. 07/10/23 08:53:22.349
STEP: Destroying namespace "webhook-4276-markers" for this suite. 07/10/23 08:53:22.366
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":182,"skipped":3574,"failed":0}
------------------------------
• [3.995 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:18.473
    Jul 10 08:53:18.473: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:53:18.474
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:18.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:18.506
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:53:18.533
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:53:19.118
    STEP: Deploying the webhook pod 07/10/23 08:53:19.134
    STEP: Wait for the deployment to be ready 07/10/23 08:53:19.167
    Jul 10 08:53:19.186: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 07/10/23 08:53:21.223
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:53:21.246
    Jul 10 08:53:22.246: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 07/10/23 08:53:22.25
    STEP: create a namespace for the webhook 07/10/23 08:53:22.272
    STEP: create a configmap should be unconditionally rejected by the webhook 07/10/23 08:53:22.307
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:53:22.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4276" for this suite. 07/10/23 08:53:22.349
    STEP: Destroying namespace "webhook-4276-markers" for this suite. 07/10/23 08:53:22.366
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:22.468
Jul 10 08:53:22.468: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 08:53:22.469
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:22.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:22.517
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 07/10/23 08:53:22.521
STEP: Wait for the Deployment to create new ReplicaSet 07/10/23 08:53:22.535
STEP: delete the deployment 07/10/23 08:53:23.048
STEP: wait for all rs to be garbage collected 07/10/23 08:53:23.061
STEP: expected 0 rs, got 1 rs 07/10/23 08:53:23.067
STEP: expected 0 pods, got 2 pods 07/10/23 08:53:23.074
STEP: Gathering metrics 07/10/23 08:53:23.592
W0710 08:53:23.600352      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul 10 08:53:23.600: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 08:53:23.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4484" for this suite. 07/10/23 08:53:23.607
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":183,"skipped":3574,"failed":0}
------------------------------
• [1.151 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:22.468
    Jul 10 08:53:22.468: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 08:53:22.469
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:22.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:22.517
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 07/10/23 08:53:22.521
    STEP: Wait for the Deployment to create new ReplicaSet 07/10/23 08:53:22.535
    STEP: delete the deployment 07/10/23 08:53:23.048
    STEP: wait for all rs to be garbage collected 07/10/23 08:53:23.061
    STEP: expected 0 rs, got 1 rs 07/10/23 08:53:23.067
    STEP: expected 0 pods, got 2 pods 07/10/23 08:53:23.074
    STEP: Gathering metrics 07/10/23 08:53:23.592
    W0710 08:53:23.600352      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jul 10 08:53:23.600: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 08:53:23.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4484" for this suite. 07/10/23 08:53:23.607
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:23.62
Jul 10 08:53:23.620: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename csistoragecapacity 07/10/23 08:53:23.621
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:23.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:23.664
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 07/10/23 08:53:23.666
STEP: getting /apis/storage.k8s.io 07/10/23 08:53:23.669
STEP: getting /apis/storage.k8s.io/v1 07/10/23 08:53:23.67
STEP: creating 07/10/23 08:53:23.671
STEP: watching 07/10/23 08:53:23.714
Jul 10 08:53:23.714: INFO: starting watch
STEP: getting 07/10/23 08:53:23.729
STEP: listing in namespace 07/10/23 08:53:23.731
STEP: listing across namespaces 07/10/23 08:53:23.742
STEP: patching 07/10/23 08:53:23.745
STEP: updating 07/10/23 08:53:23.757
Jul 10 08:53:23.786: INFO: waiting for watch events with expected annotations in namespace
Jul 10 08:53:23.787: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 07/10/23 08:53:23.787
STEP: deleting a collection 07/10/23 08:53:23.802
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Jul 10 08:53:23.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-3059" for this suite. 07/10/23 08:53:23.828
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":184,"skipped":3583,"failed":0}
------------------------------
• [0.217 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:23.62
    Jul 10 08:53:23.620: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename csistoragecapacity 07/10/23 08:53:23.621
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:23.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:23.664
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 07/10/23 08:53:23.666
    STEP: getting /apis/storage.k8s.io 07/10/23 08:53:23.669
    STEP: getting /apis/storage.k8s.io/v1 07/10/23 08:53:23.67
    STEP: creating 07/10/23 08:53:23.671
    STEP: watching 07/10/23 08:53:23.714
    Jul 10 08:53:23.714: INFO: starting watch
    STEP: getting 07/10/23 08:53:23.729
    STEP: listing in namespace 07/10/23 08:53:23.731
    STEP: listing across namespaces 07/10/23 08:53:23.742
    STEP: patching 07/10/23 08:53:23.745
    STEP: updating 07/10/23 08:53:23.757
    Jul 10 08:53:23.786: INFO: waiting for watch events with expected annotations in namespace
    Jul 10 08:53:23.787: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 07/10/23 08:53:23.787
    STEP: deleting a collection 07/10/23 08:53:23.802
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Jul 10 08:53:23.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-3059" for this suite. 07/10/23 08:53:23.828
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:23.838
Jul 10 08:53:23.838: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 08:53:23.839
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:23.865
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:23.868
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-1b84d586-42d1-4ae0-88c3-f88e345e034f 07/10/23 08:53:23.872
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 08:53:23.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-178" for this suite. 07/10/23 08:53:23.878
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":185,"skipped":3586,"failed":0}
------------------------------
• [0.051 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:23.838
    Jul 10 08:53:23.838: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 08:53:23.839
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:23.865
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:23.868
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-1b84d586-42d1-4ae0-88c3-f88e345e034f 07/10/23 08:53:23.872
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 08:53:23.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-178" for this suite. 07/10/23 08:53:23.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:53:23.89
Jul 10 08:53:23.890: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-preemption 07/10/23 08:53:23.891
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:23.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:23.93
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul 10 08:53:23.962: INFO: Waiting up to 1m0s for all nodes to be ready
Jul 10 08:54:23.999: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 07/10/23 08:54:24.004
Jul 10 08:54:24.042: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jul 10 08:54:24.059: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jul 10 08:54:24.099: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jul 10 08:54:24.128: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jul 10 08:54:24.179: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jul 10 08:54:24.191: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 07/10/23 08:54:24.191
Jul 10 08:54:24.191: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:24.198: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522675ms
Jul 10 08:54:26.205: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014257302s
Jul 10 08:54:28.202: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.011076517s
Jul 10 08:54:28.202: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Jul 10 08:54:28.202: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:28.206: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.22263ms
Jul 10 08:54:28.207: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:54:28.207: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:28.212: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.570076ms
Jul 10 08:54:30.218: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011794253s
Jul 10 08:54:32.219: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012577267s
Jul 10 08:54:34.218: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.011131552s
Jul 10 08:54:34.218: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:54:34.218: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:34.223: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.944169ms
Jul 10 08:54:34.223: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:54:34.223: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:34.226: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.35686ms
Jul 10 08:54:34.226: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Jul 10 08:54:34.226: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:34.230: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.643604ms
Jul 10 08:54:34.230: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 07/10/23 08:54:34.23
Jul 10 08:54:34.243: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-569" to be "running"
Jul 10 08:54:34.248: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.590268ms
Jul 10 08:54:36.254: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010892779s
Jul 10 08:54:38.254: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011039673s
Jul 10 08:54:38.254: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jul 10 08:54:38.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-569" for this suite. 07/10/23 08:54:38.292
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":186,"skipped":3609,"failed":0}
------------------------------
• [SLOW TEST] [74.481 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:53:23.89
    Jul 10 08:53:23.890: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-preemption 07/10/23 08:53:23.891
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:53:23.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:53:23.93
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jul 10 08:53:23.962: INFO: Waiting up to 1m0s for all nodes to be ready
    Jul 10 08:54:23.999: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 07/10/23 08:54:24.004
    Jul 10 08:54:24.042: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Jul 10 08:54:24.059: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Jul 10 08:54:24.099: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Jul 10 08:54:24.128: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Jul 10 08:54:24.179: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Jul 10 08:54:24.191: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 07/10/23 08:54:24.191
    Jul 10 08:54:24.191: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:24.198: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522675ms
    Jul 10 08:54:26.205: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014257302s
    Jul 10 08:54:28.202: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.011076517s
    Jul 10 08:54:28.202: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Jul 10 08:54:28.202: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:28.206: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.22263ms
    Jul 10 08:54:28.207: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:54:28.207: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:28.212: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.570076ms
    Jul 10 08:54:30.218: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011794253s
    Jul 10 08:54:32.219: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012577267s
    Jul 10 08:54:34.218: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.011131552s
    Jul 10 08:54:34.218: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:54:34.218: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:34.223: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.944169ms
    Jul 10 08:54:34.223: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:54:34.223: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:34.226: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.35686ms
    Jul 10 08:54:34.226: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Jul 10 08:54:34.226: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:34.230: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.643604ms
    Jul 10 08:54:34.230: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 07/10/23 08:54:34.23
    Jul 10 08:54:34.243: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-569" to be "running"
    Jul 10 08:54:34.248: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.590268ms
    Jul 10 08:54:36.254: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010892779s
    Jul 10 08:54:38.254: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011039673s
    Jul 10 08:54:38.254: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 08:54:38.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-569" for this suite. 07/10/23 08:54:38.292
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:54:38.371
Jul 10 08:54:38.371: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename security-context-test 07/10/23 08:54:38.372
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:38.39
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:38.393
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Jul 10 08:54:38.415: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2" in namespace "security-context-test-4564" to be "Succeeded or Failed"
Jul 10 08:54:38.420: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.702741ms
Jul 10 08:54:40.427: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011952651s
Jul 10 08:54:42.428: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012979989s
Jul 10 08:54:42.428: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2" satisfied condition "Succeeded or Failed"
Jul 10 08:54:42.449: INFO: Got logs for pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jul 10 08:54:42.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4564" for this suite. 07/10/23 08:54:42.454
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":187,"skipped":3611,"failed":0}
------------------------------
• [4.092 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:54:38.371
    Jul 10 08:54:38.371: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename security-context-test 07/10/23 08:54:38.372
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:38.39
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:38.393
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Jul 10 08:54:38.415: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2" in namespace "security-context-test-4564" to be "Succeeded or Failed"
    Jul 10 08:54:38.420: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.702741ms
    Jul 10 08:54:40.427: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011952651s
    Jul 10 08:54:42.428: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012979989s
    Jul 10 08:54:42.428: INFO: Pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2" satisfied condition "Succeeded or Failed"
    Jul 10 08:54:42.449: INFO: Got logs for pod "busybox-privileged-false-cfcdbba8-d4b3-445a-b242-6172334df1a2": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jul 10 08:54:42.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4564" for this suite. 07/10/23 08:54:42.454
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:54:42.464
Jul 10 08:54:42.464: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replicaset 07/10/23 08:54:42.465
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:42.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:42.508
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 07/10/23 08:54:42.511
Jul 10 08:54:42.521: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-3195" to be "running and ready"
Jul 10 08:54:42.526: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54515ms
Jul 10 08:54:42.526: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:54:44.531: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.009490479s
Jul 10 08:54:44.531: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Jul 10 08:54:44.531: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 07/10/23 08:54:44.534
STEP: Then the orphan pod is adopted 07/10/23 08:54:44.543
STEP: When the matched label of one of its pods change 07/10/23 08:54:45.574
Jul 10 08:54:45.587: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 07/10/23 08:54:45.61
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jul 10 08:54:45.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3195" for this suite. 07/10/23 08:54:45.655
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":188,"skipped":3623,"failed":0}
------------------------------
• [3.231 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:54:42.464
    Jul 10 08:54:42.464: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replicaset 07/10/23 08:54:42.465
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:42.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:42.508
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 07/10/23 08:54:42.511
    Jul 10 08:54:42.521: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-3195" to be "running and ready"
    Jul 10 08:54:42.526: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54515ms
    Jul 10 08:54:42.526: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:54:44.531: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.009490479s
    Jul 10 08:54:44.531: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Jul 10 08:54:44.531: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 07/10/23 08:54:44.534
    STEP: Then the orphan pod is adopted 07/10/23 08:54:44.543
    STEP: When the matched label of one of its pods change 07/10/23 08:54:45.574
    Jul 10 08:54:45.587: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 07/10/23 08:54:45.61
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jul 10 08:54:45.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3195" for this suite. 07/10/23 08:54:45.655
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:54:45.695
Jul 10 08:54:45.695: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:54:45.696
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:45.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:45.759
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Jul 10 08:54:45.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 create -f -'
Jul 10 08:54:46.499: INFO: stderr: ""
Jul 10 08:54:46.499: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Jul 10 08:54:46.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 create -f -'
Jul 10 08:54:46.760: INFO: stderr: ""
Jul 10 08:54:46.760: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 07/10/23 08:54:46.76
Jul 10 08:54:47.773: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:54:47.773: INFO: Found 0 / 1
Jul 10 08:54:48.767: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:54:48.767: INFO: Found 1 / 1
Jul 10 08:54:48.767: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 10 08:54:48.773: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:54:48.773: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 10 08:54:48.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe pod agnhost-primary-gtrfz'
Jul 10 08:54:48.856: INFO: stderr: ""
Jul 10 08:54:48.856: INFO: stdout: "Name:             agnhost-primary-gtrfz\nNamespace:        kubectl-7214\nPriority:         0\nService Account:  default\nNode:             10-62-109-101.test/10.62.109.101\nStart Time:       Mon, 10 Jul 2023 08:54:46 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 1684fc8ebfabb38d1751cb30f094836400bc68d1e67745955157649272146fe0\n                  cni.projectcalico.org/podIP: 192.168.103.127/32\n                  cni.projectcalico.org/podIPs: 192.168.103.127/32\nStatus:           Running\nIP:               192.168.103.127\nIPs:\n  IP:           192.168.103.127\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://1aebc77caecbfab4a9d8393388cac8bd997bdf3173374aa22c99f12744f7b41c\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 10 Jul 2023 08:54:47 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6z45t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-6z45t:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-7214/agnhost-primary-gtrfz to 10-62-109-101.test\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Jul 10 08:54:48.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe rc agnhost-primary'
Jul 10 08:54:48.942: INFO: stderr: ""
Jul 10 08:54:48.942: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-7214\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-gtrfz\n"
Jul 10 08:54:48.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe service agnhost-primary'
Jul 10 08:54:49.028: INFO: stderr: ""
Jul 10 08:54:49.028: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-7214\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                192.168.182.55\nIPs:               192.168.182.55\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.103.127:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul 10 08:54:49.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe node 10-62-109-100.test'
Jul 10 08:54:49.163: INFO: stderr: ""
Jul 10 08:54:49.163: INFO: stdout: "Name:               10-62-109-100.test\nRoles:              etcd,master,system,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10-62-109-100.test\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/etcd=yes\n                    node-role.kubernetes.io/master=yes\n                    node-role.kubernetes.io/system=yes\n                    node-role.kubernetes.io/worker=yes\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"nfs.csi.com\":\"10-62-109-100.test\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.62.109.100/23\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.172.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 10 Jul 2023 02:50:12 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10-62-109-100.test\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 10 Jul 2023 08:54:46 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 10 Jul 2023 07:24:22 +0000   Mon, 10 Jul 2023 07:24:22 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 02:50:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 02:50:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 02:50:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 03:00:10 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.62.109.100\n  Hostname:    10-62-109-100.test\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      98393808Ki\n  example.com/fakecpu:    1k\n  hugepages-2Mi:          0\n  memory:                 16387860Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      90679733303\n  example.com/fakecpu:    1k\n  hugepages-2Mi:          0\n  memory:                 16285460Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 ec2657014a354acbb2ff6f3219b544db\n  System UUID:                d787c7ec-645c-4967-8d32-ae1414b3f296\n  Boot ID:                    ec5c4d3a-3a79-467f-af30-ba1fdbec5aab\n  Kernel Version:             5.4.249-1.el7.elrepo.x86_64\n  OS Image:                   CentOS Linux 7 (Core)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.24\n  Kubelet Version:            v1.25.9\n  Kube-Proxy Version:         v1.25.9\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-5f46b455c5-gnpmg                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                 calico-node-r8w75                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         90m\n  kube-system                 csi-controller-75f447d67-cnjdb                             40m (1%)      4 (100%)    80Mi (0%)        1200Mi (7%)    87m\n  kube-system                 csi-node-8lwxr                                             20m (0%)      2 (50%)     40Mi (0%)        400Mi (2%)     4h59m\n  kube-system                 metrics-server-848cdbf678-6x7cs                            5m (0%)       1 (25%)     512Mi (3%)       2Gi (12%)      67m\n  replicaset-3195             pod-adoption-release                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         7s\n  replicaset-3195             pod-adoption-release-w4n87                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w    0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    315m (7%)   7 (175%)\n  memory                 632Mi (3%)  3648Mi (22%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  example.com/fakecpu    0           0\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type    Reason          Age   From             Message\n  ----    ------          ----  ----             -------\n  Normal  RegisteredNode  59m   node-controller  Node 10-62-109-100.test event: Registered Node 10-62-109-100.test in Controller\n  Normal  RegisteredNode  58m   node-controller  Node 10-62-109-100.test event: Registered Node 10-62-109-100.test in Controller\n"
Jul 10 08:54:49.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe namespace kubectl-7214'
Jul 10 08:54:49.252: INFO: stderr: ""
Jul 10 08:54:49.252: INFO: stdout: "Name:         kubectl-7214\nLabels:       e2e-framework=kubectl\n              e2e-run=feee08b5-d807-4939-9381-6d0e6aee29af\n              kubernetes.io/metadata.name=kubectl-7214\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:54:49.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7214" for this suite. 07/10/23 08:54:49.259
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":189,"skipped":3623,"failed":0}
------------------------------
• [3.576 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:54:45.695
    Jul 10 08:54:45.695: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:54:45.696
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:45.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:45.759
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Jul 10 08:54:45.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 create -f -'
    Jul 10 08:54:46.499: INFO: stderr: ""
    Jul 10 08:54:46.499: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Jul 10 08:54:46.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 create -f -'
    Jul 10 08:54:46.760: INFO: stderr: ""
    Jul 10 08:54:46.760: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 07/10/23 08:54:46.76
    Jul 10 08:54:47.773: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:54:47.773: INFO: Found 0 / 1
    Jul 10 08:54:48.767: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:54:48.767: INFO: Found 1 / 1
    Jul 10 08:54:48.767: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Jul 10 08:54:48.773: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:54:48.773: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jul 10 08:54:48.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe pod agnhost-primary-gtrfz'
    Jul 10 08:54:48.856: INFO: stderr: ""
    Jul 10 08:54:48.856: INFO: stdout: "Name:             agnhost-primary-gtrfz\nNamespace:        kubectl-7214\nPriority:         0\nService Account:  default\nNode:             10-62-109-101.test/10.62.109.101\nStart Time:       Mon, 10 Jul 2023 08:54:46 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 1684fc8ebfabb38d1751cb30f094836400bc68d1e67745955157649272146fe0\n                  cni.projectcalico.org/podIP: 192.168.103.127/32\n                  cni.projectcalico.org/podIPs: 192.168.103.127/32\nStatus:           Running\nIP:               192.168.103.127\nIPs:\n  IP:           192.168.103.127\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://1aebc77caecbfab4a9d8393388cac8bd997bdf3173374aa22c99f12744f7b41c\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 10 Jul 2023 08:54:47 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-6z45t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-6z45t:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-7214/agnhost-primary-gtrfz to 10-62-109-101.test\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Jul 10 08:54:48.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe rc agnhost-primary'
    Jul 10 08:54:48.942: INFO: stderr: ""
    Jul 10 08:54:48.942: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-7214\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-gtrfz\n"
    Jul 10 08:54:48.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe service agnhost-primary'
    Jul 10 08:54:49.028: INFO: stderr: ""
    Jul 10 08:54:49.028: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-7214\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                192.168.182.55\nIPs:               192.168.182.55\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.103.127:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Jul 10 08:54:49.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe node 10-62-109-100.test'
    Jul 10 08:54:49.163: INFO: stderr: ""
    Jul 10 08:54:49.163: INFO: stdout: "Name:               10-62-109-100.test\nRoles:              etcd,master,system,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10-62-109-100.test\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/etcd=yes\n                    node-role.kubernetes.io/master=yes\n                    node-role.kubernetes.io/system=yes\n                    node-role.kubernetes.io/worker=yes\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"nfs.csi.com\":\"10-62-109-100.test\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.62.109.100/23\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.172.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 10 Jul 2023 02:50:12 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10-62-109-100.test\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 10 Jul 2023 08:54:46 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 10 Jul 2023 07:24:22 +0000   Mon, 10 Jul 2023 07:24:22 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 02:50:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 02:50:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 02:50:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 10 Jul 2023 08:54:24 +0000   Mon, 10 Jul 2023 03:00:10 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.62.109.100\n  Hostname:    10-62-109-100.test\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      98393808Ki\n  example.com/fakecpu:    1k\n  hugepages-2Mi:          0\n  memory:                 16387860Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      90679733303\n  example.com/fakecpu:    1k\n  hugepages-2Mi:          0\n  memory:                 16285460Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 ec2657014a354acbb2ff6f3219b544db\n  System UUID:                d787c7ec-645c-4967-8d32-ae1414b3f296\n  Boot ID:                    ec5c4d3a-3a79-467f-af30-ba1fdbec5aab\n  Kernel Version:             5.4.249-1.el7.elrepo.x86_64\n  OS Image:                   CentOS Linux 7 (Core)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.24\n  Kubelet Version:            v1.25.9\n  Kube-Proxy Version:         v1.25.9\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-5f46b455c5-gnpmg                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                 calico-node-r8w75                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         90m\n  kube-system                 csi-controller-75f447d67-cnjdb                             40m (1%)      4 (100%)    80Mi (0%)        1200Mi (7%)    87m\n  kube-system                 csi-node-8lwxr                                             20m (0%)      2 (50%)     40Mi (0%)        400Mi (2%)     4h59m\n  kube-system                 metrics-server-848cdbf678-6x7cs                            5m (0%)       1 (25%)     512Mi (3%)       2Gi (12%)      67m\n  replicaset-3195             pod-adoption-release                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         7s\n  replicaset-3195             pod-adoption-release-w4n87                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w    0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    315m (7%)   7 (175%)\n  memory                 632Mi (3%)  3648Mi (22%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  example.com/fakecpu    0           0\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type    Reason          Age   From             Message\n  ----    ------          ----  ----             -------\n  Normal  RegisteredNode  59m   node-controller  Node 10-62-109-100.test event: Registered Node 10-62-109-100.test in Controller\n  Normal  RegisteredNode  58m   node-controller  Node 10-62-109-100.test event: Registered Node 10-62-109-100.test in Controller\n"
    Jul 10 08:54:49.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-7214 describe namespace kubectl-7214'
    Jul 10 08:54:49.252: INFO: stderr: ""
    Jul 10 08:54:49.252: INFO: stdout: "Name:         kubectl-7214\nLabels:       e2e-framework=kubectl\n              e2e-run=feee08b5-d807-4939-9381-6d0e6aee29af\n              kubernetes.io/metadata.name=kubectl-7214\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:54:49.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7214" for this suite. 07/10/23 08:54:49.259
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:54:49.271
Jul 10 08:54:49.271: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:54:49.272
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:49.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:49.307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:54:49.338
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:54:49.598
STEP: Deploying the webhook pod 07/10/23 08:54:49.612
STEP: Wait for the deployment to be ready 07/10/23 08:54:49.637
Jul 10 08:54:49.651: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jul 10 08:54:51.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 08:54:53.674
STEP: Verifying the service has paired with the endpoint 07/10/23 08:54:53.696
Jul 10 08:54:54.697: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 07/10/23 08:54:54.703
STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:54:54.728
STEP: Updating a validating webhook configuration's rules to not include the create operation 07/10/23 08:54:54.736
STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:54:54.755
STEP: Patching a validating webhook configuration's rules to include the create operation 07/10/23 08:54:54.775
STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:54:54.79
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:54:54.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1418" for this suite. 07/10/23 08:54:54.811
STEP: Destroying namespace "webhook-1418-markers" for this suite. 07/10/23 08:54:54.837
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":190,"skipped":3627,"failed":0}
------------------------------
• [SLOW TEST] [5.655 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:54:49.271
    Jul 10 08:54:49.271: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:54:49.272
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:49.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:49.307
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:54:49.338
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:54:49.598
    STEP: Deploying the webhook pod 07/10/23 08:54:49.612
    STEP: Wait for the deployment to be ready 07/10/23 08:54:49.637
    Jul 10 08:54:49.651: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jul 10 08:54:51.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 8, 54, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 08:54:53.674
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:54:53.696
    Jul 10 08:54:54.697: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 07/10/23 08:54:54.703
    STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:54:54.728
    STEP: Updating a validating webhook configuration's rules to not include the create operation 07/10/23 08:54:54.736
    STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:54:54.755
    STEP: Patching a validating webhook configuration's rules to include the create operation 07/10/23 08:54:54.775
    STEP: Creating a configMap that does not comply to the validation webhook rules 07/10/23 08:54:54.79
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:54:54.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1418" for this suite. 07/10/23 08:54:54.811
    STEP: Destroying namespace "webhook-1418-markers" for this suite. 07/10/23 08:54:54.837
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:54:54.93
Jul 10 08:54:54.930: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 08:54:54.931
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:54.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:54.973
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 07/10/23 08:54:54.976
Jul 10 08:54:54.976: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: rename a version 07/10/23 08:55:03.541
STEP: check the new version name is served 07/10/23 08:55:03.563
STEP: check the old version name is removed 07/10/23 08:55:06.179
STEP: check the other version is not changed 07/10/23 08:55:07.967
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:55:14.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6625" for this suite. 07/10/23 08:55:14.493
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":191,"skipped":3672,"failed":0}
------------------------------
• [SLOW TEST] [19.573 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:54:54.93
    Jul 10 08:54:54.930: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 08:54:54.931
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:54:54.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:54:54.973
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 07/10/23 08:54:54.976
    Jul 10 08:54:54.976: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: rename a version 07/10/23 08:55:03.541
    STEP: check the new version name is served 07/10/23 08:55:03.563
    STEP: check the old version name is removed 07/10/23 08:55:06.179
    STEP: check the other version is not changed 07/10/23 08:55:07.967
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:55:14.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6625" for this suite. 07/10/23 08:55:14.493
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:55:14.503
Jul 10 08:55:14.504: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename endpointslice 07/10/23 08:55:14.505
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:55:14.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:55:14.541
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Jul 10 08:55:14.554: INFO: Endpoints addresses: [10.62.109.100 10.62.109.101 10.62.109.102] , ports: [7443]
Jul 10 08:55:14.554: INFO: EndpointSlices addresses: [10.62.109.100 10.62.109.101 10.62.109.102] , ports: [7443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jul 10 08:55:14.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3412" for this suite. 07/10/23 08:55:14.558
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":192,"skipped":3682,"failed":0}
------------------------------
• [0.064 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:55:14.503
    Jul 10 08:55:14.504: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename endpointslice 07/10/23 08:55:14.505
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:55:14.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:55:14.541
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Jul 10 08:55:14.554: INFO: Endpoints addresses: [10.62.109.100 10.62.109.101 10.62.109.102] , ports: [7443]
    Jul 10 08:55:14.554: INFO: EndpointSlices addresses: [10.62.109.100 10.62.109.101 10.62.109.102] , ports: [7443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jul 10 08:55:14.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-3412" for this suite. 07/10/23 08:55:14.558
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:55:14.568
Jul 10 08:55:14.568: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir-wrapper 07/10/23 08:55:14.569
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:55:14.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:55:14.6
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 07/10/23 08:55:14.602
STEP: Creating RC which spawns configmap-volume pods 07/10/23 08:55:15.018
Jul 10 08:55:15.048: INFO: Pod name wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0: Found 0 pods out of 5
Jul 10 08:55:20.056: INFO: Pod name wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0: Found 5 pods out of 5
STEP: Ensuring each pod is running 07/10/23 08:55:20.056
Jul 10 08:55:20.056: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:20.060: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210192ms
Jul 10 08:55:22.067: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010565168s
Jul 10 08:55:24.068: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011430218s
Jul 10 08:55:26.065: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009251691s
Jul 10 08:55:28.069: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012752266s
Jul 10 08:55:30.067: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Running", Reason="", readiness=true. Elapsed: 10.010432386s
Jul 10 08:55:30.067: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc" satisfied condition "running"
Jul 10 08:55:30.067: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-hr267" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:30.071: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-hr267": Phase="Running", Reason="", readiness=true. Elapsed: 4.413786ms
Jul 10 08:55:30.071: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-hr267" satisfied condition "running"
Jul 10 08:55:30.071: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-thgmp" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:30.076: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-thgmp": Phase="Running", Reason="", readiness=true. Elapsed: 4.646089ms
Jul 10 08:55:30.076: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-thgmp" satisfied condition "running"
Jul 10 08:55:30.076: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-v6kbm" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:30.080: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-v6kbm": Phase="Running", Reason="", readiness=true. Elapsed: 4.098241ms
Jul 10 08:55:30.080: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-v6kbm" satisfied condition "running"
Jul 10 08:55:30.080: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-xvhnw" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:30.089: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-xvhnw": Phase="Running", Reason="", readiness=true. Elapsed: 9.289872ms
Jul 10 08:55:30.089: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-xvhnw" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0 in namespace emptydir-wrapper-1450, will wait for the garbage collector to delete the pods 07/10/23 08:55:30.089
Jul 10 08:55:30.165: INFO: Deleting ReplicationController wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0 took: 11.631336ms
Jul 10 08:55:30.265: INFO: Terminating ReplicationController wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0 pods took: 100.403302ms
STEP: Creating RC which spawns configmap-volume pods 07/10/23 08:55:34.273
Jul 10 08:55:34.292: INFO: Pod name wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba: Found 0 pods out of 5
Jul 10 08:55:39.301: INFO: Pod name wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba: Found 5 pods out of 5
STEP: Ensuring each pod is running 07/10/23 08:55:39.301
Jul 10 08:55:39.301: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:39.307: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.533976ms
Jul 10 08:55:41.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013178705s
Jul 10 08:55:43.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012779434s
Jul 10 08:55:45.313: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01247485s
Jul 10 08:55:47.317: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015753539s
Jul 10 08:55:49.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Running", Reason="", readiness=true. Elapsed: 10.012987712s
Jul 10 08:55:49.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn" satisfied condition "running"
Jul 10 08:55:49.314: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-9bwtk" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:49.319: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-9bwtk": Phase="Running", Reason="", readiness=true. Elapsed: 5.037942ms
Jul 10 08:55:49.319: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-9bwtk" satisfied condition "running"
Jul 10 08:55:49.319: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-bsdt7" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:49.324: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-bsdt7": Phase="Running", Reason="", readiness=true. Elapsed: 5.034258ms
Jul 10 08:55:49.324: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-bsdt7" satisfied condition "running"
Jul 10 08:55:49.324: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-cgh98" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:49.329: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-cgh98": Phase="Running", Reason="", readiness=true. Elapsed: 5.128364ms
Jul 10 08:55:49.329: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-cgh98" satisfied condition "running"
Jul 10 08:55:49.329: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-kcrwf" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:49.334: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-kcrwf": Phase="Running", Reason="", readiness=true. Elapsed: 4.762749ms
Jul 10 08:55:49.334: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-kcrwf" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba in namespace emptydir-wrapper-1450, will wait for the garbage collector to delete the pods 07/10/23 08:55:49.334
Jul 10 08:55:49.405: INFO: Deleting ReplicationController wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba took: 13.572811ms
Jul 10 08:55:49.505: INFO: Terminating ReplicationController wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba pods took: 100.52999ms
STEP: Creating RC which spawns configmap-volume pods 07/10/23 08:55:53.715
Jul 10 08:55:53.742: INFO: Pod name wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99: Found 0 pods out of 5
Jul 10 08:55:58.767: INFO: Pod name wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99: Found 5 pods out of 5
STEP: Ensuring each pod is running 07/10/23 08:55:58.767
Jul 10 08:55:58.767: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:55:58.772: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230108ms
Jul 10 08:56:00.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010739104s
Jul 10 08:56:02.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010269728s
Jul 10 08:56:04.777: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009456845s
Jul 10 08:56:06.777: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009563233s
Jul 10 08:56:08.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Running", Reason="", readiness=true. Elapsed: 10.010957841s
Jul 10 08:56:08.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc" satisfied condition "running"
Jul 10 08:56:08.778: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-8zds8" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:56:08.783: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-8zds8": Phase="Running", Reason="", readiness=true. Elapsed: 4.818505ms
Jul 10 08:56:08.783: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-8zds8" satisfied condition "running"
Jul 10 08:56:08.783: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-lnsfs" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:56:08.787: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-lnsfs": Phase="Running", Reason="", readiness=true. Elapsed: 4.217444ms
Jul 10 08:56:08.788: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-lnsfs" satisfied condition "running"
Jul 10 08:56:08.788: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-nd952" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:56:08.802: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-nd952": Phase="Running", Reason="", readiness=true. Elapsed: 14.761739ms
Jul 10 08:56:08.802: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-nd952" satisfied condition "running"
Jul 10 08:56:08.802: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-qwcn8" in namespace "emptydir-wrapper-1450" to be "running"
Jul 10 08:56:08.806: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-qwcn8": Phase="Running", Reason="", readiness=true. Elapsed: 3.719509ms
Jul 10 08:56:08.806: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-qwcn8" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99 in namespace emptydir-wrapper-1450, will wait for the garbage collector to delete the pods 07/10/23 08:56:08.806
Jul 10 08:56:08.876: INFO: Deleting ReplicationController wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99 took: 15.20404ms
Jul 10 08:56:08.977: INFO: Terminating ReplicationController wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99 pods took: 100.338867ms
STEP: Cleaning up the configMaps 07/10/23 08:56:13.277
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Jul 10 08:56:13.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1450" for this suite. 07/10/23 08:56:13.854
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":193,"skipped":3692,"failed":0}
------------------------------
• [SLOW TEST] [59.295 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:55:14.568
    Jul 10 08:55:14.568: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir-wrapper 07/10/23 08:55:14.569
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:55:14.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:55:14.6
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 07/10/23 08:55:14.602
    STEP: Creating RC which spawns configmap-volume pods 07/10/23 08:55:15.018
    Jul 10 08:55:15.048: INFO: Pod name wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0: Found 0 pods out of 5
    Jul 10 08:55:20.056: INFO: Pod name wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0: Found 5 pods out of 5
    STEP: Ensuring each pod is running 07/10/23 08:55:20.056
    Jul 10 08:55:20.056: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:20.060: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210192ms
    Jul 10 08:55:22.067: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010565168s
    Jul 10 08:55:24.068: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011430218s
    Jul 10 08:55:26.065: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009251691s
    Jul 10 08:55:28.069: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012752266s
    Jul 10 08:55:30.067: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc": Phase="Running", Reason="", readiness=true. Elapsed: 10.010432386s
    Jul 10 08:55:30.067: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-9xlqc" satisfied condition "running"
    Jul 10 08:55:30.067: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-hr267" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:30.071: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-hr267": Phase="Running", Reason="", readiness=true. Elapsed: 4.413786ms
    Jul 10 08:55:30.071: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-hr267" satisfied condition "running"
    Jul 10 08:55:30.071: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-thgmp" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:30.076: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-thgmp": Phase="Running", Reason="", readiness=true. Elapsed: 4.646089ms
    Jul 10 08:55:30.076: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-thgmp" satisfied condition "running"
    Jul 10 08:55:30.076: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-v6kbm" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:30.080: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-v6kbm": Phase="Running", Reason="", readiness=true. Elapsed: 4.098241ms
    Jul 10 08:55:30.080: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-v6kbm" satisfied condition "running"
    Jul 10 08:55:30.080: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-xvhnw" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:30.089: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-xvhnw": Phase="Running", Reason="", readiness=true. Elapsed: 9.289872ms
    Jul 10 08:55:30.089: INFO: Pod "wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0-xvhnw" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0 in namespace emptydir-wrapper-1450, will wait for the garbage collector to delete the pods 07/10/23 08:55:30.089
    Jul 10 08:55:30.165: INFO: Deleting ReplicationController wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0 took: 11.631336ms
    Jul 10 08:55:30.265: INFO: Terminating ReplicationController wrapped-volume-race-0201ab87-da83-44c1-b49f-38d9e0c00af0 pods took: 100.403302ms
    STEP: Creating RC which spawns configmap-volume pods 07/10/23 08:55:34.273
    Jul 10 08:55:34.292: INFO: Pod name wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba: Found 0 pods out of 5
    Jul 10 08:55:39.301: INFO: Pod name wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba: Found 5 pods out of 5
    STEP: Ensuring each pod is running 07/10/23 08:55:39.301
    Jul 10 08:55:39.301: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:39.307: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.533976ms
    Jul 10 08:55:41.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013178705s
    Jul 10 08:55:43.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012779434s
    Jul 10 08:55:45.313: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01247485s
    Jul 10 08:55:47.317: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015753539s
    Jul 10 08:55:49.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn": Phase="Running", Reason="", readiness=true. Elapsed: 10.012987712s
    Jul 10 08:55:49.314: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-5pssn" satisfied condition "running"
    Jul 10 08:55:49.314: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-9bwtk" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:49.319: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-9bwtk": Phase="Running", Reason="", readiness=true. Elapsed: 5.037942ms
    Jul 10 08:55:49.319: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-9bwtk" satisfied condition "running"
    Jul 10 08:55:49.319: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-bsdt7" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:49.324: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-bsdt7": Phase="Running", Reason="", readiness=true. Elapsed: 5.034258ms
    Jul 10 08:55:49.324: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-bsdt7" satisfied condition "running"
    Jul 10 08:55:49.324: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-cgh98" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:49.329: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-cgh98": Phase="Running", Reason="", readiness=true. Elapsed: 5.128364ms
    Jul 10 08:55:49.329: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-cgh98" satisfied condition "running"
    Jul 10 08:55:49.329: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-kcrwf" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:49.334: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-kcrwf": Phase="Running", Reason="", readiness=true. Elapsed: 4.762749ms
    Jul 10 08:55:49.334: INFO: Pod "wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba-kcrwf" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba in namespace emptydir-wrapper-1450, will wait for the garbage collector to delete the pods 07/10/23 08:55:49.334
    Jul 10 08:55:49.405: INFO: Deleting ReplicationController wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba took: 13.572811ms
    Jul 10 08:55:49.505: INFO: Terminating ReplicationController wrapped-volume-race-dbccefdc-751d-4354-a9e2-16ccd484b7ba pods took: 100.52999ms
    STEP: Creating RC which spawns configmap-volume pods 07/10/23 08:55:53.715
    Jul 10 08:55:53.742: INFO: Pod name wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99: Found 0 pods out of 5
    Jul 10 08:55:58.767: INFO: Pod name wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99: Found 5 pods out of 5
    STEP: Ensuring each pod is running 07/10/23 08:55:58.767
    Jul 10 08:55:58.767: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:55:58.772: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230108ms
    Jul 10 08:56:00.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010739104s
    Jul 10 08:56:02.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010269728s
    Jul 10 08:56:04.777: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009456845s
    Jul 10 08:56:06.777: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009563233s
    Jul 10 08:56:08.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc": Phase="Running", Reason="", readiness=true. Elapsed: 10.010957841s
    Jul 10 08:56:08.778: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-4xwjc" satisfied condition "running"
    Jul 10 08:56:08.778: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-8zds8" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:56:08.783: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-8zds8": Phase="Running", Reason="", readiness=true. Elapsed: 4.818505ms
    Jul 10 08:56:08.783: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-8zds8" satisfied condition "running"
    Jul 10 08:56:08.783: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-lnsfs" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:56:08.787: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-lnsfs": Phase="Running", Reason="", readiness=true. Elapsed: 4.217444ms
    Jul 10 08:56:08.788: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-lnsfs" satisfied condition "running"
    Jul 10 08:56:08.788: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-nd952" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:56:08.802: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-nd952": Phase="Running", Reason="", readiness=true. Elapsed: 14.761739ms
    Jul 10 08:56:08.802: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-nd952" satisfied condition "running"
    Jul 10 08:56:08.802: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-qwcn8" in namespace "emptydir-wrapper-1450" to be "running"
    Jul 10 08:56:08.806: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-qwcn8": Phase="Running", Reason="", readiness=true. Elapsed: 3.719509ms
    Jul 10 08:56:08.806: INFO: Pod "wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99-qwcn8" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99 in namespace emptydir-wrapper-1450, will wait for the garbage collector to delete the pods 07/10/23 08:56:08.806
    Jul 10 08:56:08.876: INFO: Deleting ReplicationController wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99 took: 15.20404ms
    Jul 10 08:56:08.977: INFO: Terminating ReplicationController wrapped-volume-race-6de4b4ff-fad0-4f3a-a188-34ce94650c99 pods took: 100.338867ms
    STEP: Cleaning up the configMaps 07/10/23 08:56:13.277
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:56:13.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-1450" for this suite. 07/10/23 08:56:13.854
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:56:13.867
Jul 10 08:56:13.867: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 08:56:13.868
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:13.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:13.902
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 07/10/23 08:56:13.905
Jul 10 08:56:13.917: INFO: Waiting up to 5m0s for pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327" in namespace "var-expansion-3024" to be "Succeeded or Failed"
Jul 10 08:56:13.925: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327": Phase="Pending", Reason="", readiness=false. Elapsed: 8.541954ms
Jul 10 08:56:15.932: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014983833s
Jul 10 08:56:17.934: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016606545s
STEP: Saw pod success 07/10/23 08:56:17.934
Jul 10 08:56:17.934: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327" satisfied condition "Succeeded or Failed"
Jul 10 08:56:17.938: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-50b32079-3c32-4709-a076-4466f2389327 container dapi-container: <nil>
STEP: delete the pod 07/10/23 08:56:17.954
Jul 10 08:56:17.986: INFO: Waiting for pod var-expansion-50b32079-3c32-4709-a076-4466f2389327 to disappear
Jul 10 08:56:17.991: INFO: Pod var-expansion-50b32079-3c32-4709-a076-4466f2389327 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 08:56:17.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3024" for this suite. 07/10/23 08:56:17.996
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":194,"skipped":3713,"failed":0}
------------------------------
• [4.144 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:56:13.867
    Jul 10 08:56:13.867: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 08:56:13.868
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:13.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:13.902
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 07/10/23 08:56:13.905
    Jul 10 08:56:13.917: INFO: Waiting up to 5m0s for pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327" in namespace "var-expansion-3024" to be "Succeeded or Failed"
    Jul 10 08:56:13.925: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327": Phase="Pending", Reason="", readiness=false. Elapsed: 8.541954ms
    Jul 10 08:56:15.932: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014983833s
    Jul 10 08:56:17.934: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016606545s
    STEP: Saw pod success 07/10/23 08:56:17.934
    Jul 10 08:56:17.934: INFO: Pod "var-expansion-50b32079-3c32-4709-a076-4466f2389327" satisfied condition "Succeeded or Failed"
    Jul 10 08:56:17.938: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-50b32079-3c32-4709-a076-4466f2389327 container dapi-container: <nil>
    STEP: delete the pod 07/10/23 08:56:17.954
    Jul 10 08:56:17.986: INFO: Waiting for pod var-expansion-50b32079-3c32-4709-a076-4466f2389327 to disappear
    Jul 10 08:56:17.991: INFO: Pod var-expansion-50b32079-3c32-4709-a076-4466f2389327 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 08:56:17.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3024" for this suite. 07/10/23 08:56:17.996
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:56:18.011
Jul 10 08:56:18.011: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:56:18.012
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:18.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:18.045
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 07/10/23 08:56:18.048
Jul 10 08:56:18.048: INFO: namespace kubectl-113
Jul 10 08:56:18.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 create -f -'
Jul 10 08:56:18.677: INFO: stderr: ""
Jul 10 08:56:18.677: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 07/10/23 08:56:18.677
Jul 10 08:56:19.684: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:56:19.684: INFO: Found 0 / 1
Jul 10 08:56:20.681: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:56:20.681: INFO: Found 1 / 1
Jul 10 08:56:20.681: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 10 08:56:20.684: INFO: Selector matched 1 pods for map[app:agnhost]
Jul 10 08:56:20.684: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 10 08:56:20.684: INFO: wait on agnhost-primary startup in kubectl-113 
Jul 10 08:56:20.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 logs agnhost-primary-bx48m agnhost-primary'
Jul 10 08:56:20.778: INFO: stderr: ""
Jul 10 08:56:20.779: INFO: stdout: "Paused\n"
STEP: exposing RC 07/10/23 08:56:20.779
Jul 10 08:56:20.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Jul 10 08:56:20.882: INFO: stderr: ""
Jul 10 08:56:20.882: INFO: stdout: "service/rm2 exposed\n"
Jul 10 08:56:20.891: INFO: Service rm2 in namespace kubectl-113 found.
STEP: exposing service 07/10/23 08:56:22.9
Jul 10 08:56:22.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Jul 10 08:56:22.997: INFO: stderr: ""
Jul 10 08:56:22.997: INFO: stdout: "service/rm3 exposed\n"
Jul 10 08:56:23.002: INFO: Service rm3 in namespace kubectl-113 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:56:25.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-113" for this suite. 07/10/23 08:56:25.015
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":195,"skipped":3714,"failed":0}
------------------------------
• [SLOW TEST] [7.015 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:56:18.011
    Jul 10 08:56:18.011: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:56:18.012
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:18.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:18.045
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 07/10/23 08:56:18.048
    Jul 10 08:56:18.048: INFO: namespace kubectl-113
    Jul 10 08:56:18.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 create -f -'
    Jul 10 08:56:18.677: INFO: stderr: ""
    Jul 10 08:56:18.677: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 07/10/23 08:56:18.677
    Jul 10 08:56:19.684: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:56:19.684: INFO: Found 0 / 1
    Jul 10 08:56:20.681: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:56:20.681: INFO: Found 1 / 1
    Jul 10 08:56:20.681: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Jul 10 08:56:20.684: INFO: Selector matched 1 pods for map[app:agnhost]
    Jul 10 08:56:20.684: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jul 10 08:56:20.684: INFO: wait on agnhost-primary startup in kubectl-113 
    Jul 10 08:56:20.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 logs agnhost-primary-bx48m agnhost-primary'
    Jul 10 08:56:20.778: INFO: stderr: ""
    Jul 10 08:56:20.779: INFO: stdout: "Paused\n"
    STEP: exposing RC 07/10/23 08:56:20.779
    Jul 10 08:56:20.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Jul 10 08:56:20.882: INFO: stderr: ""
    Jul 10 08:56:20.882: INFO: stdout: "service/rm2 exposed\n"
    Jul 10 08:56:20.891: INFO: Service rm2 in namespace kubectl-113 found.
    STEP: exposing service 07/10/23 08:56:22.9
    Jul 10 08:56:22.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-113 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Jul 10 08:56:22.997: INFO: stderr: ""
    Jul 10 08:56:22.997: INFO: stdout: "service/rm3 exposed\n"
    Jul 10 08:56:23.002: INFO: Service rm3 in namespace kubectl-113 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:56:25.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-113" for this suite. 07/10/23 08:56:25.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:56:25.028
Jul 10 08:56:25.028: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:56:25.029
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:25.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:25.06
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 07/10/23 08:56:25.062
STEP: Creating a ResourceQuota 07/10/23 08:56:30.067
STEP: Ensuring resource quota status is calculated 07/10/23 08:56:30.077
STEP: Creating a Pod that fits quota 07/10/23 08:56:32.083
STEP: Ensuring ResourceQuota status captures the pod usage 07/10/23 08:56:32.113
STEP: Not allowing a pod to be created that exceeds remaining quota 07/10/23 08:56:34.12
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 07/10/23 08:56:34.122
STEP: Ensuring a pod cannot update its resource requirements 07/10/23 08:56:34.124
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 07/10/23 08:56:34.13
STEP: Deleting the pod 07/10/23 08:56:36.136
STEP: Ensuring resource quota status released the pod usage 07/10/23 08:56:36.166
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:56:38.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3978" for this suite. 07/10/23 08:56:38.179
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":196,"skipped":3760,"failed":0}
------------------------------
• [SLOW TEST] [13.160 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:56:25.028
    Jul 10 08:56:25.028: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:56:25.029
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:25.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:25.06
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 07/10/23 08:56:25.062
    STEP: Creating a ResourceQuota 07/10/23 08:56:30.067
    STEP: Ensuring resource quota status is calculated 07/10/23 08:56:30.077
    STEP: Creating a Pod that fits quota 07/10/23 08:56:32.083
    STEP: Ensuring ResourceQuota status captures the pod usage 07/10/23 08:56:32.113
    STEP: Not allowing a pod to be created that exceeds remaining quota 07/10/23 08:56:34.12
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 07/10/23 08:56:34.122
    STEP: Ensuring a pod cannot update its resource requirements 07/10/23 08:56:34.124
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 07/10/23 08:56:34.13
    STEP: Deleting the pod 07/10/23 08:56:36.136
    STEP: Ensuring resource quota status released the pod usage 07/10/23 08:56:36.166
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:56:38.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3978" for this suite. 07/10/23 08:56:38.179
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:56:38.188
Jul 10 08:56:38.188: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 08:56:38.189
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:38.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:38.228
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 07/10/23 08:56:38.23
STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:56:38.248
STEP: Creating a ResourceQuota with not best effort scope 07/10/23 08:56:40.253
STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:56:40.261
STEP: Creating a best-effort pod 07/10/23 08:56:42.267
STEP: Ensuring resource quota with best effort scope captures the pod usage 07/10/23 08:56:42.291
STEP: Ensuring resource quota with not best effort ignored the pod usage 07/10/23 08:56:44.297
STEP: Deleting the pod 07/10/23 08:56:46.303
STEP: Ensuring resource quota status released the pod usage 07/10/23 08:56:46.339
STEP: Creating a not best-effort pod 07/10/23 08:56:48.344
STEP: Ensuring resource quota with not best effort scope captures the pod usage 07/10/23 08:56:48.367
STEP: Ensuring resource quota with best effort scope ignored the pod usage 07/10/23 08:56:50.371
STEP: Deleting the pod 07/10/23 08:56:52.377
STEP: Ensuring resource quota status released the pod usage 07/10/23 08:56:52.395
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 08:56:54.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6219" for this suite. 07/10/23 08:56:54.429
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":197,"skipped":3761,"failed":0}
------------------------------
• [SLOW TEST] [16.254 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:56:38.188
    Jul 10 08:56:38.188: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 08:56:38.189
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:38.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:38.228
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 07/10/23 08:56:38.23
    STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:56:38.248
    STEP: Creating a ResourceQuota with not best effort scope 07/10/23 08:56:40.253
    STEP: Ensuring ResourceQuota status is calculated 07/10/23 08:56:40.261
    STEP: Creating a best-effort pod 07/10/23 08:56:42.267
    STEP: Ensuring resource quota with best effort scope captures the pod usage 07/10/23 08:56:42.291
    STEP: Ensuring resource quota with not best effort ignored the pod usage 07/10/23 08:56:44.297
    STEP: Deleting the pod 07/10/23 08:56:46.303
    STEP: Ensuring resource quota status released the pod usage 07/10/23 08:56:46.339
    STEP: Creating a not best-effort pod 07/10/23 08:56:48.344
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 07/10/23 08:56:48.367
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 07/10/23 08:56:50.371
    STEP: Deleting the pod 07/10/23 08:56:52.377
    STEP: Ensuring resource quota status released the pod usage 07/10/23 08:56:52.395
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 08:56:54.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6219" for this suite. 07/10/23 08:56:54.429
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:56:54.443
Jul 10 08:56:54.444: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 08:56:54.445
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:54.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:54.48
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 07/10/23 08:56:54.483
Jul 10 08:56:54.493: INFO: Waiting up to 5m0s for pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554" in namespace "emptydir-3442" to be "Succeeded or Failed"
Jul 10 08:56:54.496: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554": Phase="Pending", Reason="", readiness=false. Elapsed: 3.271961ms
Jul 10 08:56:56.502: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009306294s
Jul 10 08:56:58.502: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009263701s
STEP: Saw pod success 07/10/23 08:56:58.502
Jul 10 08:56:58.503: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554" satisfied condition "Succeeded or Failed"
Jul 10 08:56:58.506: INFO: Trying to get logs from node 10-62-109-100.test pod pod-00d3d596-ed71-48fb-9cad-7a44e98c6554 container test-container: <nil>
STEP: delete the pod 07/10/23 08:56:58.517
Jul 10 08:56:58.541: INFO: Waiting for pod pod-00d3d596-ed71-48fb-9cad-7a44e98c6554 to disappear
Jul 10 08:56:58.544: INFO: Pod pod-00d3d596-ed71-48fb-9cad-7a44e98c6554 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 08:56:58.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3442" for this suite. 07/10/23 08:56:58.554
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":198,"skipped":3786,"failed":0}
------------------------------
• [4.118 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:56:54.443
    Jul 10 08:56:54.444: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 08:56:54.445
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:54.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:54.48
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 07/10/23 08:56:54.483
    Jul 10 08:56:54.493: INFO: Waiting up to 5m0s for pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554" in namespace "emptydir-3442" to be "Succeeded or Failed"
    Jul 10 08:56:54.496: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554": Phase="Pending", Reason="", readiness=false. Elapsed: 3.271961ms
    Jul 10 08:56:56.502: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009306294s
    Jul 10 08:56:58.502: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009263701s
    STEP: Saw pod success 07/10/23 08:56:58.502
    Jul 10 08:56:58.503: INFO: Pod "pod-00d3d596-ed71-48fb-9cad-7a44e98c6554" satisfied condition "Succeeded or Failed"
    Jul 10 08:56:58.506: INFO: Trying to get logs from node 10-62-109-100.test pod pod-00d3d596-ed71-48fb-9cad-7a44e98c6554 container test-container: <nil>
    STEP: delete the pod 07/10/23 08:56:58.517
    Jul 10 08:56:58.541: INFO: Waiting for pod pod-00d3d596-ed71-48fb-9cad-7a44e98c6554 to disappear
    Jul 10 08:56:58.544: INFO: Pod pod-00d3d596-ed71-48fb-9cad-7a44e98c6554 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 08:56:58.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3442" for this suite. 07/10/23 08:56:58.554
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:56:58.562
Jul 10 08:56:58.562: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 08:56:58.564
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:58.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:58.593
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Jul 10 08:56:58.595: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: creating the pod 07/10/23 08:56:58.596
STEP: submitting the pod to kubernetes 07/10/23 08:56:58.596
Jul 10 08:56:58.614: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804" in namespace "pods-3683" to be "running and ready"
Jul 10 08:56:58.618: INFO: Pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804": Phase="Pending", Reason="", readiness=false. Elapsed: 3.576062ms
Jul 10 08:56:58.618: INFO: The phase of Pod pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:57:00.626: INFO: Pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804": Phase="Running", Reason="", readiness=true. Elapsed: 2.011549379s
Jul 10 08:57:00.626: INFO: The phase of Pod pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804 is Running (Ready = true)
Jul 10 08:57:00.626: INFO: Pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 08:57:00.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3683" for this suite. 07/10/23 08:57:00.721
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":199,"skipped":3790,"failed":0}
------------------------------
• [2.174 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:56:58.562
    Jul 10 08:56:58.562: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 08:56:58.564
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:56:58.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:56:58.593
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Jul 10 08:56:58.595: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: creating the pod 07/10/23 08:56:58.596
    STEP: submitting the pod to kubernetes 07/10/23 08:56:58.596
    Jul 10 08:56:58.614: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804" in namespace "pods-3683" to be "running and ready"
    Jul 10 08:56:58.618: INFO: Pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804": Phase="Pending", Reason="", readiness=false. Elapsed: 3.576062ms
    Jul 10 08:56:58.618: INFO: The phase of Pod pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:57:00.626: INFO: Pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804": Phase="Running", Reason="", readiness=true. Elapsed: 2.011549379s
    Jul 10 08:57:00.626: INFO: The phase of Pod pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804 is Running (Ready = true)
    Jul 10 08:57:00.626: INFO: Pod "pod-exec-websocket-1d73e9af-249c-47ce-bcab-023f66d55804" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 08:57:00.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3683" for this suite. 07/10/23 08:57:00.721
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:57:00.738
Jul 10 08:57:00.738: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 08:57:00.739
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:57:00.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:57:00.778
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 07/10/23 08:57:00.781
Jul 10 08:57:00.799: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c" in namespace "projected-894" to be "Succeeded or Failed"
Jul 10 08:57:00.803: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.807952ms
Jul 10 08:57:02.809: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009616517s
Jul 10 08:57:04.809: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009679882s
Jul 10 08:57:06.811: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011452388s
STEP: Saw pod success 07/10/23 08:57:06.811
Jul 10 08:57:06.811: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c" satisfied condition "Succeeded or Failed"
Jul 10 08:57:06.814: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c container client-container: <nil>
STEP: delete the pod 07/10/23 08:57:06.823
Jul 10 08:57:06.856: INFO: Waiting for pod downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c to disappear
Jul 10 08:57:06.859: INFO: Pod downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 08:57:06.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-894" for this suite. 07/10/23 08:57:06.863
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":200,"skipped":3832,"failed":0}
------------------------------
• [SLOW TEST] [6.138 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:57:00.738
    Jul 10 08:57:00.738: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 08:57:00.739
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:57:00.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:57:00.778
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 07/10/23 08:57:00.781
    Jul 10 08:57:00.799: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c" in namespace "projected-894" to be "Succeeded or Failed"
    Jul 10 08:57:00.803: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.807952ms
    Jul 10 08:57:02.809: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009616517s
    Jul 10 08:57:04.809: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009679882s
    Jul 10 08:57:06.811: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011452388s
    STEP: Saw pod success 07/10/23 08:57:06.811
    Jul 10 08:57:06.811: INFO: Pod "downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c" satisfied condition "Succeeded or Failed"
    Jul 10 08:57:06.814: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c container client-container: <nil>
    STEP: delete the pod 07/10/23 08:57:06.823
    Jul 10 08:57:06.856: INFO: Waiting for pod downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c to disappear
    Jul 10 08:57:06.859: INFO: Pod downwardapi-volume-19160928-8b7a-4956-aec5-65c73082cc2c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 08:57:06.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-894" for this suite. 07/10/23 08:57:06.863
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:57:06.876
Jul 10 08:57:06.876: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename disruption 07/10/23 08:57:06.878
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:57:06.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:57:06.909
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 07/10/23 08:57:06.921
STEP: Updating PodDisruptionBudget status 07/10/23 08:57:08.929
STEP: Waiting for all pods to be running 07/10/23 08:57:08.942
Jul 10 08:57:08.952: INFO: running pods: 0 < 1
STEP: locating a running pod 07/10/23 08:57:10.958
STEP: Waiting for the pdb to be processed 07/10/23 08:57:10.98
STEP: Patching PodDisruptionBudget status 07/10/23 08:57:10.995
STEP: Waiting for the pdb to be processed 07/10/23 08:57:11.01
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jul 10 08:57:11.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7066" for this suite. 07/10/23 08:57:11.021
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":201,"skipped":3832,"failed":0}
------------------------------
• [4.158 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:57:06.876
    Jul 10 08:57:06.876: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename disruption 07/10/23 08:57:06.878
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:57:06.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:57:06.909
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 07/10/23 08:57:06.921
    STEP: Updating PodDisruptionBudget status 07/10/23 08:57:08.929
    STEP: Waiting for all pods to be running 07/10/23 08:57:08.942
    Jul 10 08:57:08.952: INFO: running pods: 0 < 1
    STEP: locating a running pod 07/10/23 08:57:10.958
    STEP: Waiting for the pdb to be processed 07/10/23 08:57:10.98
    STEP: Patching PodDisruptionBudget status 07/10/23 08:57:10.995
    STEP: Waiting for the pdb to be processed 07/10/23 08:57:11.01
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jul 10 08:57:11.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-7066" for this suite. 07/10/23 08:57:11.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:57:11.035
Jul 10 08:57:11.035: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 08:57:11.036
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:57:11.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:57:11.069
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9668 07/10/23 08:57:11.071
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 07/10/23 08:57:11.078
STEP: Creating stateful set ss in namespace statefulset-9668 07/10/23 08:57:11.083
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9668 07/10/23 08:57:11.101
Jul 10 08:57:11.103: INFO: Found 0 stateful pods, waiting for 1
Jul 10 08:57:21.109: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 07/10/23 08:57:21.109
Jul 10 08:57:21.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:57:21.279: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:57:21.279: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:57:21.279: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:57:21.283: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 10 08:57:31.291: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:57:31.291: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:57:31.321: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999681s
Jul 10 08:57:32.327: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995352093s
Jul 10 08:57:33.332: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989445518s
Jul 10 08:57:34.342: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983716369s
Jul 10 08:57:35.347: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974209828s
Jul 10 08:57:36.352: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.969237533s
Jul 10 08:57:37.358: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.963487511s
Jul 10 08:57:38.364: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.958235296s
Jul 10 08:57:39.369: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.952155097s
Jul 10 08:57:40.376: INFO: Verifying statefulset ss doesn't scale past 1 for another 947.516432ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9668 07/10/23 08:57:41.377
Jul 10 08:57:41.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:57:41.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:57:41.554: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:57:41.554: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:57:41.559: INFO: Found 1 stateful pods, waiting for 3
Jul 10 08:57:51.566: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:57:51.566: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 08:57:51.566: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 07/10/23 08:57:51.566
STEP: Scale down will halt with unhealthy stateful pod 07/10/23 08:57:51.566
Jul 10 08:57:51.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:57:51.735: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:57:51.735: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:57:51.735: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:57:51.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:57:51.881: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:57:51.881: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:57:51.881: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:57:51.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul 10 08:57:52.032: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul 10 08:57:52.032: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul 10 08:57:52.032: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul 10 08:57:52.032: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:57:52.036: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul 10 08:58:02.045: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:58:02.045: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:58:02.045: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 10 08:58:02.075: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999437s
Jul 10 08:58:03.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993222973s
Jul 10 08:58:04.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986793914s
Jul 10 08:58:05.097: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977530656s
Jul 10 08:58:06.101: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971911022s
Jul 10 08:58:07.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967475213s
Jul 10 08:58:08.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9613247s
Jul 10 08:58:09.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955956723s
Jul 10 08:58:10.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950222239s
Jul 10 08:58:11.130: INFO: Verifying statefulset ss doesn't scale past 3 for another 944.443265ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9668 07/10/23 08:58:12.13
Jul 10 08:58:12.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:58:12.293: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:58:12.293: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:58:12.293: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:58:12.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:58:12.439: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:58:12.439: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:58:12.439: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:58:12.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul 10 08:58:12.588: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul 10 08:58:12.588: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul 10 08:58:12.588: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul 10 08:58:12.588: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 07/10/23 08:58:22.631
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 08:58:22.631: INFO: Deleting all statefulset in ns statefulset-9668
Jul 10 08:58:22.640: INFO: Scaling statefulset ss to 0
Jul 10 08:58:22.652: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 08:58:22.654: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 08:58:22.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9668" for this suite. 07/10/23 08:58:22.674
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":202,"skipped":3841,"failed":0}
------------------------------
• [SLOW TEST] [71.703 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:57:11.035
    Jul 10 08:57:11.035: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 08:57:11.036
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:57:11.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:57:11.069
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9668 07/10/23 08:57:11.071
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 07/10/23 08:57:11.078
    STEP: Creating stateful set ss in namespace statefulset-9668 07/10/23 08:57:11.083
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9668 07/10/23 08:57:11.101
    Jul 10 08:57:11.103: INFO: Found 0 stateful pods, waiting for 1
    Jul 10 08:57:21.109: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 07/10/23 08:57:21.109
    Jul 10 08:57:21.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:57:21.279: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:57:21.279: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:57:21.279: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:57:21.283: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Jul 10 08:57:31.291: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:57:31.291: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:57:31.321: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999681s
    Jul 10 08:57:32.327: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995352093s
    Jul 10 08:57:33.332: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989445518s
    Jul 10 08:57:34.342: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983716369s
    Jul 10 08:57:35.347: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974209828s
    Jul 10 08:57:36.352: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.969237533s
    Jul 10 08:57:37.358: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.963487511s
    Jul 10 08:57:38.364: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.958235296s
    Jul 10 08:57:39.369: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.952155097s
    Jul 10 08:57:40.376: INFO: Verifying statefulset ss doesn't scale past 1 for another 947.516432ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9668 07/10/23 08:57:41.377
    Jul 10 08:57:41.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:57:41.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:57:41.554: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:57:41.554: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:57:41.559: INFO: Found 1 stateful pods, waiting for 3
    Jul 10 08:57:51.566: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:57:51.566: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 08:57:51.566: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 07/10/23 08:57:51.566
    STEP: Scale down will halt with unhealthy stateful pod 07/10/23 08:57:51.566
    Jul 10 08:57:51.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:57:51.735: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:57:51.735: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:57:51.735: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:57:51.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:57:51.881: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:57:51.881: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:57:51.881: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:57:51.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jul 10 08:57:52.032: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jul 10 08:57:52.032: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jul 10 08:57:52.032: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jul 10 08:57:52.032: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:57:52.036: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Jul 10 08:58:02.045: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:58:02.045: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:58:02.045: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Jul 10 08:58:02.075: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999437s
    Jul 10 08:58:03.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993222973s
    Jul 10 08:58:04.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986793914s
    Jul 10 08:58:05.097: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977530656s
    Jul 10 08:58:06.101: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971911022s
    Jul 10 08:58:07.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967475213s
    Jul 10 08:58:08.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9613247s
    Jul 10 08:58:09.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955956723s
    Jul 10 08:58:10.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950222239s
    Jul 10 08:58:11.130: INFO: Verifying statefulset ss doesn't scale past 3 for another 944.443265ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9668 07/10/23 08:58:12.13
    Jul 10 08:58:12.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:58:12.293: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:58:12.293: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:58:12.293: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:58:12.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:58:12.439: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:58:12.439: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:58:12.439: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:58:12.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=statefulset-9668 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jul 10 08:58:12.588: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jul 10 08:58:12.588: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jul 10 08:58:12.588: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jul 10 08:58:12.588: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 07/10/23 08:58:22.631
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 08:58:22.631: INFO: Deleting all statefulset in ns statefulset-9668
    Jul 10 08:58:22.640: INFO: Scaling statefulset ss to 0
    Jul 10 08:58:22.652: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 08:58:22.654: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 08:58:22.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9668" for this suite. 07/10/23 08:58:22.674
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:58:22.742
Jul 10 08:58:22.742: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 08:58:22.743
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:22.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:22.781
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 07/10/23 08:58:22.783
Jul 10 08:58:22.797: INFO: Waiting up to 5m0s for pod "downward-api-74b70229-3f55-477f-b156-9631c4968419" in namespace "downward-api-1106" to be "Succeeded or Failed"
Jul 10 08:58:22.802: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419": Phase="Pending", Reason="", readiness=false. Elapsed: 4.581316ms
Jul 10 08:58:24.808: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011232035s
Jul 10 08:58:26.807: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010047946s
STEP: Saw pod success 07/10/23 08:58:26.807
Jul 10 08:58:26.807: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419" satisfied condition "Succeeded or Failed"
Jul 10 08:58:26.811: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-74b70229-3f55-477f-b156-9631c4968419 container dapi-container: <nil>
STEP: delete the pod 07/10/23 08:58:26.823
Jul 10 08:58:26.853: INFO: Waiting for pod downward-api-74b70229-3f55-477f-b156-9631c4968419 to disappear
Jul 10 08:58:26.856: INFO: Pod downward-api-74b70229-3f55-477f-b156-9631c4968419 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jul 10 08:58:26.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1106" for this suite. 07/10/23 08:58:26.861
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":203,"skipped":3915,"failed":0}
------------------------------
• [4.131 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:58:22.742
    Jul 10 08:58:22.742: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 08:58:22.743
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:22.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:22.781
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 07/10/23 08:58:22.783
    Jul 10 08:58:22.797: INFO: Waiting up to 5m0s for pod "downward-api-74b70229-3f55-477f-b156-9631c4968419" in namespace "downward-api-1106" to be "Succeeded or Failed"
    Jul 10 08:58:22.802: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419": Phase="Pending", Reason="", readiness=false. Elapsed: 4.581316ms
    Jul 10 08:58:24.808: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011232035s
    Jul 10 08:58:26.807: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010047946s
    STEP: Saw pod success 07/10/23 08:58:26.807
    Jul 10 08:58:26.807: INFO: Pod "downward-api-74b70229-3f55-477f-b156-9631c4968419" satisfied condition "Succeeded or Failed"
    Jul 10 08:58:26.811: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-74b70229-3f55-477f-b156-9631c4968419 container dapi-container: <nil>
    STEP: delete the pod 07/10/23 08:58:26.823
    Jul 10 08:58:26.853: INFO: Waiting for pod downward-api-74b70229-3f55-477f-b156-9631c4968419 to disappear
    Jul 10 08:58:26.856: INFO: Pod downward-api-74b70229-3f55-477f-b156-9631c4968419 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jul 10 08:58:26.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1106" for this suite. 07/10/23 08:58:26.861
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:58:26.874
Jul 10 08:58:26.874: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename certificates 07/10/23 08:58:26.875
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:26.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:26.91
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 07/10/23 08:58:27.815
STEP: getting /apis/certificates.k8s.io 07/10/23 08:58:27.818
STEP: getting /apis/certificates.k8s.io/v1 07/10/23 08:58:27.818
STEP: creating 07/10/23 08:58:27.819
STEP: getting 07/10/23 08:58:27.845
STEP: listing 07/10/23 08:58:27.855
STEP: watching 07/10/23 08:58:27.859
Jul 10 08:58:27.859: INFO: starting watch
STEP: patching 07/10/23 08:58:27.86
STEP: updating 07/10/23 08:58:27.876
Jul 10 08:58:27.890: INFO: waiting for watch events with expected annotations
Jul 10 08:58:27.891: INFO: saw patched and updated annotations
STEP: getting /approval 07/10/23 08:58:27.891
STEP: patching /approval 07/10/23 08:58:27.894
STEP: updating /approval 07/10/23 08:58:27.905
STEP: getting /status 07/10/23 08:58:27.919
STEP: patching /status 07/10/23 08:58:27.924
STEP: updating /status 07/10/23 08:58:27.938
STEP: deleting 07/10/23 08:58:27.951
STEP: deleting a collection 07/10/23 08:58:27.983
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:58:28.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-6035" for this suite. 07/10/23 08:58:28.032
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":204,"skipped":3917,"failed":0}
------------------------------
• [1.171 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:58:26.874
    Jul 10 08:58:26.874: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename certificates 07/10/23 08:58:26.875
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:26.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:26.91
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 07/10/23 08:58:27.815
    STEP: getting /apis/certificates.k8s.io 07/10/23 08:58:27.818
    STEP: getting /apis/certificates.k8s.io/v1 07/10/23 08:58:27.818
    STEP: creating 07/10/23 08:58:27.819
    STEP: getting 07/10/23 08:58:27.845
    STEP: listing 07/10/23 08:58:27.855
    STEP: watching 07/10/23 08:58:27.859
    Jul 10 08:58:27.859: INFO: starting watch
    STEP: patching 07/10/23 08:58:27.86
    STEP: updating 07/10/23 08:58:27.876
    Jul 10 08:58:27.890: INFO: waiting for watch events with expected annotations
    Jul 10 08:58:27.891: INFO: saw patched and updated annotations
    STEP: getting /approval 07/10/23 08:58:27.891
    STEP: patching /approval 07/10/23 08:58:27.894
    STEP: updating /approval 07/10/23 08:58:27.905
    STEP: getting /status 07/10/23 08:58:27.919
    STEP: patching /status 07/10/23 08:58:27.924
    STEP: updating /status 07/10/23 08:58:27.938
    STEP: deleting 07/10/23 08:58:27.951
    STEP: deleting a collection 07/10/23 08:58:27.983
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:58:28.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-6035" for this suite. 07/10/23 08:58:28.032
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:58:28.046
Jul 10 08:58:28.046: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 08:58:28.046
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:28.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:28.088
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 08:58:28.115
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:58:28.638
STEP: Deploying the webhook pod 07/10/23 08:58:28.652
STEP: Wait for the deployment to be ready 07/10/23 08:58:28.672
Jul 10 08:58:28.692: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 07/10/23 08:58:30.705
STEP: Verifying the service has paired with the endpoint 07/10/23 08:58:30.729
Jul 10 08:58:31.730: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 07/10/23 08:58:31.735
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 07/10/23 08:58:31.736
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 07/10/23 08:58:31.736
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 07/10/23 08:58:31.736
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 07/10/23 08:58:31.737
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 07/10/23 08:58:31.737
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 07/10/23 08:58:31.738
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 08:58:31.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5822" for this suite. 07/10/23 08:58:31.743
STEP: Destroying namespace "webhook-5822-markers" for this suite. 07/10/23 08:58:31.757
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":205,"skipped":3929,"failed":0}
------------------------------
• [3.808 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:58:28.046
    Jul 10 08:58:28.046: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 08:58:28.046
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:28.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:28.088
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 08:58:28.115
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 08:58:28.638
    STEP: Deploying the webhook pod 07/10/23 08:58:28.652
    STEP: Wait for the deployment to be ready 07/10/23 08:58:28.672
    Jul 10 08:58:28.692: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 07/10/23 08:58:30.705
    STEP: Verifying the service has paired with the endpoint 07/10/23 08:58:30.729
    Jul 10 08:58:31.730: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 07/10/23 08:58:31.735
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 07/10/23 08:58:31.736
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 07/10/23 08:58:31.736
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 07/10/23 08:58:31.736
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 07/10/23 08:58:31.737
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 07/10/23 08:58:31.737
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 07/10/23 08:58:31.738
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 08:58:31.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5822" for this suite. 07/10/23 08:58:31.743
    STEP: Destroying namespace "webhook-5822-markers" for this suite. 07/10/23 08:58:31.757
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:58:31.856
Jul 10 08:58:31.856: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:58:31.857
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:31.907
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:31.909
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-1076 07/10/23 08:58:31.911
STEP: creating service affinity-clusterip in namespace services-1076 07/10/23 08:58:31.911
STEP: creating replication controller affinity-clusterip in namespace services-1076 07/10/23 08:58:31.931
I0710 08:58:31.947898      21 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1076, replica count: 3
I0710 08:58:35.001000      21 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 08:58:35.010: INFO: Creating new exec pod
Jul 10 08:58:35.028: INFO: Waiting up to 5m0s for pod "execpod-affinitybdgnn" in namespace "services-1076" to be "running"
Jul 10 08:58:35.032: INFO: Pod "execpod-affinitybdgnn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.984171ms
Jul 10 08:58:37.036: INFO: Pod "execpod-affinitybdgnn": Phase="Running", Reason="", readiness=true. Elapsed: 2.008359898s
Jul 10 08:58:37.036: INFO: Pod "execpod-affinitybdgnn" satisfied condition "running"
Jul 10 08:58:38.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1076 exec execpod-affinitybdgnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Jul 10 08:58:38.198: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Jul 10 08:58:38.198: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:58:38.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1076 exec execpod-affinitybdgnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.255.65 80'
Jul 10 08:58:38.341: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.255.65 80\nConnection to 192.168.255.65 80 port [tcp/http] succeeded!\n"
Jul 10 08:58:38.341: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 08:58:38.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1076 exec execpod-affinitybdgnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.255.65:80/ ; done'
Jul 10 08:58:38.573: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n"
Jul 10 08:58:38.573: INFO: stdout: "\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h"
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
Jul 10 08:58:38.573: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-1076, will wait for the garbage collector to delete the pods 07/10/23 08:58:38.621
Jul 10 08:58:38.691: INFO: Deleting ReplicationController affinity-clusterip took: 10.299776ms
Jul 10 08:58:38.792: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.026678ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:58:41.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1076" for this suite. 07/10/23 08:58:41.541
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":206,"skipped":3974,"failed":0}
------------------------------
• [SLOW TEST] [9.694 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:58:31.856
    Jul 10 08:58:31.856: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:58:31.857
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:31.907
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:31.909
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-1076 07/10/23 08:58:31.911
    STEP: creating service affinity-clusterip in namespace services-1076 07/10/23 08:58:31.911
    STEP: creating replication controller affinity-clusterip in namespace services-1076 07/10/23 08:58:31.931
    I0710 08:58:31.947898      21 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1076, replica count: 3
    I0710 08:58:35.001000      21 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 08:58:35.010: INFO: Creating new exec pod
    Jul 10 08:58:35.028: INFO: Waiting up to 5m0s for pod "execpod-affinitybdgnn" in namespace "services-1076" to be "running"
    Jul 10 08:58:35.032: INFO: Pod "execpod-affinitybdgnn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.984171ms
    Jul 10 08:58:37.036: INFO: Pod "execpod-affinitybdgnn": Phase="Running", Reason="", readiness=true. Elapsed: 2.008359898s
    Jul 10 08:58:37.036: INFO: Pod "execpod-affinitybdgnn" satisfied condition "running"
    Jul 10 08:58:38.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1076 exec execpod-affinitybdgnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Jul 10 08:58:38.198: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Jul 10 08:58:38.198: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:58:38.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1076 exec execpod-affinitybdgnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.255.65 80'
    Jul 10 08:58:38.341: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.255.65 80\nConnection to 192.168.255.65 80 port [tcp/http] succeeded!\n"
    Jul 10 08:58:38.341: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 08:58:38.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-1076 exec execpod-affinitybdgnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.255.65:80/ ; done'
    Jul 10 08:58:38.573: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.255.65:80/\n"
    Jul 10 08:58:38.573: INFO: stdout: "\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h\naffinity-clusterip-7k94h"
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Received response from host: affinity-clusterip-7k94h
    Jul 10 08:58:38.573: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-1076, will wait for the garbage collector to delete the pods 07/10/23 08:58:38.621
    Jul 10 08:58:38.691: INFO: Deleting ReplicationController affinity-clusterip took: 10.299776ms
    Jul 10 08:58:38.792: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.026678ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:58:41.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1076" for this suite. 07/10/23 08:58:41.541
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:58:41.552
Jul 10 08:58:41.552: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename job 07/10/23 08:58:41.553
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:41.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:41.584
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 07/10/23 08:58:41.586
STEP: Ensuring job reaches completions 07/10/23 08:58:41.596
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jul 10 08:58:55.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1323" for this suite. 07/10/23 08:58:55.605
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":207,"skipped":4016,"failed":0}
------------------------------
• [SLOW TEST] [14.063 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:58:41.552
    Jul 10 08:58:41.552: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename job 07/10/23 08:58:41.553
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:41.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:41.584
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 07/10/23 08:58:41.586
    STEP: Ensuring job reaches completions 07/10/23 08:58:41.596
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jul 10 08:58:55.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1323" for this suite. 07/10/23 08:58:55.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:58:55.617
Jul 10 08:58:55.617: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svcaccounts 07/10/23 08:58:55.618
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:55.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:55.648
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  07/10/23 08:58:55.656
Jul 10 08:58:55.667: INFO: Waiting up to 5m0s for pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f" in namespace "svcaccounts-7647" to be "Succeeded or Failed"
Jul 10 08:58:55.671: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850059ms
Jul 10 08:58:57.732: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065282615s
Jul 10 08:58:59.677: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009567381s
Jul 10 08:59:01.678: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010566947s
STEP: Saw pod success 07/10/23 08:59:01.678
Jul 10 08:59:01.678: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f" satisfied condition "Succeeded or Failed"
Jul 10 08:59:01.680: INFO: Trying to get logs from node 10-62-109-100.test pod test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f container agnhost-container: <nil>
STEP: delete the pod 07/10/23 08:59:01.69
Jul 10 08:59:01.715: INFO: Waiting for pod test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f to disappear
Jul 10 08:59:01.719: INFO: Pod test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jul 10 08:59:01.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7647" for this suite. 07/10/23 08:59:01.725
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":208,"skipped":4047,"failed":0}
------------------------------
• [SLOW TEST] [6.117 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:58:55.617
    Jul 10 08:58:55.617: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svcaccounts 07/10/23 08:58:55.618
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:58:55.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:58:55.648
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  07/10/23 08:58:55.656
    Jul 10 08:58:55.667: INFO: Waiting up to 5m0s for pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f" in namespace "svcaccounts-7647" to be "Succeeded or Failed"
    Jul 10 08:58:55.671: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850059ms
    Jul 10 08:58:57.732: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065282615s
    Jul 10 08:58:59.677: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009567381s
    Jul 10 08:59:01.678: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010566947s
    STEP: Saw pod success 07/10/23 08:59:01.678
    Jul 10 08:59:01.678: INFO: Pod "test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f" satisfied condition "Succeeded or Failed"
    Jul 10 08:59:01.680: INFO: Trying to get logs from node 10-62-109-100.test pod test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 08:59:01.69
    Jul 10 08:59:01.715: INFO: Waiting for pod test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f to disappear
    Jul 10 08:59:01.719: INFO: Pod test-pod-66edfc2b-1ae6-4a88-91c2-d30603a2bd6f no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jul 10 08:59:01.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7647" for this suite. 07/10/23 08:59:01.725
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:59:01.736
Jul 10 08:59:01.736: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 08:59:01.737
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:01.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:01.765
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 08:59:01.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7385" for this suite. 07/10/23 08:59:01.779
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":209,"skipped":4078,"failed":0}
------------------------------
• [0.053 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:59:01.736
    Jul 10 08:59:01.736: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 08:59:01.737
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:01.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:01.765
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 08:59:01.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7385" for this suite. 07/10/23 08:59:01.779
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:59:01.794
Jul 10 08:59:01.794: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 08:59:01.795
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:01.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:01.822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 07/10/23 08:59:01.825
Jul 10 08:59:01.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4991 create -f -'
Jul 10 08:59:02.651: INFO: stderr: ""
Jul 10 08:59:02.651: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 07/10/23 08:59:02.651
Jul 10 08:59:02.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4991 diff -f -'
Jul 10 08:59:03.343: INFO: rc: 1
Jul 10 08:59:03.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4991 delete -f -'
Jul 10 08:59:03.439: INFO: stderr: ""
Jul 10 08:59:03.439: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 08:59:03.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4991" for this suite. 07/10/23 08:59:03.445
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":210,"skipped":4126,"failed":0}
------------------------------
• [1.760 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:59:01.794
    Jul 10 08:59:01.794: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 08:59:01.795
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:01.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:01.822
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 07/10/23 08:59:01.825
    Jul 10 08:59:01.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4991 create -f -'
    Jul 10 08:59:02.651: INFO: stderr: ""
    Jul 10 08:59:02.651: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 07/10/23 08:59:02.651
    Jul 10 08:59:02.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4991 diff -f -'
    Jul 10 08:59:03.343: INFO: rc: 1
    Jul 10 08:59:03.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-4991 delete -f -'
    Jul 10 08:59:03.439: INFO: stderr: ""
    Jul 10 08:59:03.439: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 08:59:03.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4991" for this suite. 07/10/23 08:59:03.445
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:59:03.555
Jul 10 08:59:03.555: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename init-container 07/10/23 08:59:03.556
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:03.595
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:03.597
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 07/10/23 08:59:03.6
Jul 10 08:59:03.600: INFO: PodSpec: initContainers in spec.initContainers
Jul 10 08:59:49.535: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-56e5f89e-2f49-4555-a60b-edbae693ad88", GenerateName:"", Namespace:"init-container-4642", SelfLink:"", UID:"a6c29062-431e-453b-a0cf-34a74dd80b98", ResourceVersion:"92403", Generation:0, CreationTimestamp:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"600187049"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"1b0d57c6e96a990205863e3ed094bf6866b064f351705e8f676594caac1b8da7", "cni.projectcalico.org/podIP":"192.168.172.4/32", "cni.projectcalico.org/podIPs":"192.168.172.4/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003a396c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.July, 10, 8, 59, 4, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003a396f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.July, 10, 8, 59, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003a39728), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-x9hpm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0039dc620), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x9hpm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x9hpm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x9hpm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0035efcf0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10-62-109-100.test", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004677d50), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0035efd80)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0035efda0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0035efda8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0035efdac), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000dd47b0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.62.109.100", PodIP:"192.168.172.4", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.172.4"}}, StartTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004677e30)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004677ea0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"docker-pullable://registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"docker://0ea1927e722f7f9f6575d734397a473fe4103e7521b84e05b9d671b0cac690a8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0039dc6a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0039dc680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0035efe24)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 08:59:49.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4642" for this suite. 07/10/23 08:59:49.541
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":211,"skipped":4133,"failed":0}
------------------------------
• [SLOW TEST] [46.006 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:59:03.555
    Jul 10 08:59:03.555: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename init-container 07/10/23 08:59:03.556
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:03.595
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:03.597
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 07/10/23 08:59:03.6
    Jul 10 08:59:03.600: INFO: PodSpec: initContainers in spec.initContainers
    Jul 10 08:59:49.535: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-56e5f89e-2f49-4555-a60b-edbae693ad88", GenerateName:"", Namespace:"init-container-4642", SelfLink:"", UID:"a6c29062-431e-453b-a0cf-34a74dd80b98", ResourceVersion:"92403", Generation:0, CreationTimestamp:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"600187049"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"1b0d57c6e96a990205863e3ed094bf6866b064f351705e8f676594caac1b8da7", "cni.projectcalico.org/podIP":"192.168.172.4/32", "cni.projectcalico.org/podIPs":"192.168.172.4/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003a396c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.July, 10, 8, 59, 4, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003a396f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.July, 10, 8, 59, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003a39728), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-x9hpm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0039dc620), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x9hpm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x9hpm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x9hpm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0035efcf0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10-62-109-100.test", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004677d50), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0035efd80)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0035efda0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0035efda8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0035efdac), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000dd47b0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.62.109.100", PodIP:"192.168.172.4", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.172.4"}}, StartTime:time.Date(2023, time.July, 10, 8, 59, 3, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004677e30)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004677ea0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"docker-pullable://registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"docker://0ea1927e722f7f9f6575d734397a473fe4103e7521b84e05b9d671b0cac690a8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0039dc6a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0039dc680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0035efe24)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 08:59:49.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-4642" for this suite. 07/10/23 08:59:49.541
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 08:59:49.568
Jul 10 08:59:49.568: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pod-network-test 07/10/23 08:59:49.569
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:49.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:49.615
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-7250 07/10/23 08:59:49.618
STEP: creating a selector 07/10/23 08:59:49.618
STEP: Creating the service pods in kubernetes 07/10/23 08:59:49.618
Jul 10 08:59:49.618: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul 10 08:59:49.673: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7250" to be "running and ready"
Jul 10 08:59:49.684: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.854947ms
Jul 10 08:59:49.684: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 08:59:51.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017378691s
Jul 10 08:59:51.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:59:53.690: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017025341s
Jul 10 08:59:53.690: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:59:55.695: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.021176142s
Jul 10 08:59:55.695: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:59:57.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.017139727s
Jul 10 08:59:57.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 08:59:59.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.0172131s
Jul 10 08:59:59.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:00:01.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.017377279s
Jul 10 09:00:01.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:00:03.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.017492459s
Jul 10 09:00:03.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:00:05.693: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.019270533s
Jul 10 09:00:05.693: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:00:07.690: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.01624891s
Jul 10 09:00:07.690: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:00:09.694: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.020947533s
Jul 10 09:00:09.694: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:00:11.692: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.018189322s
Jul 10 09:00:11.692: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jul 10 09:00:11.692: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jul 10 09:00:11.695: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7250" to be "running and ready"
Jul 10 09:00:11.700: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.548641ms
Jul 10 09:00:11.700: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jul 10 09:00:11.700: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jul 10 09:00:11.703: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7250" to be "running and ready"
Jul 10 09:00:11.706: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.048966ms
Jul 10 09:00:11.707: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jul 10 09:00:11.707: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 07/10/23 09:00:11.711
Jul 10 09:00:11.722: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7250" to be "running"
Jul 10 09:00:11.726: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677958ms
Jul 10 09:00:13.748: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025402377s
Jul 10 09:00:15.793: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.070540112s
Jul 10 09:00:15.793: INFO: Pod "test-container-pod" satisfied condition "running"
Jul 10 09:00:15.798: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul 10 09:00:15.798: INFO: Breadth first check of 192.168.172.17 on host 10.62.109.100...
Jul 10 09:00:15.801: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.7:9080/dial?request=hostname&protocol=http&host=192.168.172.17&port=8083&tries=1'] Namespace:pod-network-test-7250 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:00:15.801: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:00:15.802: INFO: ExecWithOptions: Clientset creation
Jul 10 09:00:15.802: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-7250/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.7%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.172.17%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul 10 09:00:15.886: INFO: Waiting for responses: map[]
Jul 10 09:00:15.887: INFO: reached 192.168.172.17 after 0/1 tries
Jul 10 09:00:15.887: INFO: Breadth first check of 192.168.103.106 on host 10.62.109.101...
Jul 10 09:00:15.892: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.7:9080/dial?request=hostname&protocol=http&host=192.168.103.106&port=8083&tries=1'] Namespace:pod-network-test-7250 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:00:15.892: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:00:15.892: INFO: ExecWithOptions: Clientset creation
Jul 10 09:00:15.892: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-7250/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.7%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.103.106%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul 10 09:00:15.992: INFO: Waiting for responses: map[]
Jul 10 09:00:15.992: INFO: reached 192.168.103.106 after 0/1 tries
Jul 10 09:00:15.992: INFO: Breadth first check of 192.168.120.23 on host 10.62.109.102...
Jul 10 09:00:15.996: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.7:9080/dial?request=hostname&protocol=http&host=192.168.120.23&port=8083&tries=1'] Namespace:pod-network-test-7250 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:00:15.996: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:00:15.997: INFO: ExecWithOptions: Clientset creation
Jul 10 09:00:15.997: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-7250/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.7%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.120.23%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul 10 09:00:16.127: INFO: Waiting for responses: map[]
Jul 10 09:00:16.127: INFO: reached 192.168.120.23 after 0/1 tries
Jul 10 09:00:16.127: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jul 10 09:00:16.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7250" for this suite. 07/10/23 09:00:16.133
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":212,"skipped":4168,"failed":0}
------------------------------
• [SLOW TEST] [26.579 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 08:59:49.568
    Jul 10 08:59:49.568: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pod-network-test 07/10/23 08:59:49.569
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 08:59:49.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 08:59:49.615
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-7250 07/10/23 08:59:49.618
    STEP: creating a selector 07/10/23 08:59:49.618
    STEP: Creating the service pods in kubernetes 07/10/23 08:59:49.618
    Jul 10 08:59:49.618: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jul 10 08:59:49.673: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7250" to be "running and ready"
    Jul 10 08:59:49.684: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.854947ms
    Jul 10 08:59:49.684: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 08:59:51.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017378691s
    Jul 10 08:59:51.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:59:53.690: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017025341s
    Jul 10 08:59:53.690: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:59:55.695: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.021176142s
    Jul 10 08:59:55.695: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:59:57.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.017139727s
    Jul 10 08:59:57.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 08:59:59.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.0172131s
    Jul 10 08:59:59.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:00:01.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.017377279s
    Jul 10 09:00:01.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:00:03.691: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.017492459s
    Jul 10 09:00:03.691: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:00:05.693: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.019270533s
    Jul 10 09:00:05.693: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:00:07.690: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.01624891s
    Jul 10 09:00:07.690: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:00:09.694: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.020947533s
    Jul 10 09:00:09.694: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:00:11.692: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.018189322s
    Jul 10 09:00:11.692: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jul 10 09:00:11.692: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jul 10 09:00:11.695: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7250" to be "running and ready"
    Jul 10 09:00:11.700: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.548641ms
    Jul 10 09:00:11.700: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jul 10 09:00:11.700: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jul 10 09:00:11.703: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7250" to be "running and ready"
    Jul 10 09:00:11.706: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.048966ms
    Jul 10 09:00:11.707: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jul 10 09:00:11.707: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 07/10/23 09:00:11.711
    Jul 10 09:00:11.722: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7250" to be "running"
    Jul 10 09:00:11.726: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677958ms
    Jul 10 09:00:13.748: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025402377s
    Jul 10 09:00:15.793: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.070540112s
    Jul 10 09:00:15.793: INFO: Pod "test-container-pod" satisfied condition "running"
    Jul 10 09:00:15.798: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jul 10 09:00:15.798: INFO: Breadth first check of 192.168.172.17 on host 10.62.109.100...
    Jul 10 09:00:15.801: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.7:9080/dial?request=hostname&protocol=http&host=192.168.172.17&port=8083&tries=1'] Namespace:pod-network-test-7250 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:00:15.801: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:00:15.802: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:00:15.802: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-7250/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.7%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.172.17%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jul 10 09:00:15.886: INFO: Waiting for responses: map[]
    Jul 10 09:00:15.887: INFO: reached 192.168.172.17 after 0/1 tries
    Jul 10 09:00:15.887: INFO: Breadth first check of 192.168.103.106 on host 10.62.109.101...
    Jul 10 09:00:15.892: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.7:9080/dial?request=hostname&protocol=http&host=192.168.103.106&port=8083&tries=1'] Namespace:pod-network-test-7250 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:00:15.892: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:00:15.892: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:00:15.892: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-7250/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.7%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.103.106%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jul 10 09:00:15.992: INFO: Waiting for responses: map[]
    Jul 10 09:00:15.992: INFO: reached 192.168.103.106 after 0/1 tries
    Jul 10 09:00:15.992: INFO: Breadth first check of 192.168.120.23 on host 10.62.109.102...
    Jul 10 09:00:15.996: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.7:9080/dial?request=hostname&protocol=http&host=192.168.120.23&port=8083&tries=1'] Namespace:pod-network-test-7250 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:00:15.996: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:00:15.997: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:00:15.997: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-7250/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.7%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.120.23%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jul 10 09:00:16.127: INFO: Waiting for responses: map[]
    Jul 10 09:00:16.127: INFO: reached 192.168.120.23 after 0/1 tries
    Jul 10 09:00:16.127: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jul 10 09:00:16.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7250" for this suite. 07/10/23 09:00:16.133
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:16.148
Jul 10 09:00:16.148: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 09:00:16.149
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:16.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:16.18
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Jul 10 09:00:16.182: INFO: Creating deployment "webserver-deployment"
Jul 10 09:00:16.192: INFO: Waiting for observed generation 1
Jul 10 09:00:18.219: INFO: Waiting for all required pods to come up
Jul 10 09:00:18.225: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 07/10/23 09:00:18.225
Jul 10 09:00:18.225: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-dzvnf" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.225: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-j5kzv" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f8jp2" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fnd7b" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f55kl" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-n85x2" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-q84n2" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-jv725" in namespace "deployment-9468" to be "running"
Jul 10 09:00:18.231: INFO: Pod "webserver-deployment-845c8977d9-dzvnf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.239916ms
Jul 10 09:00:18.231: INFO: Pod "webserver-deployment-845c8977d9-f55kl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.225759ms
Jul 10 09:00:18.231: INFO: Pod "webserver-deployment-845c8977d9-q84n2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.367431ms
Jul 10 09:00:18.232: INFO: Pod "webserver-deployment-845c8977d9-n85x2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.565166ms
Jul 10 09:00:18.232: INFO: Pod "webserver-deployment-845c8977d9-jv725": Phase="Pending", Reason="", readiness=false. Elapsed: 6.566304ms
Jul 10 09:00:18.274: INFO: Pod "webserver-deployment-845c8977d9-j5kzv": Phase="Pending", Reason="", readiness=false. Elapsed: 48.323065ms
Jul 10 09:00:18.274: INFO: Pod "webserver-deployment-845c8977d9-fnd7b": Phase="Pending", Reason="", readiness=false. Elapsed: 48.314004ms
Jul 10 09:00:18.274: INFO: Pod "webserver-deployment-845c8977d9-f8jp2": Phase="Pending", Reason="", readiness=false. Elapsed: 48.694829ms
Jul 10 09:00:20.237: INFO: Pod "webserver-deployment-845c8977d9-jv725": Phase="Running", Reason="", readiness=true. Elapsed: 2.010885729s
Jul 10 09:00:20.237: INFO: Pod "webserver-deployment-845c8977d9-jv725" satisfied condition "running"
Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-q84n2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011807199s
Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-q84n2" satisfied condition "running"
Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-dzvnf": Phase="Running", Reason="", readiness=true. Elapsed: 2.012386688s
Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-dzvnf" satisfied condition "running"
Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-n85x2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013912763s
Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-n85x2" satisfied condition "running"
Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-f55kl": Phase="Running", Reason="", readiness=true. Elapsed: 2.01404613s
Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-f55kl" satisfied condition "running"
Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-fnd7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.052339961s
Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-fnd7b" satisfied condition "running"
Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-j5kzv": Phase="Running", Reason="", readiness=true. Elapsed: 2.052791244s
Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-j5kzv" satisfied condition "running"
Jul 10 09:00:20.279: INFO: Pod "webserver-deployment-845c8977d9-f8jp2": Phase="Running", Reason="", readiness=true. Elapsed: 2.05296721s
Jul 10 09:00:20.279: INFO: Pod "webserver-deployment-845c8977d9-f8jp2" satisfied condition "running"
Jul 10 09:00:20.279: INFO: Waiting for deployment "webserver-deployment" to complete
Jul 10 09:00:20.286: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jul 10 09:00:20.300: INFO: Updating deployment webserver-deployment
Jul 10 09:00:20.300: INFO: Waiting for observed generation 2
Jul 10 09:00:22.312: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul 10 09:00:22.315: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul 10 09:00:22.319: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jul 10 09:00:22.367: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul 10 09:00:22.367: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul 10 09:00:22.370: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jul 10 09:00:22.380: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jul 10 09:00:22.380: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jul 10 09:00:22.420: INFO: Updating deployment webserver-deployment
Jul 10 09:00:22.420: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jul 10 09:00:22.427: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul 10 09:00:24.485: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 09:00:24.496: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9468  ebded664-d869-45ef-91eb-e3faad283659 92903 3 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00447f488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-07-10 09:00:22 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-07-10 09:00:23 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jul 10 09:00:24.524: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-9468  c63eb41e-4c56-4163-9d3f-8d069613f4a6 92899 3 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ebded664-d869-45ef-91eb-e3faad283659 0xc003ca9b07 0xc003ca9b08}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ebded664-d869-45ef-91eb-e3faad283659\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca9ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:00:24.524: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jul 10 09:00:24.524: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-9468  ac7b7de0-c3ef-461d-b9a9-7c09b211be85 92882 3 2023-07-10 09:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ebded664-d869-45ef-91eb-e3faad283659 0xc003ca9c07 0xc003ca9c08}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ebded664-d869-45ef-91eb-e3faad283659\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca9c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:00:24.540: INFO: Pod "webserver-deployment-69b7448995-5fcj9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5fcj9 webserver-deployment-69b7448995- deployment-9468  28f3d03d-6e11-4f30-8aba-e0a43101b35a 92759 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8e575a70b86254f432c9870a67a25dfa03623ac904134748b87a87398142ab9d cni.projectcalico.org/podIP:192.168.172.18/32 cni.projectcalico.org/podIPs:192.168.172.18/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d421a7 0xc003d421a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-652r4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-652r4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.541: INFO: Pod "webserver-deployment-69b7448995-5xnxp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5xnxp webserver-deployment-69b7448995- deployment-9468  032078dc-9d72-4c93-910d-62e28da5998b 92936 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:a56c947c3afc17330f51b76d89dce42653dc78b46e9885ed452d1530afb48e0d cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d423a7 0xc003d423a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x2bjh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x2bjh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.541: INFO: Pod "webserver-deployment-69b7448995-6h4cx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6h4cx webserver-deployment-69b7448995- deployment-9468  78d2f348-6df3-4a8a-9b5c-beb0f3a94738 92955 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ff9d112e3b594f814f003c4e49c91d472ede96b1b5826eaa34f34862e63b6ea3 cni.projectcalico.org/podIP:192.168.120.49/32 cni.projectcalico.org/podIPs:192.168.120.49/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d425a7 0xc003d425a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b7zhd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b7zhd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.541: INFO: Pod "webserver-deployment-69b7448995-8m5vb" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-8m5vb webserver-deployment-69b7448995- deployment-9468  dfc8fa9b-7ea2-4591-b63c-35a4e82073df 92781 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8c81d8e9ca445fbbbbf4b857eeef16ca734421e5450dd1312e2cdfdc77d20ad7 cni.projectcalico.org/podIP:192.168.172.37/32 cni.projectcalico.org/podIPs:192.168.172.37/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d427a7 0xc003d427a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-grf8q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-grf8q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-9mdnn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9mdnn webserver-deployment-69b7448995- deployment-9468  3a51fec6-1611-40d5-8d64-17cb8cc3d249 92962 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d429a7 0xc003d429a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4jn7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4jn7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-btvsz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-btvsz webserver-deployment-69b7448995- deployment-9468  d13326f7-e6bd-42f1-b6a3-8e6ca5528ccb 92938 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b7077869276fdf24331c63cdd611dab112cc954f709c44dcda1db023ccec8447 cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d42b87 0xc003d42b88}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r456l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r456l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-jmsh9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jmsh9 webserver-deployment-69b7448995- deployment-9468  40ff2f8f-a059-4e55-968d-0532f7d8ce17 92889 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d42d87 0xc003d42d88}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vjswv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vjswv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-psztc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-psztc webserver-deployment-69b7448995- deployment-9468  96310a69-9d6b-4683-a424-9b315108576f 92916 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d42f77 0xc003d42f78}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qxh6p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qxh6p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-s7lbf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-s7lbf webserver-deployment-69b7448995- deployment-9468  d2611bb3-6e00-4960-9013-03d396d1f074 92761 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b9455e60b15945639e26a0a36b0887f22fe837fb5b94dfd80d9913bf8e33f43a cni.projectcalico.org/podIP:192.168.120.41/32 cni.projectcalico.org/podIPs:192.168.120.41/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43157 0xc003d43158}] [] [{kubelet Update v1 2023-07-10 09:00:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwbp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwbp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-txwtg" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-txwtg webserver-deployment-69b7448995- deployment-9468  8a164ab9-ba7d-422f-89ba-c534c7675df6 92952 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d2eef665fe8ea6b04d60ad1fce6575925191c54cbebf3de5a078ed18586237bd cni.projectcalico.org/podIP:192.168.103.66/32 cni.projectcalico.org/podIPs:192.168.103.66/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43347 0xc003d43348}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dcr92,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dcr92,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-vdgst" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-vdgst webserver-deployment-69b7448995- deployment-9468  9fa450de-8c7c-4417-9831-ddf9ac8044f0 92941 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43547 0xc003d43548}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w7jpq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w7jpq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-xbfzw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xbfzw webserver-deployment-69b7448995- deployment-9468  739eaee1-ffa1-42c8-9eaf-a3a48dc16787 92958 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43727 0xc003d43728}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lgbbb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lgbbb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-zvf7b" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zvf7b webserver-deployment-69b7448995- deployment-9468  4155968a-c196-468a-baaa-2009cbcc3869 92875 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43907 0xc003d43908}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8829r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8829r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-22dnf" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-22dnf webserver-deployment-845c8977d9- deployment-9468  0baf4f17-65de-4eea-bd51-9bc3029d277e 92870 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43a70 0xc003d43a71}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-psqlh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-psqlh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-46gtn" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-46gtn webserver-deployment-845c8977d9- deployment-9468  67c7af4d-00c0-42ec-863c-70946792c49b 92893 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43bc0 0xc003d43bc1}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qn2ff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qn2ff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-4bfmr" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4bfmr webserver-deployment-845c8977d9- deployment-9468  a3cdf192-1605-4a19-b3e2-26fffa03a22c 92885 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43d77 0xc003d43d78}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xsbf8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xsbf8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-b95n5" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b95n5 webserver-deployment-845c8977d9- deployment-9468  cae9ed94-64df-4434-be59-fc2809e054db 92917 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43f37 0xc003d43f38}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xjbcq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xjbcq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-dzvnf" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dzvnf webserver-deployment-845c8977d9- deployment-9468  a7c6f914-86d6-48d0-acd6-49b1cf7dbd6b 92679 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9710110775ff8bc58c1bfa0de499572ad8b6b824d43ffc2a37445479d1355033 cni.projectcalico.org/podIP:192.168.120.11/32 cni.projectcalico.org/podIPs:192.168.120.11/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a80f7 0xc0038a80f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkr8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkr8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.11,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://86b228eb2e0a55b0bfd41f2adaf107127a7f95c02c16b6874c74d706d5bd10c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-f8jp2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-f8jp2 webserver-deployment-845c8977d9- deployment-9468  9d9159ac-4481-47b4-a47b-a43eb6381df9 92681 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:80fad5bb038fdff607daef8f578bfc7bc3d6d74989c9426ebe8c955d56ff2811 cni.projectcalico.org/podIP:192.168.120.32/32 cni.projectcalico.org/podIPs:192.168.120.32/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a82f7 0xc0038a82f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rctqs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rctqs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.32,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://bcac14eeda51c1918634359e2987cff1ff095ab10df9f6dd377b4d1f5ea94119,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-fnd7b" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fnd7b webserver-deployment-845c8977d9- deployment-9468  22cb0b21-8e0a-4d45-b5c4-190a7dc86120 92676 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8bc08593bbe3314b5dc9818b752eab3c11ea1d5c8b26cd531d06c542f352990e cni.projectcalico.org/podIP:192.168.120.27/32 cni.projectcalico.org/podIPs:192.168.120.27/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a84f7 0xc0038a84f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4vsv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4vsv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.27,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://c95065be7b744959fe0e9546b85e5fefb762411f87b215eba480f6477395075d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-gfs2h" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gfs2h webserver-deployment-845c8977d9- deployment-9468  072d7c0e-248a-49ad-bda5-43ba5578e2e8 92954 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:86af0461a16c8d5cd2e5fe7a2ed62ec1a572757930bd995e4bd61eb85838afcb cni.projectcalico.org/podIP:192.168.172.62/32 cni.projectcalico.org/podIPs:192.168.172.62/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a86f7 0xc0038a86f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-647l8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-647l8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.546: INFO: Pod "webserver-deployment-845c8977d9-h22vk" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-h22vk webserver-deployment-845c8977d9- deployment-9468  9d41ca39-4bb1-4d03-b2f6-a4e855758770 92854 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a88d7 0xc0038a88d8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gsc24,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gsc24,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.546: INFO: Pod "webserver-deployment-845c8977d9-j5kzv" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-j5kzv webserver-deployment-845c8977d9- deployment-9468  5891499a-b26e-4c57-8e3d-0723d7114bda 92671 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:54a24c6f66a2ef3f6276a8457cdecf2fa0c8ce379f9d644aca091e96d1b9cb48 cni.projectcalico.org/podIP:192.168.172.45/32 cni.projectcalico.org/podIPs:192.168.172.45/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a8a97 0xc0038a8a98}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.45\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zgmdv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zgmdv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.45,StartTime:2023-07-10 09:00:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://9b77a7a856299a04ee22fa94268a19ea93bba19a1d57403841d5e54deb0476d1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.45,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.546: INFO: Pod "webserver-deployment-845c8977d9-jv725" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-jv725 webserver-deployment-845c8977d9- deployment-9468  e294e540-eab5-4966-9a72-b36847fa6d00 92667 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6bf112bd9ed13b2269845e3d1404c2af61ec6507839681923ecc4200fa162227 cni.projectcalico.org/podIP:192.168.172.38/32 cni.projectcalico.org/podIPs:192.168.172.38/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a8c97 0xc0038a8c98}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.38\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r92h7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r92h7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.38,StartTime:2023-07-10 09:00:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://182f1836db816529d658afa1f91d5be18262b9e6bb074f2cff009f0fd21690d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.38,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-n85x2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-n85x2 webserver-deployment-845c8977d9- deployment-9468  06eaec3a-8f99-4c0e-90dd-5eea35a728db 92665 0 2023-07-10 09:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:2211edf44b0eb41597e9b6b00d6e3a7d294be5e5805dad430a59d2d29fd9b733 cni.projectcalico.org/podIP:192.168.172.33/32 cni.projectcalico.org/podIPs:192.168.172.33/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a8e97 0xc0038a8e98}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.33\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sgqbc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sgqbc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.33,StartTime:2023-07-10 09:00:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://4f8800bad9522b24494ae7e43f1d4dfbb80b0ef5e50c331a897a699de5ac04d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-qsrs2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qsrs2 webserver-deployment-845c8977d9- deployment-9468  4d061ca8-8727-41ad-bf3a-e049d7e5a411 92657 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f4871a9e12b8f220aeba9bad38e20ec078dfc284ec1aaefdb016fea886ba2cb8 cni.projectcalico.org/podIP:192.168.103.90/32 cni.projectcalico.org/podIPs:192.168.103.90/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9097 0xc0038a9098}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.90\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2zjx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2zjx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:192.168.103.90,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://8df6bae7d29b4c4a654356758a9bf02b8cd199e238bb7e9a6e582f6d66757143,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.103.90,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-s9t57" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-s9t57 webserver-deployment-845c8977d9- deployment-9468  3f063a6e-7c3c-46c2-8aeb-842e9516001c 92886 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9297 0xc0038a9298}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f6nnr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f6nnr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-slvvw" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-slvvw webserver-deployment-845c8977d9- deployment-9468  e963fff7-2985-45dd-b702-a921a2138e13 92880 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9457 0xc0038a9458}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-97l6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-97l6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-t87qf" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-t87qf webserver-deployment-845c8977d9- deployment-9468  8788f50c-db8a-428c-9af6-c04b2e399f98 92934 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9617 0xc0038a9618}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtwgz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtwgz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-wvr84" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wvr84 webserver-deployment-845c8977d9- deployment-9468  683a7c06-cb63-4462-b251-3019eecdc873 92924 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a97d7 0xc0038a97d8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtd2k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtd2k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-x8mn9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-x8mn9 webserver-deployment-845c8977d9- deployment-9468  d0892581-92ac-471c-930e-12b248ed2a63 92861 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a99a7 0xc0038a99a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lddkn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lddkn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-xsgzc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xsgzc webserver-deployment-845c8977d9- deployment-9468  5c8cb27c-120d-40bc-ae46-b2f41b67f6c0 92937 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9b67 0xc0038a9b68}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8pfvq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8pfvq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-zqxt5" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zqxt5 webserver-deployment-845c8977d9- deployment-9468  608bbf9e-959a-425b-8b63-17f1f2117efd 92649 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9d42dc69c4b1d0453a0e18a62b8693bc3bae220976bc1e1f4740bbd700cee708 cni.projectcalico.org/podIP:192.168.103.121/32 cni.projectcalico.org/podIPs:192.168.103.121/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9d27 0xc0038a9d28}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.121\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n6ktx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n6ktx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:192.168.103.121,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://12f5c60611f027d85cf8d1a717d49f3fd0389acf0e2e0943f9b345d3dc05e9d8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.103.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 09:00:24.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9468" for this suite. 07/10/23 09:00:24.554
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":213,"skipped":4182,"failed":0}
------------------------------
• [SLOW TEST] [8.454 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:16.148
    Jul 10 09:00:16.148: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 09:00:16.149
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:16.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:16.18
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Jul 10 09:00:16.182: INFO: Creating deployment "webserver-deployment"
    Jul 10 09:00:16.192: INFO: Waiting for observed generation 1
    Jul 10 09:00:18.219: INFO: Waiting for all required pods to come up
    Jul 10 09:00:18.225: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 07/10/23 09:00:18.225
    Jul 10 09:00:18.225: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-dzvnf" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.225: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-j5kzv" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f8jp2" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fnd7b" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f55kl" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-n85x2" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-q84n2" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.226: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-jv725" in namespace "deployment-9468" to be "running"
    Jul 10 09:00:18.231: INFO: Pod "webserver-deployment-845c8977d9-dzvnf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.239916ms
    Jul 10 09:00:18.231: INFO: Pod "webserver-deployment-845c8977d9-f55kl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.225759ms
    Jul 10 09:00:18.231: INFO: Pod "webserver-deployment-845c8977d9-q84n2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.367431ms
    Jul 10 09:00:18.232: INFO: Pod "webserver-deployment-845c8977d9-n85x2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.565166ms
    Jul 10 09:00:18.232: INFO: Pod "webserver-deployment-845c8977d9-jv725": Phase="Pending", Reason="", readiness=false. Elapsed: 6.566304ms
    Jul 10 09:00:18.274: INFO: Pod "webserver-deployment-845c8977d9-j5kzv": Phase="Pending", Reason="", readiness=false. Elapsed: 48.323065ms
    Jul 10 09:00:18.274: INFO: Pod "webserver-deployment-845c8977d9-fnd7b": Phase="Pending", Reason="", readiness=false. Elapsed: 48.314004ms
    Jul 10 09:00:18.274: INFO: Pod "webserver-deployment-845c8977d9-f8jp2": Phase="Pending", Reason="", readiness=false. Elapsed: 48.694829ms
    Jul 10 09:00:20.237: INFO: Pod "webserver-deployment-845c8977d9-jv725": Phase="Running", Reason="", readiness=true. Elapsed: 2.010885729s
    Jul 10 09:00:20.237: INFO: Pod "webserver-deployment-845c8977d9-jv725" satisfied condition "running"
    Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-q84n2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011807199s
    Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-q84n2" satisfied condition "running"
    Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-dzvnf": Phase="Running", Reason="", readiness=true. Elapsed: 2.012386688s
    Jul 10 09:00:20.238: INFO: Pod "webserver-deployment-845c8977d9-dzvnf" satisfied condition "running"
    Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-n85x2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013912763s
    Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-n85x2" satisfied condition "running"
    Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-f55kl": Phase="Running", Reason="", readiness=true. Elapsed: 2.01404613s
    Jul 10 09:00:20.240: INFO: Pod "webserver-deployment-845c8977d9-f55kl" satisfied condition "running"
    Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-fnd7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.052339961s
    Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-fnd7b" satisfied condition "running"
    Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-j5kzv": Phase="Running", Reason="", readiness=true. Elapsed: 2.052791244s
    Jul 10 09:00:20.278: INFO: Pod "webserver-deployment-845c8977d9-j5kzv" satisfied condition "running"
    Jul 10 09:00:20.279: INFO: Pod "webserver-deployment-845c8977d9-f8jp2": Phase="Running", Reason="", readiness=true. Elapsed: 2.05296721s
    Jul 10 09:00:20.279: INFO: Pod "webserver-deployment-845c8977d9-f8jp2" satisfied condition "running"
    Jul 10 09:00:20.279: INFO: Waiting for deployment "webserver-deployment" to complete
    Jul 10 09:00:20.286: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Jul 10 09:00:20.300: INFO: Updating deployment webserver-deployment
    Jul 10 09:00:20.300: INFO: Waiting for observed generation 2
    Jul 10 09:00:22.312: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Jul 10 09:00:22.315: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Jul 10 09:00:22.319: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Jul 10 09:00:22.367: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Jul 10 09:00:22.367: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Jul 10 09:00:22.370: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Jul 10 09:00:22.380: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Jul 10 09:00:22.380: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Jul 10 09:00:22.420: INFO: Updating deployment webserver-deployment
    Jul 10 09:00:22.420: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Jul 10 09:00:22.427: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Jul 10 09:00:24.485: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 09:00:24.496: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-9468  ebded664-d869-45ef-91eb-e3faad283659 92903 3 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00447f488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-07-10 09:00:22 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-07-10 09:00:23 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Jul 10 09:00:24.524: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-9468  c63eb41e-4c56-4163-9d3f-8d069613f4a6 92899 3 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ebded664-d869-45ef-91eb-e3faad283659 0xc003ca9b07 0xc003ca9b08}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ebded664-d869-45ef-91eb-e3faad283659\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca9ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:00:24.524: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Jul 10 09:00:24.524: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-9468  ac7b7de0-c3ef-461d-b9a9-7c09b211be85 92882 3 2023-07-10 09:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ebded664-d869-45ef-91eb-e3faad283659 0xc003ca9c07 0xc003ca9c08}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ebded664-d869-45ef-91eb-e3faad283659\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ca9c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:00:24.540: INFO: Pod "webserver-deployment-69b7448995-5fcj9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5fcj9 webserver-deployment-69b7448995- deployment-9468  28f3d03d-6e11-4f30-8aba-e0a43101b35a 92759 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8e575a70b86254f432c9870a67a25dfa03623ac904134748b87a87398142ab9d cni.projectcalico.org/podIP:192.168.172.18/32 cni.projectcalico.org/podIPs:192.168.172.18/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d421a7 0xc003d421a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-652r4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-652r4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.541: INFO: Pod "webserver-deployment-69b7448995-5xnxp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5xnxp webserver-deployment-69b7448995- deployment-9468  032078dc-9d72-4c93-910d-62e28da5998b 92936 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:a56c947c3afc17330f51b76d89dce42653dc78b46e9885ed452d1530afb48e0d cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d423a7 0xc003d423a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x2bjh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x2bjh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.541: INFO: Pod "webserver-deployment-69b7448995-6h4cx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6h4cx webserver-deployment-69b7448995- deployment-9468  78d2f348-6df3-4a8a-9b5c-beb0f3a94738 92955 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ff9d112e3b594f814f003c4e49c91d472ede96b1b5826eaa34f34862e63b6ea3 cni.projectcalico.org/podIP:192.168.120.49/32 cni.projectcalico.org/podIPs:192.168.120.49/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d425a7 0xc003d425a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b7zhd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b7zhd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.541: INFO: Pod "webserver-deployment-69b7448995-8m5vb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-8m5vb webserver-deployment-69b7448995- deployment-9468  dfc8fa9b-7ea2-4591-b63c-35a4e82073df 92781 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8c81d8e9ca445fbbbbf4b857eeef16ca734421e5450dd1312e2cdfdc77d20ad7 cni.projectcalico.org/podIP:192.168.172.37/32 cni.projectcalico.org/podIPs:192.168.172.37/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d427a7 0xc003d427a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-grf8q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-grf8q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-9mdnn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9mdnn webserver-deployment-69b7448995- deployment-9468  3a51fec6-1611-40d5-8d64-17cb8cc3d249 92962 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d429a7 0xc003d429a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4jn7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4jn7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-btvsz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-btvsz webserver-deployment-69b7448995- deployment-9468  d13326f7-e6bd-42f1-b6a3-8e6ca5528ccb 92938 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b7077869276fdf24331c63cdd611dab112cc954f709c44dcda1db023ccec8447 cni.projectcalico.org/podIP: cni.projectcalico.org/podIPs:] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d42b87 0xc003d42b88}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r456l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r456l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-jmsh9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jmsh9 webserver-deployment-69b7448995- deployment-9468  40ff2f8f-a059-4e55-968d-0532f7d8ce17 92889 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d42d87 0xc003d42d88}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vjswv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vjswv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.542: INFO: Pod "webserver-deployment-69b7448995-psztc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-psztc webserver-deployment-69b7448995- deployment-9468  96310a69-9d6b-4683-a424-9b315108576f 92916 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d42f77 0xc003d42f78}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qxh6p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qxh6p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-s7lbf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-s7lbf webserver-deployment-69b7448995- deployment-9468  d2611bb3-6e00-4960-9013-03d396d1f074 92761 0 2023-07-10 09:00:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b9455e60b15945639e26a0a36b0887f22fe837fb5b94dfd80d9913bf8e33f43a cni.projectcalico.org/podIP:192.168.120.41/32 cni.projectcalico.org/podIPs:192.168.120.41/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43157 0xc003d43158}] [] [{kubelet Update v1 2023-07-10 09:00:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-07-10 09:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwbp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwbp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-txwtg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-txwtg webserver-deployment-69b7448995- deployment-9468  8a164ab9-ba7d-422f-89ba-c534c7675df6 92952 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d2eef665fe8ea6b04d60ad1fce6575925191c54cbebf3de5a078ed18586237bd cni.projectcalico.org/podIP:192.168.103.66/32 cni.projectcalico.org/podIPs:192.168.103.66/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43347 0xc003d43348}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dcr92,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dcr92,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-vdgst" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-vdgst webserver-deployment-69b7448995- deployment-9468  9fa450de-8c7c-4417-9831-ddf9ac8044f0 92941 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43547 0xc003d43548}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w7jpq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w7jpq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-xbfzw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xbfzw webserver-deployment-69b7448995- deployment-9468  739eaee1-ffa1-42c8-9eaf-a3a48dc16787 92958 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43727 0xc003d43728}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lgbbb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lgbbb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.543: INFO: Pod "webserver-deployment-69b7448995-zvf7b" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zvf7b webserver-deployment-69b7448995- deployment-9468  4155968a-c196-468a-baaa-2009cbcc3869 92875 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 c63eb41e-4c56-4163-9d3f-8d069613f4a6 0xc003d43907 0xc003d43908}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c63eb41e-4c56-4163-9d3f-8d069613f4a6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8829r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8829r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-22dnf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-22dnf webserver-deployment-845c8977d9- deployment-9468  0baf4f17-65de-4eea-bd51-9bc3029d277e 92870 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43a70 0xc003d43a71}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-psqlh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-psqlh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-46gtn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-46gtn webserver-deployment-845c8977d9- deployment-9468  67c7af4d-00c0-42ec-863c-70946792c49b 92893 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43bc0 0xc003d43bc1}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qn2ff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qn2ff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-4bfmr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4bfmr webserver-deployment-845c8977d9- deployment-9468  a3cdf192-1605-4a19-b3e2-26fffa03a22c 92885 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43d77 0xc003d43d78}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xsbf8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xsbf8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.544: INFO: Pod "webserver-deployment-845c8977d9-b95n5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b95n5 webserver-deployment-845c8977d9- deployment-9468  cae9ed94-64df-4434-be59-fc2809e054db 92917 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc003d43f37 0xc003d43f38}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xjbcq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xjbcq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-dzvnf" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dzvnf webserver-deployment-845c8977d9- deployment-9468  a7c6f914-86d6-48d0-acd6-49b1cf7dbd6b 92679 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9710110775ff8bc58c1bfa0de499572ad8b6b824d43ffc2a37445479d1355033 cni.projectcalico.org/podIP:192.168.120.11/32 cni.projectcalico.org/podIPs:192.168.120.11/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a80f7 0xc0038a80f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkr8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkr8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.11,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://86b228eb2e0a55b0bfd41f2adaf107127a7f95c02c16b6874c74d706d5bd10c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-f8jp2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-f8jp2 webserver-deployment-845c8977d9- deployment-9468  9d9159ac-4481-47b4-a47b-a43eb6381df9 92681 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:80fad5bb038fdff607daef8f578bfc7bc3d6d74989c9426ebe8c955d56ff2811 cni.projectcalico.org/podIP:192.168.120.32/32 cni.projectcalico.org/podIPs:192.168.120.32/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a82f7 0xc0038a82f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rctqs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rctqs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.32,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://bcac14eeda51c1918634359e2987cff1ff095ab10df9f6dd377b4d1f5ea94119,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-fnd7b" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fnd7b webserver-deployment-845c8977d9- deployment-9468  22cb0b21-8e0a-4d45-b5c4-190a7dc86120 92676 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8bc08593bbe3314b5dc9818b752eab3c11ea1d5c8b26cd531d06c542f352990e cni.projectcalico.org/podIP:192.168.120.27/32 cni.projectcalico.org/podIPs:192.168.120.27/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a84f7 0xc0038a84f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.120.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4vsv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4vsv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:192.168.120.27,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://c95065be7b744959fe0e9546b85e5fefb762411f87b215eba480f6477395075d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.120.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.545: INFO: Pod "webserver-deployment-845c8977d9-gfs2h" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gfs2h webserver-deployment-845c8977d9- deployment-9468  072d7c0e-248a-49ad-bda5-43ba5578e2e8 92954 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:86af0461a16c8d5cd2e5fe7a2ed62ec1a572757930bd995e4bd61eb85838afcb cni.projectcalico.org/podIP:192.168.172.62/32 cni.projectcalico.org/podIPs:192.168.172.62/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a86f7 0xc0038a86f8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-07-10 09:00:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-647l8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-647l8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.546: INFO: Pod "webserver-deployment-845c8977d9-h22vk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-h22vk webserver-deployment-845c8977d9- deployment-9468  9d41ca39-4bb1-4d03-b2f6-a4e855758770 92854 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a88d7 0xc0038a88d8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gsc24,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gsc24,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.546: INFO: Pod "webserver-deployment-845c8977d9-j5kzv" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-j5kzv webserver-deployment-845c8977d9- deployment-9468  5891499a-b26e-4c57-8e3d-0723d7114bda 92671 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:54a24c6f66a2ef3f6276a8457cdecf2fa0c8ce379f9d644aca091e96d1b9cb48 cni.projectcalico.org/podIP:192.168.172.45/32 cni.projectcalico.org/podIPs:192.168.172.45/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a8a97 0xc0038a8a98}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.45\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zgmdv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zgmdv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.45,StartTime:2023-07-10 09:00:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://9b77a7a856299a04ee22fa94268a19ea93bba19a1d57403841d5e54deb0476d1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.45,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.546: INFO: Pod "webserver-deployment-845c8977d9-jv725" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-jv725 webserver-deployment-845c8977d9- deployment-9468  e294e540-eab5-4966-9a72-b36847fa6d00 92667 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6bf112bd9ed13b2269845e3d1404c2af61ec6507839681923ecc4200fa162227 cni.projectcalico.org/podIP:192.168.172.38/32 cni.projectcalico.org/podIPs:192.168.172.38/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a8c97 0xc0038a8c98}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.38\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r92h7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r92h7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.38,StartTime:2023-07-10 09:00:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://182f1836db816529d658afa1f91d5be18262b9e6bb074f2cff009f0fd21690d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.38,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-n85x2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-n85x2 webserver-deployment-845c8977d9- deployment-9468  06eaec3a-8f99-4c0e-90dd-5eea35a728db 92665 0 2023-07-10 09:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:2211edf44b0eb41597e9b6b00d6e3a7d294be5e5805dad430a59d2d29fd9b733 cni.projectcalico.org/podIP:192.168.172.33/32 cni.projectcalico.org/podIPs:192.168.172.33/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a8e97 0xc0038a8e98}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.33\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sgqbc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sgqbc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.33,StartTime:2023-07-10 09:00:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://4f8800bad9522b24494ae7e43f1d4dfbb80b0ef5e50c331a897a699de5ac04d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-qsrs2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qsrs2 webserver-deployment-845c8977d9- deployment-9468  4d061ca8-8727-41ad-bf3a-e049d7e5a411 92657 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f4871a9e12b8f220aeba9bad38e20ec078dfc284ec1aaefdb016fea886ba2cb8 cni.projectcalico.org/podIP:192.168.103.90/32 cni.projectcalico.org/podIPs:192.168.103.90/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9097 0xc0038a9098}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.90\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2zjx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2zjx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:192.168.103.90,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://8df6bae7d29b4c4a654356758a9bf02b8cd199e238bb7e9a6e582f6d66757143,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.103.90,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-s9t57" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-s9t57 webserver-deployment-845c8977d9- deployment-9468  3f063a6e-7c3c-46c2-8aeb-842e9516001c 92886 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9297 0xc0038a9298}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f6nnr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f6nnr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-slvvw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-slvvw webserver-deployment-845c8977d9- deployment-9468  e963fff7-2985-45dd-b702-a921a2138e13 92880 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9457 0xc0038a9458}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-97l6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-97l6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.547: INFO: Pod "webserver-deployment-845c8977d9-t87qf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-t87qf webserver-deployment-845c8977d9- deployment-9468  8788f50c-db8a-428c-9af6-c04b2e399f98 92934 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9617 0xc0038a9618}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtwgz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtwgz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-wvr84" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wvr84 webserver-deployment-845c8977d9- deployment-9468  683a7c06-cb63-4462-b251-3019eecdc873 92924 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a97d7 0xc0038a97d8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtd2k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtd2k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-x8mn9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-x8mn9 webserver-deployment-845c8977d9- deployment-9468  d0892581-92ac-471c-930e-12b248ed2a63 92861 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a99a7 0xc0038a99a8}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lddkn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lddkn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-102.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.102,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-xsgzc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xsgzc webserver-deployment-845c8977d9- deployment-9468  5c8cb27c-120d-40bc-ae46-b2f41b67f6c0 92937 0 2023-07-10 09:00:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9b67 0xc0038a9b68}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:00:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8pfvq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8pfvq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:,StartTime:2023-07-10 09:00:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:00:24.548: INFO: Pod "webserver-deployment-845c8977d9-zqxt5" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zqxt5 webserver-deployment-845c8977d9- deployment-9468  608bbf9e-959a-425b-8b63-17f1f2117efd 92649 0 2023-07-10 09:00:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9d42dc69c4b1d0453a0e18a62b8693bc3bae220976bc1e1f4740bbd700cee708 cni.projectcalico.org/podIP:192.168.103.121/32 cni.projectcalico.org/podIPs:192.168.103.121/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 ac7b7de0-c3ef-461d-b9a9-7c09b211be85 0xc0038a9d27 0xc0038a9d28}] [] [{kube-controller-manager Update v1 2023-07-10 09:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac7b7de0-c3ef-461d-b9a9-7c09b211be85\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:00:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.103.121\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n6ktx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n6ktx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-101.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.101,PodIP:192.168.103.121,StartTime:2023-07-10 09:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:00:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://12f5c60611f027d85cf8d1a717d49f3fd0389acf0e2e0943f9b345d3dc05e9d8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.103.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 09:00:24.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9468" for this suite. 07/10/23 09:00:24.554
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:24.611
Jul 10 09:00:24.611: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:00:24.612
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:24.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:24.754
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Jul 10 09:00:24.761: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 07/10/23 09:00:28.062
Jul 10 09:00:28.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 create -f -'
Jul 10 09:00:28.795: INFO: stderr: ""
Jul 10 09:00:28.795: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jul 10 09:00:28.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 delete e2e-test-crd-publish-openapi-3108-crds test-cr'
Jul 10 09:00:28.968: INFO: stderr: ""
Jul 10 09:00:28.968: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jul 10 09:00:28.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 apply -f -'
Jul 10 09:00:29.311: INFO: stderr: ""
Jul 10 09:00:29.311: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jul 10 09:00:29.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 delete e2e-test-crd-publish-openapi-3108-crds test-cr'
Jul 10 09:00:29.415: INFO: stderr: ""
Jul 10 09:00:29.415: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 07/10/23 09:00:29.415
Jul 10 09:00:29.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 explain e2e-test-crd-publish-openapi-3108-crds'
Jul 10 09:00:29.688: INFO: stderr: ""
Jul 10 09:00:29.688: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3108-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:00:34.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2577" for this suite. 07/10/23 09:00:34.407
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":214,"skipped":4226,"failed":0}
------------------------------
• [SLOW TEST] [9.806 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:24.611
    Jul 10 09:00:24.611: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:00:24.612
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:24.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:24.754
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Jul 10 09:00:24.761: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 07/10/23 09:00:28.062
    Jul 10 09:00:28.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 create -f -'
    Jul 10 09:00:28.795: INFO: stderr: ""
    Jul 10 09:00:28.795: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Jul 10 09:00:28.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 delete e2e-test-crd-publish-openapi-3108-crds test-cr'
    Jul 10 09:00:28.968: INFO: stderr: ""
    Jul 10 09:00:28.968: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Jul 10 09:00:28.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 apply -f -'
    Jul 10 09:00:29.311: INFO: stderr: ""
    Jul 10 09:00:29.311: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Jul 10 09:00:29.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 --namespace=crd-publish-openapi-2577 delete e2e-test-crd-publish-openapi-3108-crds test-cr'
    Jul 10 09:00:29.415: INFO: stderr: ""
    Jul 10 09:00:29.415: INFO: stdout: "e2e-test-crd-publish-openapi-3108-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 07/10/23 09:00:29.415
    Jul 10 09:00:29.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-2577 explain e2e-test-crd-publish-openapi-3108-crds'
    Jul 10 09:00:29.688: INFO: stderr: ""
    Jul 10 09:00:29.688: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3108-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:00:34.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2577" for this suite. 07/10/23 09:00:34.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:34.418
Jul 10 09:00:34.418: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:00:34.419
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:34.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:34.46
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-c2599e44-68a5-4960-a3b5-0924df03bf12 07/10/23 09:00:34.463
STEP: Creating a pod to test consume configMaps 07/10/23 09:00:34.472
Jul 10 09:00:34.567: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b" in namespace "configmap-4025" to be "Succeeded or Failed"
Jul 10 09:00:34.570: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204894ms
Jul 10 09:00:36.577: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010081576s
Jul 10 09:00:38.576: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008623237s
STEP: Saw pod success 07/10/23 09:00:38.576
Jul 10 09:00:38.576: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b" satisfied condition "Succeeded or Failed"
Jul 10 09:00:38.579: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b container configmap-volume-test: <nil>
STEP: delete the pod 07/10/23 09:00:38.6
Jul 10 09:00:38.619: INFO: Waiting for pod pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b to disappear
Jul 10 09:00:38.623: INFO: Pod pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:00:38.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4025" for this suite. 07/10/23 09:00:38.627
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":215,"skipped":4243,"failed":0}
------------------------------
• [4.257 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:34.418
    Jul 10 09:00:34.418: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:00:34.419
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:34.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:34.46
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-c2599e44-68a5-4960-a3b5-0924df03bf12 07/10/23 09:00:34.463
    STEP: Creating a pod to test consume configMaps 07/10/23 09:00:34.472
    Jul 10 09:00:34.567: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b" in namespace "configmap-4025" to be "Succeeded or Failed"
    Jul 10 09:00:34.570: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204894ms
    Jul 10 09:00:36.577: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010081576s
    Jul 10 09:00:38.576: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008623237s
    STEP: Saw pod success 07/10/23 09:00:38.576
    Jul 10 09:00:38.576: INFO: Pod "pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b" satisfied condition "Succeeded or Failed"
    Jul 10 09:00:38.579: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b container configmap-volume-test: <nil>
    STEP: delete the pod 07/10/23 09:00:38.6
    Jul 10 09:00:38.619: INFO: Waiting for pod pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b to disappear
    Jul 10 09:00:38.623: INFO: Pod pod-configmaps-9b06f1c5-338b-4126-9811-ff234e45b60b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:00:38.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4025" for this suite. 07/10/23 09:00:38.627
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:38.678
Jul 10 09:00:38.678: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubelet-test 07/10/23 09:00:38.679
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:38.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:38.714
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Jul 10 09:00:38.734: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db" in namespace "kubelet-test-7718" to be "running and ready"
Jul 10 09:00:38.743: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db": Phase="Pending", Reason="", readiness=false. Elapsed: 9.146748ms
Jul 10 09:00:38.743: INFO: The phase of Pod busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:00:40.748: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014603262s
Jul 10 09:00:40.749: INFO: The phase of Pod busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:00:42.750: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db": Phase="Running", Reason="", readiness=true. Elapsed: 4.016280372s
Jul 10 09:00:42.750: INFO: The phase of Pod busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db is Running (Ready = true)
Jul 10 09:00:42.750: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jul 10 09:00:42.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7718" for this suite. 07/10/23 09:00:42.769
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":216,"skipped":4288,"failed":0}
------------------------------
• [4.102 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:38.678
    Jul 10 09:00:38.678: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubelet-test 07/10/23 09:00:38.679
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:38.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:38.714
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Jul 10 09:00:38.734: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db" in namespace "kubelet-test-7718" to be "running and ready"
    Jul 10 09:00:38.743: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db": Phase="Pending", Reason="", readiness=false. Elapsed: 9.146748ms
    Jul 10 09:00:38.743: INFO: The phase of Pod busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:00:40.748: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014603262s
    Jul 10 09:00:40.749: INFO: The phase of Pod busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:00:42.750: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db": Phase="Running", Reason="", readiness=true. Elapsed: 4.016280372s
    Jul 10 09:00:42.750: INFO: The phase of Pod busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db is Running (Ready = true)
    Jul 10 09:00:42.750: INFO: Pod "busybox-readonly-fs192c9418-c682-4597-97ab-7a7360da31db" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jul 10 09:00:42.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7718" for this suite. 07/10/23 09:00:42.769
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:42.781
Jul 10 09:00:42.781: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 09:00:42.782
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:42.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:42.812
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 07/10/23 09:00:42.815
Jul 10 09:00:42.826: INFO: Waiting up to 5m0s for pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e" in namespace "emptydir-6126" to be "Succeeded or Failed"
Jul 10 09:00:42.830: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.172974ms
Jul 10 09:00:44.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009429188s
Jul 10 09:00:46.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009861453s
Jul 10 09:00:48.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009510152s
STEP: Saw pod success 07/10/23 09:00:48.835
Jul 10 09:00:48.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e" satisfied condition "Succeeded or Failed"
Jul 10 09:00:48.839: INFO: Trying to get logs from node 10-62-109-100.test pod pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e container test-container: <nil>
STEP: delete the pod 07/10/23 09:00:48.849
Jul 10 09:00:48.868: INFO: Waiting for pod pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e to disappear
Jul 10 09:00:48.878: INFO: Pod pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 09:00:48.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6126" for this suite. 07/10/23 09:00:48.881
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":217,"skipped":4301,"failed":0}
------------------------------
• [SLOW TEST] [6.109 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:42.781
    Jul 10 09:00:42.781: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 09:00:42.782
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:42.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:42.812
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 07/10/23 09:00:42.815
    Jul 10 09:00:42.826: INFO: Waiting up to 5m0s for pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e" in namespace "emptydir-6126" to be "Succeeded or Failed"
    Jul 10 09:00:42.830: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.172974ms
    Jul 10 09:00:44.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009429188s
    Jul 10 09:00:46.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009861453s
    Jul 10 09:00:48.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009510152s
    STEP: Saw pod success 07/10/23 09:00:48.835
    Jul 10 09:00:48.835: INFO: Pod "pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e" satisfied condition "Succeeded or Failed"
    Jul 10 09:00:48.839: INFO: Trying to get logs from node 10-62-109-100.test pod pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e container test-container: <nil>
    STEP: delete the pod 07/10/23 09:00:48.849
    Jul 10 09:00:48.868: INFO: Waiting for pod pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e to disappear
    Jul 10 09:00:48.878: INFO: Pod pod-67b6de3e-d491-4314-b9cf-025ec6a9d25e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 09:00:48.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6126" for this suite. 07/10/23 09:00:48.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:48.893
Jul 10 09:00:48.894: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:00:48.894
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:48.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:48.929
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 07/10/23 09:00:48.931
Jul 10 09:00:48.943: INFO: Waiting up to 5m0s for pod "pod-g59rw" in namespace "pods-2005" to be "running"
Jul 10 09:00:48.947: INFO: Pod "pod-g59rw": Phase="Pending", Reason="", readiness=false. Elapsed: 3.407883ms
Jul 10 09:00:50.953: INFO: Pod "pod-g59rw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009518576s
Jul 10 09:00:52.951: INFO: Pod "pod-g59rw": Phase="Running", Reason="", readiness=true. Elapsed: 4.008005193s
Jul 10 09:00:52.951: INFO: Pod "pod-g59rw" satisfied condition "running"
STEP: patching /status 07/10/23 09:00:52.951
Jul 10 09:00:52.964: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 09:00:52.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2005" for this suite. 07/10/23 09:00:52.97
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":218,"skipped":4360,"failed":0}
------------------------------
• [4.096 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:48.893
    Jul 10 09:00:48.894: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:00:48.894
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:48.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:48.929
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 07/10/23 09:00:48.931
    Jul 10 09:00:48.943: INFO: Waiting up to 5m0s for pod "pod-g59rw" in namespace "pods-2005" to be "running"
    Jul 10 09:00:48.947: INFO: Pod "pod-g59rw": Phase="Pending", Reason="", readiness=false. Elapsed: 3.407883ms
    Jul 10 09:00:50.953: INFO: Pod "pod-g59rw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009518576s
    Jul 10 09:00:52.951: INFO: Pod "pod-g59rw": Phase="Running", Reason="", readiness=true. Elapsed: 4.008005193s
    Jul 10 09:00:52.951: INFO: Pod "pod-g59rw" satisfied condition "running"
    STEP: patching /status 07/10/23 09:00:52.951
    Jul 10 09:00:52.964: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 09:00:52.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2005" for this suite. 07/10/23 09:00:52.97
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:00:52.99
Jul 10 09:00:52.990: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 09:00:52.991
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:53.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:53.034
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 07/10/23 09:00:53.036
STEP: delete the rc 07/10/23 09:00:58.052
STEP: wait for all pods to be garbage collected 07/10/23 09:00:58.066
STEP: Gathering metrics 07/10/23 09:01:03.075
W0710 09:01:03.083490      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul 10 09:01:03.083: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 09:01:03.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6950" for this suite. 07/10/23 09:01:03.089
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":219,"skipped":4370,"failed":0}
------------------------------
• [SLOW TEST] [10.111 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:00:52.99
    Jul 10 09:00:52.990: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 09:00:52.991
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:00:53.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:00:53.034
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 07/10/23 09:00:53.036
    STEP: delete the rc 07/10/23 09:00:58.052
    STEP: wait for all pods to be garbage collected 07/10/23 09:00:58.066
    STEP: Gathering metrics 07/10/23 09:01:03.075
    W0710 09:01:03.083490      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jul 10 09:01:03.083: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 09:01:03.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6950" for this suite. 07/10/23 09:01:03.089
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:01:03.102
Jul 10 09:01:03.102: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 09:01:03.103
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:03.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:03.145
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6336 07/10/23 09:01:03.148
STEP: changing the ExternalName service to type=ClusterIP 07/10/23 09:01:03.156
STEP: creating replication controller externalname-service in namespace services-6336 07/10/23 09:01:03.196
I0710 09:01:03.205600      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6336, replica count: 2
I0710 09:01:06.257173      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 09:01:06.257: INFO: Creating new exec pod
Jul 10 09:01:06.273: INFO: Waiting up to 5m0s for pod "execpodph2pd" in namespace "services-6336" to be "running"
Jul 10 09:01:06.277: INFO: Pod "execpodph2pd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525921ms
Jul 10 09:01:08.281: INFO: Pod "execpodph2pd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007828032s
Jul 10 09:01:10.282: INFO: Pod "execpodph2pd": Phase="Running", Reason="", readiness=true. Elapsed: 4.008735354s
Jul 10 09:01:10.282: INFO: Pod "execpodph2pd" satisfied condition "running"
Jul 10 09:01:11.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6336 exec execpodph2pd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul 10 09:01:11.445: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul 10 09:01:11.445: INFO: stdout: ""
Jul 10 09:01:12.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6336 exec execpodph2pd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul 10 09:01:12.603: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul 10 09:01:12.603: INFO: stdout: "externalname-service-mj66n"
Jul 10 09:01:12.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6336 exec execpodph2pd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.194.222 80'
Jul 10 09:01:12.755: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.194.222 80\nConnection to 192.168.194.222 80 port [tcp/http] succeeded!\n"
Jul 10 09:01:12.755: INFO: stdout: "externalname-service-lngtk"
Jul 10 09:01:12.755: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 09:01:12.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6336" for this suite. 07/10/23 09:01:12.825
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":220,"skipped":4373,"failed":0}
------------------------------
• [SLOW TEST] [9.734 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:01:03.102
    Jul 10 09:01:03.102: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 09:01:03.103
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:03.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:03.145
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-6336 07/10/23 09:01:03.148
    STEP: changing the ExternalName service to type=ClusterIP 07/10/23 09:01:03.156
    STEP: creating replication controller externalname-service in namespace services-6336 07/10/23 09:01:03.196
    I0710 09:01:03.205600      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6336, replica count: 2
    I0710 09:01:06.257173      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 09:01:06.257: INFO: Creating new exec pod
    Jul 10 09:01:06.273: INFO: Waiting up to 5m0s for pod "execpodph2pd" in namespace "services-6336" to be "running"
    Jul 10 09:01:06.277: INFO: Pod "execpodph2pd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.525921ms
    Jul 10 09:01:08.281: INFO: Pod "execpodph2pd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007828032s
    Jul 10 09:01:10.282: INFO: Pod "execpodph2pd": Phase="Running", Reason="", readiness=true. Elapsed: 4.008735354s
    Jul 10 09:01:10.282: INFO: Pod "execpodph2pd" satisfied condition "running"
    Jul 10 09:01:11.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6336 exec execpodph2pd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jul 10 09:01:11.445: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jul 10 09:01:11.445: INFO: stdout: ""
    Jul 10 09:01:12.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6336 exec execpodph2pd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jul 10 09:01:12.603: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jul 10 09:01:12.603: INFO: stdout: "externalname-service-mj66n"
    Jul 10 09:01:12.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-6336 exec execpodph2pd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.194.222 80'
    Jul 10 09:01:12.755: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.194.222 80\nConnection to 192.168.194.222 80 port [tcp/http] succeeded!\n"
    Jul 10 09:01:12.755: INFO: stdout: "externalname-service-lngtk"
    Jul 10 09:01:12.755: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 09:01:12.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6336" for this suite. 07/10/23 09:01:12.825
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:01:12.837
Jul 10 09:01:12.837: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pod-network-test 07/10/23 09:01:12.838
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:12.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:12.88
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-9175 07/10/23 09:01:12.883
STEP: creating a selector 07/10/23 09:01:12.883
STEP: Creating the service pods in kubernetes 07/10/23 09:01:12.883
Jul 10 09:01:12.883: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul 10 09:01:12.933: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9175" to be "running and ready"
Jul 10 09:01:12.949: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.405672ms
Jul 10 09:01:12.949: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:01:14.956: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022740891s
Jul 10 09:01:14.956: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:01:16.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022932796s
Jul 10 09:01:16.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:18.953: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.019809097s
Jul 10 09:01:18.953: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:20.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.020308028s
Jul 10 09:01:20.954: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:22.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021603643s
Jul 10 09:01:22.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:24.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.021311928s
Jul 10 09:01:24.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:26.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021691473s
Jul 10 09:01:26.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:28.953: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.019725361s
Jul 10 09:01:28.953: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:30.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.020888832s
Jul 10 09:01:30.954: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:32.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.021461617s
Jul 10 09:01:32.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jul 10 09:01:34.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.020843608s
Jul 10 09:01:34.954: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jul 10 09:01:34.954: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jul 10 09:01:34.958: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9175" to be "running and ready"
Jul 10 09:01:34.962: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.976966ms
Jul 10 09:01:34.962: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jul 10 09:01:34.962: INFO: Pod "netserver-1" satisfied condition "running and ready"
Jul 10 09:01:34.966: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9175" to be "running and ready"
Jul 10 09:01:34.969: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.413704ms
Jul 10 09:01:34.969: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Jul 10 09:01:34.969: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 07/10/23 09:01:34.973
Jul 10 09:01:34.984: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9175" to be "running"
Jul 10 09:01:34.988: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031351ms
Jul 10 09:01:36.996: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011811745s
Jul 10 09:01:36.996: INFO: Pod "test-container-pod" satisfied condition "running"
Jul 10 09:01:36.999: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul 10 09:01:36.999: INFO: Breadth first check of 192.168.172.21 on host 10.62.109.100...
Jul 10 09:01:37.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.40:9080/dial?request=hostname&protocol=udp&host=192.168.172.21&port=8081&tries=1'] Namespace:pod-network-test-9175 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:01:37.002: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:01:37.003: INFO: ExecWithOptions: Clientset creation
Jul 10 09:01:37.003: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-9175/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.40%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.172.21%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul 10 09:01:37.077: INFO: Waiting for responses: map[]
Jul 10 09:01:37.077: INFO: reached 192.168.172.21 after 0/1 tries
Jul 10 09:01:37.078: INFO: Breadth first check of 192.168.103.73 on host 10.62.109.101...
Jul 10 09:01:37.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.40:9080/dial?request=hostname&protocol=udp&host=192.168.103.73&port=8081&tries=1'] Namespace:pod-network-test-9175 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:01:37.082: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:01:37.083: INFO: ExecWithOptions: Clientset creation
Jul 10 09:01:37.083: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-9175/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.40%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.103.73%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul 10 09:01:37.154: INFO: Waiting for responses: map[]
Jul 10 09:01:37.154: INFO: reached 192.168.103.73 after 0/1 tries
Jul 10 09:01:37.154: INFO: Breadth first check of 192.168.120.10 on host 10.62.109.102...
Jul 10 09:01:37.158: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.40:9080/dial?request=hostname&protocol=udp&host=192.168.120.10&port=8081&tries=1'] Namespace:pod-network-test-9175 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:01:37.158: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:01:37.159: INFO: ExecWithOptions: Clientset creation
Jul 10 09:01:37.159: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-9175/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.40%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.120.10%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul 10 09:01:37.231: INFO: Waiting for responses: map[]
Jul 10 09:01:37.231: INFO: reached 192.168.120.10 after 0/1 tries
Jul 10 09:01:37.231: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jul 10 09:01:37.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9175" for this suite. 07/10/23 09:01:37.237
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":221,"skipped":4383,"failed":0}
------------------------------
• [SLOW TEST] [24.410 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:01:12.837
    Jul 10 09:01:12.837: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pod-network-test 07/10/23 09:01:12.838
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:12.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:12.88
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-9175 07/10/23 09:01:12.883
    STEP: creating a selector 07/10/23 09:01:12.883
    STEP: Creating the service pods in kubernetes 07/10/23 09:01:12.883
    Jul 10 09:01:12.883: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jul 10 09:01:12.933: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9175" to be "running and ready"
    Jul 10 09:01:12.949: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.405672ms
    Jul 10 09:01:12.949: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:01:14.956: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022740891s
    Jul 10 09:01:14.956: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:01:16.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022932796s
    Jul 10 09:01:16.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:18.953: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.019809097s
    Jul 10 09:01:18.953: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:20.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.020308028s
    Jul 10 09:01:20.954: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:22.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021603643s
    Jul 10 09:01:22.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:24.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.021311928s
    Jul 10 09:01:24.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:26.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.021691473s
    Jul 10 09:01:26.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:28.953: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.019725361s
    Jul 10 09:01:28.953: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:30.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.020888832s
    Jul 10 09:01:30.954: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:32.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.021461617s
    Jul 10 09:01:32.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jul 10 09:01:34.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.020843608s
    Jul 10 09:01:34.954: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jul 10 09:01:34.954: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jul 10 09:01:34.958: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9175" to be "running and ready"
    Jul 10 09:01:34.962: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.976966ms
    Jul 10 09:01:34.962: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jul 10 09:01:34.962: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Jul 10 09:01:34.966: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9175" to be "running and ready"
    Jul 10 09:01:34.969: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.413704ms
    Jul 10 09:01:34.969: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Jul 10 09:01:34.969: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 07/10/23 09:01:34.973
    Jul 10 09:01:34.984: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9175" to be "running"
    Jul 10 09:01:34.988: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031351ms
    Jul 10 09:01:36.996: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011811745s
    Jul 10 09:01:36.996: INFO: Pod "test-container-pod" satisfied condition "running"
    Jul 10 09:01:36.999: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Jul 10 09:01:36.999: INFO: Breadth first check of 192.168.172.21 on host 10.62.109.100...
    Jul 10 09:01:37.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.40:9080/dial?request=hostname&protocol=udp&host=192.168.172.21&port=8081&tries=1'] Namespace:pod-network-test-9175 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:01:37.002: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:01:37.003: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:01:37.003: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-9175/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.40%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.172.21%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jul 10 09:01:37.077: INFO: Waiting for responses: map[]
    Jul 10 09:01:37.077: INFO: reached 192.168.172.21 after 0/1 tries
    Jul 10 09:01:37.078: INFO: Breadth first check of 192.168.103.73 on host 10.62.109.101...
    Jul 10 09:01:37.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.40:9080/dial?request=hostname&protocol=udp&host=192.168.103.73&port=8081&tries=1'] Namespace:pod-network-test-9175 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:01:37.082: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:01:37.083: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:01:37.083: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-9175/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.40%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.103.73%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jul 10 09:01:37.154: INFO: Waiting for responses: map[]
    Jul 10 09:01:37.154: INFO: reached 192.168.103.73 after 0/1 tries
    Jul 10 09:01:37.154: INFO: Breadth first check of 192.168.120.10 on host 10.62.109.102...
    Jul 10 09:01:37.158: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.172.40:9080/dial?request=hostname&protocol=udp&host=192.168.120.10&port=8081&tries=1'] Namespace:pod-network-test-9175 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:01:37.158: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:01:37.159: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:01:37.159: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/pod-network-test-9175/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.172.40%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.120.10%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jul 10 09:01:37.231: INFO: Waiting for responses: map[]
    Jul 10 09:01:37.231: INFO: reached 192.168.120.10 after 0/1 tries
    Jul 10 09:01:37.231: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jul 10 09:01:37.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9175" for this suite. 07/10/23 09:01:37.237
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:01:37.248
Jul 10 09:01:37.248: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:01:37.25
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:37.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:37.326
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:01:37.329
Jul 10 09:01:37.342: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc" in namespace "downward-api-460" to be "Succeeded or Failed"
Jul 10 09:01:37.345: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057945ms
Jul 10 09:01:39.350: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007858461s
Jul 10 09:01:41.351: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009123822s
Jul 10 09:01:43.350: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007728685s
STEP: Saw pod success 07/10/23 09:01:43.35
Jul 10 09:01:43.350: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc" satisfied condition "Succeeded or Failed"
Jul 10 09:01:43.354: INFO: Trying to get logs from node 10-62-109-101.test pod downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc container client-container: <nil>
STEP: delete the pod 07/10/23 09:01:43.375
Jul 10 09:01:43.397: INFO: Waiting for pod downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc to disappear
Jul 10 09:01:43.411: INFO: Pod downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 09:01:43.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-460" for this suite. 07/10/23 09:01:43.417
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":222,"skipped":4394,"failed":0}
------------------------------
• [SLOW TEST] [6.191 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:01:37.248
    Jul 10 09:01:37.248: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:01:37.25
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:37.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:37.326
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:01:37.329
    Jul 10 09:01:37.342: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc" in namespace "downward-api-460" to be "Succeeded or Failed"
    Jul 10 09:01:37.345: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057945ms
    Jul 10 09:01:39.350: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007858461s
    Jul 10 09:01:41.351: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009123822s
    Jul 10 09:01:43.350: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007728685s
    STEP: Saw pod success 07/10/23 09:01:43.35
    Jul 10 09:01:43.350: INFO: Pod "downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc" satisfied condition "Succeeded or Failed"
    Jul 10 09:01:43.354: INFO: Trying to get logs from node 10-62-109-101.test pod downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc container client-container: <nil>
    STEP: delete the pod 07/10/23 09:01:43.375
    Jul 10 09:01:43.397: INFO: Waiting for pod downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc to disappear
    Jul 10 09:01:43.411: INFO: Pod downwardapi-volume-d63bd7a6-ce40-4746-b092-14ca57c7b6fc no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 09:01:43.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-460" for this suite. 07/10/23 09:01:43.417
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:01:43.44
Jul 10 09:01:43.440: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-pred 07/10/23 09:01:43.441
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:43.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:43.487
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul 10 09:01:43.489: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 10 09:01:43.508: INFO: Waiting for terminating namespaces to be deleted...
Jul 10 09:01:43.512: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-100.test before test
Jul 10 09:01:43.520: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 09:01:43.520: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 09:01:43.520: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container nfs-attacher ready: true, restart count 0
Jul 10 09:01:43.520: INFO: 	Container nfs-provisioner ready: true, restart count 0
Jul 10 09:01:43.520: INFO: 	Container plugin ready: true, restart count 0
Jul 10 09:01:43.520: INFO: 	Container snapshotter-controller ready: true, restart count 0
Jul 10 09:01:43.520: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 09:01:43.520: INFO: 	Container plugin ready: true, restart count 0
Jul 10 09:01:43.520: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container metrics-server ready: true, restart count 7
Jul 10 09:01:43.520: INFO: netserver-0 from pod-network-test-9175 started at 2023-07-10 09:01:12 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container webserver ready: true, restart count 0
Jul 10 09:01:43.520: INFO: test-container-pod from pod-network-test-9175 started at 2023-07-10 09:01:34 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container webserver ready: true, restart count 0
Jul 10 09:01:43.520: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 10 09:01:43.520: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.520: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 09:01:43.520: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 09:01:43.520: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-101.test before test
Jul 10 09:01:43.528: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.528: INFO: 	Container calico-kube-controllers ready: true, restart count 4
Jul 10 09:01:43.528: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.528: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 09:01:43.528: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.528: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 09:01:43.528: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.528: INFO: 	Container coredns ready: true, restart count 0
Jul 10 09:01:43.528: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.528: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 09:01:43.528: INFO: 	Container plugin ready: true, restart count 0
Jul 10 09:01:43.528: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.528: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 09:01:43.528: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 10 09:01:43.528: INFO: 
Logging pods the apiserver thinks is on node 10-62-109-102.test before test
Jul 10 09:01:43.538: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.538: INFO: 	Container calico-node ready: true, restart count 0
Jul 10 09:01:43.538: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.538: INFO: 	Container calico-typha ready: true, restart count 0
Jul 10 09:01:43.538: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
Jul 10 09:01:43.538: INFO: 	Container coredns ready: true, restart count 0
Jul 10 09:01:43.538: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.538: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
Jul 10 09:01:43.538: INFO: 	Container plugin ready: true, restart count 0
Jul 10 09:01:43.538: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.538: INFO: 	Container e2e ready: true, restart count 0
Jul 10 09:01:43.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 09:01:43.538: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
Jul 10 09:01:43.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 10 09:01:43.538: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node 10-62-109-100.test 07/10/23 09:01:43.565
STEP: verifying the node has the label node 10-62-109-101.test 07/10/23 09:01:43.611
STEP: verifying the node has the label node 10-62-109-102.test 07/10/23 09:01:43.861
Jul 10 09:01:43.887: INFO: Pod calico-kube-controllers-5f46b455c5-gnpmg requesting resource cpu=0m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod calico-kube-controllers-5f46b455c5-lw7pm requesting resource cpu=0m on Node 10-62-109-101.test
Jul 10 09:01:43.887: INFO: Pod calico-node-cvhbv requesting resource cpu=250m on Node 10-62-109-102.test
Jul 10 09:01:43.887: INFO: Pod calico-node-nfcct requesting resource cpu=250m on Node 10-62-109-101.test
Jul 10 09:01:43.887: INFO: Pod calico-node-r8w75 requesting resource cpu=250m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod calico-typha-78d5847d6d-5m7vs requesting resource cpu=0m on Node 10-62-109-101.test
Jul 10 09:01:43.887: INFO: Pod calico-typha-78d5847d6d-n82m7 requesting resource cpu=0m on Node 10-62-109-102.test
Jul 10 09:01:43.887: INFO: Pod coredns-5b847c7cc9-6dc8v requesting resource cpu=100m on Node 10-62-109-102.test
Jul 10 09:01:43.887: INFO: Pod coredns-5b847c7cc9-qvw9m requesting resource cpu=100m on Node 10-62-109-101.test
Jul 10 09:01:43.887: INFO: Pod csi-controller-75f447d67-cnjdb requesting resource cpu=40m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod csi-node-554h2 requesting resource cpu=20m on Node 10-62-109-101.test
Jul 10 09:01:43.887: INFO: Pod csi-node-87lfb requesting resource cpu=20m on Node 10-62-109-102.test
Jul 10 09:01:43.887: INFO: Pod csi-node-8lwxr requesting resource cpu=20m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod metrics-server-848cdbf678-6x7cs requesting resource cpu=5m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod netserver-0 requesting resource cpu=0m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod test-container-pod requesting resource cpu=0m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod sonobuoy-e2e-job-a3a41d8772c341f5 requesting resource cpu=0m on Node 10-62-109-102.test
Jul 10 09:01:43.887: INFO: Pod sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s requesting resource cpu=0m on Node 10-62-109-101.test
Jul 10 09:01:43.887: INFO: Pod sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w requesting resource cpu=0m on Node 10-62-109-100.test
Jul 10 09:01:43.887: INFO: Pod sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 requesting resource cpu=0m on Node 10-62-109-102.test
STEP: Starting Pods to consume most of the cluster CPU. 07/10/23 09:01:43.887
Jul 10 09:01:43.887: INFO: Creating a pod which consumes cpu=2541m on Node 10-62-109-101.test
Jul 10 09:01:43.899: INFO: Creating a pod which consumes cpu=2541m on Node 10-62-109-102.test
Jul 10 09:01:43.913: INFO: Creating a pod which consumes cpu=2579m on Node 10-62-109-100.test
Jul 10 09:01:43.927: INFO: Waiting up to 5m0s for pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a" in namespace "sched-pred-8882" to be "running"
Jul 10 09:01:43.935: INFO: Pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.684703ms
Jul 10 09:01:45.940: INFO: Pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a": Phase="Running", Reason="", readiness=true. Elapsed: 2.012906047s
Jul 10 09:01:45.940: INFO: Pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a" satisfied condition "running"
Jul 10 09:01:45.940: INFO: Waiting up to 5m0s for pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e" in namespace "sched-pred-8882" to be "running"
Jul 10 09:01:45.944: INFO: Pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805703ms
Jul 10 09:01:47.949: INFO: Pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008806766s
Jul 10 09:01:47.949: INFO: Pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e" satisfied condition "running"
Jul 10 09:01:47.949: INFO: Waiting up to 5m0s for pod "filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f" in namespace "sched-pred-8882" to be "running"
Jul 10 09:01:47.952: INFO: Pod "filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f": Phase="Running", Reason="", readiness=true. Elapsed: 3.541377ms
Jul 10 09:01:47.952: INFO: Pod "filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 07/10/23 09:01:47.952
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.177076178c64da29], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8882/filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f to 10-62-109-100.test] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.17707617c3bf23ce], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.17707617ce08aa62], Reason = [Created], Message = [Created container filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.17707617d51c94cf], Reason = [Started], Message = [Started container filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.177076178833c215], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8882/filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e to 10-62-109-102.test] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.17707617cb90b7d6], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.17707617d3ca74df], Reason = [Created], Message = [Created container filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e] 07/10/23 09:01:47.957
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.17707617dc011a8f], Reason = [Started], Message = [Started container filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e] 07/10/23 09:01:47.958
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.1770761788089ede], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8882/filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a to 10-62-109-101.test] 07/10/23 09:01:47.958
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.17707617c284ffd0], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 07/10/23 09:01:47.958
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.17707617c998a5c7], Reason = [Created], Message = [Created container filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a] 07/10/23 09:01:47.958
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.17707617d20eb28f], Reason = [Started], Message = [Started container filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a] 07/10/23 09:01:47.958
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17707618792448f3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 07/10/23 09:01:47.984
STEP: removing the label node off the node 10-62-109-100.test 07/10/23 09:01:48.985
STEP: verifying the node doesn't have the label node 07/10/23 09:01:49.008
STEP: removing the label node off the node 10-62-109-101.test 07/10/23 09:01:49.013
STEP: verifying the node doesn't have the label node 07/10/23 09:01:49.031
STEP: removing the label node off the node 10-62-109-102.test 07/10/23 09:01:49.034
STEP: verifying the node doesn't have the label node 07/10/23 09:01:49.057
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:01:49.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8882" for this suite. 07/10/23 09:01:49.066
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":223,"skipped":4397,"failed":0}
------------------------------
• [SLOW TEST] [5.637 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:01:43.44
    Jul 10 09:01:43.440: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-pred 07/10/23 09:01:43.441
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:43.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:43.487
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jul 10 09:01:43.489: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jul 10 09:01:43.508: INFO: Waiting for terminating namespaces to be deleted...
    Jul 10 09:01:43.512: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-100.test before test
    Jul 10 09:01:43.520: INFO: calico-kube-controllers-5f46b455c5-gnpmg from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 09:01:43.520: INFO: calico-node-r8w75 from kube-system started at 2023-07-10 07:24:16 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: csi-controller-75f447d67-cnjdb from kube-system started at 2023-07-10 07:27:00 +0000 UTC (4 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container nfs-attacher ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: 	Container nfs-provisioner ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: 	Container snapshotter-controller ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: csi-node-8lwxr from kube-system started at 2023-07-10 03:55:00 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: metrics-server-848cdbf678-6x7cs from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container metrics-server ready: true, restart count 7
    Jul 10 09:01:43.520: INFO: netserver-0 from pod-network-test-9175 started at 2023-07-10 09:01:12 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container webserver ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: test-container-pod from pod-network-test-9175 started at 2023-07-10 09:01:34 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container webserver ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: sonobuoy from sonobuoy started at 2023-07-10 07:57:15 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.520: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 09:01:43.520: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-101.test before test
    Jul 10 09:01:43.528: INFO: calico-kube-controllers-5f46b455c5-lw7pm from kube-system started at 2023-07-10 07:47:13 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.528: INFO: 	Container calico-kube-controllers ready: true, restart count 4
    Jul 10 09:01:43.528: INFO: calico-node-nfcct from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.528: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: calico-typha-78d5847d6d-5m7vs from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.528: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: coredns-5b847c7cc9-qvw9m from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.528: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: csi-node-554h2 from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.528: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.528: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: 	Container systemd-logs ready: true, restart count 0
    Jul 10 09:01:43.528: INFO: 
    Logging pods the apiserver thinks is on node 10-62-109-102.test before test
    Jul 10 09:01:43.538: INFO: calico-node-cvhbv from kube-system started at 2023-07-10 07:24:17 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.538: INFO: 	Container calico-node ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: calico-typha-78d5847d6d-n82m7 from kube-system started at 2023-07-10 04:37:59 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.538: INFO: 	Container calico-typha ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: coredns-5b847c7cc9-6dc8v from kube-system started at 2023-07-10 03:00:10 +0000 UTC (1 container statuses recorded)
    Jul 10 09:01:43.538: INFO: 	Container coredns ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: csi-node-87lfb from kube-system started at 2023-07-10 03:55:01 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.538: INFO: 	Container nfs-driver-registrar ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: 	Container plugin ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: sonobuoy-e2e-job-a3a41d8772c341f5 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.538: INFO: 	Container e2e ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 from sonobuoy started at 2023-07-10 07:57:17 +0000 UTC (2 container statuses recorded)
    Jul 10 09:01:43.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jul 10 09:01:43.538: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node 10-62-109-100.test 07/10/23 09:01:43.565
    STEP: verifying the node has the label node 10-62-109-101.test 07/10/23 09:01:43.611
    STEP: verifying the node has the label node 10-62-109-102.test 07/10/23 09:01:43.861
    Jul 10 09:01:43.887: INFO: Pod calico-kube-controllers-5f46b455c5-gnpmg requesting resource cpu=0m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod calico-kube-controllers-5f46b455c5-lw7pm requesting resource cpu=0m on Node 10-62-109-101.test
    Jul 10 09:01:43.887: INFO: Pod calico-node-cvhbv requesting resource cpu=250m on Node 10-62-109-102.test
    Jul 10 09:01:43.887: INFO: Pod calico-node-nfcct requesting resource cpu=250m on Node 10-62-109-101.test
    Jul 10 09:01:43.887: INFO: Pod calico-node-r8w75 requesting resource cpu=250m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod calico-typha-78d5847d6d-5m7vs requesting resource cpu=0m on Node 10-62-109-101.test
    Jul 10 09:01:43.887: INFO: Pod calico-typha-78d5847d6d-n82m7 requesting resource cpu=0m on Node 10-62-109-102.test
    Jul 10 09:01:43.887: INFO: Pod coredns-5b847c7cc9-6dc8v requesting resource cpu=100m on Node 10-62-109-102.test
    Jul 10 09:01:43.887: INFO: Pod coredns-5b847c7cc9-qvw9m requesting resource cpu=100m on Node 10-62-109-101.test
    Jul 10 09:01:43.887: INFO: Pod csi-controller-75f447d67-cnjdb requesting resource cpu=40m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod csi-node-554h2 requesting resource cpu=20m on Node 10-62-109-101.test
    Jul 10 09:01:43.887: INFO: Pod csi-node-87lfb requesting resource cpu=20m on Node 10-62-109-102.test
    Jul 10 09:01:43.887: INFO: Pod csi-node-8lwxr requesting resource cpu=20m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod metrics-server-848cdbf678-6x7cs requesting resource cpu=5m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod netserver-0 requesting resource cpu=0m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod test-container-pod requesting resource cpu=0m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod sonobuoy-e2e-job-a3a41d8772c341f5 requesting resource cpu=0m on Node 10-62-109-102.test
    Jul 10 09:01:43.887: INFO: Pod sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-2th5s requesting resource cpu=0m on Node 10-62-109-101.test
    Jul 10 09:01:43.887: INFO: Pod sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-lmp6w requesting resource cpu=0m on Node 10-62-109-100.test
    Jul 10 09:01:43.887: INFO: Pod sonobuoy-systemd-logs-daemon-set-0318020fe4b4479a-qr2w2 requesting resource cpu=0m on Node 10-62-109-102.test
    STEP: Starting Pods to consume most of the cluster CPU. 07/10/23 09:01:43.887
    Jul 10 09:01:43.887: INFO: Creating a pod which consumes cpu=2541m on Node 10-62-109-101.test
    Jul 10 09:01:43.899: INFO: Creating a pod which consumes cpu=2541m on Node 10-62-109-102.test
    Jul 10 09:01:43.913: INFO: Creating a pod which consumes cpu=2579m on Node 10-62-109-100.test
    Jul 10 09:01:43.927: INFO: Waiting up to 5m0s for pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a" in namespace "sched-pred-8882" to be "running"
    Jul 10 09:01:43.935: INFO: Pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.684703ms
    Jul 10 09:01:45.940: INFO: Pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a": Phase="Running", Reason="", readiness=true. Elapsed: 2.012906047s
    Jul 10 09:01:45.940: INFO: Pod "filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a" satisfied condition "running"
    Jul 10 09:01:45.940: INFO: Waiting up to 5m0s for pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e" in namespace "sched-pred-8882" to be "running"
    Jul 10 09:01:45.944: INFO: Pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805703ms
    Jul 10 09:01:47.949: INFO: Pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008806766s
    Jul 10 09:01:47.949: INFO: Pod "filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e" satisfied condition "running"
    Jul 10 09:01:47.949: INFO: Waiting up to 5m0s for pod "filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f" in namespace "sched-pred-8882" to be "running"
    Jul 10 09:01:47.952: INFO: Pod "filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f": Phase="Running", Reason="", readiness=true. Elapsed: 3.541377ms
    Jul 10 09:01:47.952: INFO: Pod "filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 07/10/23 09:01:47.952
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.177076178c64da29], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8882/filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f to 10-62-109-100.test] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.17707617c3bf23ce], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.17707617ce08aa62], Reason = [Created], Message = [Created container filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f.17707617d51c94cf], Reason = [Started], Message = [Started container filler-pod-19c1db62-0582-44eb-a0f0-b3817c62586f] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.177076178833c215], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8882/filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e to 10-62-109-102.test] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.17707617cb90b7d6], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.17707617d3ca74df], Reason = [Created], Message = [Created container filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e] 07/10/23 09:01:47.957
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e.17707617dc011a8f], Reason = [Started], Message = [Started container filler-pod-35e716d7-485e-4e79-8339-4d9ce484988e] 07/10/23 09:01:47.958
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.1770761788089ede], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8882/filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a to 10-62-109-101.test] 07/10/23 09:01:47.958
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.17707617c284ffd0], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 07/10/23 09:01:47.958
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.17707617c998a5c7], Reason = [Created], Message = [Created container filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a] 07/10/23 09:01:47.958
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a.17707617d20eb28f], Reason = [Started], Message = [Started container filler-pod-73d6f612-3bc5-4af9-a03c-0c0616b39b0a] 07/10/23 09:01:47.958
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.17707618792448f3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 07/10/23 09:01:47.984
    STEP: removing the label node off the node 10-62-109-100.test 07/10/23 09:01:48.985
    STEP: verifying the node doesn't have the label node 07/10/23 09:01:49.008
    STEP: removing the label node off the node 10-62-109-101.test 07/10/23 09:01:49.013
    STEP: verifying the node doesn't have the label node 07/10/23 09:01:49.031
    STEP: removing the label node off the node 10-62-109-102.test 07/10/23 09:01:49.034
    STEP: verifying the node doesn't have the label node 07/10/23 09:01:49.057
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:01:49.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8882" for this suite. 07/10/23 09:01:49.066
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:01:49.077
Jul 10 09:01:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubelet-test 07/10/23 09:01:49.079
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:49.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:49.117
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 07/10/23 09:01:49.138
Jul 10 09:01:49.138: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc" in namespace "kubelet-test-2777" to be "completed"
Jul 10 09:01:49.265: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc": Phase="Pending", Reason="", readiness=false. Elapsed: 127.082466ms
Jul 10 09:01:51.270: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.131368809s
Jul 10 09:01:53.271: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.132861297s
Jul 10 09:01:53.271: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jul 10 09:01:53.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2777" for this suite. 07/10/23 09:01:53.287
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":224,"skipped":4398,"failed":0}
------------------------------
• [4.218 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:01:49.077
    Jul 10 09:01:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubelet-test 07/10/23 09:01:49.079
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:49.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:49.117
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 07/10/23 09:01:49.138
    Jul 10 09:01:49.138: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc" in namespace "kubelet-test-2777" to be "completed"
    Jul 10 09:01:49.265: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc": Phase="Pending", Reason="", readiness=false. Elapsed: 127.082466ms
    Jul 10 09:01:51.270: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.131368809s
    Jul 10 09:01:53.271: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.132861297s
    Jul 10 09:01:53.271: INFO: Pod "agnhost-host-aliases99aef543-faa8-47de-aa42-bc28abe229dc" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jul 10 09:01:53.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2777" for this suite. 07/10/23 09:01:53.287
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:01:53.297
Jul 10 09:01:53.297: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replicaset 07/10/23 09:01:53.299
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:53.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:53.496
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Jul 10 09:01:53.498: INFO: Creating ReplicaSet my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682
Jul 10 09:01:53.508: INFO: Pod name my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682: Found 0 pods out of 1
Jul 10 09:01:58.513: INFO: Pod name my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682: Found 1 pods out of 1
Jul 10 09:01:58.513: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682" is running
Jul 10 09:01:58.513: INFO: Waiting up to 5m0s for pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp" in namespace "replicaset-3279" to be "running"
Jul 10 09:01:58.516: INFO: Pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp": Phase="Running", Reason="", readiness=true. Elapsed: 2.923898ms
Jul 10 09:01:58.516: INFO: Pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp" satisfied condition "running"
Jul 10 09:01:58.516: INFO: Pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:55 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:53 +0000 UTC Reason: Message:}])
Jul 10 09:01:58.516: INFO: Trying to dial the pod
Jul 10 09:02:03.531: INFO: Controller my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682: Got expected result from replica 1 [my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp]: "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jul 10 09:02:03.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3279" for this suite. 07/10/23 09:02:03.536
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":225,"skipped":4418,"failed":0}
------------------------------
• [SLOW TEST] [10.250 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:01:53.297
    Jul 10 09:01:53.297: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replicaset 07/10/23 09:01:53.299
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:01:53.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:01:53.496
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Jul 10 09:01:53.498: INFO: Creating ReplicaSet my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682
    Jul 10 09:01:53.508: INFO: Pod name my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682: Found 0 pods out of 1
    Jul 10 09:01:58.513: INFO: Pod name my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682: Found 1 pods out of 1
    Jul 10 09:01:58.513: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682" is running
    Jul 10 09:01:58.513: INFO: Waiting up to 5m0s for pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp" in namespace "replicaset-3279" to be "running"
    Jul 10 09:01:58.516: INFO: Pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp": Phase="Running", Reason="", readiness=true. Elapsed: 2.923898ms
    Jul 10 09:01:58.516: INFO: Pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp" satisfied condition "running"
    Jul 10 09:01:58.516: INFO: Pod "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:55 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-10 09:01:53 +0000 UTC Reason: Message:}])
    Jul 10 09:01:58.516: INFO: Trying to dial the pod
    Jul 10 09:02:03.531: INFO: Controller my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682: Got expected result from replica 1 [my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp]: "my-hostname-basic-24903b9a-cc29-4039-bf82-b214dd4a0682-kqnxp", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jul 10 09:02:03.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3279" for this suite. 07/10/23 09:02:03.536
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:03.548
Jul 10 09:02:03.548: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename disruption 07/10/23 09:02:03.549
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:03.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:03.598
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 07/10/23 09:02:03.6
STEP: Waiting for the pdb to be processed 07/10/23 09:02:03.608
STEP: updating the pdb 07/10/23 09:02:05.616
STEP: Waiting for the pdb to be processed 07/10/23 09:02:05.634
STEP: patching the pdb 07/10/23 09:02:07.65
STEP: Waiting for the pdb to be processed 07/10/23 09:02:07.671
STEP: Waiting for the pdb to be deleted 07/10/23 09:02:09.695
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jul 10 09:02:09.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-232" for this suite. 07/10/23 09:02:09.704
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":226,"skipped":4428,"failed":0}
------------------------------
• [SLOW TEST] [6.166 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:03.548
    Jul 10 09:02:03.548: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename disruption 07/10/23 09:02:03.549
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:03.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:03.598
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 07/10/23 09:02:03.6
    STEP: Waiting for the pdb to be processed 07/10/23 09:02:03.608
    STEP: updating the pdb 07/10/23 09:02:05.616
    STEP: Waiting for the pdb to be processed 07/10/23 09:02:05.634
    STEP: patching the pdb 07/10/23 09:02:07.65
    STEP: Waiting for the pdb to be processed 07/10/23 09:02:07.671
    STEP: Waiting for the pdb to be deleted 07/10/23 09:02:09.695
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jul 10 09:02:09.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-232" for this suite. 07/10/23 09:02:09.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:09.715
Jul 10 09:02:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 09:02:09.716
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:09.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:09.748
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 07/10/23 09:02:09.782
STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:02:09.792
Jul 10 09:02:09.801: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:02:09.801: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:02:10.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:02:10.890: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:02:11.810: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:02:11.810: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
Jul 10 09:02:12.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:02:12.811: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 07/10/23 09:02:12.814
Jul 10 09:02:12.844: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:02:12.844: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:02:14.099: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:02:14.099: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:02:14.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:02:14.854: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:02:15.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:02:15.899: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:02:16.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:02:16.854: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:02:16.86
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1959, will wait for the garbage collector to delete the pods 07/10/23 09:02:16.86
Jul 10 09:02:16.927: INFO: Deleting DaemonSet.extensions daemon-set took: 12.708335ms
Jul 10 09:02:17.128: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.020167ms
Jul 10 09:02:19.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:02:19.748: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul 10 09:02:19.752: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"94500"},"items":null}

Jul 10 09:02:19.756: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"94500"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:02:19.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1959" for this suite. 07/10/23 09:02:19.782
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":227,"skipped":4448,"failed":0}
------------------------------
• [SLOW TEST] [10.079 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:09.715
    Jul 10 09:02:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 09:02:09.716
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:09.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:09.748
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 07/10/23 09:02:09.782
    STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:02:09.792
    Jul 10 09:02:09.801: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:02:09.801: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:02:10.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:02:10.890: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:02:11.810: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:02:11.810: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
    Jul 10 09:02:12.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:02:12.811: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 07/10/23 09:02:12.814
    Jul 10 09:02:12.844: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:02:12.844: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:02:14.099: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:02:14.099: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:02:14.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:02:14.854: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:02:15.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:02:15.899: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:02:16.854: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:02:16.854: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:02:16.86
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1959, will wait for the garbage collector to delete the pods 07/10/23 09:02:16.86
    Jul 10 09:02:16.927: INFO: Deleting DaemonSet.extensions daemon-set took: 12.708335ms
    Jul 10 09:02:17.128: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.020167ms
    Jul 10 09:02:19.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:02:19.748: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jul 10 09:02:19.752: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"94500"},"items":null}

    Jul 10 09:02:19.756: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"94500"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:02:19.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1959" for this suite. 07/10/23 09:02:19.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:19.797
Jul 10 09:02:19.797: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:02:19.798
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:19.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:19.829
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 07/10/23 09:02:19.832
STEP: submitting the pod to kubernetes 07/10/23 09:02:19.832
Jul 10 09:02:19.846: INFO: Waiting up to 5m0s for pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" in namespace "pods-6885" to be "running and ready"
Jul 10 09:02:19.860: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164": Phase="Pending", Reason="", readiness=false. Elapsed: 13.862816ms
Jul 10 09:02:19.860: INFO: The phase of Pod pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:02:21.866: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164": Phase="Running", Reason="", readiness=true. Elapsed: 2.019491576s
Jul 10 09:02:21.866: INFO: The phase of Pod pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164 is Running (Ready = true)
Jul 10 09:02:21.866: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 07/10/23 09:02:21.869
STEP: updating the pod 07/10/23 09:02:21.872
Jul 10 09:02:22.390: INFO: Successfully updated pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164"
Jul 10 09:02:22.391: INFO: Waiting up to 5m0s for pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" in namespace "pods-6885" to be "running"
Jul 10 09:02:22.395: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164": Phase="Running", Reason="", readiness=true. Elapsed: 4.513284ms
Jul 10 09:02:22.395: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 07/10/23 09:02:22.395
Jul 10 09:02:22.407: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 09:02:22.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6885" for this suite. 07/10/23 09:02:22.412
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":228,"skipped":4490,"failed":0}
------------------------------
• [2.847 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:19.797
    Jul 10 09:02:19.797: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:02:19.798
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:19.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:19.829
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 07/10/23 09:02:19.832
    STEP: submitting the pod to kubernetes 07/10/23 09:02:19.832
    Jul 10 09:02:19.846: INFO: Waiting up to 5m0s for pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" in namespace "pods-6885" to be "running and ready"
    Jul 10 09:02:19.860: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164": Phase="Pending", Reason="", readiness=false. Elapsed: 13.862816ms
    Jul 10 09:02:19.860: INFO: The phase of Pod pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:02:21.866: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164": Phase="Running", Reason="", readiness=true. Elapsed: 2.019491576s
    Jul 10 09:02:21.866: INFO: The phase of Pod pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164 is Running (Ready = true)
    Jul 10 09:02:21.866: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 07/10/23 09:02:21.869
    STEP: updating the pod 07/10/23 09:02:21.872
    Jul 10 09:02:22.390: INFO: Successfully updated pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164"
    Jul 10 09:02:22.391: INFO: Waiting up to 5m0s for pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" in namespace "pods-6885" to be "running"
    Jul 10 09:02:22.395: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164": Phase="Running", Reason="", readiness=true. Elapsed: 4.513284ms
    Jul 10 09:02:22.395: INFO: Pod "pod-update-581d1ad9-60af-4dad-b2ba-48fb69f52164" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 07/10/23 09:02:22.395
    Jul 10 09:02:22.407: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 09:02:22.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6885" for this suite. 07/10/23 09:02:22.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:22.645
Jul 10 09:02:22.645: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:02:22.646
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:22.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:22.674
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-a259deef-6bc3-4011-a595-28b9e6d0f920 07/10/23 09:02:22.682
STEP: Creating configMap with name cm-test-opt-upd-45aba23a-b972-4703-8b6d-48aa05cee788 07/10/23 09:02:22.689
STEP: Creating the pod 07/10/23 09:02:22.701
Jul 10 09:02:22.717: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f" in namespace "configmap-6406" to be "running and ready"
Jul 10 09:02:22.720: INFO: Pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14004ms
Jul 10 09:02:22.720: INFO: The phase of Pod pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:02:24.724: INFO: Pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007099742s
Jul 10 09:02:24.724: INFO: The phase of Pod pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f is Running (Ready = true)
Jul 10 09:02:24.724: INFO: Pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-a259deef-6bc3-4011-a595-28b9e6d0f920 07/10/23 09:02:24.76
STEP: Updating configmap cm-test-opt-upd-45aba23a-b972-4703-8b6d-48aa05cee788 07/10/23 09:02:24.769
STEP: Creating configMap with name cm-test-opt-create-512373dd-83de-477b-af0d-c54420e6c49f 07/10/23 09:02:24.783
STEP: waiting to observe update in volume 07/10/23 09:02:24.79
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:02:26.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6406" for this suite. 07/10/23 09:02:26.845
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":229,"skipped":4498,"failed":0}
------------------------------
• [4.214 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:22.645
    Jul 10 09:02:22.645: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:02:22.646
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:22.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:22.674
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-a259deef-6bc3-4011-a595-28b9e6d0f920 07/10/23 09:02:22.682
    STEP: Creating configMap with name cm-test-opt-upd-45aba23a-b972-4703-8b6d-48aa05cee788 07/10/23 09:02:22.689
    STEP: Creating the pod 07/10/23 09:02:22.701
    Jul 10 09:02:22.717: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f" in namespace "configmap-6406" to be "running and ready"
    Jul 10 09:02:22.720: INFO: Pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14004ms
    Jul 10 09:02:22.720: INFO: The phase of Pod pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:02:24.724: INFO: Pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007099742s
    Jul 10 09:02:24.724: INFO: The phase of Pod pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f is Running (Ready = true)
    Jul 10 09:02:24.724: INFO: Pod "pod-configmaps-7b795d4e-cf8c-4808-90e9-76c91d1b2e1f" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-a259deef-6bc3-4011-a595-28b9e6d0f920 07/10/23 09:02:24.76
    STEP: Updating configmap cm-test-opt-upd-45aba23a-b972-4703-8b6d-48aa05cee788 07/10/23 09:02:24.769
    STEP: Creating configMap with name cm-test-opt-create-512373dd-83de-477b-af0d-c54420e6c49f 07/10/23 09:02:24.783
    STEP: waiting to observe update in volume 07/10/23 09:02:24.79
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:02:26.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6406" for this suite. 07/10/23 09:02:26.845
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:26.859
Jul 10 09:02:26.859: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 09:02:26.86
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:26.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:26.897
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 09:02:27.008
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:02:27.581
STEP: Deploying the webhook pod 07/10/23 09:02:27.593
STEP: Wait for the deployment to be ready 07/10/23 09:02:27.609
Jul 10 09:02:27.616: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jul 10 09:02:29.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 07/10/23 09:02:31.635
STEP: Verifying the service has paired with the endpoint 07/10/23 09:02:31.814
Jul 10 09:02:32.814: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 07/10/23 09:02:32.939
STEP: Creating a configMap that should be mutated 07/10/23 09:02:32.966
STEP: Deleting the collection of validation webhooks 07/10/23 09:02:33.002
STEP: Creating a configMap that should not be mutated 07/10/23 09:02:33.088
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:02:33.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7682" for this suite. 07/10/23 09:02:33.124
STEP: Destroying namespace "webhook-7682-markers" for this suite. 07/10/23 09:02:33.136
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":230,"skipped":4499,"failed":0}
------------------------------
• [SLOW TEST] [6.366 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:26.859
    Jul 10 09:02:26.859: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 09:02:26.86
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:26.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:26.897
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 09:02:27.008
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:02:27.581
    STEP: Deploying the webhook pod 07/10/23 09:02:27.593
    STEP: Wait for the deployment to be ready 07/10/23 09:02:27.609
    Jul 10 09:02:27.616: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jul 10 09:02:29.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 2, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 07/10/23 09:02:31.635
    STEP: Verifying the service has paired with the endpoint 07/10/23 09:02:31.814
    Jul 10 09:02:32.814: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 07/10/23 09:02:32.939
    STEP: Creating a configMap that should be mutated 07/10/23 09:02:32.966
    STEP: Deleting the collection of validation webhooks 07/10/23 09:02:33.002
    STEP: Creating a configMap that should not be mutated 07/10/23 09:02:33.088
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:02:33.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7682" for this suite. 07/10/23 09:02:33.124
    STEP: Destroying namespace "webhook-7682-markers" for this suite. 07/10/23 09:02:33.136
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:33.225
Jul 10 09:02:33.225: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 09:02:33.226
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:33.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:33.268
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 07/10/23 09:02:33.27
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
 07/10/23 09:02:33.29
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
 07/10/23 09:02:33.29
STEP: creating a pod to probe DNS 07/10/23 09:02:33.29
STEP: submitting the pod to kubernetes 07/10/23 09:02:33.29
Jul 10 09:02:33.306: INFO: Waiting up to 15m0s for pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73" in namespace "dns-4840" to be "running"
Jul 10 09:02:33.316: INFO: Pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322711ms
Jul 10 09:02:35.322: INFO: Pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73": Phase="Running", Reason="", readiness=true. Elapsed: 2.016126645s
Jul 10 09:02:35.322: INFO: Pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73" satisfied condition "running"
STEP: retrieving the pod 07/10/23 09:02:35.322
STEP: looking for the results for each expected name from probers 07/10/23 09:02:35.327
Jul 10 09:02:35.336: INFO: DNS probes using dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73 succeeded

STEP: deleting the pod 07/10/23 09:02:35.336
STEP: changing the externalName to bar.example.com 07/10/23 09:02:35.361
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
 07/10/23 09:02:35.372
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
 07/10/23 09:02:35.372
STEP: creating a second pod to probe DNS 07/10/23 09:02:35.372
STEP: submitting the pod to kubernetes 07/10/23 09:02:35.372
Jul 10 09:02:35.383: INFO: Waiting up to 15m0s for pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af" in namespace "dns-4840" to be "running"
Jul 10 09:02:35.387: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.627354ms
Jul 10 09:02:37.393: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009347533s
Jul 10 09:02:39.394: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af": Phase="Running", Reason="", readiness=true. Elapsed: 4.01048239s
Jul 10 09:02:39.394: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af" satisfied condition "running"
STEP: retrieving the pod 07/10/23 09:02:39.394
STEP: looking for the results for each expected name from probers 07/10/23 09:02:39.398
Jul 10 09:02:39.403: INFO: File wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local from pod  dns-4840/dns-test-d2087d55-0138-45bf-a741-4c873aa456af contains 'foo.example.com.
' instead of 'bar.example.com.'
Jul 10 09:02:39.409: INFO: Lookups using dns-4840/dns-test-d2087d55-0138-45bf-a741-4c873aa456af failed for: [wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local]

Jul 10 09:02:44.420: INFO: DNS probes using dns-test-d2087d55-0138-45bf-a741-4c873aa456af succeeded

STEP: deleting the pod 07/10/23 09:02:44.42
STEP: changing the service to type=ClusterIP 07/10/23 09:02:44.461
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
 07/10/23 09:02:44.484
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
 07/10/23 09:02:44.484
STEP: creating a third pod to probe DNS 07/10/23 09:02:44.484
STEP: submitting the pod to kubernetes 07/10/23 09:02:44.506
Jul 10 09:02:44.530: INFO: Waiting up to 15m0s for pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0" in namespace "dns-4840" to be "running"
Jul 10 09:02:44.535: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.736269ms
Jul 10 09:02:46.541: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010980335s
Jul 10 09:02:48.541: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0": Phase="Running", Reason="", readiness=true. Elapsed: 4.010708538s
Jul 10 09:02:48.541: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0" satisfied condition "running"
STEP: retrieving the pod 07/10/23 09:02:48.541
STEP: looking for the results for each expected name from probers 07/10/23 09:02:48.545
Jul 10 09:02:48.554: INFO: DNS probes using dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0 succeeded

STEP: deleting the pod 07/10/23 09:02:48.554
STEP: deleting the test externalName service 07/10/23 09:02:48.623
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 09:02:48.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4840" for this suite. 07/10/23 09:02:48.662
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":231,"skipped":4499,"failed":0}
------------------------------
• [SLOW TEST] [15.458 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:33.225
    Jul 10 09:02:33.225: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 09:02:33.226
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:33.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:33.268
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 07/10/23 09:02:33.27
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
     07/10/23 09:02:33.29
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
     07/10/23 09:02:33.29
    STEP: creating a pod to probe DNS 07/10/23 09:02:33.29
    STEP: submitting the pod to kubernetes 07/10/23 09:02:33.29
    Jul 10 09:02:33.306: INFO: Waiting up to 15m0s for pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73" in namespace "dns-4840" to be "running"
    Jul 10 09:02:33.316: INFO: Pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322711ms
    Jul 10 09:02:35.322: INFO: Pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73": Phase="Running", Reason="", readiness=true. Elapsed: 2.016126645s
    Jul 10 09:02:35.322: INFO: Pod "dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 09:02:35.322
    STEP: looking for the results for each expected name from probers 07/10/23 09:02:35.327
    Jul 10 09:02:35.336: INFO: DNS probes using dns-test-7f9fb901-eb70-40b0-963d-97470ebe5c73 succeeded

    STEP: deleting the pod 07/10/23 09:02:35.336
    STEP: changing the externalName to bar.example.com 07/10/23 09:02:35.361
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
     07/10/23 09:02:35.372
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
     07/10/23 09:02:35.372
    STEP: creating a second pod to probe DNS 07/10/23 09:02:35.372
    STEP: submitting the pod to kubernetes 07/10/23 09:02:35.372
    Jul 10 09:02:35.383: INFO: Waiting up to 15m0s for pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af" in namespace "dns-4840" to be "running"
    Jul 10 09:02:35.387: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.627354ms
    Jul 10 09:02:37.393: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009347533s
    Jul 10 09:02:39.394: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af": Phase="Running", Reason="", readiness=true. Elapsed: 4.01048239s
    Jul 10 09:02:39.394: INFO: Pod "dns-test-d2087d55-0138-45bf-a741-4c873aa456af" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 09:02:39.394
    STEP: looking for the results for each expected name from probers 07/10/23 09:02:39.398
    Jul 10 09:02:39.403: INFO: File wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local from pod  dns-4840/dns-test-d2087d55-0138-45bf-a741-4c873aa456af contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Jul 10 09:02:39.409: INFO: Lookups using dns-4840/dns-test-d2087d55-0138-45bf-a741-4c873aa456af failed for: [wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local]

    Jul 10 09:02:44.420: INFO: DNS probes using dns-test-d2087d55-0138-45bf-a741-4c873aa456af succeeded

    STEP: deleting the pod 07/10/23 09:02:44.42
    STEP: changing the service to type=ClusterIP 07/10/23 09:02:44.461
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
     07/10/23 09:02:44.484
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4840.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4840.svc.cluster.local; sleep 1; done
     07/10/23 09:02:44.484
    STEP: creating a third pod to probe DNS 07/10/23 09:02:44.484
    STEP: submitting the pod to kubernetes 07/10/23 09:02:44.506
    Jul 10 09:02:44.530: INFO: Waiting up to 15m0s for pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0" in namespace "dns-4840" to be "running"
    Jul 10 09:02:44.535: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.736269ms
    Jul 10 09:02:46.541: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010980335s
    Jul 10 09:02:48.541: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0": Phase="Running", Reason="", readiness=true. Elapsed: 4.010708538s
    Jul 10 09:02:48.541: INFO: Pod "dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 09:02:48.541
    STEP: looking for the results for each expected name from probers 07/10/23 09:02:48.545
    Jul 10 09:02:48.554: INFO: DNS probes using dns-test-40877cce-300a-4b6f-951a-50c3012e9dd0 succeeded

    STEP: deleting the pod 07/10/23 09:02:48.554
    STEP: deleting the test externalName service 07/10/23 09:02:48.623
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 09:02:48.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4840" for this suite. 07/10/23 09:02:48.662
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:48.684
Jul 10 09:02:48.684: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 09:02:48.685
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:48.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:48.72
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 07/10/23 09:02:48.724
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1929.svc.cluster.local;sleep 1; done
 07/10/23 09:02:48.738
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1929.svc.cluster.local;sleep 1; done
 07/10/23 09:02:48.738
STEP: creating a pod to probe DNS 07/10/23 09:02:48.738
STEP: submitting the pod to kubernetes 07/10/23 09:02:48.738
Jul 10 09:02:48.760: INFO: Waiting up to 15m0s for pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f" in namespace "dns-1929" to be "running"
Jul 10 09:02:48.764: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.572821ms
Jul 10 09:02:50.769: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008847748s
Jul 10 09:02:52.770: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f": Phase="Running", Reason="", readiness=true. Elapsed: 4.009831413s
Jul 10 09:02:52.770: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f" satisfied condition "running"
STEP: retrieving the pod 07/10/23 09:02:52.77
STEP: looking for the results for each expected name from probers 07/10/23 09:02:52.774
Jul 10 09:02:52.779: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.783: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.787: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.791: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.794: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.798: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.802: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.806: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
Jul 10 09:02:52.806: INFO: Lookups using dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1929.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1929.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local jessie_udp@dns-test-service-2.dns-1929.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1929.svc.cluster.local]

Jul 10 09:02:57.841: INFO: DNS probes using dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f succeeded

STEP: deleting the pod 07/10/23 09:02:57.841
STEP: deleting the test headless service 07/10/23 09:02:57.87
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 09:02:57.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1929" for this suite. 07/10/23 09:02:57.922
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":232,"skipped":4508,"failed":0}
------------------------------
• [SLOW TEST] [9.248 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:48.684
    Jul 10 09:02:48.684: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 09:02:48.685
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:48.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:48.72
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 07/10/23 09:02:48.724
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1929.svc.cluster.local;sleep 1; done
     07/10/23 09:02:48.738
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1929.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1929.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1929.svc.cluster.local;sleep 1; done
     07/10/23 09:02:48.738
    STEP: creating a pod to probe DNS 07/10/23 09:02:48.738
    STEP: submitting the pod to kubernetes 07/10/23 09:02:48.738
    Jul 10 09:02:48.760: INFO: Waiting up to 15m0s for pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f" in namespace "dns-1929" to be "running"
    Jul 10 09:02:48.764: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.572821ms
    Jul 10 09:02:50.769: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008847748s
    Jul 10 09:02:52.770: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f": Phase="Running", Reason="", readiness=true. Elapsed: 4.009831413s
    Jul 10 09:02:52.770: INFO: Pod "dns-test-62705b37-2f22-4042-a1b6-497c736c336f" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 09:02:52.77
    STEP: looking for the results for each expected name from probers 07/10/23 09:02:52.774
    Jul 10 09:02:52.779: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.783: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.787: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.791: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.794: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.798: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.802: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.806: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1929.svc.cluster.local from pod dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f: the server could not find the requested resource (get pods dns-test-62705b37-2f22-4042-a1b6-497c736c336f)
    Jul 10 09:02:52.806: INFO: Lookups using dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1929.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1929.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1929.svc.cluster.local jessie_udp@dns-test-service-2.dns-1929.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1929.svc.cluster.local]

    Jul 10 09:02:57.841: INFO: DNS probes using dns-1929/dns-test-62705b37-2f22-4042-a1b6-497c736c336f succeeded

    STEP: deleting the pod 07/10/23 09:02:57.841
    STEP: deleting the test headless service 07/10/23 09:02:57.87
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 09:02:57.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1929" for this suite. 07/10/23 09:02:57.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:57.933
Jul 10 09:02:57.933: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:02:57.934
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:58.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:58.082
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:02:58.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5671" for this suite. 07/10/23 09:02:58.147
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":233,"skipped":4519,"failed":0}
------------------------------
• [0.223 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:57.933
    Jul 10 09:02:57.933: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:02:57.934
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:58.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:58.082
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:02:58.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5671" for this suite. 07/10/23 09:02:58.147
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:02:58.157
Jul 10 09:02:58.157: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 09:02:58.158
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:58.179
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:58.181
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-374 07/10/23 09:02:58.189
STEP: creating replication controller nodeport-test in namespace services-374 07/10/23 09:02:58.224
I0710 09:02:58.235101      21 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-374, replica count: 2
I0710 09:03:01.286903      21 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 09:03:01.286: INFO: Creating new exec pod
Jul 10 09:03:01.303: INFO: Waiting up to 5m0s for pod "execpodjwx5q" in namespace "services-374" to be "running"
Jul 10 09:03:01.308: INFO: Pod "execpodjwx5q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.191733ms
Jul 10 09:03:03.313: INFO: Pod "execpodjwx5q": Phase="Running", Reason="", readiness=true. Elapsed: 2.009313702s
Jul 10 09:03:03.313: INFO: Pod "execpodjwx5q" satisfied condition "running"
Jul 10 09:03:04.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jul 10 09:03:04.488: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jul 10 09:03:04.488: INFO: stdout: "nodeport-test-dl46s"
Jul 10 09:03:04.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.101.194 80'
Jul 10 09:03:04.645: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.101.194 80\nConnection to 192.168.101.194 80 port [tcp/http] succeeded!\n"
Jul 10 09:03:04.645: INFO: stdout: "nodeport-test-dl46s"
Jul 10 09:03:04.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30508'
Jul 10 09:03:04.790: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30508\nConnection to 10.62.109.101 30508 port [tcp/*] succeeded!\n"
Jul 10 09:03:04.790: INFO: stdout: ""
Jul 10 09:03:05.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30508'
Jul 10 09:03:05.946: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30508\nConnection to 10.62.109.101 30508 port [tcp/*] succeeded!\n"
Jul 10 09:03:05.946: INFO: stdout: ""
Jul 10 09:03:06.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30508'
Jul 10 09:03:06.940: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30508\nConnection to 10.62.109.101 30508 port [tcp/*] succeeded!\n"
Jul 10 09:03:06.940: INFO: stdout: "nodeport-test-dl46s"
Jul 10 09:03:06.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.102 30508'
Jul 10 09:03:07.086: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.102 30508\nConnection to 10.62.109.102 30508 port [tcp/*] succeeded!\n"
Jul 10 09:03:07.086: INFO: stdout: "nodeport-test-lclkf"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 09:03:07.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-374" for this suite. 07/10/23 09:03:07.095
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":234,"skipped":4523,"failed":0}
------------------------------
• [SLOW TEST] [8.948 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:02:58.157
    Jul 10 09:02:58.157: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 09:02:58.158
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:02:58.179
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:02:58.181
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-374 07/10/23 09:02:58.189
    STEP: creating replication controller nodeport-test in namespace services-374 07/10/23 09:02:58.224
    I0710 09:02:58.235101      21 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-374, replica count: 2
    I0710 09:03:01.286903      21 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 09:03:01.286: INFO: Creating new exec pod
    Jul 10 09:03:01.303: INFO: Waiting up to 5m0s for pod "execpodjwx5q" in namespace "services-374" to be "running"
    Jul 10 09:03:01.308: INFO: Pod "execpodjwx5q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.191733ms
    Jul 10 09:03:03.313: INFO: Pod "execpodjwx5q": Phase="Running", Reason="", readiness=true. Elapsed: 2.009313702s
    Jul 10 09:03:03.313: INFO: Pod "execpodjwx5q" satisfied condition "running"
    Jul 10 09:03:04.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Jul 10 09:03:04.488: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Jul 10 09:03:04.488: INFO: stdout: "nodeport-test-dl46s"
    Jul 10 09:03:04.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.101.194 80'
    Jul 10 09:03:04.645: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.101.194 80\nConnection to 192.168.101.194 80 port [tcp/http] succeeded!\n"
    Jul 10 09:03:04.645: INFO: stdout: "nodeport-test-dl46s"
    Jul 10 09:03:04.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30508'
    Jul 10 09:03:04.790: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30508\nConnection to 10.62.109.101 30508 port [tcp/*] succeeded!\n"
    Jul 10 09:03:04.790: INFO: stdout: ""
    Jul 10 09:03:05.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30508'
    Jul 10 09:03:05.946: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30508\nConnection to 10.62.109.101 30508 port [tcp/*] succeeded!\n"
    Jul 10 09:03:05.946: INFO: stdout: ""
    Jul 10 09:03:06.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 30508'
    Jul 10 09:03:06.940: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 30508\nConnection to 10.62.109.101 30508 port [tcp/*] succeeded!\n"
    Jul 10 09:03:06.940: INFO: stdout: "nodeport-test-dl46s"
    Jul 10 09:03:06.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-374 exec execpodjwx5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.102 30508'
    Jul 10 09:03:07.086: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.102 30508\nConnection to 10.62.109.102 30508 port [tcp/*] succeeded!\n"
    Jul 10 09:03:07.086: INFO: stdout: "nodeport-test-lclkf"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 09:03:07.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-374" for this suite. 07/10/23 09:03:07.095
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:07.105
Jul 10 09:03:07.106: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:03:07.106
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:07.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:07.135
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 07/10/23 09:03:07.138
STEP: submitting the pod to kubernetes 07/10/23 09:03:07.138
STEP: verifying QOS class is set on the pod 07/10/23 09:03:07.152
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Jul 10 09:03:07.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5267" for this suite. 07/10/23 09:03:07.16
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":235,"skipped":4532,"failed":0}
------------------------------
• [0.074 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:07.105
    Jul 10 09:03:07.106: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:03:07.106
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:07.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:07.135
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 07/10/23 09:03:07.138
    STEP: submitting the pod to kubernetes 07/10/23 09:03:07.138
    STEP: verifying QOS class is set on the pod 07/10/23 09:03:07.152
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Jul 10 09:03:07.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5267" for this suite. 07/10/23 09:03:07.16
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:07.179
Jul 10 09:03:07.179: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 09:03:07.181
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:07.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:07.215
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-e06ab3ee-bcf3-4879-9259-d8d1ecdb54b3 07/10/23 09:03:07.217
STEP: Creating a pod to test consume secrets 07/10/23 09:03:07.224
Jul 10 09:03:07.254: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c" in namespace "projected-8912" to be "Succeeded or Failed"
Jul 10 09:03:07.268: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.806758ms
Jul 10 09:03:09.273: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018514466s
Jul 10 09:03:11.276: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021157271s
STEP: Saw pod success 07/10/23 09:03:11.276
Jul 10 09:03:11.276: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c" satisfied condition "Succeeded or Failed"
Jul 10 09:03:11.279: INFO: Trying to get logs from node 10-62-109-102.test pod pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c container projected-secret-volume-test: <nil>
STEP: delete the pod 07/10/23 09:03:11.299
Jul 10 09:03:11.320: INFO: Waiting for pod pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c to disappear
Jul 10 09:03:11.324: INFO: Pod pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jul 10 09:03:11.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8912" for this suite. 07/10/23 09:03:11.329
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":236,"skipped":4532,"failed":0}
------------------------------
• [4.159 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:07.179
    Jul 10 09:03:07.179: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 09:03:07.181
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:07.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:07.215
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-e06ab3ee-bcf3-4879-9259-d8d1ecdb54b3 07/10/23 09:03:07.217
    STEP: Creating a pod to test consume secrets 07/10/23 09:03:07.224
    Jul 10 09:03:07.254: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c" in namespace "projected-8912" to be "Succeeded or Failed"
    Jul 10 09:03:07.268: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.806758ms
    Jul 10 09:03:09.273: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018514466s
    Jul 10 09:03:11.276: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021157271s
    STEP: Saw pod success 07/10/23 09:03:11.276
    Jul 10 09:03:11.276: INFO: Pod "pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c" satisfied condition "Succeeded or Failed"
    Jul 10 09:03:11.279: INFO: Trying to get logs from node 10-62-109-102.test pod pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c container projected-secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 09:03:11.299
    Jul 10 09:03:11.320: INFO: Waiting for pod pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c to disappear
    Jul 10 09:03:11.324: INFO: Pod pod-projected-secrets-ac499ec8-17c2-47da-b97c-2bde4f1c489c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jul 10 09:03:11.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8912" for this suite. 07/10/23 09:03:11.329
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:11.339
Jul 10 09:03:11.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename job 07/10/23 09:03:11.341
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:11.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:11.387
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 07/10/23 09:03:11.39
STEP: Ensuring active pods == parallelism 07/10/23 09:03:11.399
STEP: Orphaning one of the Job's Pods 07/10/23 09:03:13.404
Jul 10 09:03:13.991: INFO: Successfully updated pod "adopt-release-9j5n5"
STEP: Checking that the Job readopts the Pod 07/10/23 09:03:13.991
Jul 10 09:03:13.991: INFO: Waiting up to 15m0s for pod "adopt-release-9j5n5" in namespace "job-1739" to be "adopted"
Jul 10 09:03:13.997: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 5.668587ms
Jul 10 09:03:16.002: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 2.011183117s
Jul 10 09:03:16.002: INFO: Pod "adopt-release-9j5n5" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 07/10/23 09:03:16.002
Jul 10 09:03:16.525: INFO: Successfully updated pod "adopt-release-9j5n5"
STEP: Checking that the Job releases the Pod 07/10/23 09:03:16.525
Jul 10 09:03:16.525: INFO: Waiting up to 15m0s for pod "adopt-release-9j5n5" in namespace "job-1739" to be "released"
Jul 10 09:03:16.531: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 6.255555ms
Jul 10 09:03:18.538: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 2.012871689s
Jul 10 09:03:18.538: INFO: Pod "adopt-release-9j5n5" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jul 10 09:03:18.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1739" for this suite. 07/10/23 09:03:18.543
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":237,"skipped":4532,"failed":0}
------------------------------
• [SLOW TEST] [7.217 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:11.339
    Jul 10 09:03:11.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename job 07/10/23 09:03:11.341
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:11.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:11.387
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 07/10/23 09:03:11.39
    STEP: Ensuring active pods == parallelism 07/10/23 09:03:11.399
    STEP: Orphaning one of the Job's Pods 07/10/23 09:03:13.404
    Jul 10 09:03:13.991: INFO: Successfully updated pod "adopt-release-9j5n5"
    STEP: Checking that the Job readopts the Pod 07/10/23 09:03:13.991
    Jul 10 09:03:13.991: INFO: Waiting up to 15m0s for pod "adopt-release-9j5n5" in namespace "job-1739" to be "adopted"
    Jul 10 09:03:13.997: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 5.668587ms
    Jul 10 09:03:16.002: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 2.011183117s
    Jul 10 09:03:16.002: INFO: Pod "adopt-release-9j5n5" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 07/10/23 09:03:16.002
    Jul 10 09:03:16.525: INFO: Successfully updated pod "adopt-release-9j5n5"
    STEP: Checking that the Job releases the Pod 07/10/23 09:03:16.525
    Jul 10 09:03:16.525: INFO: Waiting up to 15m0s for pod "adopt-release-9j5n5" in namespace "job-1739" to be "released"
    Jul 10 09:03:16.531: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 6.255555ms
    Jul 10 09:03:18.538: INFO: Pod "adopt-release-9j5n5": Phase="Running", Reason="", readiness=true. Elapsed: 2.012871689s
    Jul 10 09:03:18.538: INFO: Pod "adopt-release-9j5n5" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jul 10 09:03:18.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1739" for this suite. 07/10/23 09:03:18.543
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:18.557
Jul 10 09:03:18.557: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename aggregator 07/10/23 09:03:18.558
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:18.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:18.631
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Jul 10 09:03:18.634: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 07/10/23 09:03:18.634
Jul 10 09:03:19.959: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul 10 09:03:22.032: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:24.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:26.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:28.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:30.043: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:32.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:34.037: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:36.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:38.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:40.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:42.040: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:03:44.177: INFO: Waited 125.835203ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 07/10/23 09:03:44.246
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 07/10/23 09:03:44.251
STEP: List APIServices 07/10/23 09:03:44.262
Jul 10 09:03:44.274: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Jul 10 09:03:44.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6704" for this suite. 07/10/23 09:03:44.677
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":238,"skipped":4559,"failed":0}
------------------------------
• [SLOW TEST] [26.164 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:18.557
    Jul 10 09:03:18.557: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename aggregator 07/10/23 09:03:18.558
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:18.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:18.631
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Jul 10 09:03:18.634: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 07/10/23 09:03:18.634
    Jul 10 09:03:19.959: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Jul 10 09:03:22.032: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:24.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:26.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:28.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:30.043: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:32.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:34.037: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:36.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:38.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:40.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:42.040: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 3, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:03:44.177: INFO: Waited 125.835203ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 07/10/23 09:03:44.246
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 07/10/23 09:03:44.251
    STEP: List APIServices 07/10/23 09:03:44.262
    Jul 10 09:03:44.274: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Jul 10 09:03:44.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-6704" for this suite. 07/10/23 09:03:44.677
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:44.722
Jul 10 09:03:44.723: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:03:44.724
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:44.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:44.759
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 07/10/23 09:03:44.761
STEP: submitting the pod to kubernetes 07/10/23 09:03:44.761
Jul 10 09:03:44.775: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" in namespace "pods-6699" to be "running and ready"
Jul 10 09:03:44.780: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Pending", Reason="", readiness=false. Elapsed: 5.33855ms
Jul 10 09:03:44.780: INFO: The phase of Pod pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:03:46.786: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010936095s
Jul 10 09:03:46.786: INFO: The phase of Pod pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:03:48.787: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Running", Reason="", readiness=true. Elapsed: 4.011455844s
Jul 10 09:03:48.787: INFO: The phase of Pod pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317 is Running (Ready = true)
Jul 10 09:03:48.787: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 07/10/23 09:03:48.791
STEP: updating the pod 07/10/23 09:03:48.796
Jul 10 09:03:49.316: INFO: Successfully updated pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317"
Jul 10 09:03:49.316: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" in namespace "pods-6699" to be "terminated with reason DeadlineExceeded"
Jul 10 09:03:49.322: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Running", Reason="", readiness=true. Elapsed: 5.960314ms
Jul 10 09:03:51.329: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.013092724s
Jul 10 09:03:51.329: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 09:03:51.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6699" for this suite. 07/10/23 09:03:51.334
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":239,"skipped":4567,"failed":0}
------------------------------
• [SLOW TEST] [6.625 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:44.722
    Jul 10 09:03:44.723: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:03:44.724
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:44.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:44.759
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 07/10/23 09:03:44.761
    STEP: submitting the pod to kubernetes 07/10/23 09:03:44.761
    Jul 10 09:03:44.775: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" in namespace "pods-6699" to be "running and ready"
    Jul 10 09:03:44.780: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Pending", Reason="", readiness=false. Elapsed: 5.33855ms
    Jul 10 09:03:44.780: INFO: The phase of Pod pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:03:46.786: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010936095s
    Jul 10 09:03:46.786: INFO: The phase of Pod pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:03:48.787: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Running", Reason="", readiness=true. Elapsed: 4.011455844s
    Jul 10 09:03:48.787: INFO: The phase of Pod pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317 is Running (Ready = true)
    Jul 10 09:03:48.787: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 07/10/23 09:03:48.791
    STEP: updating the pod 07/10/23 09:03:48.796
    Jul 10 09:03:49.316: INFO: Successfully updated pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317"
    Jul 10 09:03:49.316: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" in namespace "pods-6699" to be "terminated with reason DeadlineExceeded"
    Jul 10 09:03:49.322: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Running", Reason="", readiness=true. Elapsed: 5.960314ms
    Jul 10 09:03:51.329: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.013092724s
    Jul 10 09:03:51.329: INFO: Pod "pod-update-activedeadlineseconds-31c9b2f3-7901-41d8-8c38-1c5903795317" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 09:03:51.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6699" for this suite. 07/10/23 09:03:51.334
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:51.348
Jul 10 09:03:51.348: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 09:03:51.349
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:51.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:51.377
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 07/10/23 09:03:51.38
STEP: Getting a ResourceQuota 07/10/23 09:03:51.393
STEP: Updating a ResourceQuota 07/10/23 09:03:51.403
STEP: Verifying a ResourceQuota was modified 07/10/23 09:03:51.411
STEP: Deleting a ResourceQuota 07/10/23 09:03:51.414
STEP: Verifying the deleted ResourceQuota 07/10/23 09:03:51.43
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 09:03:51.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-268" for this suite. 07/10/23 09:03:51.437
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":240,"skipped":4577,"failed":0}
------------------------------
• [0.106 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:51.348
    Jul 10 09:03:51.348: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 09:03:51.349
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:51.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:51.377
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 07/10/23 09:03:51.38
    STEP: Getting a ResourceQuota 07/10/23 09:03:51.393
    STEP: Updating a ResourceQuota 07/10/23 09:03:51.403
    STEP: Verifying a ResourceQuota was modified 07/10/23 09:03:51.411
    STEP: Deleting a ResourceQuota 07/10/23 09:03:51.414
    STEP: Verifying the deleted ResourceQuota 07/10/23 09:03:51.43
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 09:03:51.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-268" for this suite. 07/10/23 09:03:51.437
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:03:51.455
Jul 10 09:03:51.455: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename subpath 07/10/23 09:03:51.456
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:51.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:51.487
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 07/10/23 09:03:51.49
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-cbv8 07/10/23 09:03:51.504
STEP: Creating a pod to test atomic-volume-subpath 07/10/23 09:03:51.504
Jul 10 09:03:51.521: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cbv8" in namespace "subpath-2760" to be "Succeeded or Failed"
Jul 10 09:03:51.524: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217732ms
Jul 10 09:03:53.533: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 2.011992112s
Jul 10 09:03:55.528: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 4.007262134s
Jul 10 09:03:57.533: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 6.011424486s
Jul 10 09:03:59.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 8.008844343s
Jul 10 09:04:01.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 10.008679047s
Jul 10 09:04:03.531: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 12.009794225s
Jul 10 09:04:05.529: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 14.008381729s
Jul 10 09:04:07.531: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 16.010267471s
Jul 10 09:04:09.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 18.008735584s
Jul 10 09:04:11.531: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 20.010052595s
Jul 10 09:04:13.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=false. Elapsed: 22.008749588s
Jul 10 09:04:15.529: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008226743s
STEP: Saw pod success 07/10/23 09:04:15.529
Jul 10 09:04:15.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8" satisfied condition "Succeeded or Failed"
Jul 10 09:04:15.535: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-downwardapi-cbv8 container test-container-subpath-downwardapi-cbv8: <nil>
STEP: delete the pod 07/10/23 09:04:15.551
Jul 10 09:04:15.591: INFO: Waiting for pod pod-subpath-test-downwardapi-cbv8 to disappear
Jul 10 09:04:15.595: INFO: Pod pod-subpath-test-downwardapi-cbv8 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cbv8 07/10/23 09:04:15.595
Jul 10 09:04:15.595: INFO: Deleting pod "pod-subpath-test-downwardapi-cbv8" in namespace "subpath-2760"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jul 10 09:04:15.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2760" for this suite. 07/10/23 09:04:15.604
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":241,"skipped":4588,"failed":0}
------------------------------
• [SLOW TEST] [24.161 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:03:51.455
    Jul 10 09:03:51.455: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename subpath 07/10/23 09:03:51.456
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:03:51.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:03:51.487
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 07/10/23 09:03:51.49
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-cbv8 07/10/23 09:03:51.504
    STEP: Creating a pod to test atomic-volume-subpath 07/10/23 09:03:51.504
    Jul 10 09:03:51.521: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cbv8" in namespace "subpath-2760" to be "Succeeded or Failed"
    Jul 10 09:03:51.524: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217732ms
    Jul 10 09:03:53.533: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 2.011992112s
    Jul 10 09:03:55.528: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 4.007262134s
    Jul 10 09:03:57.533: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 6.011424486s
    Jul 10 09:03:59.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 8.008844343s
    Jul 10 09:04:01.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 10.008679047s
    Jul 10 09:04:03.531: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 12.009794225s
    Jul 10 09:04:05.529: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 14.008381729s
    Jul 10 09:04:07.531: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 16.010267471s
    Jul 10 09:04:09.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 18.008735584s
    Jul 10 09:04:11.531: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=true. Elapsed: 20.010052595s
    Jul 10 09:04:13.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Running", Reason="", readiness=false. Elapsed: 22.008749588s
    Jul 10 09:04:15.529: INFO: Pod "pod-subpath-test-downwardapi-cbv8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008226743s
    STEP: Saw pod success 07/10/23 09:04:15.529
    Jul 10 09:04:15.530: INFO: Pod "pod-subpath-test-downwardapi-cbv8" satisfied condition "Succeeded or Failed"
    Jul 10 09:04:15.535: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-downwardapi-cbv8 container test-container-subpath-downwardapi-cbv8: <nil>
    STEP: delete the pod 07/10/23 09:04:15.551
    Jul 10 09:04:15.591: INFO: Waiting for pod pod-subpath-test-downwardapi-cbv8 to disappear
    Jul 10 09:04:15.595: INFO: Pod pod-subpath-test-downwardapi-cbv8 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-cbv8 07/10/23 09:04:15.595
    Jul 10 09:04:15.595: INFO: Deleting pod "pod-subpath-test-downwardapi-cbv8" in namespace "subpath-2760"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jul 10 09:04:15.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2760" for this suite. 07/10/23 09:04:15.604
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:04:15.617
Jul 10 09:04:15.617: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename server-version 07/10/23 09:04:15.618
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:15.644
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:15.647
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 07/10/23 09:04:15.65
STEP: Confirm major version 07/10/23 09:04:15.651
Jul 10 09:04:15.651: INFO: Major version: 1
STEP: Confirm minor version 07/10/23 09:04:15.651
Jul 10 09:04:15.651: INFO: cleanMinorVersion: 25
Jul 10 09:04:15.651: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Jul 10 09:04:15.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1807" for this suite. 07/10/23 09:04:15.656
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":242,"skipped":4590,"failed":0}
------------------------------
• [0.051 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:04:15.617
    Jul 10 09:04:15.617: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename server-version 07/10/23 09:04:15.618
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:15.644
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:15.647
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 07/10/23 09:04:15.65
    STEP: Confirm major version 07/10/23 09:04:15.651
    Jul 10 09:04:15.651: INFO: Major version: 1
    STEP: Confirm minor version 07/10/23 09:04:15.651
    Jul 10 09:04:15.651: INFO: cleanMinorVersion: 25
    Jul 10 09:04:15.651: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Jul 10 09:04:15.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-1807" for this suite. 07/10/23 09:04:15.656
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:04:15.668
Jul 10 09:04:15.668: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:04:15.67
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:15.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:15.709
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 07/10/23 09:04:15.711
Jul 10 09:04:15.712: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: mark a version not serverd 07/10/23 09:04:24.247
STEP: check the unserved version gets removed 07/10/23 09:04:24.281
STEP: check the other version is not changed 07/10/23 09:04:28.405
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:04:36.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1445" for this suite. 07/10/23 09:04:36.425
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":243,"skipped":4590,"failed":0}
------------------------------
• [SLOW TEST] [20.769 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:04:15.668
    Jul 10 09:04:15.668: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:04:15.67
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:15.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:15.709
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 07/10/23 09:04:15.711
    Jul 10 09:04:15.712: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: mark a version not serverd 07/10/23 09:04:24.247
    STEP: check the unserved version gets removed 07/10/23 09:04:24.281
    STEP: check the other version is not changed 07/10/23 09:04:28.405
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:04:36.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1445" for this suite. 07/10/23 09:04:36.425
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:04:36.439
Jul 10 09:04:36.439: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 09:04:36.44
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:36.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:36.47
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 07/10/23 09:04:36.473
Jul 10 09:04:36.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8293 cluster-info'
Jul 10 09:04:36.553: INFO: stderr: ""
Jul 10 09:04:36.553: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://192.168.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 09:04:36.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8293" for this suite. 07/10/23 09:04:36.559
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":244,"skipped":4624,"failed":0}
------------------------------
• [0.134 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:04:36.439
    Jul 10 09:04:36.439: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 09:04:36.44
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:36.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:36.47
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 07/10/23 09:04:36.473
    Jul 10 09:04:36.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-8293 cluster-info'
    Jul 10 09:04:36.553: INFO: stderr: ""
    Jul 10 09:04:36.553: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://192.168.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 09:04:36.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8293" for this suite. 07/10/23 09:04:36.559
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:04:36.574
Jul 10 09:04:36.574: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename subpath 07/10/23 09:04:36.575
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:36.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:36.604
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 07/10/23 09:04:36.607
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-vdtr 07/10/23 09:04:36.686
STEP: Creating a pod to test atomic-volume-subpath 07/10/23 09:04:36.686
Jul 10 09:04:36.706: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vdtr" in namespace "subpath-2940" to be "Succeeded or Failed"
Jul 10 09:04:36.723: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Pending", Reason="", readiness=false. Elapsed: 16.890781ms
Jul 10 09:04:38.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022850112s
Jul 10 09:04:40.730: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 4.023840737s
Jul 10 09:04:42.735: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 6.028052117s
Jul 10 09:04:44.728: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 8.021804268s
Jul 10 09:04:46.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 10.022163408s
Jul 10 09:04:48.738: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 12.0318086s
Jul 10 09:04:50.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 14.022431801s
Jul 10 09:04:52.733: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 16.026394998s
Jul 10 09:04:54.731: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 18.024595413s
Jul 10 09:04:56.730: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 20.023126712s
Jul 10 09:04:58.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 22.022850486s
Jul 10 09:05:00.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=false. Elapsed: 24.022521458s
Jul 10 09:05:02.730: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.023282314s
STEP: Saw pod success 07/10/23 09:05:02.73
Jul 10 09:05:02.730: INFO: Pod "pod-subpath-test-configmap-vdtr" satisfied condition "Succeeded or Failed"
Jul 10 09:05:02.735: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-configmap-vdtr container test-container-subpath-configmap-vdtr: <nil>
STEP: delete the pod 07/10/23 09:05:02.75
Jul 10 09:05:02.772: INFO: Waiting for pod pod-subpath-test-configmap-vdtr to disappear
Jul 10 09:05:02.776: INFO: Pod pod-subpath-test-configmap-vdtr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vdtr 07/10/23 09:05:02.776
Jul 10 09:05:02.776: INFO: Deleting pod "pod-subpath-test-configmap-vdtr" in namespace "subpath-2940"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jul 10 09:05:02.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2940" for this suite. 07/10/23 09:05:02.789
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":245,"skipped":4626,"failed":0}
------------------------------
• [SLOW TEST] [26.225 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:04:36.574
    Jul 10 09:04:36.574: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename subpath 07/10/23 09:04:36.575
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:04:36.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:04:36.604
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 07/10/23 09:04:36.607
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-vdtr 07/10/23 09:04:36.686
    STEP: Creating a pod to test atomic-volume-subpath 07/10/23 09:04:36.686
    Jul 10 09:04:36.706: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vdtr" in namespace "subpath-2940" to be "Succeeded or Failed"
    Jul 10 09:04:36.723: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Pending", Reason="", readiness=false. Elapsed: 16.890781ms
    Jul 10 09:04:38.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022850112s
    Jul 10 09:04:40.730: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 4.023840737s
    Jul 10 09:04:42.735: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 6.028052117s
    Jul 10 09:04:44.728: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 8.021804268s
    Jul 10 09:04:46.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 10.022163408s
    Jul 10 09:04:48.738: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 12.0318086s
    Jul 10 09:04:50.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 14.022431801s
    Jul 10 09:04:52.733: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 16.026394998s
    Jul 10 09:04:54.731: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 18.024595413s
    Jul 10 09:04:56.730: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 20.023126712s
    Jul 10 09:04:58.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=true. Elapsed: 22.022850486s
    Jul 10 09:05:00.729: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Running", Reason="", readiness=false. Elapsed: 24.022521458s
    Jul 10 09:05:02.730: INFO: Pod "pod-subpath-test-configmap-vdtr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.023282314s
    STEP: Saw pod success 07/10/23 09:05:02.73
    Jul 10 09:05:02.730: INFO: Pod "pod-subpath-test-configmap-vdtr" satisfied condition "Succeeded or Failed"
    Jul 10 09:05:02.735: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-configmap-vdtr container test-container-subpath-configmap-vdtr: <nil>
    STEP: delete the pod 07/10/23 09:05:02.75
    Jul 10 09:05:02.772: INFO: Waiting for pod pod-subpath-test-configmap-vdtr to disappear
    Jul 10 09:05:02.776: INFO: Pod pod-subpath-test-configmap-vdtr no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-vdtr 07/10/23 09:05:02.776
    Jul 10 09:05:02.776: INFO: Deleting pod "pod-subpath-test-configmap-vdtr" in namespace "subpath-2940"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jul 10 09:05:02.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2940" for this suite. 07/10/23 09:05:02.789
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:05:02.8
Jul 10 09:05:02.800: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 09:05:02.801
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:02.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:02.836
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 07/10/23 09:05:02.873
STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:05:02.884
Jul 10 09:05:02.893: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:05:02.893: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:05:03.912: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:05:03.912: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:05:04.906: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul 10 09:05:04.906: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:05:05.905: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:05:05.905: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 07/10/23 09:05:05.909
Jul 10 09:05:05.914: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 07/10/23 09:05:05.914
Jul 10 09:05:05.929: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 07/10/23 09:05:05.929
Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: ADDED
Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.932: INFO: Found daemon set daemon-set in namespace daemonsets-673 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul 10 09:05:05.932: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 07/10/23 09:05:05.932
STEP: watching for the daemon set status to be patched 07/10/23 09:05:05.955
Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: ADDED
Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.959: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.959: INFO: Observed daemon set daemon-set in namespace daemonsets-673 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul 10 09:05:05.959: INFO: Observed &DaemonSet event: MODIFIED
Jul 10 09:05:05.959: INFO: Found daemon set daemon-set in namespace daemonsets-673 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Jul 10 09:05:05.959: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:05:05.968
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-673, will wait for the garbage collector to delete the pods 07/10/23 09:05:05.968
Jul 10 09:05:06.042: INFO: Deleting DaemonSet.extensions daemon-set took: 12.829401ms
Jul 10 09:05:06.143: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.995074ms
Jul 10 09:05:08.448: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:05:08.448: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul 10 09:05:08.452: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"95863"},"items":null}

Jul 10 09:05:08.457: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"95863"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:05:08.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-673" for this suite. 07/10/23 09:05:08.483
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":246,"skipped":4645,"failed":0}
------------------------------
• [SLOW TEST] [5.697 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:05:02.8
    Jul 10 09:05:02.800: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 09:05:02.801
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:02.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:02.836
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 07/10/23 09:05:02.873
    STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:05:02.884
    Jul 10 09:05:02.893: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:05:02.893: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:05:03.912: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:05:03.912: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:05:04.906: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jul 10 09:05:04.906: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:05:05.905: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:05:05.905: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 07/10/23 09:05:05.909
    Jul 10 09:05:05.914: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 07/10/23 09:05:05.914
    Jul 10 09:05:05.929: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 07/10/23 09:05:05.929
    Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: ADDED
    Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.932: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.932: INFO: Found daemon set daemon-set in namespace daemonsets-673 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jul 10 09:05:05.932: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 07/10/23 09:05:05.932
    STEP: watching for the daemon set status to be patched 07/10/23 09:05:05.955
    Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: ADDED
    Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.958: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.959: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.959: INFO: Observed daemon set daemon-set in namespace daemonsets-673 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jul 10 09:05:05.959: INFO: Observed &DaemonSet event: MODIFIED
    Jul 10 09:05:05.959: INFO: Found daemon set daemon-set in namespace daemonsets-673 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Jul 10 09:05:05.959: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:05:05.968
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-673, will wait for the garbage collector to delete the pods 07/10/23 09:05:05.968
    Jul 10 09:05:06.042: INFO: Deleting DaemonSet.extensions daemon-set took: 12.829401ms
    Jul 10 09:05:06.143: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.995074ms
    Jul 10 09:05:08.448: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:05:08.448: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jul 10 09:05:08.452: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"95863"},"items":null}

    Jul 10 09:05:08.457: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"95863"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:05:08.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-673" for this suite. 07/10/23 09:05:08.483
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:05:08.497
Jul 10 09:05:08.497: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename ingressclass 07/10/23 09:05:08.499
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:08.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:08.533
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 07/10/23 09:05:08.536
STEP: getting /apis/networking.k8s.io 07/10/23 09:05:08.538
STEP: getting /apis/networking.k8s.iov1 07/10/23 09:05:08.539
STEP: creating 07/10/23 09:05:08.54
STEP: getting 07/10/23 09:05:08.598
STEP: listing 07/10/23 09:05:08.602
STEP: watching 07/10/23 09:05:08.606
Jul 10 09:05:08.606: INFO: starting watch
STEP: patching 07/10/23 09:05:08.607
STEP: updating 07/10/23 09:05:08.616
Jul 10 09:05:08.623: INFO: waiting for watch events with expected annotations
Jul 10 09:05:08.623: INFO: saw patched and updated annotations
STEP: deleting 07/10/23 09:05:08.623
STEP: deleting a collection 07/10/23 09:05:08.639
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Jul 10 09:05:08.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-8043" for this suite. 07/10/23 09:05:08.669
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":247,"skipped":4646,"failed":0}
------------------------------
• [0.182 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:05:08.497
    Jul 10 09:05:08.497: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename ingressclass 07/10/23 09:05:08.499
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:08.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:08.533
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 07/10/23 09:05:08.536
    STEP: getting /apis/networking.k8s.io 07/10/23 09:05:08.538
    STEP: getting /apis/networking.k8s.iov1 07/10/23 09:05:08.539
    STEP: creating 07/10/23 09:05:08.54
    STEP: getting 07/10/23 09:05:08.598
    STEP: listing 07/10/23 09:05:08.602
    STEP: watching 07/10/23 09:05:08.606
    Jul 10 09:05:08.606: INFO: starting watch
    STEP: patching 07/10/23 09:05:08.607
    STEP: updating 07/10/23 09:05:08.616
    Jul 10 09:05:08.623: INFO: waiting for watch events with expected annotations
    Jul 10 09:05:08.623: INFO: saw patched and updated annotations
    STEP: deleting 07/10/23 09:05:08.623
    STEP: deleting a collection 07/10/23 09:05:08.639
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Jul 10 09:05:08.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-8043" for this suite. 07/10/23 09:05:08.669
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:05:08.68
Jul 10 09:05:08.680: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename security-context 07/10/23 09:05:08.681
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:08.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:08.714
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 07/10/23 09:05:08.718
Jul 10 09:05:08.734: INFO: Waiting up to 5m0s for pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3" in namespace "security-context-9115" to be "Succeeded or Failed"
Jul 10 09:05:08.739: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.34379ms
Jul 10 09:05:10.744: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009916187s
Jul 10 09:05:12.744: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010230588s
STEP: Saw pod success 07/10/23 09:05:12.745
Jul 10 09:05:12.745: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3" satisfied condition "Succeeded or Failed"
Jul 10 09:05:12.748: INFO: Trying to get logs from node 10-62-109-100.test pod security-context-d029a635-1ab8-438b-bc4a-17958e1236f3 container test-container: <nil>
STEP: delete the pod 07/10/23 09:05:12.758
Jul 10 09:05:12.788: INFO: Waiting for pod security-context-d029a635-1ab8-438b-bc4a-17958e1236f3 to disappear
Jul 10 09:05:12.791: INFO: Pod security-context-d029a635-1ab8-438b-bc4a-17958e1236f3 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jul 10 09:05:12.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-9115" for this suite. 07/10/23 09:05:12.796
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":248,"skipped":4658,"failed":0}
------------------------------
• [4.125 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:05:08.68
    Jul 10 09:05:08.680: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename security-context 07/10/23 09:05:08.681
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:08.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:08.714
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 07/10/23 09:05:08.718
    Jul 10 09:05:08.734: INFO: Waiting up to 5m0s for pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3" in namespace "security-context-9115" to be "Succeeded or Failed"
    Jul 10 09:05:08.739: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.34379ms
    Jul 10 09:05:10.744: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009916187s
    Jul 10 09:05:12.744: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010230588s
    STEP: Saw pod success 07/10/23 09:05:12.745
    Jul 10 09:05:12.745: INFO: Pod "security-context-d029a635-1ab8-438b-bc4a-17958e1236f3" satisfied condition "Succeeded or Failed"
    Jul 10 09:05:12.748: INFO: Trying to get logs from node 10-62-109-100.test pod security-context-d029a635-1ab8-438b-bc4a-17958e1236f3 container test-container: <nil>
    STEP: delete the pod 07/10/23 09:05:12.758
    Jul 10 09:05:12.788: INFO: Waiting for pod security-context-d029a635-1ab8-438b-bc4a-17958e1236f3 to disappear
    Jul 10 09:05:12.791: INFO: Pod security-context-d029a635-1ab8-438b-bc4a-17958e1236f3 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jul 10 09:05:12.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-9115" for this suite. 07/10/23 09:05:12.796
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:05:12.805
Jul 10 09:05:12.805: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename cronjob 07/10/23 09:05:12.806
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:12.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:12.847
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 07/10/23 09:05:12.85
STEP: Ensuring more than one job is running at a time 07/10/23 09:05:12.859
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 07/10/23 09:07:00.864
STEP: Removing cronjob 07/10/23 09:07:00.869
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jul 10 09:07:00.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2509" for this suite. 07/10/23 09:07:00.883
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":249,"skipped":4660,"failed":0}
------------------------------
• [SLOW TEST] [108.092 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:05:12.805
    Jul 10 09:05:12.805: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename cronjob 07/10/23 09:05:12.806
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:05:12.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:05:12.847
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 07/10/23 09:05:12.85
    STEP: Ensuring more than one job is running at a time 07/10/23 09:05:12.859
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 07/10/23 09:07:00.864
    STEP: Removing cronjob 07/10/23 09:07:00.869
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jul 10 09:07:00.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2509" for this suite. 07/10/23 09:07:00.883
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:07:00.9
Jul 10 09:07:00.901: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 09:07:00.902
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:07:00.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:07:00.967
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 07/10/23 09:07:00.97
Jul 10 09:07:00.997: INFO: Waiting up to 5m0s for pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c" in namespace "emptydir-9705" to be "Succeeded or Failed"
Jul 10 09:07:01.007: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.977337ms
Jul 10 09:07:03.017: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019603184s
Jul 10 09:07:05.013: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016137232s
Jul 10 09:07:07.016: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018997327s
STEP: Saw pod success 07/10/23 09:07:07.016
Jul 10 09:07:07.016: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c" satisfied condition "Succeeded or Failed"
Jul 10 09:07:07.020: INFO: Trying to get logs from node 10-62-109-101.test pod pod-18c36252-0bfd-45aa-ae73-610681cb544c container test-container: <nil>
STEP: delete the pod 07/10/23 09:07:07.036
Jul 10 09:07:07.059: INFO: Waiting for pod pod-18c36252-0bfd-45aa-ae73-610681cb544c to disappear
Jul 10 09:07:07.063: INFO: Pod pod-18c36252-0bfd-45aa-ae73-610681cb544c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 09:07:07.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9705" for this suite. 07/10/23 09:07:07.068
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":250,"skipped":4686,"failed":0}
------------------------------
• [SLOW TEST] [6.177 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:07:00.9
    Jul 10 09:07:00.901: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 09:07:00.902
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:07:00.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:07:00.967
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 07/10/23 09:07:00.97
    Jul 10 09:07:00.997: INFO: Waiting up to 5m0s for pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c" in namespace "emptydir-9705" to be "Succeeded or Failed"
    Jul 10 09:07:01.007: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.977337ms
    Jul 10 09:07:03.017: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019603184s
    Jul 10 09:07:05.013: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016137232s
    Jul 10 09:07:07.016: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018997327s
    STEP: Saw pod success 07/10/23 09:07:07.016
    Jul 10 09:07:07.016: INFO: Pod "pod-18c36252-0bfd-45aa-ae73-610681cb544c" satisfied condition "Succeeded or Failed"
    Jul 10 09:07:07.020: INFO: Trying to get logs from node 10-62-109-101.test pod pod-18c36252-0bfd-45aa-ae73-610681cb544c container test-container: <nil>
    STEP: delete the pod 07/10/23 09:07:07.036
    Jul 10 09:07:07.059: INFO: Waiting for pod pod-18c36252-0bfd-45aa-ae73-610681cb544c to disappear
    Jul 10 09:07:07.063: INFO: Pod pod-18c36252-0bfd-45aa-ae73-610681cb544c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 09:07:07.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9705" for this suite. 07/10/23 09:07:07.068
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:07:07.08
Jul 10 09:07:07.080: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename gc 07/10/23 09:07:07.081
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:07:07.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:07:07.116
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 07/10/23 09:07:07.128
STEP: delete the rc 07/10/23 09:07:12.209
STEP: wait for the rc to be deleted 07/10/23 09:07:12.288
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 07/10/23 09:07:17.317
STEP: Gathering metrics 07/10/23 09:07:47.344
W0710 09:07:47.355094      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul 10 09:07:47.355: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jul 10 09:07:47.355: INFO: Deleting pod "simpletest.rc-246sh" in namespace "gc-1333"
Jul 10 09:07:47.423: INFO: Deleting pod "simpletest.rc-2b49z" in namespace "gc-1333"
Jul 10 09:07:47.476: INFO: Deleting pod "simpletest.rc-2bgwg" in namespace "gc-1333"
Jul 10 09:07:47.549: INFO: Deleting pod "simpletest.rc-2bwph" in namespace "gc-1333"
Jul 10 09:07:47.618: INFO: Deleting pod "simpletest.rc-2d7t2" in namespace "gc-1333"
Jul 10 09:07:47.673: INFO: Deleting pod "simpletest.rc-48bf8" in namespace "gc-1333"
Jul 10 09:07:47.718: INFO: Deleting pod "simpletest.rc-4cm6b" in namespace "gc-1333"
Jul 10 09:07:47.774: INFO: Deleting pod "simpletest.rc-4dk56" in namespace "gc-1333"
Jul 10 09:07:47.833: INFO: Deleting pod "simpletest.rc-5k6gn" in namespace "gc-1333"
Jul 10 09:07:47.977: INFO: Deleting pod "simpletest.rc-5pwgh" in namespace "gc-1333"
Jul 10 09:07:48.012: INFO: Deleting pod "simpletest.rc-5s427" in namespace "gc-1333"
Jul 10 09:07:48.096: INFO: Deleting pod "simpletest.rc-65x95" in namespace "gc-1333"
Jul 10 09:07:48.159: INFO: Deleting pod "simpletest.rc-6d6d2" in namespace "gc-1333"
Jul 10 09:07:48.311: INFO: Deleting pod "simpletest.rc-6k6wc" in namespace "gc-1333"
Jul 10 09:07:48.353: INFO: Deleting pod "simpletest.rc-6xqrp" in namespace "gc-1333"
Jul 10 09:07:48.413: INFO: Deleting pod "simpletest.rc-7cbrh" in namespace "gc-1333"
Jul 10 09:07:48.451: INFO: Deleting pod "simpletest.rc-7qhtj" in namespace "gc-1333"
Jul 10 09:07:48.493: INFO: Deleting pod "simpletest.rc-7sxp5" in namespace "gc-1333"
Jul 10 09:07:48.562: INFO: Deleting pod "simpletest.rc-7tchk" in namespace "gc-1333"
Jul 10 09:07:48.624: INFO: Deleting pod "simpletest.rc-7tpmt" in namespace "gc-1333"
Jul 10 09:07:48.722: INFO: Deleting pod "simpletest.rc-7x722" in namespace "gc-1333"
Jul 10 09:07:48.898: INFO: Deleting pod "simpletest.rc-84vjt" in namespace "gc-1333"
Jul 10 09:07:49.050: INFO: Deleting pod "simpletest.rc-8g647" in namespace "gc-1333"
Jul 10 09:07:49.091: INFO: Deleting pod "simpletest.rc-8lr29" in namespace "gc-1333"
Jul 10 09:07:49.150: INFO: Deleting pod "simpletest.rc-8vl8v" in namespace "gc-1333"
Jul 10 09:07:49.234: INFO: Deleting pod "simpletest.rc-9dtks" in namespace "gc-1333"
Jul 10 09:07:49.311: INFO: Deleting pod "simpletest.rc-9w5jb" in namespace "gc-1333"
Jul 10 09:07:49.375: INFO: Deleting pod "simpletest.rc-9xmnc" in namespace "gc-1333"
Jul 10 09:07:49.471: INFO: Deleting pod "simpletest.rc-bg6tc" in namespace "gc-1333"
Jul 10 09:07:49.526: INFO: Deleting pod "simpletest.rc-bnl4c" in namespace "gc-1333"
Jul 10 09:07:49.629: INFO: Deleting pod "simpletest.rc-bqvwg" in namespace "gc-1333"
Jul 10 09:07:49.681: INFO: Deleting pod "simpletest.rc-c2zq9" in namespace "gc-1333"
Jul 10 09:07:49.768: INFO: Deleting pod "simpletest.rc-cjfhs" in namespace "gc-1333"
Jul 10 09:07:49.826: INFO: Deleting pod "simpletest.rc-cjvvt" in namespace "gc-1333"
Jul 10 09:07:50.000: INFO: Deleting pod "simpletest.rc-d28jd" in namespace "gc-1333"
Jul 10 09:07:50.040: INFO: Deleting pod "simpletest.rc-dmjsp" in namespace "gc-1333"
Jul 10 09:07:50.122: INFO: Deleting pod "simpletest.rc-dv6fd" in namespace "gc-1333"
Jul 10 09:07:50.224: INFO: Deleting pod "simpletest.rc-dz8pg" in namespace "gc-1333"
Jul 10 09:07:50.418: INFO: Deleting pod "simpletest.rc-fhns9" in namespace "gc-1333"
Jul 10 09:07:50.524: INFO: Deleting pod "simpletest.rc-flnpx" in namespace "gc-1333"
Jul 10 09:07:50.582: INFO: Deleting pod "simpletest.rc-g2lj6" in namespace "gc-1333"
Jul 10 09:07:50.745: INFO: Deleting pod "simpletest.rc-g6qqp" in namespace "gc-1333"
Jul 10 09:07:50.813: INFO: Deleting pod "simpletest.rc-gk225" in namespace "gc-1333"
Jul 10 09:07:50.877: INFO: Deleting pod "simpletest.rc-gmp7n" in namespace "gc-1333"
Jul 10 09:07:50.972: INFO: Deleting pod "simpletest.rc-gt57k" in namespace "gc-1333"
Jul 10 09:07:51.107: INFO: Deleting pod "simpletest.rc-hk7xf" in namespace "gc-1333"
Jul 10 09:07:51.155: INFO: Deleting pod "simpletest.rc-hkwhk" in namespace "gc-1333"
Jul 10 09:07:51.490: INFO: Deleting pod "simpletest.rc-hszfg" in namespace "gc-1333"
Jul 10 09:07:51.579: INFO: Deleting pod "simpletest.rc-jl2ss" in namespace "gc-1333"
Jul 10 09:07:51.671: INFO: Deleting pod "simpletest.rc-kp2vv" in namespace "gc-1333"
Jul 10 09:07:51.726: INFO: Deleting pod "simpletest.rc-lk5qm" in namespace "gc-1333"
Jul 10 09:07:51.782: INFO: Deleting pod "simpletest.rc-lxl52" in namespace "gc-1333"
Jul 10 09:07:51.857: INFO: Deleting pod "simpletest.rc-m5j6m" in namespace "gc-1333"
Jul 10 09:07:51.919: INFO: Deleting pod "simpletest.rc-m7vqp" in namespace "gc-1333"
Jul 10 09:07:51.951: INFO: Deleting pod "simpletest.rc-mp9xg" in namespace "gc-1333"
Jul 10 09:07:52.001: INFO: Deleting pod "simpletest.rc-mq62d" in namespace "gc-1333"
Jul 10 09:07:52.077: INFO: Deleting pod "simpletest.rc-mqqnj" in namespace "gc-1333"
Jul 10 09:07:52.110: INFO: Deleting pod "simpletest.rc-ms8nc" in namespace "gc-1333"
Jul 10 09:07:52.205: INFO: Deleting pod "simpletest.rc-n7phf" in namespace "gc-1333"
Jul 10 09:07:52.254: INFO: Deleting pod "simpletest.rc-nskg8" in namespace "gc-1333"
Jul 10 09:07:52.311: INFO: Deleting pod "simpletest.rc-p8hp7" in namespace "gc-1333"
Jul 10 09:07:52.363: INFO: Deleting pod "simpletest.rc-pbvss" in namespace "gc-1333"
Jul 10 09:07:52.434: INFO: Deleting pod "simpletest.rc-pgrrf" in namespace "gc-1333"
Jul 10 09:07:52.504: INFO: Deleting pod "simpletest.rc-pl5f6" in namespace "gc-1333"
Jul 10 09:07:52.584: INFO: Deleting pod "simpletest.rc-pn7b7" in namespace "gc-1333"
Jul 10 09:07:52.650: INFO: Deleting pod "simpletest.rc-q429w" in namespace "gc-1333"
Jul 10 09:07:52.699: INFO: Deleting pod "simpletest.rc-q5jhv" in namespace "gc-1333"
Jul 10 09:07:52.756: INFO: Deleting pod "simpletest.rc-q8dtx" in namespace "gc-1333"
Jul 10 09:07:52.804: INFO: Deleting pod "simpletest.rc-qmf8q" in namespace "gc-1333"
Jul 10 09:07:52.890: INFO: Deleting pod "simpletest.rc-qmqrb" in namespace "gc-1333"
Jul 10 09:07:52.947: INFO: Deleting pod "simpletest.rc-qn6lr" in namespace "gc-1333"
Jul 10 09:07:53.007: INFO: Deleting pod "simpletest.rc-qwwr2" in namespace "gc-1333"
Jul 10 09:07:53.041: INFO: Deleting pod "simpletest.rc-qz74s" in namespace "gc-1333"
Jul 10 09:07:53.150: INFO: Deleting pod "simpletest.rc-r4qg8" in namespace "gc-1333"
Jul 10 09:07:53.252: INFO: Deleting pod "simpletest.rc-rb99f" in namespace "gc-1333"
Jul 10 09:07:53.307: INFO: Deleting pod "simpletest.rc-rfblm" in namespace "gc-1333"
Jul 10 09:07:53.429: INFO: Deleting pod "simpletest.rc-rkkpf" in namespace "gc-1333"
Jul 10 09:07:53.490: INFO: Deleting pod "simpletest.rc-rn8g9" in namespace "gc-1333"
Jul 10 09:07:53.589: INFO: Deleting pod "simpletest.rc-rx54c" in namespace "gc-1333"
Jul 10 09:07:53.634: INFO: Deleting pod "simpletest.rc-s79nx" in namespace "gc-1333"
Jul 10 09:07:53.729: INFO: Deleting pod "simpletest.rc-s9hcr" in namespace "gc-1333"
Jul 10 09:07:53.917: INFO: Deleting pod "simpletest.rc-spzmv" in namespace "gc-1333"
Jul 10 09:07:54.000: INFO: Deleting pod "simpletest.rc-srh59" in namespace "gc-1333"
Jul 10 09:07:54.035: INFO: Deleting pod "simpletest.rc-t6gqz" in namespace "gc-1333"
Jul 10 09:07:54.088: INFO: Deleting pod "simpletest.rc-t6q8r" in namespace "gc-1333"
Jul 10 09:07:54.122: INFO: Deleting pod "simpletest.rc-t8z5k" in namespace "gc-1333"
Jul 10 09:07:54.288: INFO: Deleting pod "simpletest.rc-td9g2" in namespace "gc-1333"
Jul 10 09:07:54.341: INFO: Deleting pod "simpletest.rc-tr759" in namespace "gc-1333"
Jul 10 09:07:54.379: INFO: Deleting pod "simpletest.rc-vkspg" in namespace "gc-1333"
Jul 10 09:07:54.411: INFO: Deleting pod "simpletest.rc-vqbmn" in namespace "gc-1333"
Jul 10 09:07:54.603: INFO: Deleting pod "simpletest.rc-w8nlm" in namespace "gc-1333"
Jul 10 09:07:54.655: INFO: Deleting pod "simpletest.rc-w9dgk" in namespace "gc-1333"
Jul 10 09:07:54.705: INFO: Deleting pod "simpletest.rc-wbwck" in namespace "gc-1333"
Jul 10 09:07:54.785: INFO: Deleting pod "simpletest.rc-xjthg" in namespace "gc-1333"
Jul 10 09:07:54.859: INFO: Deleting pod "simpletest.rc-xqth8" in namespace "gc-1333"
Jul 10 09:07:54.940: INFO: Deleting pod "simpletest.rc-xrm99" in namespace "gc-1333"
Jul 10 09:07:54.990: INFO: Deleting pod "simpletest.rc-z6p97" in namespace "gc-1333"
Jul 10 09:07:55.105: INFO: Deleting pod "simpletest.rc-z9jtw" in namespace "gc-1333"
Jul 10 09:07:55.271: INFO: Deleting pod "simpletest.rc-zdfzc" in namespace "gc-1333"
Jul 10 09:07:55.323: INFO: Deleting pod "simpletest.rc-zjcjk" in namespace "gc-1333"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jul 10 09:07:55.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1333" for this suite. 07/10/23 09:07:55.397
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":251,"skipped":4722,"failed":0}
------------------------------
• [SLOW TEST] [48.357 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:07:07.08
    Jul 10 09:07:07.080: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename gc 07/10/23 09:07:07.081
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:07:07.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:07:07.116
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 07/10/23 09:07:07.128
    STEP: delete the rc 07/10/23 09:07:12.209
    STEP: wait for the rc to be deleted 07/10/23 09:07:12.288
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 07/10/23 09:07:17.317
    STEP: Gathering metrics 07/10/23 09:07:47.344
    W0710 09:07:47.355094      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jul 10 09:07:47.355: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Jul 10 09:07:47.355: INFO: Deleting pod "simpletest.rc-246sh" in namespace "gc-1333"
    Jul 10 09:07:47.423: INFO: Deleting pod "simpletest.rc-2b49z" in namespace "gc-1333"
    Jul 10 09:07:47.476: INFO: Deleting pod "simpletest.rc-2bgwg" in namespace "gc-1333"
    Jul 10 09:07:47.549: INFO: Deleting pod "simpletest.rc-2bwph" in namespace "gc-1333"
    Jul 10 09:07:47.618: INFO: Deleting pod "simpletest.rc-2d7t2" in namespace "gc-1333"
    Jul 10 09:07:47.673: INFO: Deleting pod "simpletest.rc-48bf8" in namespace "gc-1333"
    Jul 10 09:07:47.718: INFO: Deleting pod "simpletest.rc-4cm6b" in namespace "gc-1333"
    Jul 10 09:07:47.774: INFO: Deleting pod "simpletest.rc-4dk56" in namespace "gc-1333"
    Jul 10 09:07:47.833: INFO: Deleting pod "simpletest.rc-5k6gn" in namespace "gc-1333"
    Jul 10 09:07:47.977: INFO: Deleting pod "simpletest.rc-5pwgh" in namespace "gc-1333"
    Jul 10 09:07:48.012: INFO: Deleting pod "simpletest.rc-5s427" in namespace "gc-1333"
    Jul 10 09:07:48.096: INFO: Deleting pod "simpletest.rc-65x95" in namespace "gc-1333"
    Jul 10 09:07:48.159: INFO: Deleting pod "simpletest.rc-6d6d2" in namespace "gc-1333"
    Jul 10 09:07:48.311: INFO: Deleting pod "simpletest.rc-6k6wc" in namespace "gc-1333"
    Jul 10 09:07:48.353: INFO: Deleting pod "simpletest.rc-6xqrp" in namespace "gc-1333"
    Jul 10 09:07:48.413: INFO: Deleting pod "simpletest.rc-7cbrh" in namespace "gc-1333"
    Jul 10 09:07:48.451: INFO: Deleting pod "simpletest.rc-7qhtj" in namespace "gc-1333"
    Jul 10 09:07:48.493: INFO: Deleting pod "simpletest.rc-7sxp5" in namespace "gc-1333"
    Jul 10 09:07:48.562: INFO: Deleting pod "simpletest.rc-7tchk" in namespace "gc-1333"
    Jul 10 09:07:48.624: INFO: Deleting pod "simpletest.rc-7tpmt" in namespace "gc-1333"
    Jul 10 09:07:48.722: INFO: Deleting pod "simpletest.rc-7x722" in namespace "gc-1333"
    Jul 10 09:07:48.898: INFO: Deleting pod "simpletest.rc-84vjt" in namespace "gc-1333"
    Jul 10 09:07:49.050: INFO: Deleting pod "simpletest.rc-8g647" in namespace "gc-1333"
    Jul 10 09:07:49.091: INFO: Deleting pod "simpletest.rc-8lr29" in namespace "gc-1333"
    Jul 10 09:07:49.150: INFO: Deleting pod "simpletest.rc-8vl8v" in namespace "gc-1333"
    Jul 10 09:07:49.234: INFO: Deleting pod "simpletest.rc-9dtks" in namespace "gc-1333"
    Jul 10 09:07:49.311: INFO: Deleting pod "simpletest.rc-9w5jb" in namespace "gc-1333"
    Jul 10 09:07:49.375: INFO: Deleting pod "simpletest.rc-9xmnc" in namespace "gc-1333"
    Jul 10 09:07:49.471: INFO: Deleting pod "simpletest.rc-bg6tc" in namespace "gc-1333"
    Jul 10 09:07:49.526: INFO: Deleting pod "simpletest.rc-bnl4c" in namespace "gc-1333"
    Jul 10 09:07:49.629: INFO: Deleting pod "simpletest.rc-bqvwg" in namespace "gc-1333"
    Jul 10 09:07:49.681: INFO: Deleting pod "simpletest.rc-c2zq9" in namespace "gc-1333"
    Jul 10 09:07:49.768: INFO: Deleting pod "simpletest.rc-cjfhs" in namespace "gc-1333"
    Jul 10 09:07:49.826: INFO: Deleting pod "simpletest.rc-cjvvt" in namespace "gc-1333"
    Jul 10 09:07:50.000: INFO: Deleting pod "simpletest.rc-d28jd" in namespace "gc-1333"
    Jul 10 09:07:50.040: INFO: Deleting pod "simpletest.rc-dmjsp" in namespace "gc-1333"
    Jul 10 09:07:50.122: INFO: Deleting pod "simpletest.rc-dv6fd" in namespace "gc-1333"
    Jul 10 09:07:50.224: INFO: Deleting pod "simpletest.rc-dz8pg" in namespace "gc-1333"
    Jul 10 09:07:50.418: INFO: Deleting pod "simpletest.rc-fhns9" in namespace "gc-1333"
    Jul 10 09:07:50.524: INFO: Deleting pod "simpletest.rc-flnpx" in namespace "gc-1333"
    Jul 10 09:07:50.582: INFO: Deleting pod "simpletest.rc-g2lj6" in namespace "gc-1333"
    Jul 10 09:07:50.745: INFO: Deleting pod "simpletest.rc-g6qqp" in namespace "gc-1333"
    Jul 10 09:07:50.813: INFO: Deleting pod "simpletest.rc-gk225" in namespace "gc-1333"
    Jul 10 09:07:50.877: INFO: Deleting pod "simpletest.rc-gmp7n" in namespace "gc-1333"
    Jul 10 09:07:50.972: INFO: Deleting pod "simpletest.rc-gt57k" in namespace "gc-1333"
    Jul 10 09:07:51.107: INFO: Deleting pod "simpletest.rc-hk7xf" in namespace "gc-1333"
    Jul 10 09:07:51.155: INFO: Deleting pod "simpletest.rc-hkwhk" in namespace "gc-1333"
    Jul 10 09:07:51.490: INFO: Deleting pod "simpletest.rc-hszfg" in namespace "gc-1333"
    Jul 10 09:07:51.579: INFO: Deleting pod "simpletest.rc-jl2ss" in namespace "gc-1333"
    Jul 10 09:07:51.671: INFO: Deleting pod "simpletest.rc-kp2vv" in namespace "gc-1333"
    Jul 10 09:07:51.726: INFO: Deleting pod "simpletest.rc-lk5qm" in namespace "gc-1333"
    Jul 10 09:07:51.782: INFO: Deleting pod "simpletest.rc-lxl52" in namespace "gc-1333"
    Jul 10 09:07:51.857: INFO: Deleting pod "simpletest.rc-m5j6m" in namespace "gc-1333"
    Jul 10 09:07:51.919: INFO: Deleting pod "simpletest.rc-m7vqp" in namespace "gc-1333"
    Jul 10 09:07:51.951: INFO: Deleting pod "simpletest.rc-mp9xg" in namespace "gc-1333"
    Jul 10 09:07:52.001: INFO: Deleting pod "simpletest.rc-mq62d" in namespace "gc-1333"
    Jul 10 09:07:52.077: INFO: Deleting pod "simpletest.rc-mqqnj" in namespace "gc-1333"
    Jul 10 09:07:52.110: INFO: Deleting pod "simpletest.rc-ms8nc" in namespace "gc-1333"
    Jul 10 09:07:52.205: INFO: Deleting pod "simpletest.rc-n7phf" in namespace "gc-1333"
    Jul 10 09:07:52.254: INFO: Deleting pod "simpletest.rc-nskg8" in namespace "gc-1333"
    Jul 10 09:07:52.311: INFO: Deleting pod "simpletest.rc-p8hp7" in namespace "gc-1333"
    Jul 10 09:07:52.363: INFO: Deleting pod "simpletest.rc-pbvss" in namespace "gc-1333"
    Jul 10 09:07:52.434: INFO: Deleting pod "simpletest.rc-pgrrf" in namespace "gc-1333"
    Jul 10 09:07:52.504: INFO: Deleting pod "simpletest.rc-pl5f6" in namespace "gc-1333"
    Jul 10 09:07:52.584: INFO: Deleting pod "simpletest.rc-pn7b7" in namespace "gc-1333"
    Jul 10 09:07:52.650: INFO: Deleting pod "simpletest.rc-q429w" in namespace "gc-1333"
    Jul 10 09:07:52.699: INFO: Deleting pod "simpletest.rc-q5jhv" in namespace "gc-1333"
    Jul 10 09:07:52.756: INFO: Deleting pod "simpletest.rc-q8dtx" in namespace "gc-1333"
    Jul 10 09:07:52.804: INFO: Deleting pod "simpletest.rc-qmf8q" in namespace "gc-1333"
    Jul 10 09:07:52.890: INFO: Deleting pod "simpletest.rc-qmqrb" in namespace "gc-1333"
    Jul 10 09:07:52.947: INFO: Deleting pod "simpletest.rc-qn6lr" in namespace "gc-1333"
    Jul 10 09:07:53.007: INFO: Deleting pod "simpletest.rc-qwwr2" in namespace "gc-1333"
    Jul 10 09:07:53.041: INFO: Deleting pod "simpletest.rc-qz74s" in namespace "gc-1333"
    Jul 10 09:07:53.150: INFO: Deleting pod "simpletest.rc-r4qg8" in namespace "gc-1333"
    Jul 10 09:07:53.252: INFO: Deleting pod "simpletest.rc-rb99f" in namespace "gc-1333"
    Jul 10 09:07:53.307: INFO: Deleting pod "simpletest.rc-rfblm" in namespace "gc-1333"
    Jul 10 09:07:53.429: INFO: Deleting pod "simpletest.rc-rkkpf" in namespace "gc-1333"
    Jul 10 09:07:53.490: INFO: Deleting pod "simpletest.rc-rn8g9" in namespace "gc-1333"
    Jul 10 09:07:53.589: INFO: Deleting pod "simpletest.rc-rx54c" in namespace "gc-1333"
    Jul 10 09:07:53.634: INFO: Deleting pod "simpletest.rc-s79nx" in namespace "gc-1333"
    Jul 10 09:07:53.729: INFO: Deleting pod "simpletest.rc-s9hcr" in namespace "gc-1333"
    Jul 10 09:07:53.917: INFO: Deleting pod "simpletest.rc-spzmv" in namespace "gc-1333"
    Jul 10 09:07:54.000: INFO: Deleting pod "simpletest.rc-srh59" in namespace "gc-1333"
    Jul 10 09:07:54.035: INFO: Deleting pod "simpletest.rc-t6gqz" in namespace "gc-1333"
    Jul 10 09:07:54.088: INFO: Deleting pod "simpletest.rc-t6q8r" in namespace "gc-1333"
    Jul 10 09:07:54.122: INFO: Deleting pod "simpletest.rc-t8z5k" in namespace "gc-1333"
    Jul 10 09:07:54.288: INFO: Deleting pod "simpletest.rc-td9g2" in namespace "gc-1333"
    Jul 10 09:07:54.341: INFO: Deleting pod "simpletest.rc-tr759" in namespace "gc-1333"
    Jul 10 09:07:54.379: INFO: Deleting pod "simpletest.rc-vkspg" in namespace "gc-1333"
    Jul 10 09:07:54.411: INFO: Deleting pod "simpletest.rc-vqbmn" in namespace "gc-1333"
    Jul 10 09:07:54.603: INFO: Deleting pod "simpletest.rc-w8nlm" in namespace "gc-1333"
    Jul 10 09:07:54.655: INFO: Deleting pod "simpletest.rc-w9dgk" in namespace "gc-1333"
    Jul 10 09:07:54.705: INFO: Deleting pod "simpletest.rc-wbwck" in namespace "gc-1333"
    Jul 10 09:07:54.785: INFO: Deleting pod "simpletest.rc-xjthg" in namespace "gc-1333"
    Jul 10 09:07:54.859: INFO: Deleting pod "simpletest.rc-xqth8" in namespace "gc-1333"
    Jul 10 09:07:54.940: INFO: Deleting pod "simpletest.rc-xrm99" in namespace "gc-1333"
    Jul 10 09:07:54.990: INFO: Deleting pod "simpletest.rc-z6p97" in namespace "gc-1333"
    Jul 10 09:07:55.105: INFO: Deleting pod "simpletest.rc-z9jtw" in namespace "gc-1333"
    Jul 10 09:07:55.271: INFO: Deleting pod "simpletest.rc-zdfzc" in namespace "gc-1333"
    Jul 10 09:07:55.323: INFO: Deleting pod "simpletest.rc-zjcjk" in namespace "gc-1333"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jul 10 09:07:55.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1333" for this suite. 07/10/23 09:07:55.397
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:07:55.437
Jul 10 09:07:55.438: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-runtime 07/10/23 09:07:55.441
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:07:55.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:07:55.574
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 07/10/23 09:07:55.577
STEP: wait for the container to reach Succeeded 07/10/23 09:07:55.593
STEP: get the container status 07/10/23 09:08:00.637
STEP: the container should be terminated 07/10/23 09:08:00.645
STEP: the termination message should be set 07/10/23 09:08:00.646
Jul 10 09:08:00.646: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 07/10/23 09:08:00.646
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jul 10 09:08:00.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6116" for this suite. 07/10/23 09:08:00.686
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":252,"skipped":4725,"failed":0}
------------------------------
• [SLOW TEST] [5.257 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:07:55.437
    Jul 10 09:07:55.438: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-runtime 07/10/23 09:07:55.441
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:07:55.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:07:55.574
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 07/10/23 09:07:55.577
    STEP: wait for the container to reach Succeeded 07/10/23 09:07:55.593
    STEP: get the container status 07/10/23 09:08:00.637
    STEP: the container should be terminated 07/10/23 09:08:00.645
    STEP: the termination message should be set 07/10/23 09:08:00.646
    Jul 10 09:08:00.646: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 07/10/23 09:08:00.646
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jul 10 09:08:00.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6116" for this suite. 07/10/23 09:08:00.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:00.697
Jul 10 09:08:00.697: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 09:08:00.698
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:00.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:00.738
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 07/10/23 09:08:00.748
Jul 10 09:08:00.749: INFO: Creating simple deployment test-deployment-bjt8n
Jul 10 09:08:00.785: INFO: deployment "test-deployment-bjt8n" doesn't have the required revision set
STEP: Getting /status 07/10/23 09:08:02.822
Jul 10 09:08:02.830: INFO: Deployment test-deployment-bjt8n has Conditions: [{Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 07/10/23 09:08:02.83
Jul 10 09:08:02.843: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 2, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 0, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-bjt8n-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 07/10/23 09:08:02.843
Jul 10 09:08:02.846: INFO: Observed &Deployment event: ADDED
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
Jul 10 09:08:02.846: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul 10 09:08:02.846: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-bjt8n-777898ffcc" is progressing.}
Jul 10 09:08:02.846: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
Jul 10 09:08:02.847: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.847: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul 10 09:08:02.847: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
Jul 10 09:08:02.847: INFO: Found Deployment test-deployment-bjt8n in namespace deployment-902 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul 10 09:08:02.847: INFO: Deployment test-deployment-bjt8n has an updated status
STEP: patching the Statefulset Status 07/10/23 09:08:02.847
Jul 10 09:08:02.847: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul 10 09:08:02.863: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 07/10/23 09:08:02.863
Jul 10 09:08:02.865: INFO: Observed &Deployment event: ADDED
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
Jul 10 09:08:02.865: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul 10 09:08:02.865: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-bjt8n-777898ffcc" is progressing.}
Jul 10 09:08:02.865: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
Jul 10 09:08:02.866: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.866: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul 10 09:08:02.866: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
Jul 10 09:08:02.866: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul 10 09:08:02.866: INFO: Observed &Deployment event: MODIFIED
Jul 10 09:08:02.866: INFO: Found deployment test-deployment-bjt8n in namespace deployment-902 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Jul 10 09:08:02.866: INFO: Deployment test-deployment-bjt8n has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 09:08:02.871: INFO: Deployment "test-deployment-bjt8n":
&Deployment{ObjectMeta:{test-deployment-bjt8n  deployment-902  1b79bcf6-a70d-4e38-9354-842caa45119c 98490 1 2023-07-10 09:08:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-07-10 09:08:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038a89f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul 10 09:08:02.881: INFO: New ReplicaSet "test-deployment-bjt8n-777898ffcc" of Deployment "test-deployment-bjt8n":
&ReplicaSet{ObjectMeta:{test-deployment-bjt8n-777898ffcc  deployment-902  016f316f-c239-4177-8bcf-53b2ce52dd48 98461 1 2023-07-10 09:08:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-bjt8n 1b79bcf6-a70d-4e38-9354-842caa45119c 0xc003d427b0 0xc003d427b1}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:08:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1b79bcf6-a70d-4e38-9354-842caa45119c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d42858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:08:02.886: INFO: Pod "test-deployment-bjt8n-777898ffcc-gkp7x" is available:
&Pod{ObjectMeta:{test-deployment-bjt8n-777898ffcc-gkp7x test-deployment-bjt8n-777898ffcc- deployment-902  e64f7e97-0825-4e71-b37c-b7838465abfb 98459 0 2023-07-10 09:08:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:32feeeaf873448b7dc0076089be3f4cba3d081e0926b262ceb2a8a6424bcdf4b cni.projectcalico.org/podIP:192.168.172.63/32 cni.projectcalico.org/podIPs:192.168.172.63/32] [{apps/v1 ReplicaSet test-deployment-bjt8n-777898ffcc 016f316f-c239-4177-8bcf-53b2ce52dd48 0xc0038a8da0 0xc0038a8da1}] [] [{kube-controller-manager Update v1 2023-07-10 09:08:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"016f316f-c239-4177-8bcf-53b2ce52dd48\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:08:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jxdk6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jxdk6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.63,StartTime:2023-07-10 09:08:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:08:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://3500ff82baad38fd9bf311a206bde9f55f80ac6eb8e73057421a8f201dafe823,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 09:08:02.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-902" for this suite. 07/10/23 09:08:02.899
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":253,"skipped":4737,"failed":0}
------------------------------
• [2.218 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:00.697
    Jul 10 09:08:00.697: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 09:08:00.698
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:00.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:00.738
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 07/10/23 09:08:00.748
    Jul 10 09:08:00.749: INFO: Creating simple deployment test-deployment-bjt8n
    Jul 10 09:08:00.785: INFO: deployment "test-deployment-bjt8n" doesn't have the required revision set
    STEP: Getting /status 07/10/23 09:08:02.822
    Jul 10 09:08:02.830: INFO: Deployment test-deployment-bjt8n has Conditions: [{Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 07/10/23 09:08:02.83
    Jul 10 09:08:02.843: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 2, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 0, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-bjt8n-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 07/10/23 09:08:02.843
    Jul 10 09:08:02.846: INFO: Observed &Deployment event: ADDED
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
    Jul 10 09:08:02.846: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jul 10 09:08:02.846: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-bjt8n-777898ffcc" is progressing.}
    Jul 10 09:08:02.846: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jul 10 09:08:02.846: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
    Jul 10 09:08:02.847: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.847: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jul 10 09:08:02.847: INFO: Observed Deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
    Jul 10 09:08:02.847: INFO: Found Deployment test-deployment-bjt8n in namespace deployment-902 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jul 10 09:08:02.847: INFO: Deployment test-deployment-bjt8n has an updated status
    STEP: patching the Statefulset Status 07/10/23 09:08:02.847
    Jul 10 09:08:02.847: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jul 10 09:08:02.863: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 07/10/23 09:08:02.863
    Jul 10 09:08:02.865: INFO: Observed &Deployment event: ADDED
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
    Jul 10 09:08:02.865: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-bjt8n-777898ffcc"}
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jul 10 09:08:02.865: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:00 +0000 UTC 2023-07-10 09:08:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-bjt8n-777898ffcc" is progressing.}
    Jul 10 09:08:02.865: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jul 10 09:08:02.865: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
    Jul 10 09:08:02.866: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.866: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jul 10 09:08:02.866: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-07-10 09:08:02 +0000 UTC 2023-07-10 09:08:00 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-bjt8n-777898ffcc" has successfully progressed.}
    Jul 10 09:08:02.866: INFO: Observed deployment test-deployment-bjt8n in namespace deployment-902 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jul 10 09:08:02.866: INFO: Observed &Deployment event: MODIFIED
    Jul 10 09:08:02.866: INFO: Found deployment test-deployment-bjt8n in namespace deployment-902 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Jul 10 09:08:02.866: INFO: Deployment test-deployment-bjt8n has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 09:08:02.871: INFO: Deployment "test-deployment-bjt8n":
    &Deployment{ObjectMeta:{test-deployment-bjt8n  deployment-902  1b79bcf6-a70d-4e38-9354-842caa45119c 98490 1 2023-07-10 09:08:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-07-10 09:08:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038a89f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jul 10 09:08:02.881: INFO: New ReplicaSet "test-deployment-bjt8n-777898ffcc" of Deployment "test-deployment-bjt8n":
    &ReplicaSet{ObjectMeta:{test-deployment-bjt8n-777898ffcc  deployment-902  016f316f-c239-4177-8bcf-53b2ce52dd48 98461 1 2023-07-10 09:08:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-bjt8n 1b79bcf6-a70d-4e38-9354-842caa45119c 0xc003d427b0 0xc003d427b1}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:08:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1b79bcf6-a70d-4e38-9354-842caa45119c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d42858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:08:02.886: INFO: Pod "test-deployment-bjt8n-777898ffcc-gkp7x" is available:
    &Pod{ObjectMeta:{test-deployment-bjt8n-777898ffcc-gkp7x test-deployment-bjt8n-777898ffcc- deployment-902  e64f7e97-0825-4e71-b37c-b7838465abfb 98459 0 2023-07-10 09:08:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:32feeeaf873448b7dc0076089be3f4cba3d081e0926b262ceb2a8a6424bcdf4b cni.projectcalico.org/podIP:192.168.172.63/32 cni.projectcalico.org/podIPs:192.168.172.63/32] [{apps/v1 ReplicaSet test-deployment-bjt8n-777898ffcc 016f316f-c239-4177-8bcf-53b2ce52dd48 0xc0038a8da0 0xc0038a8da1}] [] [{kube-controller-manager Update v1 2023-07-10 09:08:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"016f316f-c239-4177-8bcf-53b2ce52dd48\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-07-10 09:08:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-07-10 09:08:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jxdk6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jxdk6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.63,StartTime:2023-07-10 09:08:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:08:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://3500ff82baad38fd9bf311a206bde9f55f80ac6eb8e73057421a8f201dafe823,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 09:08:02.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-902" for this suite. 07/10/23 09:08:02.899
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:02.916
Jul 10 09:08:02.916: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename security-context-test 07/10/23 09:08:02.917
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:02.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:02.949
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Jul 10 09:08:02.967: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c" in namespace "security-context-test-704" to be "Succeeded or Failed"
Jul 10 09:08:02.977: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.331127ms
Jul 10 09:08:04.981: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014841905s
Jul 10 09:08:06.982: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015696395s
Jul 10 09:08:06.982: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jul 10 09:08:06.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-704" for this suite. 07/10/23 09:08:07.002
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":254,"skipped":4749,"failed":0}
------------------------------
• [4.110 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:02.916
    Jul 10 09:08:02.916: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename security-context-test 07/10/23 09:08:02.917
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:02.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:02.949
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Jul 10 09:08:02.967: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c" in namespace "security-context-test-704" to be "Succeeded or Failed"
    Jul 10 09:08:02.977: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.331127ms
    Jul 10 09:08:04.981: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014841905s
    Jul 10 09:08:06.982: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015696395s
    Jul 10 09:08:06.982: INFO: Pod "alpine-nnp-false-358986fe-d4db-4ea3-b94e-c2fc9663128c" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jul 10 09:08:06.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-704" for this suite. 07/10/23 09:08:07.002
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:07.029
Jul 10 09:08:07.029: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svcaccounts 07/10/23 09:08:07.03
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:07.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:07.066
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Jul 10 09:08:07.092: INFO: Waiting up to 5m0s for pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9" in namespace "svcaccounts-6390" to be "running"
Jul 10 09:08:07.099: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.673472ms
Jul 10 09:08:09.105: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012707501s
Jul 10 09:08:11.105: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9": Phase="Running", Reason="", readiness=true. Elapsed: 4.012927708s
Jul 10 09:08:11.105: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9" satisfied condition "running"
STEP: reading a file in the container 07/10/23 09:08:11.105
Jul 10 09:08:11.106: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6390 pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 07/10/23 09:08:11.253
Jul 10 09:08:11.253: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6390 pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 07/10/23 09:08:11.389
Jul 10 09:08:11.389: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6390 pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Jul 10 09:08:11.537: INFO: Got root ca configmap in namespace "svcaccounts-6390"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jul 10 09:08:11.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6390" for this suite. 07/10/23 09:08:11.546
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":255,"skipped":4785,"failed":0}
------------------------------
• [4.527 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:07.029
    Jul 10 09:08:07.029: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svcaccounts 07/10/23 09:08:07.03
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:07.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:07.066
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Jul 10 09:08:07.092: INFO: Waiting up to 5m0s for pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9" in namespace "svcaccounts-6390" to be "running"
    Jul 10 09:08:07.099: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.673472ms
    Jul 10 09:08:09.105: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012707501s
    Jul 10 09:08:11.105: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9": Phase="Running", Reason="", readiness=true. Elapsed: 4.012927708s
    Jul 10 09:08:11.105: INFO: Pod "pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9" satisfied condition "running"
    STEP: reading a file in the container 07/10/23 09:08:11.105
    Jul 10 09:08:11.106: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6390 pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 07/10/23 09:08:11.253
    Jul 10 09:08:11.253: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6390 pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 07/10/23 09:08:11.389
    Jul 10 09:08:11.389: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6390 pod-service-account-093c94b4-d456-498d-9bff-9ab77553ebb9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Jul 10 09:08:11.537: INFO: Got root ca configmap in namespace "svcaccounts-6390"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jul 10 09:08:11.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6390" for this suite. 07/10/23 09:08:11.546
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:11.556
Jul 10 09:08:11.556: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 09:08:11.557
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:11.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:11.6
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1644 07/10/23 09:08:11.603
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 07/10/23 09:08:11.614
STEP: Creating pod with conflicting port in namespace statefulset-1644 07/10/23 09:08:11.625
STEP: Waiting until pod test-pod will start running in namespace statefulset-1644 07/10/23 09:08:11.635
Jul 10 09:08:11.636: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-1644" to be "running"
Jul 10 09:08:11.640: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.909773ms
Jul 10 09:08:13.647: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011272645s
Jul 10 09:08:15.645: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009256302s
Jul 10 09:08:15.645: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-1644 07/10/23 09:08:15.645
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1644 07/10/23 09:08:15.658
Jul 10 09:08:15.679: INFO: Observed stateful pod in namespace: statefulset-1644, name: ss-0, uid: 47f0a148-5a59-49d5-b642-817b9a876cff, status phase: Pending. Waiting for statefulset controller to delete.
Jul 10 09:08:15.708: INFO: Observed stateful pod in namespace: statefulset-1644, name: ss-0, uid: 47f0a148-5a59-49d5-b642-817b9a876cff, status phase: Failed. Waiting for statefulset controller to delete.
Jul 10 09:08:15.736: INFO: Observed stateful pod in namespace: statefulset-1644, name: ss-0, uid: 47f0a148-5a59-49d5-b642-817b9a876cff, status phase: Failed. Waiting for statefulset controller to delete.
Jul 10 09:08:15.748: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1644
STEP: Removing pod with conflicting port in namespace statefulset-1644 07/10/23 09:08:15.748
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1644 and will be in running state 07/10/23 09:08:15.789
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 09:08:17.801: INFO: Deleting all statefulset in ns statefulset-1644
Jul 10 09:08:17.805: INFO: Scaling statefulset ss to 0
Jul 10 09:08:27.831: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 09:08:27.835: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 09:08:27.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1644" for this suite. 07/10/23 09:08:27.864
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":256,"skipped":4789,"failed":0}
------------------------------
• [SLOW TEST] [16.328 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:11.556
    Jul 10 09:08:11.556: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 09:08:11.557
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:11.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:11.6
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1644 07/10/23 09:08:11.603
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 07/10/23 09:08:11.614
    STEP: Creating pod with conflicting port in namespace statefulset-1644 07/10/23 09:08:11.625
    STEP: Waiting until pod test-pod will start running in namespace statefulset-1644 07/10/23 09:08:11.635
    Jul 10 09:08:11.636: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-1644" to be "running"
    Jul 10 09:08:11.640: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.909773ms
    Jul 10 09:08:13.647: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011272645s
    Jul 10 09:08:15.645: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009256302s
    Jul 10 09:08:15.645: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-1644 07/10/23 09:08:15.645
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1644 07/10/23 09:08:15.658
    Jul 10 09:08:15.679: INFO: Observed stateful pod in namespace: statefulset-1644, name: ss-0, uid: 47f0a148-5a59-49d5-b642-817b9a876cff, status phase: Pending. Waiting for statefulset controller to delete.
    Jul 10 09:08:15.708: INFO: Observed stateful pod in namespace: statefulset-1644, name: ss-0, uid: 47f0a148-5a59-49d5-b642-817b9a876cff, status phase: Failed. Waiting for statefulset controller to delete.
    Jul 10 09:08:15.736: INFO: Observed stateful pod in namespace: statefulset-1644, name: ss-0, uid: 47f0a148-5a59-49d5-b642-817b9a876cff, status phase: Failed. Waiting for statefulset controller to delete.
    Jul 10 09:08:15.748: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1644
    STEP: Removing pod with conflicting port in namespace statefulset-1644 07/10/23 09:08:15.748
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1644 and will be in running state 07/10/23 09:08:15.789
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 09:08:17.801: INFO: Deleting all statefulset in ns statefulset-1644
    Jul 10 09:08:17.805: INFO: Scaling statefulset ss to 0
    Jul 10 09:08:27.831: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 09:08:27.835: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 09:08:27.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1644" for this suite. 07/10/23 09:08:27.864
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:27.887
Jul 10 09:08:27.887: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 09:08:27.888
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:27.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:27.93
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 07/10/23 09:08:27.933
Jul 10 09:08:27.945: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3467  7a25cf1f-55ef-4dac-94e4-543a5171388c 99060 0 2023-07-10 09:08:27 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-07-10 09:08:27 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cgpcc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cgpcc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul 10 09:08:27.946: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3467" to be "running and ready"
Jul 10 09:08:27.955: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 8.94081ms
Jul 10 09:08:27.955: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:08:29.960: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.014731011s
Jul 10 09:08:29.960: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Jul 10 09:08:29.960: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 07/10/23 09:08:29.961
Jul 10 09:08:29.961: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3467 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:08:29.961: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:08:29.961: INFO: ExecWithOptions: Clientset creation
Jul 10 09:08:29.961: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/dns-3467/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 07/10/23 09:08:30.048
Jul 10 09:08:30.048: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3467 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:08:30.048: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:08:30.048: INFO: ExecWithOptions: Clientset creation
Jul 10 09:08:30.048: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/dns-3467/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul 10 09:08:30.151: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 09:08:30.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3467" for this suite. 07/10/23 09:08:30.193
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":257,"skipped":4831,"failed":0}
------------------------------
• [2.325 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:27.887
    Jul 10 09:08:27.887: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 09:08:27.888
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:27.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:27.93
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 07/10/23 09:08:27.933
    Jul 10 09:08:27.945: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3467  7a25cf1f-55ef-4dac-94e4-543a5171388c 99060 0 2023-07-10 09:08:27 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-07-10 09:08:27 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cgpcc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cgpcc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jul 10 09:08:27.946: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-3467" to be "running and ready"
    Jul 10 09:08:27.955: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 8.94081ms
    Jul 10 09:08:27.955: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:08:29.960: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.014731011s
    Jul 10 09:08:29.960: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Jul 10 09:08:29.960: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 07/10/23 09:08:29.961
    Jul 10 09:08:29.961: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3467 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:08:29.961: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:08:29.961: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:08:29.961: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/dns-3467/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 07/10/23 09:08:30.048
    Jul 10 09:08:30.048: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3467 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:08:30.048: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:08:30.048: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:08:30.048: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/dns-3467/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jul 10 09:08:30.151: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 09:08:30.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3467" for this suite. 07/10/23 09:08:30.193
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:30.213
Jul 10 09:08:30.213: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 09:08:30.214
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:30.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:30.246
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Jul 10 09:08:30.249: INFO: Creating deployment "test-recreate-deployment"
Jul 10 09:08:30.261: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul 10 09:08:30.271: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul 10 09:08:32.283: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul 10 09:08:32.287: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:08:34.295: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul 10 09:08:34.317: INFO: Updating deployment test-recreate-deployment
Jul 10 09:08:34.317: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 09:08:34.543: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2006  b7f5cacd-74dd-4e3c-babe-a27692163af2 99159 2 2023-07-10 09:08:29 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-07-10 09:08:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00353e058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-07-10 09:08:34 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-07-10 09:08:34 +0000 UTC,LastTransitionTime:2023-07-10 09:08:30 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jul 10 09:08:34.547: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2006  42f9ef1c-e6ca-4acf-ba4b-363f7b3fc908 99158 1 2023-07-10 09:08:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b7f5cacd-74dd-4e3c-babe-a27692163af2 0xc00353e760 0xc00353e761}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7f5cacd-74dd-4e3c-babe-a27692163af2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00353e7f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:08:34.547: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul 10 09:08:34.547: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2006  24d240ba-de7e-4d8b-81be-26ade41ff91e 99145 2 2023-07-10 09:08:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b7f5cacd-74dd-4e3c-babe-a27692163af2 0xc00353e647 0xc00353e648}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7f5cacd-74dd-4e3c-babe-a27692163af2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00353e6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:08:34.552: INFO: Pod "test-recreate-deployment-9d58999df-7bqg5" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-7bqg5 test-recreate-deployment-9d58999df- deployment-2006  e1961c9d-22cd-47ba-a0bb-301cd3fc9929 99157 0 2023-07-10 09:08:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 42f9ef1c-e6ca-4acf-ba4b-363f7b3fc908 0xc00353ec70 0xc00353ec71}] [] [{kube-controller-manager Update v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"42f9ef1c-e6ca-4acf-ba4b-363f7b3fc908\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-525jx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-525jx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:08:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 09:08:34.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2006" for this suite. 07/10/23 09:08:34.561
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":258,"skipped":4846,"failed":0}
------------------------------
• [4.356 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:30.213
    Jul 10 09:08:30.213: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 09:08:30.214
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:30.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:30.246
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Jul 10 09:08:30.249: INFO: Creating deployment "test-recreate-deployment"
    Jul 10 09:08:30.261: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Jul 10 09:08:30.271: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Jul 10 09:08:32.283: INFO: Waiting deployment "test-recreate-deployment" to complete
    Jul 10 09:08:32.287: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 8, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:08:34.295: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Jul 10 09:08:34.317: INFO: Updating deployment test-recreate-deployment
    Jul 10 09:08:34.317: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 09:08:34.543: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-2006  b7f5cacd-74dd-4e3c-babe-a27692163af2 99159 2 2023-07-10 09:08:29 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-07-10 09:08:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00353e058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-07-10 09:08:34 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-07-10 09:08:34 +0000 UTC,LastTransitionTime:2023-07-10 09:08:30 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Jul 10 09:08:34.547: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2006  42f9ef1c-e6ca-4acf-ba4b-363f7b3fc908 99158 1 2023-07-10 09:08:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b7f5cacd-74dd-4e3c-babe-a27692163af2 0xc00353e760 0xc00353e761}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7f5cacd-74dd-4e3c-babe-a27692163af2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00353e7f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:08:34.547: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Jul 10 09:08:34.547: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2006  24d240ba-de7e-4d8b-81be-26ade41ff91e 99145 2 2023-07-10 09:08:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b7f5cacd-74dd-4e3c-babe-a27692163af2 0xc00353e647 0xc00353e648}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7f5cacd-74dd-4e3c-babe-a27692163af2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00353e6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:08:34.552: INFO: Pod "test-recreate-deployment-9d58999df-7bqg5" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-7bqg5 test-recreate-deployment-9d58999df- deployment-2006  e1961c9d-22cd-47ba-a0bb-301cd3fc9929 99157 0 2023-07-10 09:08:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 42f9ef1c-e6ca-4acf-ba4b-363f7b3fc908 0xc00353ec70 0xc00353ec71}] [] [{kube-controller-manager Update v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"42f9ef1c-e6ca-4acf-ba4b-363f7b3fc908\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:08:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-525jx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-525jx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:08:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:,StartTime:2023-07-10 09:08:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 09:08:34.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2006" for this suite. 07/10/23 09:08:34.561
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:34.572
Jul 10 09:08:34.572: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 09:08:34.573
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:34.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:34.604
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 07/10/23 09:08:34.634
STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:08:34.644
Jul 10 09:08:34.658: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:08:34.658: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:08:35.703: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:08:35.703: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:08:36.670: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:08:36.670: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:08:37.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:08:37.679: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 07/10/23 09:08:37.684
Jul 10 09:08:37.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:08:37.729: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
Jul 10 09:08:38.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:08:38.740: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
Jul 10 09:08:39.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:08:39.741: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
Jul 10 09:08:40.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:08:40.741: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 07/10/23 09:08:40.741
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:08:40.748
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6965, will wait for the garbage collector to delete the pods 07/10/23 09:08:40.748
Jul 10 09:08:40.814: INFO: Deleting DaemonSet.extensions daemon-set took: 10.967917ms
Jul 10 09:08:40.915: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.57084ms
Jul 10 09:08:43.020: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:08:43.020: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul 10 09:08:43.024: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"99309"},"items":null}

Jul 10 09:08:43.028: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"99309"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:08:43.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6965" for this suite. 07/10/23 09:08:43.057
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":259,"skipped":4858,"failed":0}
------------------------------
• [SLOW TEST] [8.505 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:34.572
    Jul 10 09:08:34.572: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 09:08:34.573
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:34.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:34.604
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 07/10/23 09:08:34.634
    STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:08:34.644
    Jul 10 09:08:34.658: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:08:34.658: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:08:35.703: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:08:35.703: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:08:36.670: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:08:36.670: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:08:37.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:08:37.679: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 07/10/23 09:08:37.684
    Jul 10 09:08:37.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:08:37.729: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
    Jul 10 09:08:38.740: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:08:38.740: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
    Jul 10 09:08:39.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:08:39.741: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
    Jul 10 09:08:40.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:08:40.741: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 07/10/23 09:08:40.741
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:08:40.748
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6965, will wait for the garbage collector to delete the pods 07/10/23 09:08:40.748
    Jul 10 09:08:40.814: INFO: Deleting DaemonSet.extensions daemon-set took: 10.967917ms
    Jul 10 09:08:40.915: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.57084ms
    Jul 10 09:08:43.020: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:08:43.020: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jul 10 09:08:43.024: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"99309"},"items":null}

    Jul 10 09:08:43.028: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"99309"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:08:43.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6965" for this suite. 07/10/23 09:08:43.057
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:43.077
Jul 10 09:08:43.077: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:08:43.079
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:43.107
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:43.112
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 07/10/23 09:08:43.115
STEP: setting up watch 07/10/23 09:08:43.116
STEP: submitting the pod to kubernetes 07/10/23 09:08:43.22
STEP: verifying the pod is in kubernetes 07/10/23 09:08:43.237
STEP: verifying pod creation was observed 07/10/23 09:08:43.242
Jul 10 09:08:43.242: INFO: Waiting up to 5m0s for pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91" in namespace "pods-1971" to be "running"
Jul 10 09:08:43.248: INFO: Pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91": Phase="Pending", Reason="", readiness=false. Elapsed: 5.853741ms
Jul 10 09:08:45.254: INFO: Pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91": Phase="Running", Reason="", readiness=true. Elapsed: 2.011520418s
Jul 10 09:08:45.254: INFO: Pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91" satisfied condition "running"
STEP: deleting the pod gracefully 07/10/23 09:08:45.258
STEP: verifying pod deletion was observed 07/10/23 09:08:45.278
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 09:08:48.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1971" for this suite. 07/10/23 09:08:48.162
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":260,"skipped":4864,"failed":0}
------------------------------
• [SLOW TEST] [5.102 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:43.077
    Jul 10 09:08:43.077: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:08:43.079
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:43.107
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:43.112
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 07/10/23 09:08:43.115
    STEP: setting up watch 07/10/23 09:08:43.116
    STEP: submitting the pod to kubernetes 07/10/23 09:08:43.22
    STEP: verifying the pod is in kubernetes 07/10/23 09:08:43.237
    STEP: verifying pod creation was observed 07/10/23 09:08:43.242
    Jul 10 09:08:43.242: INFO: Waiting up to 5m0s for pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91" in namespace "pods-1971" to be "running"
    Jul 10 09:08:43.248: INFO: Pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91": Phase="Pending", Reason="", readiness=false. Elapsed: 5.853741ms
    Jul 10 09:08:45.254: INFO: Pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91": Phase="Running", Reason="", readiness=true. Elapsed: 2.011520418s
    Jul 10 09:08:45.254: INFO: Pod "pod-submit-remove-5b2ac6c0-5d73-419f-b202-534ac5b34c91" satisfied condition "running"
    STEP: deleting the pod gracefully 07/10/23 09:08:45.258
    STEP: verifying pod deletion was observed 07/10/23 09:08:45.278
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 09:08:48.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1971" for this suite. 07/10/23 09:08:48.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:08:48.181
Jul 10 09:08:48.181: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svcaccounts 07/10/23 09:08:48.182
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:48.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:48.365
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Jul 10 09:08:48.397: INFO: created pod
Jul 10 09:08:48.397: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7591" to be "Succeeded or Failed"
Jul 10 09:08:48.404: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.475847ms
Jul 10 09:08:50.411: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014141956s
Jul 10 09:08:52.412: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015010371s
STEP: Saw pod success 07/10/23 09:08:52.412
Jul 10 09:08:52.412: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Jul 10 09:09:22.415: INFO: polling logs
Jul 10 09:09:22.433: INFO: Pod logs: 
I0710 09:08:49.150131       1 log.go:195] OK: Got token
I0710 09:08:49.150212       1 log.go:195] validating with in-cluster discovery
I0710 09:08:49.150798       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0710 09:08:49.150835       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7591:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1688980728, NotBefore:1688980128, IssuedAt:1688980128, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7591", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"24630b6f-ef0d-4759-8710-9fd288ce395d"}}}
I0710 09:08:49.392756       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0710 09:08:49.398453       1 log.go:195] OK: Validated signature on JWT
I0710 09:08:49.398585       1 log.go:195] OK: Got valid claims from token!
I0710 09:08:49.398613       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7591:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1688980728, NotBefore:1688980128, IssuedAt:1688980128, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7591", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"24630b6f-ef0d-4759-8710-9fd288ce395d"}}}

Jul 10 09:09:22.433: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jul 10 09:09:22.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7591" for this suite. 07/10/23 09:09:22.453
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":261,"skipped":4895,"failed":0}
------------------------------
• [SLOW TEST] [34.281 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:08:48.181
    Jul 10 09:08:48.181: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svcaccounts 07/10/23 09:08:48.182
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:08:48.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:08:48.365
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Jul 10 09:08:48.397: INFO: created pod
    Jul 10 09:08:48.397: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7591" to be "Succeeded or Failed"
    Jul 10 09:08:48.404: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.475847ms
    Jul 10 09:08:50.411: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014141956s
    Jul 10 09:08:52.412: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015010371s
    STEP: Saw pod success 07/10/23 09:08:52.412
    Jul 10 09:08:52.412: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Jul 10 09:09:22.415: INFO: polling logs
    Jul 10 09:09:22.433: INFO: Pod logs: 
    I0710 09:08:49.150131       1 log.go:195] OK: Got token
    I0710 09:08:49.150212       1 log.go:195] validating with in-cluster discovery
    I0710 09:08:49.150798       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0710 09:08:49.150835       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7591:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1688980728, NotBefore:1688980128, IssuedAt:1688980128, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7591", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"24630b6f-ef0d-4759-8710-9fd288ce395d"}}}
    I0710 09:08:49.392756       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0710 09:08:49.398453       1 log.go:195] OK: Validated signature on JWT
    I0710 09:08:49.398585       1 log.go:195] OK: Got valid claims from token!
    I0710 09:08:49.398613       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7591:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1688980728, NotBefore:1688980128, IssuedAt:1688980128, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7591", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"24630b6f-ef0d-4759-8710-9fd288ce395d"}}}

    Jul 10 09:09:22.433: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jul 10 09:09:22.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7591" for this suite. 07/10/23 09:09:22.453
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:09:22.466
Jul 10 09:09:22.466: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 09:09:22.467
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:22.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:22.504
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1147 07/10/23 09:09:22.507
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-1147 07/10/23 09:09:22.519
Jul 10 09:09:22.539: INFO: Found 0 stateful pods, waiting for 1
Jul 10 09:09:32.546: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 07/10/23 09:09:32.557
STEP: updating a scale subresource 07/10/23 09:09:32.568
STEP: verifying the statefulset Spec.Replicas was modified 07/10/23 09:09:32.578
STEP: Patch a scale subresource 07/10/23 09:09:32.582
STEP: verifying the statefulset Spec.Replicas was modified 07/10/23 09:09:32.597
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 09:09:32.616: INFO: Deleting all statefulset in ns statefulset-1147
Jul 10 09:09:32.627: INFO: Scaling statefulset ss to 0
Jul 10 09:09:42.691: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 09:09:42.695: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 09:09:42.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1147" for this suite. 07/10/23 09:09:42.74
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":262,"skipped":4964,"failed":0}
------------------------------
• [SLOW TEST] [20.285 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:09:22.466
    Jul 10 09:09:22.466: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 09:09:22.467
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:22.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:22.504
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1147 07/10/23 09:09:22.507
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-1147 07/10/23 09:09:22.519
    Jul 10 09:09:22.539: INFO: Found 0 stateful pods, waiting for 1
    Jul 10 09:09:32.546: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 07/10/23 09:09:32.557
    STEP: updating a scale subresource 07/10/23 09:09:32.568
    STEP: verifying the statefulset Spec.Replicas was modified 07/10/23 09:09:32.578
    STEP: Patch a scale subresource 07/10/23 09:09:32.582
    STEP: verifying the statefulset Spec.Replicas was modified 07/10/23 09:09:32.597
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 09:09:32.616: INFO: Deleting all statefulset in ns statefulset-1147
    Jul 10 09:09:32.627: INFO: Scaling statefulset ss to 0
    Jul 10 09:09:42.691: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 09:09:42.695: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 09:09:42.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1147" for this suite. 07/10/23 09:09:42.74
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:09:42.752
Jul 10 09:09:42.752: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:09:42.753
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:42.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:42.792
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 07/10/23 09:09:42.795
Jul 10 09:09:42.807: INFO: Waiting up to 5m0s for pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0" in namespace "pods-6433" to be "running and ready"
Jul 10 09:09:42.817: INFO: Pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.687246ms
Jul 10 09:09:42.817: INFO: The phase of Pod pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:09:44.822: INFO: Pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0": Phase="Running", Reason="", readiness=true. Elapsed: 2.015062961s
Jul 10 09:09:44.822: INFO: The phase of Pod pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0 is Running (Ready = true)
Jul 10 09:09:44.822: INFO: Pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0" satisfied condition "running and ready"
Jul 10 09:09:44.831: INFO: Pod pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0 has hostIP: 10.62.109.100
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 09:09:44.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6433" for this suite. 07/10/23 09:09:44.835
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":263,"skipped":4968,"failed":0}
------------------------------
• [2.094 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:09:42.752
    Jul 10 09:09:42.752: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:09:42.753
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:42.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:42.792
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 07/10/23 09:09:42.795
    Jul 10 09:09:42.807: INFO: Waiting up to 5m0s for pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0" in namespace "pods-6433" to be "running and ready"
    Jul 10 09:09:42.817: INFO: Pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.687246ms
    Jul 10 09:09:42.817: INFO: The phase of Pod pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:09:44.822: INFO: Pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0": Phase="Running", Reason="", readiness=true. Elapsed: 2.015062961s
    Jul 10 09:09:44.822: INFO: The phase of Pod pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0 is Running (Ready = true)
    Jul 10 09:09:44.822: INFO: Pod "pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0" satisfied condition "running and ready"
    Jul 10 09:09:44.831: INFO: Pod pod-hostip-3a56b97b-9c63-4203-a23f-e36366b184e0 has hostIP: 10.62.109.100
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 09:09:44.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6433" for this suite. 07/10/23 09:09:44.835
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:09:44.845
Jul 10 09:09:44.846: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 09:09:44.846
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:44.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:44.876
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-251e859b-9dac-47ca-a2ef-8968f6226058 07/10/23 09:09:44.879
STEP: Creating a pod to test consume secrets 07/10/23 09:09:44.891
Jul 10 09:09:44.905: INFO: Waiting up to 5m0s for pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b" in namespace "secrets-9903" to be "Succeeded or Failed"
Jul 10 09:09:44.909: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053761ms
Jul 10 09:09:46.915: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01000064s
Jul 10 09:09:48.922: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017296392s
STEP: Saw pod success 07/10/23 09:09:48.922
Jul 10 09:09:48.922: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b" satisfied condition "Succeeded or Failed"
Jul 10 09:09:48.927: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b container secret-env-test: <nil>
STEP: delete the pod 07/10/23 09:09:48.937
Jul 10 09:09:48.962: INFO: Waiting for pod pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b to disappear
Jul 10 09:09:48.966: INFO: Pod pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jul 10 09:09:48.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9903" for this suite. 07/10/23 09:09:48.97
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":264,"skipped":4970,"failed":0}
------------------------------
• [4.134 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:09:44.845
    Jul 10 09:09:44.846: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 09:09:44.846
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:44.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:44.876
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-251e859b-9dac-47ca-a2ef-8968f6226058 07/10/23 09:09:44.879
    STEP: Creating a pod to test consume secrets 07/10/23 09:09:44.891
    Jul 10 09:09:44.905: INFO: Waiting up to 5m0s for pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b" in namespace "secrets-9903" to be "Succeeded or Failed"
    Jul 10 09:09:44.909: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053761ms
    Jul 10 09:09:46.915: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01000064s
    Jul 10 09:09:48.922: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017296392s
    STEP: Saw pod success 07/10/23 09:09:48.922
    Jul 10 09:09:48.922: INFO: Pod "pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b" satisfied condition "Succeeded or Failed"
    Jul 10 09:09:48.927: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b container secret-env-test: <nil>
    STEP: delete the pod 07/10/23 09:09:48.937
    Jul 10 09:09:48.962: INFO: Waiting for pod pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b to disappear
    Jul 10 09:09:48.966: INFO: Pod pod-secrets-4389d87c-c94c-4883-a64e-9e27030d0b7b no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 09:09:48.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9903" for this suite. 07/10/23 09:09:48.97
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:09:48.98
Jul 10 09:09:48.980: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svc-latency 07/10/23 09:09:48.981
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:49.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:49.015
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Jul 10 09:09:49.018: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2274 07/10/23 09:09:49.019
I0710 09:09:49.030332      21 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2274, replica count: 1
I0710 09:09:50.080976      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0710 09:09:51.081998      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 09:09:51.203: INFO: Created: latency-svc-8sgzd
Jul 10 09:09:51.228: INFO: Got endpoints: latency-svc-8sgzd [45.94258ms]
Jul 10 09:09:51.249: INFO: Created: latency-svc-vmdlx
Jul 10 09:09:51.273: INFO: Created: latency-svc-krl4g
Jul 10 09:09:51.274: INFO: Got endpoints: latency-svc-vmdlx [45.178756ms]
Jul 10 09:09:51.292: INFO: Got endpoints: latency-svc-krl4g [62.482278ms]
Jul 10 09:09:51.307: INFO: Created: latency-svc-sd6dk
Jul 10 09:09:51.330: INFO: Created: latency-svc-wdzjt
Jul 10 09:09:51.330: INFO: Got endpoints: latency-svc-sd6dk [100.722972ms]
Jul 10 09:09:51.352: INFO: Got endpoints: latency-svc-wdzjt [122.373745ms]
Jul 10 09:09:51.356: INFO: Created: latency-svc-4hhx7
Jul 10 09:09:51.376: INFO: Got endpoints: latency-svc-4hhx7 [146.165691ms]
Jul 10 09:09:51.387: INFO: Created: latency-svc-lsqtt
Jul 10 09:09:51.400: INFO: Got endpoints: latency-svc-lsqtt [169.679413ms]
Jul 10 09:09:51.401: INFO: Created: latency-svc-cps8h
Jul 10 09:09:51.428: INFO: Got endpoints: latency-svc-cps8h [198.224033ms]
Jul 10 09:09:51.430: INFO: Created: latency-svc-99l4w
Jul 10 09:09:51.456: INFO: Got endpoints: latency-svc-99l4w [225.427805ms]
Jul 10 09:09:51.456: INFO: Created: latency-svc-rft5j
Jul 10 09:09:51.477: INFO: Got endpoints: latency-svc-rft5j [246.544014ms]
Jul 10 09:09:51.480: INFO: Created: latency-svc-m69v4
Jul 10 09:09:51.491: INFO: Got endpoints: latency-svc-m69v4 [261.349464ms]
Jul 10 09:09:51.511: INFO: Created: latency-svc-dqxd7
Jul 10 09:09:51.523: INFO: Got endpoints: latency-svc-dqxd7 [292.692506ms]
Jul 10 09:09:51.545: INFO: Created: latency-svc-w9bgw
Jul 10 09:09:51.567: INFO: Got endpoints: latency-svc-w9bgw [336.347817ms]
Jul 10 09:09:51.569: INFO: Created: latency-svc-h887d
Jul 10 09:09:51.592: INFO: Got endpoints: latency-svc-h887d [361.600157ms]
Jul 10 09:09:51.597: INFO: Created: latency-svc-rm2dd
Jul 10 09:09:51.609: INFO: Got endpoints: latency-svc-rm2dd [378.588854ms]
Jul 10 09:09:51.617: INFO: Created: latency-svc-hlps8
Jul 10 09:09:51.635: INFO: Got endpoints: latency-svc-hlps8 [404.272326ms]
Jul 10 09:09:51.819: INFO: Created: latency-svc-2k45w
Jul 10 09:09:51.820: INFO: Created: latency-svc-hqp69
Jul 10 09:09:51.820: INFO: Created: latency-svc-46qk7
Jul 10 09:09:51.823: INFO: Created: latency-svc-n8vbc
Jul 10 09:09:51.823: INFO: Created: latency-svc-jzptl
Jul 10 09:09:51.826: INFO: Created: latency-svc-cs2xc
Jul 10 09:09:51.826: INFO: Created: latency-svc-kffd2
Jul 10 09:09:51.831: INFO: Created: latency-svc-85b6g
Jul 10 09:09:51.831: INFO: Created: latency-svc-gzbmn
Jul 10 09:09:51.831: INFO: Created: latency-svc-7rfcr
Jul 10 09:09:51.838: INFO: Created: latency-svc-d7dqs
Jul 10 09:09:51.838: INFO: Created: latency-svc-lnqgb
Jul 10 09:09:51.839: INFO: Created: latency-svc-bnwgr
Jul 10 09:09:51.839: INFO: Created: latency-svc-dvdpz
Jul 10 09:09:51.839: INFO: Created: latency-svc-89zjc
Jul 10 09:09:51.847: INFO: Got endpoints: latency-svc-2k45w [555.177622ms]
Jul 10 09:09:51.851: INFO: Got endpoints: latency-svc-hqp69 [474.350402ms]
Jul 10 09:09:51.851: INFO: Got endpoints: latency-svc-46qk7 [242.06793ms]
Jul 10 09:09:51.851: INFO: Got endpoints: latency-svc-jzptl [395.597014ms]
Jul 10 09:09:51.875: INFO: Got endpoints: latency-svc-dvdpz [240.085824ms]
Jul 10 09:09:51.880: INFO: Got endpoints: latency-svc-d7dqs [313.278024ms]
Jul 10 09:09:51.880: INFO: Got endpoints: latency-svc-89zjc [549.743143ms]
Jul 10 09:09:51.880: INFO: Got endpoints: latency-svc-n8vbc [357.276371ms]
Jul 10 09:09:51.891: INFO: Got endpoints: latency-svc-gzbmn [616.475368ms]
Jul 10 09:09:51.893: INFO: Got endpoints: latency-svc-bnwgr [493.627938ms]
Jul 10 09:09:51.901: INFO: Got endpoints: latency-svc-lnqgb [424.708543ms]
Jul 10 09:09:51.903: INFO: Created: latency-svc-v5qvs
Jul 10 09:09:51.905: INFO: Got endpoints: latency-svc-kffd2 [313.223439ms]
Jul 10 09:09:51.905: INFO: Got endpoints: latency-svc-85b6g [552.900274ms]
Jul 10 09:09:51.907: INFO: Got endpoints: latency-svc-cs2xc [479.114235ms]
Jul 10 09:09:51.909: INFO: Got endpoints: latency-svc-7rfcr [417.622977ms]
Jul 10 09:09:51.945: INFO: Got endpoints: latency-svc-v5qvs [97.694321ms]
Jul 10 09:09:51.946: INFO: Created: latency-svc-69jng
Jul 10 09:09:51.959: INFO: Got endpoints: latency-svc-69jng [108.094432ms]
Jul 10 09:09:51.979: INFO: Created: latency-svc-lmskj
Jul 10 09:09:51.987: INFO: Got endpoints: latency-svc-lmskj [136.345323ms]
Jul 10 09:09:51.988: INFO: Created: latency-svc-j9xtl
Jul 10 09:09:52.013: INFO: Got endpoints: latency-svc-j9xtl [161.954667ms]
Jul 10 09:09:52.014: INFO: Created: latency-svc-7ltml
Jul 10 09:09:52.029: INFO: Got endpoints: latency-svc-7ltml [154.194869ms]
Jul 10 09:09:52.046: INFO: Created: latency-svc-tb5qh
Jul 10 09:09:52.051: INFO: Created: latency-svc-k9kvt
Jul 10 09:09:52.070: INFO: Got endpoints: latency-svc-tb5qh [190.463443ms]
Jul 10 09:09:52.071: INFO: Got endpoints: latency-svc-k9kvt [191.093977ms]
Jul 10 09:09:52.078: INFO: Created: latency-svc-zftqf
Jul 10 09:09:52.094: INFO: Got endpoints: latency-svc-zftqf [213.880273ms]
Jul 10 09:09:52.103: INFO: Created: latency-svc-8zmz4
Jul 10 09:09:52.120: INFO: Got endpoints: latency-svc-8zmz4 [229.368032ms]
Jul 10 09:09:52.121: INFO: Created: latency-svc-shwpl
Jul 10 09:09:52.143: INFO: Got endpoints: latency-svc-shwpl [249.39376ms]
Jul 10 09:09:52.150: INFO: Created: latency-svc-k5mrw
Jul 10 09:09:52.170: INFO: Created: latency-svc-qm8dx
Jul 10 09:09:52.171: INFO: Got endpoints: latency-svc-k5mrw [269.600075ms]
Jul 10 09:09:52.189: INFO: Got endpoints: latency-svc-qm8dx [284.178626ms]
Jul 10 09:09:52.199: INFO: Created: latency-svc-sdfqv
Jul 10 09:09:52.221: INFO: Got endpoints: latency-svc-sdfqv [315.471369ms]
Jul 10 09:09:52.228: INFO: Created: latency-svc-hkhjq
Jul 10 09:09:52.248: INFO: Got endpoints: latency-svc-hkhjq [340.367802ms]
Jul 10 09:09:52.259: INFO: Created: latency-svc-6v789
Jul 10 09:09:52.284: INFO: Got endpoints: latency-svc-6v789 [374.742311ms]
Jul 10 09:09:52.301: INFO: Created: latency-svc-5fmsb
Jul 10 09:09:52.317: INFO: Got endpoints: latency-svc-5fmsb [372.008292ms]
Jul 10 09:09:52.318: INFO: Created: latency-svc-rh9p9
Jul 10 09:09:52.329: INFO: Got endpoints: latency-svc-rh9p9 [370.200123ms]
Jul 10 09:09:52.335: INFO: Created: latency-svc-wsctz
Jul 10 09:09:52.358: INFO: Got endpoints: latency-svc-wsctz [370.485088ms]
Jul 10 09:09:52.362: INFO: Created: latency-svc-l2q5t
Jul 10 09:09:52.372: INFO: Got endpoints: latency-svc-l2q5t [358.316289ms]
Jul 10 09:09:52.379: INFO: Created: latency-svc-f4lzz
Jul 10 09:09:52.395: INFO: Got endpoints: latency-svc-f4lzz [366.422804ms]
Jul 10 09:09:52.398: INFO: Created: latency-svc-w7fpz
Jul 10 09:09:52.416: INFO: Created: latency-svc-jtdbh
Jul 10 09:09:52.416: INFO: Got endpoints: latency-svc-w7fpz [345.803417ms]
Jul 10 09:09:52.432: INFO: Got endpoints: latency-svc-jtdbh [360.748463ms]
Jul 10 09:09:52.448: INFO: Created: latency-svc-m5lmr
Jul 10 09:09:52.461: INFO: Got endpoints: latency-svc-m5lmr [366.826586ms]
Jul 10 09:09:52.471: INFO: Created: latency-svc-8ln8m
Jul 10 09:09:52.495: INFO: Created: latency-svc-fhwbp
Jul 10 09:09:52.503: INFO: Got endpoints: latency-svc-8ln8m [382.66258ms]
Jul 10 09:09:52.534: INFO: Got endpoints: latency-svc-fhwbp [391.033394ms]
Jul 10 09:09:52.551: INFO: Created: latency-svc-9mj5s
Jul 10 09:09:52.567: INFO: Got endpoints: latency-svc-9mj5s [395.502297ms]
Jul 10 09:09:52.580: INFO: Created: latency-svc-b2kxc
Jul 10 09:09:52.586: INFO: Created: latency-svc-xfc94
Jul 10 09:09:52.600: INFO: Created: latency-svc-68jzc
Jul 10 09:09:52.624: INFO: Created: latency-svc-ps7ng
Jul 10 09:09:52.627: INFO: Got endpoints: latency-svc-b2kxc [437.8286ms]
Jul 10 09:09:52.640: INFO: Created: latency-svc-4llkh
Jul 10 09:09:52.657: INFO: Created: latency-svc-whkbr
Jul 10 09:09:52.676: INFO: Got endpoints: latency-svc-xfc94 [455.754712ms]
Jul 10 09:09:52.680: INFO: Created: latency-svc-shdf9
Jul 10 09:09:52.697: INFO: Created: latency-svc-zlw8f
Jul 10 09:09:52.722: INFO: Got endpoints: latency-svc-68jzc [474.188874ms]
Jul 10 09:09:52.722: INFO: Created: latency-svc-kl94s
Jul 10 09:09:52.738: INFO: Created: latency-svc-vh85g
Jul 10 09:09:52.751: INFO: Created: latency-svc-zmxzm
Jul 10 09:09:52.764: INFO: Got endpoints: latency-svc-ps7ng [480.465622ms]
Jul 10 09:09:52.770: INFO: Created: latency-svc-766nf
Jul 10 09:09:52.801: INFO: Created: latency-svc-mqpcs
Jul 10 09:09:52.810: INFO: Created: latency-svc-lmb6t
Jul 10 09:09:52.818: INFO: Got endpoints: latency-svc-4llkh [500.436921ms]
Jul 10 09:09:52.838: INFO: Created: latency-svc-zxk4l
Jul 10 09:09:52.878: INFO: Created: latency-svc-c2xrg
Jul 10 09:09:52.881: INFO: Got endpoints: latency-svc-whkbr [551.573167ms]
Jul 10 09:09:52.898: INFO: Created: latency-svc-h2rtr
Jul 10 09:09:52.918: INFO: Got endpoints: latency-svc-shdf9 [560.394516ms]
Jul 10 09:09:52.926: INFO: Created: latency-svc-kxxhq
Jul 10 09:09:52.953: INFO: Created: latency-svc-5h7np
Jul 10 09:09:52.973: INFO: Created: latency-svc-44qw6
Jul 10 09:09:52.982: INFO: Got endpoints: latency-svc-zlw8f [610.584592ms]
Jul 10 09:09:52.994: INFO: Created: latency-svc-zvs87
Jul 10 09:09:53.010: INFO: Created: latency-svc-9dxk4
Jul 10 09:09:53.030: INFO: Got endpoints: latency-svc-kl94s [634.479429ms]
Jul 10 09:09:53.035: INFO: Created: latency-svc-pflxw
Jul 10 09:09:53.051: INFO: Created: latency-svc-t5hxs
Jul 10 09:09:53.070: INFO: Got endpoints: latency-svc-vh85g [653.60392ms]
Jul 10 09:09:53.088: INFO: Created: latency-svc-ml9xg
Jul 10 09:09:53.129: INFO: Got endpoints: latency-svc-zmxzm [696.95978ms]
Jul 10 09:09:53.148: INFO: Created: latency-svc-w4sdc
Jul 10 09:09:53.168: INFO: Got endpoints: latency-svc-766nf [706.746651ms]
Jul 10 09:09:53.197: INFO: Created: latency-svc-wwkjw
Jul 10 09:09:53.215: INFO: Got endpoints: latency-svc-mqpcs [712.443089ms]
Jul 10 09:09:53.248: INFO: Created: latency-svc-js2sz
Jul 10 09:09:53.267: INFO: Got endpoints: latency-svc-lmb6t [733.255731ms]
Jul 10 09:09:53.289: INFO: Created: latency-svc-ncqxl
Jul 10 09:09:53.321: INFO: Got endpoints: latency-svc-zxk4l [754.485698ms]
Jul 10 09:09:53.340: INFO: Created: latency-svc-rlll5
Jul 10 09:09:53.372: INFO: Got endpoints: latency-svc-c2xrg [745.108949ms]
Jul 10 09:09:53.402: INFO: Created: latency-svc-m4d6b
Jul 10 09:09:53.414: INFO: Got endpoints: latency-svc-h2rtr [737.043193ms]
Jul 10 09:09:53.439: INFO: Created: latency-svc-csnll
Jul 10 09:09:53.468: INFO: Got endpoints: latency-svc-kxxhq [745.656237ms]
Jul 10 09:09:53.488: INFO: Created: latency-svc-djdhj
Jul 10 09:09:53.518: INFO: Got endpoints: latency-svc-5h7np [753.359351ms]
Jul 10 09:09:53.541: INFO: Created: latency-svc-4tkqc
Jul 10 09:09:53.574: INFO: Got endpoints: latency-svc-44qw6 [755.96153ms]
Jul 10 09:09:53.596: INFO: Created: latency-svc-m2kmb
Jul 10 09:09:53.618: INFO: Got endpoints: latency-svc-zvs87 [737.317806ms]
Jul 10 09:09:53.637: INFO: Created: latency-svc-fp2cg
Jul 10 09:09:53.669: INFO: Got endpoints: latency-svc-9dxk4 [750.79568ms]
Jul 10 09:09:53.726: INFO: Created: latency-svc-mdc4t
Jul 10 09:09:53.738: INFO: Got endpoints: latency-svc-pflxw [755.343474ms]
Jul 10 09:09:53.758: INFO: Created: latency-svc-x99n7
Jul 10 09:09:53.777: INFO: Got endpoints: latency-svc-t5hxs [746.763949ms]
Jul 10 09:09:53.807: INFO: Created: latency-svc-bd9wk
Jul 10 09:09:53.833: INFO: Got endpoints: latency-svc-ml9xg [762.74669ms]
Jul 10 09:09:53.867: INFO: Created: latency-svc-zrtvg
Jul 10 09:09:53.871: INFO: Got endpoints: latency-svc-w4sdc [742.264595ms]
Jul 10 09:09:53.898: INFO: Created: latency-svc-8njsj
Jul 10 09:09:53.918: INFO: Got endpoints: latency-svc-wwkjw [750.102213ms]
Jul 10 09:09:53.939: INFO: Created: latency-svc-qhzhr
Jul 10 09:09:53.969: INFO: Got endpoints: latency-svc-js2sz [753.682335ms]
Jul 10 09:09:53.988: INFO: Created: latency-svc-lzdtj
Jul 10 09:09:54.022: INFO: Got endpoints: latency-svc-ncqxl [755.162812ms]
Jul 10 09:09:54.046: INFO: Created: latency-svc-d6gjt
Jul 10 09:09:54.067: INFO: Got endpoints: latency-svc-rlll5 [745.363093ms]
Jul 10 09:09:54.089: INFO: Created: latency-svc-mtm29
Jul 10 09:09:54.117: INFO: Got endpoints: latency-svc-m4d6b [744.191534ms]
Jul 10 09:09:54.147: INFO: Created: latency-svc-xr8zr
Jul 10 09:09:54.170: INFO: Got endpoints: latency-svc-csnll [756.582491ms]
Jul 10 09:09:54.194: INFO: Created: latency-svc-qz5xv
Jul 10 09:09:54.214: INFO: Got endpoints: latency-svc-djdhj [746.333991ms]
Jul 10 09:09:54.247: INFO: Created: latency-svc-q8gtd
Jul 10 09:09:54.275: INFO: Got endpoints: latency-svc-4tkqc [757.107135ms]
Jul 10 09:09:54.303: INFO: Created: latency-svc-xllgv
Jul 10 09:09:54.324: INFO: Got endpoints: latency-svc-m2kmb [750.674064ms]
Jul 10 09:09:54.344: INFO: Created: latency-svc-lxhs4
Jul 10 09:09:54.375: INFO: Got endpoints: latency-svc-fp2cg [756.670899ms]
Jul 10 09:09:54.393: INFO: Created: latency-svc-rpwnq
Jul 10 09:09:54.412: INFO: Got endpoints: latency-svc-mdc4t [742.796357ms]
Jul 10 09:09:54.436: INFO: Created: latency-svc-blmqv
Jul 10 09:09:54.494: INFO: Got endpoints: latency-svc-x99n7 [755.981991ms]
Jul 10 09:09:54.516: INFO: Created: latency-svc-sk7bj
Jul 10 09:09:54.518: INFO: Got endpoints: latency-svc-bd9wk [740.76065ms]
Jul 10 09:09:54.538: INFO: Created: latency-svc-kkb8n
Jul 10 09:09:54.566: INFO: Got endpoints: latency-svc-zrtvg [732.78081ms]
Jul 10 09:09:54.610: INFO: Created: latency-svc-g2cmg
Jul 10 09:09:54.618: INFO: Got endpoints: latency-svc-8njsj [746.92412ms]
Jul 10 09:09:54.636: INFO: Created: latency-svc-t22pd
Jul 10 09:09:54.702: INFO: Got endpoints: latency-svc-qhzhr [783.974694ms]
Jul 10 09:09:54.719: INFO: Got endpoints: latency-svc-lzdtj [749.829109ms]
Jul 10 09:09:54.727: INFO: Created: latency-svc-cqhdx
Jul 10 09:09:54.749: INFO: Created: latency-svc-5d8hz
Jul 10 09:09:54.768: INFO: Got endpoints: latency-svc-d6gjt [745.76152ms]
Jul 10 09:09:54.789: INFO: Created: latency-svc-cvj9c
Jul 10 09:09:54.816: INFO: Got endpoints: latency-svc-mtm29 [749.397227ms]
Jul 10 09:09:54.839: INFO: Created: latency-svc-sdkrz
Jul 10 09:09:54.873: INFO: Got endpoints: latency-svc-xr8zr [756.723049ms]
Jul 10 09:09:54.901: INFO: Created: latency-svc-4b572
Jul 10 09:09:54.920: INFO: Got endpoints: latency-svc-qz5xv [749.4236ms]
Jul 10 09:09:54.939: INFO: Created: latency-svc-xr22n
Jul 10 09:09:54.968: INFO: Got endpoints: latency-svc-q8gtd [753.854645ms]
Jul 10 09:09:54.990: INFO: Created: latency-svc-444wb
Jul 10 09:09:55.014: INFO: Got endpoints: latency-svc-xllgv [738.587184ms]
Jul 10 09:09:55.046: INFO: Created: latency-svc-5ndtl
Jul 10 09:09:55.076: INFO: Got endpoints: latency-svc-lxhs4 [751.665484ms]
Jul 10 09:09:55.097: INFO: Created: latency-svc-nrksm
Jul 10 09:09:55.123: INFO: Got endpoints: latency-svc-rpwnq [748.222259ms]
Jul 10 09:09:55.145: INFO: Created: latency-svc-4kjrb
Jul 10 09:09:55.169: INFO: Got endpoints: latency-svc-blmqv [757.003161ms]
Jul 10 09:09:55.195: INFO: Created: latency-svc-74rtc
Jul 10 09:09:55.219: INFO: Got endpoints: latency-svc-sk7bj [725.573192ms]
Jul 10 09:09:55.253: INFO: Created: latency-svc-xqv56
Jul 10 09:09:55.272: INFO: Got endpoints: latency-svc-kkb8n [754.714131ms]
Jul 10 09:09:55.305: INFO: Created: latency-svc-4tlhk
Jul 10 09:09:55.317: INFO: Got endpoints: latency-svc-g2cmg [751.335982ms]
Jul 10 09:09:55.340: INFO: Created: latency-svc-qksmq
Jul 10 09:09:55.369: INFO: Got endpoints: latency-svc-t22pd [750.920352ms]
Jul 10 09:09:55.387: INFO: Created: latency-svc-pppxh
Jul 10 09:09:55.419: INFO: Got endpoints: latency-svc-cqhdx [717.433471ms]
Jul 10 09:09:55.443: INFO: Created: latency-svc-c6chq
Jul 10 09:09:55.465: INFO: Got endpoints: latency-svc-5d8hz [745.663857ms]
Jul 10 09:09:55.492: INFO: Created: latency-svc-5x6jq
Jul 10 09:09:55.516: INFO: Got endpoints: latency-svc-cvj9c [747.916898ms]
Jul 10 09:09:55.534: INFO: Created: latency-svc-5vk9f
Jul 10 09:09:55.571: INFO: Got endpoints: latency-svc-sdkrz [754.514113ms]
Jul 10 09:09:55.598: INFO: Created: latency-svc-2fqkr
Jul 10 09:09:55.619: INFO: Got endpoints: latency-svc-4b572 [745.923036ms]
Jul 10 09:09:55.645: INFO: Created: latency-svc-c4hsl
Jul 10 09:09:55.663: INFO: Got endpoints: latency-svc-xr22n [743.649114ms]
Jul 10 09:09:55.690: INFO: Created: latency-svc-zx9vq
Jul 10 09:09:55.723: INFO: Got endpoints: latency-svc-444wb [755.002119ms]
Jul 10 09:09:55.746: INFO: Created: latency-svc-pbcvn
Jul 10 09:09:55.771: INFO: Got endpoints: latency-svc-5ndtl [757.310708ms]
Jul 10 09:09:55.790: INFO: Created: latency-svc-nsw49
Jul 10 09:09:55.817: INFO: Got endpoints: latency-svc-nrksm [740.289566ms]
Jul 10 09:09:55.842: INFO: Created: latency-svc-z86c8
Jul 10 09:09:55.869: INFO: Got endpoints: latency-svc-4kjrb [746.360735ms]
Jul 10 09:09:55.912: INFO: Created: latency-svc-zjrck
Jul 10 09:09:55.918: INFO: Got endpoints: latency-svc-74rtc [748.775011ms]
Jul 10 09:09:55.947: INFO: Created: latency-svc-xrv82
Jul 10 09:09:55.970: INFO: Got endpoints: latency-svc-xqv56 [751.138198ms]
Jul 10 09:09:56.042: INFO: Got endpoints: latency-svc-4tlhk [769.520469ms]
Jul 10 09:09:56.051: INFO: Created: latency-svc-86b4d
Jul 10 09:09:56.067: INFO: Got endpoints: latency-svc-qksmq [750.478441ms]
Jul 10 09:09:56.074: INFO: Created: latency-svc-8dqt4
Jul 10 09:09:56.091: INFO: Created: latency-svc-2cnwg
Jul 10 09:09:56.119: INFO: Got endpoints: latency-svc-pppxh [750.17033ms]
Jul 10 09:09:56.143: INFO: Created: latency-svc-lkp2j
Jul 10 09:09:56.172: INFO: Got endpoints: latency-svc-c6chq [752.40023ms]
Jul 10 09:09:56.194: INFO: Created: latency-svc-86hsx
Jul 10 09:09:56.214: INFO: Got endpoints: latency-svc-5x6jq [749.135927ms]
Jul 10 09:09:56.248: INFO: Created: latency-svc-gjlls
Jul 10 09:09:56.271: INFO: Got endpoints: latency-svc-5vk9f [754.876962ms]
Jul 10 09:09:56.293: INFO: Created: latency-svc-hqj66
Jul 10 09:09:56.316: INFO: Got endpoints: latency-svc-2fqkr [745.324957ms]
Jul 10 09:09:56.456: INFO: Created: latency-svc-hntj7
Jul 10 09:09:56.456: INFO: Got endpoints: latency-svc-c4hsl [837.050612ms]
Jul 10 09:09:56.456: INFO: Got endpoints: latency-svc-zx9vq [793.066182ms]
Jul 10 09:09:56.470: INFO: Got endpoints: latency-svc-pbcvn [746.64996ms]
Jul 10 09:09:56.487: INFO: Created: latency-svc-jtpvw
Jul 10 09:09:56.505: INFO: Created: latency-svc-sqrqj
Jul 10 09:09:56.523: INFO: Got endpoints: latency-svc-nsw49 [752.049353ms]
Jul 10 09:09:56.527: INFO: Created: latency-svc-b9nn4
Jul 10 09:09:56.544: INFO: Created: latency-svc-tkbhn
Jul 10 09:09:56.566: INFO: Got endpoints: latency-svc-z86c8 [749.349096ms]
Jul 10 09:09:56.583: INFO: Created: latency-svc-dtcvx
Jul 10 09:09:56.620: INFO: Got endpoints: latency-svc-zjrck [750.124758ms]
Jul 10 09:09:56.640: INFO: Created: latency-svc-5rk2c
Jul 10 09:09:56.671: INFO: Got endpoints: latency-svc-xrv82 [753.012489ms]
Jul 10 09:09:56.692: INFO: Created: latency-svc-djcqn
Jul 10 09:09:56.719: INFO: Got endpoints: latency-svc-86b4d [748.951565ms]
Jul 10 09:09:56.743: INFO: Created: latency-svc-m7gt5
Jul 10 09:09:56.765: INFO: Got endpoints: latency-svc-8dqt4 [722.656505ms]
Jul 10 09:09:56.787: INFO: Created: latency-svc-p4jwq
Jul 10 09:09:56.818: INFO: Got endpoints: latency-svc-2cnwg [750.398553ms]
Jul 10 09:09:56.843: INFO: Created: latency-svc-848rw
Jul 10 09:09:56.873: INFO: Got endpoints: latency-svc-lkp2j [753.173545ms]
Jul 10 09:09:56.892: INFO: Created: latency-svc-d27fb
Jul 10 09:09:56.924: INFO: Got endpoints: latency-svc-86hsx [752.084701ms]
Jul 10 09:09:56.950: INFO: Created: latency-svc-6844b
Jul 10 09:09:56.967: INFO: Got endpoints: latency-svc-gjlls [753.316832ms]
Jul 10 09:09:56.987: INFO: Created: latency-svc-2grct
Jul 10 09:09:57.017: INFO: Got endpoints: latency-svc-hqj66 [745.823794ms]
Jul 10 09:09:57.044: INFO: Created: latency-svc-fctpn
Jul 10 09:09:57.067: INFO: Got endpoints: latency-svc-hntj7 [750.664266ms]
Jul 10 09:09:57.100: INFO: Created: latency-svc-c5h5d
Jul 10 09:09:57.118: INFO: Got endpoints: latency-svc-jtpvw [661.028889ms]
Jul 10 09:09:57.142: INFO: Created: latency-svc-m7r4h
Jul 10 09:09:57.169: INFO: Got endpoints: latency-svc-sqrqj [712.990571ms]
Jul 10 09:09:57.191: INFO: Created: latency-svc-dkk9b
Jul 10 09:09:57.228: INFO: Got endpoints: latency-svc-b9nn4 [758.671684ms]
Jul 10 09:09:57.256: INFO: Created: latency-svc-j5hq5
Jul 10 09:09:57.275: INFO: Got endpoints: latency-svc-tkbhn [751.516645ms]
Jul 10 09:09:57.306: INFO: Created: latency-svc-68fp6
Jul 10 09:09:57.317: INFO: Got endpoints: latency-svc-dtcvx [750.976821ms]
Jul 10 09:09:57.345: INFO: Created: latency-svc-5gdq7
Jul 10 09:09:57.368: INFO: Got endpoints: latency-svc-5rk2c [747.92888ms]
Jul 10 09:09:57.388: INFO: Created: latency-svc-dtv5s
Jul 10 09:09:57.423: INFO: Got endpoints: latency-svc-djcqn [751.500486ms]
Jul 10 09:09:57.448: INFO: Created: latency-svc-sk275
Jul 10 09:09:57.468: INFO: Got endpoints: latency-svc-m7gt5 [748.922756ms]
Jul 10 09:09:57.495: INFO: Created: latency-svc-jt25h
Jul 10 09:09:57.517: INFO: Got endpoints: latency-svc-p4jwq [752.407125ms]
Jul 10 09:09:57.545: INFO: Created: latency-svc-t4s4w
Jul 10 09:09:57.569: INFO: Got endpoints: latency-svc-848rw [751.411459ms]
Jul 10 09:09:57.592: INFO: Created: latency-svc-w9rjq
Jul 10 09:09:57.620: INFO: Got endpoints: latency-svc-d27fb [747.2869ms]
Jul 10 09:09:57.640: INFO: Created: latency-svc-ph97t
Jul 10 09:09:57.676: INFO: Got endpoints: latency-svc-6844b [751.83378ms]
Jul 10 09:09:57.707: INFO: Created: latency-svc-gn6kg
Jul 10 09:09:57.715: INFO: Got endpoints: latency-svc-2grct [747.801004ms]
Jul 10 09:09:57.745: INFO: Created: latency-svc-6psd4
Jul 10 09:09:57.771: INFO: Got endpoints: latency-svc-fctpn [754.301443ms]
Jul 10 09:09:57.792: INFO: Created: latency-svc-vwmdk
Jul 10 09:09:57.820: INFO: Got endpoints: latency-svc-c5h5d [753.42114ms]
Jul 10 09:09:57.852: INFO: Created: latency-svc-szm6n
Jul 10 09:09:57.873: INFO: Got endpoints: latency-svc-m7r4h [755.894065ms]
Jul 10 09:09:57.896: INFO: Created: latency-svc-mgbmv
Jul 10 09:09:57.922: INFO: Got endpoints: latency-svc-dkk9b [752.764915ms]
Jul 10 09:09:57.946: INFO: Created: latency-svc-f8mxw
Jul 10 09:09:57.967: INFO: Got endpoints: latency-svc-j5hq5 [738.855369ms]
Jul 10 09:09:57.994: INFO: Created: latency-svc-jq2zl
Jul 10 09:09:58.015: INFO: Got endpoints: latency-svc-68fp6 [740.48578ms]
Jul 10 09:09:58.035: INFO: Created: latency-svc-tqltc
Jul 10 09:09:58.071: INFO: Got endpoints: latency-svc-5gdq7 [754.098252ms]
Jul 10 09:09:58.096: INFO: Created: latency-svc-5mnnp
Jul 10 09:09:58.122: INFO: Got endpoints: latency-svc-dtv5s [754.385624ms]
Jul 10 09:09:58.140: INFO: Created: latency-svc-wkcm2
Jul 10 09:09:58.257: INFO: Got endpoints: latency-svc-sk275 [834.84534ms]
Jul 10 09:09:58.261: INFO: Got endpoints: latency-svc-jt25h [792.894746ms]
Jul 10 09:09:58.279: INFO: Got endpoints: latency-svc-t4s4w [761.450296ms]
Jul 10 09:09:58.307: INFO: Created: latency-svc-qtj6z
Jul 10 09:09:58.319: INFO: Got endpoints: latency-svc-w9rjq [749.273635ms]
Jul 10 09:09:58.324: INFO: Created: latency-svc-6dddl
Jul 10 09:09:58.369: INFO: Created: latency-svc-qgfd2
Jul 10 09:09:58.374: INFO: Got endpoints: latency-svc-ph97t [753.964617ms]
Jul 10 09:09:58.385: INFO: Created: latency-svc-9kzcl
Jul 10 09:09:58.400: INFO: Created: latency-svc-tfw52
Jul 10 09:09:58.422: INFO: Got endpoints: latency-svc-gn6kg [745.588007ms]
Jul 10 09:09:58.454: INFO: Created: latency-svc-gbhvc
Jul 10 09:09:58.475: INFO: Got endpoints: latency-svc-6psd4 [759.764246ms]
Jul 10 09:09:58.498: INFO: Created: latency-svc-4xkrx
Jul 10 09:09:58.522: INFO: Got endpoints: latency-svc-vwmdk [751.035558ms]
Jul 10 09:09:58.540: INFO: Created: latency-svc-r4f6z
Jul 10 09:09:58.569: INFO: Got endpoints: latency-svc-szm6n [748.811501ms]
Jul 10 09:09:58.625: INFO: Got endpoints: latency-svc-mgbmv [751.429117ms]
Jul 10 09:09:58.635: INFO: Created: latency-svc-tbn5m
Jul 10 09:09:58.668: INFO: Created: latency-svc-4z6kw
Jul 10 09:09:58.676: INFO: Got endpoints: latency-svc-f8mxw [753.666833ms]
Jul 10 09:09:58.695: INFO: Created: latency-svc-lrbdj
Jul 10 09:09:58.730: INFO: Got endpoints: latency-svc-jq2zl [762.59352ms]
Jul 10 09:09:58.752: INFO: Created: latency-svc-n67n7
Jul 10 09:09:58.763: INFO: Got endpoints: latency-svc-tqltc [747.54179ms]
Jul 10 09:09:58.793: INFO: Created: latency-svc-n6dbg
Jul 10 09:09:58.824: INFO: Got endpoints: latency-svc-5mnnp [752.982569ms]
Jul 10 09:09:58.843: INFO: Created: latency-svc-c5k7p
Jul 10 09:09:58.870: INFO: Got endpoints: latency-svc-wkcm2 [747.515918ms]
Jul 10 09:09:58.892: INFO: Created: latency-svc-p9mpf
Jul 10 09:09:58.917: INFO: Got endpoints: latency-svc-qtj6z [659.621123ms]
Jul 10 09:09:58.948: INFO: Created: latency-svc-h5rrv
Jul 10 09:09:58.969: INFO: Got endpoints: latency-svc-6dddl [707.276767ms]
Jul 10 09:09:58.990: INFO: Created: latency-svc-s55ld
Jul 10 09:09:59.021: INFO: Got endpoints: latency-svc-qgfd2 [742.763895ms]
Jul 10 09:09:59.045: INFO: Created: latency-svc-s5mjt
Jul 10 09:09:59.069: INFO: Got endpoints: latency-svc-9kzcl [750.069532ms]
Jul 10 09:09:59.118: INFO: Got endpoints: latency-svc-tfw52 [743.802747ms]
Jul 10 09:09:59.173: INFO: Got endpoints: latency-svc-gbhvc [751.39275ms]
Jul 10 09:09:59.214: INFO: Got endpoints: latency-svc-4xkrx [739.467118ms]
Jul 10 09:09:59.273: INFO: Got endpoints: latency-svc-r4f6z [750.156373ms]
Jul 10 09:09:59.321: INFO: Got endpoints: latency-svc-tbn5m [752.166413ms]
Jul 10 09:09:59.363: INFO: Got endpoints: latency-svc-4z6kw [737.568553ms]
Jul 10 09:09:59.419: INFO: Got endpoints: latency-svc-lrbdj [742.902855ms]
Jul 10 09:09:59.559: INFO: Got endpoints: latency-svc-n6dbg [796.296747ms]
Jul 10 09:09:59.559: INFO: Got endpoints: latency-svc-n67n7 [829.080388ms]
Jul 10 09:09:59.576: INFO: Got endpoints: latency-svc-c5k7p [751.617978ms]
Jul 10 09:09:59.622: INFO: Got endpoints: latency-svc-p9mpf [752.507302ms]
Jul 10 09:09:59.672: INFO: Got endpoints: latency-svc-h5rrv [754.492779ms]
Jul 10 09:09:59.725: INFO: Got endpoints: latency-svc-s55ld [756.24433ms]
Jul 10 09:09:59.780: INFO: Got endpoints: latency-svc-s5mjt [758.850935ms]
Jul 10 09:09:59.780: INFO: Latencies: [45.178756ms 62.482278ms 97.694321ms 100.722972ms 108.094432ms 122.373745ms 136.345323ms 146.165691ms 154.194869ms 161.954667ms 169.679413ms 190.463443ms 191.093977ms 198.224033ms 213.880273ms 225.427805ms 229.368032ms 240.085824ms 242.06793ms 246.544014ms 249.39376ms 261.349464ms 269.600075ms 284.178626ms 292.692506ms 313.223439ms 313.278024ms 315.471369ms 336.347817ms 340.367802ms 345.803417ms 357.276371ms 358.316289ms 360.748463ms 361.600157ms 366.422804ms 366.826586ms 370.200123ms 370.485088ms 372.008292ms 374.742311ms 378.588854ms 382.66258ms 391.033394ms 395.502297ms 395.597014ms 404.272326ms 417.622977ms 424.708543ms 437.8286ms 455.754712ms 474.188874ms 474.350402ms 479.114235ms 480.465622ms 493.627938ms 500.436921ms 549.743143ms 551.573167ms 552.900274ms 555.177622ms 560.394516ms 610.584592ms 616.475368ms 634.479429ms 653.60392ms 659.621123ms 661.028889ms 696.95978ms 706.746651ms 707.276767ms 712.443089ms 712.990571ms 717.433471ms 722.656505ms 725.573192ms 732.78081ms 733.255731ms 737.043193ms 737.317806ms 737.568553ms 738.587184ms 738.855369ms 739.467118ms 740.289566ms 740.48578ms 740.76065ms 742.264595ms 742.763895ms 742.796357ms 742.902855ms 743.649114ms 743.802747ms 744.191534ms 745.108949ms 745.324957ms 745.363093ms 745.588007ms 745.656237ms 745.663857ms 745.76152ms 745.823794ms 745.923036ms 746.333991ms 746.360735ms 746.64996ms 746.763949ms 746.92412ms 747.2869ms 747.515918ms 747.54179ms 747.801004ms 747.916898ms 747.92888ms 748.222259ms 748.775011ms 748.811501ms 748.922756ms 748.951565ms 749.135927ms 749.273635ms 749.349096ms 749.397227ms 749.4236ms 749.829109ms 750.069532ms 750.102213ms 750.124758ms 750.156373ms 750.17033ms 750.398553ms 750.478441ms 750.664266ms 750.674064ms 750.79568ms 750.920352ms 750.976821ms 751.035558ms 751.138198ms 751.335982ms 751.39275ms 751.411459ms 751.429117ms 751.500486ms 751.516645ms 751.617978ms 751.665484ms 751.83378ms 752.049353ms 752.084701ms 752.166413ms 752.40023ms 752.407125ms 752.507302ms 752.764915ms 752.982569ms 753.012489ms 753.173545ms 753.316832ms 753.359351ms 753.42114ms 753.666833ms 753.682335ms 753.854645ms 753.964617ms 754.098252ms 754.301443ms 754.385624ms 754.485698ms 754.492779ms 754.514113ms 754.714131ms 754.876962ms 755.002119ms 755.162812ms 755.343474ms 755.894065ms 755.96153ms 755.981991ms 756.24433ms 756.582491ms 756.670899ms 756.723049ms 757.003161ms 757.107135ms 757.310708ms 758.671684ms 758.850935ms 759.764246ms 761.450296ms 762.59352ms 762.74669ms 769.520469ms 783.974694ms 792.894746ms 793.066182ms 796.296747ms 829.080388ms 834.84534ms 837.050612ms]
Jul 10 09:09:59.780: INFO: 50 %ile: 745.76152ms
Jul 10 09:09:59.780: INFO: 90 %ile: 756.582491ms
Jul 10 09:09:59.780: INFO: 99 %ile: 834.84534ms
Jul 10 09:09:59.780: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Jul 10 09:09:59.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2274" for this suite. 07/10/23 09:09:59.788
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":265,"skipped":4973,"failed":0}
------------------------------
• [SLOW TEST] [10.823 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:09:48.98
    Jul 10 09:09:48.980: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svc-latency 07/10/23 09:09:48.981
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:49.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:49.015
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Jul 10 09:09:49.018: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-2274 07/10/23 09:09:49.019
    I0710 09:09:49.030332      21 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2274, replica count: 1
    I0710 09:09:50.080976      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0710 09:09:51.081998      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 09:09:51.203: INFO: Created: latency-svc-8sgzd
    Jul 10 09:09:51.228: INFO: Got endpoints: latency-svc-8sgzd [45.94258ms]
    Jul 10 09:09:51.249: INFO: Created: latency-svc-vmdlx
    Jul 10 09:09:51.273: INFO: Created: latency-svc-krl4g
    Jul 10 09:09:51.274: INFO: Got endpoints: latency-svc-vmdlx [45.178756ms]
    Jul 10 09:09:51.292: INFO: Got endpoints: latency-svc-krl4g [62.482278ms]
    Jul 10 09:09:51.307: INFO: Created: latency-svc-sd6dk
    Jul 10 09:09:51.330: INFO: Created: latency-svc-wdzjt
    Jul 10 09:09:51.330: INFO: Got endpoints: latency-svc-sd6dk [100.722972ms]
    Jul 10 09:09:51.352: INFO: Got endpoints: latency-svc-wdzjt [122.373745ms]
    Jul 10 09:09:51.356: INFO: Created: latency-svc-4hhx7
    Jul 10 09:09:51.376: INFO: Got endpoints: latency-svc-4hhx7 [146.165691ms]
    Jul 10 09:09:51.387: INFO: Created: latency-svc-lsqtt
    Jul 10 09:09:51.400: INFO: Got endpoints: latency-svc-lsqtt [169.679413ms]
    Jul 10 09:09:51.401: INFO: Created: latency-svc-cps8h
    Jul 10 09:09:51.428: INFO: Got endpoints: latency-svc-cps8h [198.224033ms]
    Jul 10 09:09:51.430: INFO: Created: latency-svc-99l4w
    Jul 10 09:09:51.456: INFO: Got endpoints: latency-svc-99l4w [225.427805ms]
    Jul 10 09:09:51.456: INFO: Created: latency-svc-rft5j
    Jul 10 09:09:51.477: INFO: Got endpoints: latency-svc-rft5j [246.544014ms]
    Jul 10 09:09:51.480: INFO: Created: latency-svc-m69v4
    Jul 10 09:09:51.491: INFO: Got endpoints: latency-svc-m69v4 [261.349464ms]
    Jul 10 09:09:51.511: INFO: Created: latency-svc-dqxd7
    Jul 10 09:09:51.523: INFO: Got endpoints: latency-svc-dqxd7 [292.692506ms]
    Jul 10 09:09:51.545: INFO: Created: latency-svc-w9bgw
    Jul 10 09:09:51.567: INFO: Got endpoints: latency-svc-w9bgw [336.347817ms]
    Jul 10 09:09:51.569: INFO: Created: latency-svc-h887d
    Jul 10 09:09:51.592: INFO: Got endpoints: latency-svc-h887d [361.600157ms]
    Jul 10 09:09:51.597: INFO: Created: latency-svc-rm2dd
    Jul 10 09:09:51.609: INFO: Got endpoints: latency-svc-rm2dd [378.588854ms]
    Jul 10 09:09:51.617: INFO: Created: latency-svc-hlps8
    Jul 10 09:09:51.635: INFO: Got endpoints: latency-svc-hlps8 [404.272326ms]
    Jul 10 09:09:51.819: INFO: Created: latency-svc-2k45w
    Jul 10 09:09:51.820: INFO: Created: latency-svc-hqp69
    Jul 10 09:09:51.820: INFO: Created: latency-svc-46qk7
    Jul 10 09:09:51.823: INFO: Created: latency-svc-n8vbc
    Jul 10 09:09:51.823: INFO: Created: latency-svc-jzptl
    Jul 10 09:09:51.826: INFO: Created: latency-svc-cs2xc
    Jul 10 09:09:51.826: INFO: Created: latency-svc-kffd2
    Jul 10 09:09:51.831: INFO: Created: latency-svc-85b6g
    Jul 10 09:09:51.831: INFO: Created: latency-svc-gzbmn
    Jul 10 09:09:51.831: INFO: Created: latency-svc-7rfcr
    Jul 10 09:09:51.838: INFO: Created: latency-svc-d7dqs
    Jul 10 09:09:51.838: INFO: Created: latency-svc-lnqgb
    Jul 10 09:09:51.839: INFO: Created: latency-svc-bnwgr
    Jul 10 09:09:51.839: INFO: Created: latency-svc-dvdpz
    Jul 10 09:09:51.839: INFO: Created: latency-svc-89zjc
    Jul 10 09:09:51.847: INFO: Got endpoints: latency-svc-2k45w [555.177622ms]
    Jul 10 09:09:51.851: INFO: Got endpoints: latency-svc-hqp69 [474.350402ms]
    Jul 10 09:09:51.851: INFO: Got endpoints: latency-svc-46qk7 [242.06793ms]
    Jul 10 09:09:51.851: INFO: Got endpoints: latency-svc-jzptl [395.597014ms]
    Jul 10 09:09:51.875: INFO: Got endpoints: latency-svc-dvdpz [240.085824ms]
    Jul 10 09:09:51.880: INFO: Got endpoints: latency-svc-d7dqs [313.278024ms]
    Jul 10 09:09:51.880: INFO: Got endpoints: latency-svc-89zjc [549.743143ms]
    Jul 10 09:09:51.880: INFO: Got endpoints: latency-svc-n8vbc [357.276371ms]
    Jul 10 09:09:51.891: INFO: Got endpoints: latency-svc-gzbmn [616.475368ms]
    Jul 10 09:09:51.893: INFO: Got endpoints: latency-svc-bnwgr [493.627938ms]
    Jul 10 09:09:51.901: INFO: Got endpoints: latency-svc-lnqgb [424.708543ms]
    Jul 10 09:09:51.903: INFO: Created: latency-svc-v5qvs
    Jul 10 09:09:51.905: INFO: Got endpoints: latency-svc-kffd2 [313.223439ms]
    Jul 10 09:09:51.905: INFO: Got endpoints: latency-svc-85b6g [552.900274ms]
    Jul 10 09:09:51.907: INFO: Got endpoints: latency-svc-cs2xc [479.114235ms]
    Jul 10 09:09:51.909: INFO: Got endpoints: latency-svc-7rfcr [417.622977ms]
    Jul 10 09:09:51.945: INFO: Got endpoints: latency-svc-v5qvs [97.694321ms]
    Jul 10 09:09:51.946: INFO: Created: latency-svc-69jng
    Jul 10 09:09:51.959: INFO: Got endpoints: latency-svc-69jng [108.094432ms]
    Jul 10 09:09:51.979: INFO: Created: latency-svc-lmskj
    Jul 10 09:09:51.987: INFO: Got endpoints: latency-svc-lmskj [136.345323ms]
    Jul 10 09:09:51.988: INFO: Created: latency-svc-j9xtl
    Jul 10 09:09:52.013: INFO: Got endpoints: latency-svc-j9xtl [161.954667ms]
    Jul 10 09:09:52.014: INFO: Created: latency-svc-7ltml
    Jul 10 09:09:52.029: INFO: Got endpoints: latency-svc-7ltml [154.194869ms]
    Jul 10 09:09:52.046: INFO: Created: latency-svc-tb5qh
    Jul 10 09:09:52.051: INFO: Created: latency-svc-k9kvt
    Jul 10 09:09:52.070: INFO: Got endpoints: latency-svc-tb5qh [190.463443ms]
    Jul 10 09:09:52.071: INFO: Got endpoints: latency-svc-k9kvt [191.093977ms]
    Jul 10 09:09:52.078: INFO: Created: latency-svc-zftqf
    Jul 10 09:09:52.094: INFO: Got endpoints: latency-svc-zftqf [213.880273ms]
    Jul 10 09:09:52.103: INFO: Created: latency-svc-8zmz4
    Jul 10 09:09:52.120: INFO: Got endpoints: latency-svc-8zmz4 [229.368032ms]
    Jul 10 09:09:52.121: INFO: Created: latency-svc-shwpl
    Jul 10 09:09:52.143: INFO: Got endpoints: latency-svc-shwpl [249.39376ms]
    Jul 10 09:09:52.150: INFO: Created: latency-svc-k5mrw
    Jul 10 09:09:52.170: INFO: Created: latency-svc-qm8dx
    Jul 10 09:09:52.171: INFO: Got endpoints: latency-svc-k5mrw [269.600075ms]
    Jul 10 09:09:52.189: INFO: Got endpoints: latency-svc-qm8dx [284.178626ms]
    Jul 10 09:09:52.199: INFO: Created: latency-svc-sdfqv
    Jul 10 09:09:52.221: INFO: Got endpoints: latency-svc-sdfqv [315.471369ms]
    Jul 10 09:09:52.228: INFO: Created: latency-svc-hkhjq
    Jul 10 09:09:52.248: INFO: Got endpoints: latency-svc-hkhjq [340.367802ms]
    Jul 10 09:09:52.259: INFO: Created: latency-svc-6v789
    Jul 10 09:09:52.284: INFO: Got endpoints: latency-svc-6v789 [374.742311ms]
    Jul 10 09:09:52.301: INFO: Created: latency-svc-5fmsb
    Jul 10 09:09:52.317: INFO: Got endpoints: latency-svc-5fmsb [372.008292ms]
    Jul 10 09:09:52.318: INFO: Created: latency-svc-rh9p9
    Jul 10 09:09:52.329: INFO: Got endpoints: latency-svc-rh9p9 [370.200123ms]
    Jul 10 09:09:52.335: INFO: Created: latency-svc-wsctz
    Jul 10 09:09:52.358: INFO: Got endpoints: latency-svc-wsctz [370.485088ms]
    Jul 10 09:09:52.362: INFO: Created: latency-svc-l2q5t
    Jul 10 09:09:52.372: INFO: Got endpoints: latency-svc-l2q5t [358.316289ms]
    Jul 10 09:09:52.379: INFO: Created: latency-svc-f4lzz
    Jul 10 09:09:52.395: INFO: Got endpoints: latency-svc-f4lzz [366.422804ms]
    Jul 10 09:09:52.398: INFO: Created: latency-svc-w7fpz
    Jul 10 09:09:52.416: INFO: Created: latency-svc-jtdbh
    Jul 10 09:09:52.416: INFO: Got endpoints: latency-svc-w7fpz [345.803417ms]
    Jul 10 09:09:52.432: INFO: Got endpoints: latency-svc-jtdbh [360.748463ms]
    Jul 10 09:09:52.448: INFO: Created: latency-svc-m5lmr
    Jul 10 09:09:52.461: INFO: Got endpoints: latency-svc-m5lmr [366.826586ms]
    Jul 10 09:09:52.471: INFO: Created: latency-svc-8ln8m
    Jul 10 09:09:52.495: INFO: Created: latency-svc-fhwbp
    Jul 10 09:09:52.503: INFO: Got endpoints: latency-svc-8ln8m [382.66258ms]
    Jul 10 09:09:52.534: INFO: Got endpoints: latency-svc-fhwbp [391.033394ms]
    Jul 10 09:09:52.551: INFO: Created: latency-svc-9mj5s
    Jul 10 09:09:52.567: INFO: Got endpoints: latency-svc-9mj5s [395.502297ms]
    Jul 10 09:09:52.580: INFO: Created: latency-svc-b2kxc
    Jul 10 09:09:52.586: INFO: Created: latency-svc-xfc94
    Jul 10 09:09:52.600: INFO: Created: latency-svc-68jzc
    Jul 10 09:09:52.624: INFO: Created: latency-svc-ps7ng
    Jul 10 09:09:52.627: INFO: Got endpoints: latency-svc-b2kxc [437.8286ms]
    Jul 10 09:09:52.640: INFO: Created: latency-svc-4llkh
    Jul 10 09:09:52.657: INFO: Created: latency-svc-whkbr
    Jul 10 09:09:52.676: INFO: Got endpoints: latency-svc-xfc94 [455.754712ms]
    Jul 10 09:09:52.680: INFO: Created: latency-svc-shdf9
    Jul 10 09:09:52.697: INFO: Created: latency-svc-zlw8f
    Jul 10 09:09:52.722: INFO: Got endpoints: latency-svc-68jzc [474.188874ms]
    Jul 10 09:09:52.722: INFO: Created: latency-svc-kl94s
    Jul 10 09:09:52.738: INFO: Created: latency-svc-vh85g
    Jul 10 09:09:52.751: INFO: Created: latency-svc-zmxzm
    Jul 10 09:09:52.764: INFO: Got endpoints: latency-svc-ps7ng [480.465622ms]
    Jul 10 09:09:52.770: INFO: Created: latency-svc-766nf
    Jul 10 09:09:52.801: INFO: Created: latency-svc-mqpcs
    Jul 10 09:09:52.810: INFO: Created: latency-svc-lmb6t
    Jul 10 09:09:52.818: INFO: Got endpoints: latency-svc-4llkh [500.436921ms]
    Jul 10 09:09:52.838: INFO: Created: latency-svc-zxk4l
    Jul 10 09:09:52.878: INFO: Created: latency-svc-c2xrg
    Jul 10 09:09:52.881: INFO: Got endpoints: latency-svc-whkbr [551.573167ms]
    Jul 10 09:09:52.898: INFO: Created: latency-svc-h2rtr
    Jul 10 09:09:52.918: INFO: Got endpoints: latency-svc-shdf9 [560.394516ms]
    Jul 10 09:09:52.926: INFO: Created: latency-svc-kxxhq
    Jul 10 09:09:52.953: INFO: Created: latency-svc-5h7np
    Jul 10 09:09:52.973: INFO: Created: latency-svc-44qw6
    Jul 10 09:09:52.982: INFO: Got endpoints: latency-svc-zlw8f [610.584592ms]
    Jul 10 09:09:52.994: INFO: Created: latency-svc-zvs87
    Jul 10 09:09:53.010: INFO: Created: latency-svc-9dxk4
    Jul 10 09:09:53.030: INFO: Got endpoints: latency-svc-kl94s [634.479429ms]
    Jul 10 09:09:53.035: INFO: Created: latency-svc-pflxw
    Jul 10 09:09:53.051: INFO: Created: latency-svc-t5hxs
    Jul 10 09:09:53.070: INFO: Got endpoints: latency-svc-vh85g [653.60392ms]
    Jul 10 09:09:53.088: INFO: Created: latency-svc-ml9xg
    Jul 10 09:09:53.129: INFO: Got endpoints: latency-svc-zmxzm [696.95978ms]
    Jul 10 09:09:53.148: INFO: Created: latency-svc-w4sdc
    Jul 10 09:09:53.168: INFO: Got endpoints: latency-svc-766nf [706.746651ms]
    Jul 10 09:09:53.197: INFO: Created: latency-svc-wwkjw
    Jul 10 09:09:53.215: INFO: Got endpoints: latency-svc-mqpcs [712.443089ms]
    Jul 10 09:09:53.248: INFO: Created: latency-svc-js2sz
    Jul 10 09:09:53.267: INFO: Got endpoints: latency-svc-lmb6t [733.255731ms]
    Jul 10 09:09:53.289: INFO: Created: latency-svc-ncqxl
    Jul 10 09:09:53.321: INFO: Got endpoints: latency-svc-zxk4l [754.485698ms]
    Jul 10 09:09:53.340: INFO: Created: latency-svc-rlll5
    Jul 10 09:09:53.372: INFO: Got endpoints: latency-svc-c2xrg [745.108949ms]
    Jul 10 09:09:53.402: INFO: Created: latency-svc-m4d6b
    Jul 10 09:09:53.414: INFO: Got endpoints: latency-svc-h2rtr [737.043193ms]
    Jul 10 09:09:53.439: INFO: Created: latency-svc-csnll
    Jul 10 09:09:53.468: INFO: Got endpoints: latency-svc-kxxhq [745.656237ms]
    Jul 10 09:09:53.488: INFO: Created: latency-svc-djdhj
    Jul 10 09:09:53.518: INFO: Got endpoints: latency-svc-5h7np [753.359351ms]
    Jul 10 09:09:53.541: INFO: Created: latency-svc-4tkqc
    Jul 10 09:09:53.574: INFO: Got endpoints: latency-svc-44qw6 [755.96153ms]
    Jul 10 09:09:53.596: INFO: Created: latency-svc-m2kmb
    Jul 10 09:09:53.618: INFO: Got endpoints: latency-svc-zvs87 [737.317806ms]
    Jul 10 09:09:53.637: INFO: Created: latency-svc-fp2cg
    Jul 10 09:09:53.669: INFO: Got endpoints: latency-svc-9dxk4 [750.79568ms]
    Jul 10 09:09:53.726: INFO: Created: latency-svc-mdc4t
    Jul 10 09:09:53.738: INFO: Got endpoints: latency-svc-pflxw [755.343474ms]
    Jul 10 09:09:53.758: INFO: Created: latency-svc-x99n7
    Jul 10 09:09:53.777: INFO: Got endpoints: latency-svc-t5hxs [746.763949ms]
    Jul 10 09:09:53.807: INFO: Created: latency-svc-bd9wk
    Jul 10 09:09:53.833: INFO: Got endpoints: latency-svc-ml9xg [762.74669ms]
    Jul 10 09:09:53.867: INFO: Created: latency-svc-zrtvg
    Jul 10 09:09:53.871: INFO: Got endpoints: latency-svc-w4sdc [742.264595ms]
    Jul 10 09:09:53.898: INFO: Created: latency-svc-8njsj
    Jul 10 09:09:53.918: INFO: Got endpoints: latency-svc-wwkjw [750.102213ms]
    Jul 10 09:09:53.939: INFO: Created: latency-svc-qhzhr
    Jul 10 09:09:53.969: INFO: Got endpoints: latency-svc-js2sz [753.682335ms]
    Jul 10 09:09:53.988: INFO: Created: latency-svc-lzdtj
    Jul 10 09:09:54.022: INFO: Got endpoints: latency-svc-ncqxl [755.162812ms]
    Jul 10 09:09:54.046: INFO: Created: latency-svc-d6gjt
    Jul 10 09:09:54.067: INFO: Got endpoints: latency-svc-rlll5 [745.363093ms]
    Jul 10 09:09:54.089: INFO: Created: latency-svc-mtm29
    Jul 10 09:09:54.117: INFO: Got endpoints: latency-svc-m4d6b [744.191534ms]
    Jul 10 09:09:54.147: INFO: Created: latency-svc-xr8zr
    Jul 10 09:09:54.170: INFO: Got endpoints: latency-svc-csnll [756.582491ms]
    Jul 10 09:09:54.194: INFO: Created: latency-svc-qz5xv
    Jul 10 09:09:54.214: INFO: Got endpoints: latency-svc-djdhj [746.333991ms]
    Jul 10 09:09:54.247: INFO: Created: latency-svc-q8gtd
    Jul 10 09:09:54.275: INFO: Got endpoints: latency-svc-4tkqc [757.107135ms]
    Jul 10 09:09:54.303: INFO: Created: latency-svc-xllgv
    Jul 10 09:09:54.324: INFO: Got endpoints: latency-svc-m2kmb [750.674064ms]
    Jul 10 09:09:54.344: INFO: Created: latency-svc-lxhs4
    Jul 10 09:09:54.375: INFO: Got endpoints: latency-svc-fp2cg [756.670899ms]
    Jul 10 09:09:54.393: INFO: Created: latency-svc-rpwnq
    Jul 10 09:09:54.412: INFO: Got endpoints: latency-svc-mdc4t [742.796357ms]
    Jul 10 09:09:54.436: INFO: Created: latency-svc-blmqv
    Jul 10 09:09:54.494: INFO: Got endpoints: latency-svc-x99n7 [755.981991ms]
    Jul 10 09:09:54.516: INFO: Created: latency-svc-sk7bj
    Jul 10 09:09:54.518: INFO: Got endpoints: latency-svc-bd9wk [740.76065ms]
    Jul 10 09:09:54.538: INFO: Created: latency-svc-kkb8n
    Jul 10 09:09:54.566: INFO: Got endpoints: latency-svc-zrtvg [732.78081ms]
    Jul 10 09:09:54.610: INFO: Created: latency-svc-g2cmg
    Jul 10 09:09:54.618: INFO: Got endpoints: latency-svc-8njsj [746.92412ms]
    Jul 10 09:09:54.636: INFO: Created: latency-svc-t22pd
    Jul 10 09:09:54.702: INFO: Got endpoints: latency-svc-qhzhr [783.974694ms]
    Jul 10 09:09:54.719: INFO: Got endpoints: latency-svc-lzdtj [749.829109ms]
    Jul 10 09:09:54.727: INFO: Created: latency-svc-cqhdx
    Jul 10 09:09:54.749: INFO: Created: latency-svc-5d8hz
    Jul 10 09:09:54.768: INFO: Got endpoints: latency-svc-d6gjt [745.76152ms]
    Jul 10 09:09:54.789: INFO: Created: latency-svc-cvj9c
    Jul 10 09:09:54.816: INFO: Got endpoints: latency-svc-mtm29 [749.397227ms]
    Jul 10 09:09:54.839: INFO: Created: latency-svc-sdkrz
    Jul 10 09:09:54.873: INFO: Got endpoints: latency-svc-xr8zr [756.723049ms]
    Jul 10 09:09:54.901: INFO: Created: latency-svc-4b572
    Jul 10 09:09:54.920: INFO: Got endpoints: latency-svc-qz5xv [749.4236ms]
    Jul 10 09:09:54.939: INFO: Created: latency-svc-xr22n
    Jul 10 09:09:54.968: INFO: Got endpoints: latency-svc-q8gtd [753.854645ms]
    Jul 10 09:09:54.990: INFO: Created: latency-svc-444wb
    Jul 10 09:09:55.014: INFO: Got endpoints: latency-svc-xllgv [738.587184ms]
    Jul 10 09:09:55.046: INFO: Created: latency-svc-5ndtl
    Jul 10 09:09:55.076: INFO: Got endpoints: latency-svc-lxhs4 [751.665484ms]
    Jul 10 09:09:55.097: INFO: Created: latency-svc-nrksm
    Jul 10 09:09:55.123: INFO: Got endpoints: latency-svc-rpwnq [748.222259ms]
    Jul 10 09:09:55.145: INFO: Created: latency-svc-4kjrb
    Jul 10 09:09:55.169: INFO: Got endpoints: latency-svc-blmqv [757.003161ms]
    Jul 10 09:09:55.195: INFO: Created: latency-svc-74rtc
    Jul 10 09:09:55.219: INFO: Got endpoints: latency-svc-sk7bj [725.573192ms]
    Jul 10 09:09:55.253: INFO: Created: latency-svc-xqv56
    Jul 10 09:09:55.272: INFO: Got endpoints: latency-svc-kkb8n [754.714131ms]
    Jul 10 09:09:55.305: INFO: Created: latency-svc-4tlhk
    Jul 10 09:09:55.317: INFO: Got endpoints: latency-svc-g2cmg [751.335982ms]
    Jul 10 09:09:55.340: INFO: Created: latency-svc-qksmq
    Jul 10 09:09:55.369: INFO: Got endpoints: latency-svc-t22pd [750.920352ms]
    Jul 10 09:09:55.387: INFO: Created: latency-svc-pppxh
    Jul 10 09:09:55.419: INFO: Got endpoints: latency-svc-cqhdx [717.433471ms]
    Jul 10 09:09:55.443: INFO: Created: latency-svc-c6chq
    Jul 10 09:09:55.465: INFO: Got endpoints: latency-svc-5d8hz [745.663857ms]
    Jul 10 09:09:55.492: INFO: Created: latency-svc-5x6jq
    Jul 10 09:09:55.516: INFO: Got endpoints: latency-svc-cvj9c [747.916898ms]
    Jul 10 09:09:55.534: INFO: Created: latency-svc-5vk9f
    Jul 10 09:09:55.571: INFO: Got endpoints: latency-svc-sdkrz [754.514113ms]
    Jul 10 09:09:55.598: INFO: Created: latency-svc-2fqkr
    Jul 10 09:09:55.619: INFO: Got endpoints: latency-svc-4b572 [745.923036ms]
    Jul 10 09:09:55.645: INFO: Created: latency-svc-c4hsl
    Jul 10 09:09:55.663: INFO: Got endpoints: latency-svc-xr22n [743.649114ms]
    Jul 10 09:09:55.690: INFO: Created: latency-svc-zx9vq
    Jul 10 09:09:55.723: INFO: Got endpoints: latency-svc-444wb [755.002119ms]
    Jul 10 09:09:55.746: INFO: Created: latency-svc-pbcvn
    Jul 10 09:09:55.771: INFO: Got endpoints: latency-svc-5ndtl [757.310708ms]
    Jul 10 09:09:55.790: INFO: Created: latency-svc-nsw49
    Jul 10 09:09:55.817: INFO: Got endpoints: latency-svc-nrksm [740.289566ms]
    Jul 10 09:09:55.842: INFO: Created: latency-svc-z86c8
    Jul 10 09:09:55.869: INFO: Got endpoints: latency-svc-4kjrb [746.360735ms]
    Jul 10 09:09:55.912: INFO: Created: latency-svc-zjrck
    Jul 10 09:09:55.918: INFO: Got endpoints: latency-svc-74rtc [748.775011ms]
    Jul 10 09:09:55.947: INFO: Created: latency-svc-xrv82
    Jul 10 09:09:55.970: INFO: Got endpoints: latency-svc-xqv56 [751.138198ms]
    Jul 10 09:09:56.042: INFO: Got endpoints: latency-svc-4tlhk [769.520469ms]
    Jul 10 09:09:56.051: INFO: Created: latency-svc-86b4d
    Jul 10 09:09:56.067: INFO: Got endpoints: latency-svc-qksmq [750.478441ms]
    Jul 10 09:09:56.074: INFO: Created: latency-svc-8dqt4
    Jul 10 09:09:56.091: INFO: Created: latency-svc-2cnwg
    Jul 10 09:09:56.119: INFO: Got endpoints: latency-svc-pppxh [750.17033ms]
    Jul 10 09:09:56.143: INFO: Created: latency-svc-lkp2j
    Jul 10 09:09:56.172: INFO: Got endpoints: latency-svc-c6chq [752.40023ms]
    Jul 10 09:09:56.194: INFO: Created: latency-svc-86hsx
    Jul 10 09:09:56.214: INFO: Got endpoints: latency-svc-5x6jq [749.135927ms]
    Jul 10 09:09:56.248: INFO: Created: latency-svc-gjlls
    Jul 10 09:09:56.271: INFO: Got endpoints: latency-svc-5vk9f [754.876962ms]
    Jul 10 09:09:56.293: INFO: Created: latency-svc-hqj66
    Jul 10 09:09:56.316: INFO: Got endpoints: latency-svc-2fqkr [745.324957ms]
    Jul 10 09:09:56.456: INFO: Created: latency-svc-hntj7
    Jul 10 09:09:56.456: INFO: Got endpoints: latency-svc-c4hsl [837.050612ms]
    Jul 10 09:09:56.456: INFO: Got endpoints: latency-svc-zx9vq [793.066182ms]
    Jul 10 09:09:56.470: INFO: Got endpoints: latency-svc-pbcvn [746.64996ms]
    Jul 10 09:09:56.487: INFO: Created: latency-svc-jtpvw
    Jul 10 09:09:56.505: INFO: Created: latency-svc-sqrqj
    Jul 10 09:09:56.523: INFO: Got endpoints: latency-svc-nsw49 [752.049353ms]
    Jul 10 09:09:56.527: INFO: Created: latency-svc-b9nn4
    Jul 10 09:09:56.544: INFO: Created: latency-svc-tkbhn
    Jul 10 09:09:56.566: INFO: Got endpoints: latency-svc-z86c8 [749.349096ms]
    Jul 10 09:09:56.583: INFO: Created: latency-svc-dtcvx
    Jul 10 09:09:56.620: INFO: Got endpoints: latency-svc-zjrck [750.124758ms]
    Jul 10 09:09:56.640: INFO: Created: latency-svc-5rk2c
    Jul 10 09:09:56.671: INFO: Got endpoints: latency-svc-xrv82 [753.012489ms]
    Jul 10 09:09:56.692: INFO: Created: latency-svc-djcqn
    Jul 10 09:09:56.719: INFO: Got endpoints: latency-svc-86b4d [748.951565ms]
    Jul 10 09:09:56.743: INFO: Created: latency-svc-m7gt5
    Jul 10 09:09:56.765: INFO: Got endpoints: latency-svc-8dqt4 [722.656505ms]
    Jul 10 09:09:56.787: INFO: Created: latency-svc-p4jwq
    Jul 10 09:09:56.818: INFO: Got endpoints: latency-svc-2cnwg [750.398553ms]
    Jul 10 09:09:56.843: INFO: Created: latency-svc-848rw
    Jul 10 09:09:56.873: INFO: Got endpoints: latency-svc-lkp2j [753.173545ms]
    Jul 10 09:09:56.892: INFO: Created: latency-svc-d27fb
    Jul 10 09:09:56.924: INFO: Got endpoints: latency-svc-86hsx [752.084701ms]
    Jul 10 09:09:56.950: INFO: Created: latency-svc-6844b
    Jul 10 09:09:56.967: INFO: Got endpoints: latency-svc-gjlls [753.316832ms]
    Jul 10 09:09:56.987: INFO: Created: latency-svc-2grct
    Jul 10 09:09:57.017: INFO: Got endpoints: latency-svc-hqj66 [745.823794ms]
    Jul 10 09:09:57.044: INFO: Created: latency-svc-fctpn
    Jul 10 09:09:57.067: INFO: Got endpoints: latency-svc-hntj7 [750.664266ms]
    Jul 10 09:09:57.100: INFO: Created: latency-svc-c5h5d
    Jul 10 09:09:57.118: INFO: Got endpoints: latency-svc-jtpvw [661.028889ms]
    Jul 10 09:09:57.142: INFO: Created: latency-svc-m7r4h
    Jul 10 09:09:57.169: INFO: Got endpoints: latency-svc-sqrqj [712.990571ms]
    Jul 10 09:09:57.191: INFO: Created: latency-svc-dkk9b
    Jul 10 09:09:57.228: INFO: Got endpoints: latency-svc-b9nn4 [758.671684ms]
    Jul 10 09:09:57.256: INFO: Created: latency-svc-j5hq5
    Jul 10 09:09:57.275: INFO: Got endpoints: latency-svc-tkbhn [751.516645ms]
    Jul 10 09:09:57.306: INFO: Created: latency-svc-68fp6
    Jul 10 09:09:57.317: INFO: Got endpoints: latency-svc-dtcvx [750.976821ms]
    Jul 10 09:09:57.345: INFO: Created: latency-svc-5gdq7
    Jul 10 09:09:57.368: INFO: Got endpoints: latency-svc-5rk2c [747.92888ms]
    Jul 10 09:09:57.388: INFO: Created: latency-svc-dtv5s
    Jul 10 09:09:57.423: INFO: Got endpoints: latency-svc-djcqn [751.500486ms]
    Jul 10 09:09:57.448: INFO: Created: latency-svc-sk275
    Jul 10 09:09:57.468: INFO: Got endpoints: latency-svc-m7gt5 [748.922756ms]
    Jul 10 09:09:57.495: INFO: Created: latency-svc-jt25h
    Jul 10 09:09:57.517: INFO: Got endpoints: latency-svc-p4jwq [752.407125ms]
    Jul 10 09:09:57.545: INFO: Created: latency-svc-t4s4w
    Jul 10 09:09:57.569: INFO: Got endpoints: latency-svc-848rw [751.411459ms]
    Jul 10 09:09:57.592: INFO: Created: latency-svc-w9rjq
    Jul 10 09:09:57.620: INFO: Got endpoints: latency-svc-d27fb [747.2869ms]
    Jul 10 09:09:57.640: INFO: Created: latency-svc-ph97t
    Jul 10 09:09:57.676: INFO: Got endpoints: latency-svc-6844b [751.83378ms]
    Jul 10 09:09:57.707: INFO: Created: latency-svc-gn6kg
    Jul 10 09:09:57.715: INFO: Got endpoints: latency-svc-2grct [747.801004ms]
    Jul 10 09:09:57.745: INFO: Created: latency-svc-6psd4
    Jul 10 09:09:57.771: INFO: Got endpoints: latency-svc-fctpn [754.301443ms]
    Jul 10 09:09:57.792: INFO: Created: latency-svc-vwmdk
    Jul 10 09:09:57.820: INFO: Got endpoints: latency-svc-c5h5d [753.42114ms]
    Jul 10 09:09:57.852: INFO: Created: latency-svc-szm6n
    Jul 10 09:09:57.873: INFO: Got endpoints: latency-svc-m7r4h [755.894065ms]
    Jul 10 09:09:57.896: INFO: Created: latency-svc-mgbmv
    Jul 10 09:09:57.922: INFO: Got endpoints: latency-svc-dkk9b [752.764915ms]
    Jul 10 09:09:57.946: INFO: Created: latency-svc-f8mxw
    Jul 10 09:09:57.967: INFO: Got endpoints: latency-svc-j5hq5 [738.855369ms]
    Jul 10 09:09:57.994: INFO: Created: latency-svc-jq2zl
    Jul 10 09:09:58.015: INFO: Got endpoints: latency-svc-68fp6 [740.48578ms]
    Jul 10 09:09:58.035: INFO: Created: latency-svc-tqltc
    Jul 10 09:09:58.071: INFO: Got endpoints: latency-svc-5gdq7 [754.098252ms]
    Jul 10 09:09:58.096: INFO: Created: latency-svc-5mnnp
    Jul 10 09:09:58.122: INFO: Got endpoints: latency-svc-dtv5s [754.385624ms]
    Jul 10 09:09:58.140: INFO: Created: latency-svc-wkcm2
    Jul 10 09:09:58.257: INFO: Got endpoints: latency-svc-sk275 [834.84534ms]
    Jul 10 09:09:58.261: INFO: Got endpoints: latency-svc-jt25h [792.894746ms]
    Jul 10 09:09:58.279: INFO: Got endpoints: latency-svc-t4s4w [761.450296ms]
    Jul 10 09:09:58.307: INFO: Created: latency-svc-qtj6z
    Jul 10 09:09:58.319: INFO: Got endpoints: latency-svc-w9rjq [749.273635ms]
    Jul 10 09:09:58.324: INFO: Created: latency-svc-6dddl
    Jul 10 09:09:58.369: INFO: Created: latency-svc-qgfd2
    Jul 10 09:09:58.374: INFO: Got endpoints: latency-svc-ph97t [753.964617ms]
    Jul 10 09:09:58.385: INFO: Created: latency-svc-9kzcl
    Jul 10 09:09:58.400: INFO: Created: latency-svc-tfw52
    Jul 10 09:09:58.422: INFO: Got endpoints: latency-svc-gn6kg [745.588007ms]
    Jul 10 09:09:58.454: INFO: Created: latency-svc-gbhvc
    Jul 10 09:09:58.475: INFO: Got endpoints: latency-svc-6psd4 [759.764246ms]
    Jul 10 09:09:58.498: INFO: Created: latency-svc-4xkrx
    Jul 10 09:09:58.522: INFO: Got endpoints: latency-svc-vwmdk [751.035558ms]
    Jul 10 09:09:58.540: INFO: Created: latency-svc-r4f6z
    Jul 10 09:09:58.569: INFO: Got endpoints: latency-svc-szm6n [748.811501ms]
    Jul 10 09:09:58.625: INFO: Got endpoints: latency-svc-mgbmv [751.429117ms]
    Jul 10 09:09:58.635: INFO: Created: latency-svc-tbn5m
    Jul 10 09:09:58.668: INFO: Created: latency-svc-4z6kw
    Jul 10 09:09:58.676: INFO: Got endpoints: latency-svc-f8mxw [753.666833ms]
    Jul 10 09:09:58.695: INFO: Created: latency-svc-lrbdj
    Jul 10 09:09:58.730: INFO: Got endpoints: latency-svc-jq2zl [762.59352ms]
    Jul 10 09:09:58.752: INFO: Created: latency-svc-n67n7
    Jul 10 09:09:58.763: INFO: Got endpoints: latency-svc-tqltc [747.54179ms]
    Jul 10 09:09:58.793: INFO: Created: latency-svc-n6dbg
    Jul 10 09:09:58.824: INFO: Got endpoints: latency-svc-5mnnp [752.982569ms]
    Jul 10 09:09:58.843: INFO: Created: latency-svc-c5k7p
    Jul 10 09:09:58.870: INFO: Got endpoints: latency-svc-wkcm2 [747.515918ms]
    Jul 10 09:09:58.892: INFO: Created: latency-svc-p9mpf
    Jul 10 09:09:58.917: INFO: Got endpoints: latency-svc-qtj6z [659.621123ms]
    Jul 10 09:09:58.948: INFO: Created: latency-svc-h5rrv
    Jul 10 09:09:58.969: INFO: Got endpoints: latency-svc-6dddl [707.276767ms]
    Jul 10 09:09:58.990: INFO: Created: latency-svc-s55ld
    Jul 10 09:09:59.021: INFO: Got endpoints: latency-svc-qgfd2 [742.763895ms]
    Jul 10 09:09:59.045: INFO: Created: latency-svc-s5mjt
    Jul 10 09:09:59.069: INFO: Got endpoints: latency-svc-9kzcl [750.069532ms]
    Jul 10 09:09:59.118: INFO: Got endpoints: latency-svc-tfw52 [743.802747ms]
    Jul 10 09:09:59.173: INFO: Got endpoints: latency-svc-gbhvc [751.39275ms]
    Jul 10 09:09:59.214: INFO: Got endpoints: latency-svc-4xkrx [739.467118ms]
    Jul 10 09:09:59.273: INFO: Got endpoints: latency-svc-r4f6z [750.156373ms]
    Jul 10 09:09:59.321: INFO: Got endpoints: latency-svc-tbn5m [752.166413ms]
    Jul 10 09:09:59.363: INFO: Got endpoints: latency-svc-4z6kw [737.568553ms]
    Jul 10 09:09:59.419: INFO: Got endpoints: latency-svc-lrbdj [742.902855ms]
    Jul 10 09:09:59.559: INFO: Got endpoints: latency-svc-n6dbg [796.296747ms]
    Jul 10 09:09:59.559: INFO: Got endpoints: latency-svc-n67n7 [829.080388ms]
    Jul 10 09:09:59.576: INFO: Got endpoints: latency-svc-c5k7p [751.617978ms]
    Jul 10 09:09:59.622: INFO: Got endpoints: latency-svc-p9mpf [752.507302ms]
    Jul 10 09:09:59.672: INFO: Got endpoints: latency-svc-h5rrv [754.492779ms]
    Jul 10 09:09:59.725: INFO: Got endpoints: latency-svc-s55ld [756.24433ms]
    Jul 10 09:09:59.780: INFO: Got endpoints: latency-svc-s5mjt [758.850935ms]
    Jul 10 09:09:59.780: INFO: Latencies: [45.178756ms 62.482278ms 97.694321ms 100.722972ms 108.094432ms 122.373745ms 136.345323ms 146.165691ms 154.194869ms 161.954667ms 169.679413ms 190.463443ms 191.093977ms 198.224033ms 213.880273ms 225.427805ms 229.368032ms 240.085824ms 242.06793ms 246.544014ms 249.39376ms 261.349464ms 269.600075ms 284.178626ms 292.692506ms 313.223439ms 313.278024ms 315.471369ms 336.347817ms 340.367802ms 345.803417ms 357.276371ms 358.316289ms 360.748463ms 361.600157ms 366.422804ms 366.826586ms 370.200123ms 370.485088ms 372.008292ms 374.742311ms 378.588854ms 382.66258ms 391.033394ms 395.502297ms 395.597014ms 404.272326ms 417.622977ms 424.708543ms 437.8286ms 455.754712ms 474.188874ms 474.350402ms 479.114235ms 480.465622ms 493.627938ms 500.436921ms 549.743143ms 551.573167ms 552.900274ms 555.177622ms 560.394516ms 610.584592ms 616.475368ms 634.479429ms 653.60392ms 659.621123ms 661.028889ms 696.95978ms 706.746651ms 707.276767ms 712.443089ms 712.990571ms 717.433471ms 722.656505ms 725.573192ms 732.78081ms 733.255731ms 737.043193ms 737.317806ms 737.568553ms 738.587184ms 738.855369ms 739.467118ms 740.289566ms 740.48578ms 740.76065ms 742.264595ms 742.763895ms 742.796357ms 742.902855ms 743.649114ms 743.802747ms 744.191534ms 745.108949ms 745.324957ms 745.363093ms 745.588007ms 745.656237ms 745.663857ms 745.76152ms 745.823794ms 745.923036ms 746.333991ms 746.360735ms 746.64996ms 746.763949ms 746.92412ms 747.2869ms 747.515918ms 747.54179ms 747.801004ms 747.916898ms 747.92888ms 748.222259ms 748.775011ms 748.811501ms 748.922756ms 748.951565ms 749.135927ms 749.273635ms 749.349096ms 749.397227ms 749.4236ms 749.829109ms 750.069532ms 750.102213ms 750.124758ms 750.156373ms 750.17033ms 750.398553ms 750.478441ms 750.664266ms 750.674064ms 750.79568ms 750.920352ms 750.976821ms 751.035558ms 751.138198ms 751.335982ms 751.39275ms 751.411459ms 751.429117ms 751.500486ms 751.516645ms 751.617978ms 751.665484ms 751.83378ms 752.049353ms 752.084701ms 752.166413ms 752.40023ms 752.407125ms 752.507302ms 752.764915ms 752.982569ms 753.012489ms 753.173545ms 753.316832ms 753.359351ms 753.42114ms 753.666833ms 753.682335ms 753.854645ms 753.964617ms 754.098252ms 754.301443ms 754.385624ms 754.485698ms 754.492779ms 754.514113ms 754.714131ms 754.876962ms 755.002119ms 755.162812ms 755.343474ms 755.894065ms 755.96153ms 755.981991ms 756.24433ms 756.582491ms 756.670899ms 756.723049ms 757.003161ms 757.107135ms 757.310708ms 758.671684ms 758.850935ms 759.764246ms 761.450296ms 762.59352ms 762.74669ms 769.520469ms 783.974694ms 792.894746ms 793.066182ms 796.296747ms 829.080388ms 834.84534ms 837.050612ms]
    Jul 10 09:09:59.780: INFO: 50 %ile: 745.76152ms
    Jul 10 09:09:59.780: INFO: 90 %ile: 756.582491ms
    Jul 10 09:09:59.780: INFO: 99 %ile: 834.84534ms
    Jul 10 09:09:59.780: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Jul 10 09:09:59.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-2274" for this suite. 07/10/23 09:09:59.788
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:09:59.804
Jul 10 09:09:59.804: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 09:09:59.805
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:59.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:59.851
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 07/10/23 09:09:59.854
STEP: waiting for pod running 07/10/23 09:09:59.867
Jul 10 09:09:59.867: INFO: Waiting up to 2m0s for pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" in namespace "var-expansion-2074" to be "running"
Jul 10 09:09:59.873: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Pending", Reason="", readiness=false. Elapsed: 5.524522ms
Jul 10 09:10:01.879: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011834209s
Jul 10 09:10:03.879: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Running", Reason="", readiness=true. Elapsed: 4.01202139s
Jul 10 09:10:03.879: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" satisfied condition "running"
STEP: creating a file in subpath 07/10/23 09:10:03.879
Jul 10 09:10:03.885: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2074 PodName:var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:10:03.885: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:10:03.885: INFO: ExecWithOptions: Clientset creation
Jul 10 09:10:03.885: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/var-expansion-2074/pods/var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 07/10/23 09:10:03.971
Jul 10 09:10:03.979: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2074 PodName:var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:10:03.979: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:10:03.979: INFO: ExecWithOptions: Clientset creation
Jul 10 09:10:03.979: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/var-expansion-2074/pods/var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 07/10/23 09:10:04.049
Jul 10 09:10:04.573: INFO: Successfully updated pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381"
STEP: waiting for annotated pod running 07/10/23 09:10:04.573
Jul 10 09:10:04.573: INFO: Waiting up to 2m0s for pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" in namespace "var-expansion-2074" to be "running"
Jul 10 09:10:04.578: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Running", Reason="", readiness=true. Elapsed: 5.029311ms
Jul 10 09:10:04.578: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" satisfied condition "running"
STEP: deleting the pod gracefully 07/10/23 09:10:04.578
Jul 10 09:10:04.578: INFO: Deleting pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" in namespace "var-expansion-2074"
Jul 10 09:10:04.595: INFO: Wait up to 5m0s for pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 09:10:36.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2074" for this suite. 07/10/23 09:10:36.624
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":266,"skipped":4996,"failed":0}
------------------------------
• [SLOW TEST] [36.832 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:09:59.804
    Jul 10 09:09:59.804: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 09:09:59.805
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:09:59.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:09:59.851
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 07/10/23 09:09:59.854
    STEP: waiting for pod running 07/10/23 09:09:59.867
    Jul 10 09:09:59.867: INFO: Waiting up to 2m0s for pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" in namespace "var-expansion-2074" to be "running"
    Jul 10 09:09:59.873: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Pending", Reason="", readiness=false. Elapsed: 5.524522ms
    Jul 10 09:10:01.879: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011834209s
    Jul 10 09:10:03.879: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Running", Reason="", readiness=true. Elapsed: 4.01202139s
    Jul 10 09:10:03.879: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" satisfied condition "running"
    STEP: creating a file in subpath 07/10/23 09:10:03.879
    Jul 10 09:10:03.885: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2074 PodName:var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:10:03.885: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:10:03.885: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:10:03.885: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/var-expansion-2074/pods/var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 07/10/23 09:10:03.971
    Jul 10 09:10:03.979: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2074 PodName:var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:10:03.979: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:10:03.979: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:10:03.979: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/var-expansion-2074/pods/var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 07/10/23 09:10:04.049
    Jul 10 09:10:04.573: INFO: Successfully updated pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381"
    STEP: waiting for annotated pod running 07/10/23 09:10:04.573
    Jul 10 09:10:04.573: INFO: Waiting up to 2m0s for pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" in namespace "var-expansion-2074" to be "running"
    Jul 10 09:10:04.578: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381": Phase="Running", Reason="", readiness=true. Elapsed: 5.029311ms
    Jul 10 09:10:04.578: INFO: Pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" satisfied condition "running"
    STEP: deleting the pod gracefully 07/10/23 09:10:04.578
    Jul 10 09:10:04.578: INFO: Deleting pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" in namespace "var-expansion-2074"
    Jul 10 09:10:04.595: INFO: Wait up to 5m0s for pod "var-expansion-89b47c49-a4ca-418b-ad0f-c19e67fc5381" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 09:10:36.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2074" for this suite. 07/10/23 09:10:36.624
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:10:36.637
Jul 10 09:10:36.637: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 09:10:36.638
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:36.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:36.671
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-29c78314-f149-4d0d-ae93-44a23ee2025a 07/10/23 09:10:36.686
STEP: Creating secret with name s-test-opt-upd-7c84c261-2416-4828-ba28-ad0886c200ef 07/10/23 09:10:36.697
STEP: Creating the pod 07/10/23 09:10:36.706
Jul 10 09:10:36.722: INFO: Waiting up to 5m0s for pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385" in namespace "secrets-4983" to be "running and ready"
Jul 10 09:10:36.728: INFO: Pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62747ms
Jul 10 09:10:36.728: INFO: The phase of Pod pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:10:38.734: INFO: Pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385": Phase="Running", Reason="", readiness=true. Elapsed: 2.012036151s
Jul 10 09:10:38.734: INFO: The phase of Pod pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385 is Running (Ready = true)
Jul 10 09:10:38.734: INFO: Pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-29c78314-f149-4d0d-ae93-44a23ee2025a 07/10/23 09:10:38.782
STEP: Updating secret s-test-opt-upd-7c84c261-2416-4828-ba28-ad0886c200ef 07/10/23 09:10:38.795
STEP: Creating secret with name s-test-opt-create-8d958d30-d8a7-4cbf-8913-dc448224ab3c 07/10/23 09:10:38.81
STEP: waiting to observe update in volume 07/10/23 09:10:38.818
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 09:10:40.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4983" for this suite. 07/10/23 09:10:40.87
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":267,"skipped":5026,"failed":0}
------------------------------
• [4.247 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:10:36.637
    Jul 10 09:10:36.637: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 09:10:36.638
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:36.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:36.671
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-29c78314-f149-4d0d-ae93-44a23ee2025a 07/10/23 09:10:36.686
    STEP: Creating secret with name s-test-opt-upd-7c84c261-2416-4828-ba28-ad0886c200ef 07/10/23 09:10:36.697
    STEP: Creating the pod 07/10/23 09:10:36.706
    Jul 10 09:10:36.722: INFO: Waiting up to 5m0s for pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385" in namespace "secrets-4983" to be "running and ready"
    Jul 10 09:10:36.728: INFO: Pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62747ms
    Jul 10 09:10:36.728: INFO: The phase of Pod pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:10:38.734: INFO: Pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385": Phase="Running", Reason="", readiness=true. Elapsed: 2.012036151s
    Jul 10 09:10:38.734: INFO: The phase of Pod pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385 is Running (Ready = true)
    Jul 10 09:10:38.734: INFO: Pod "pod-secrets-5ecaff43-f7d8-4d51-912d-6704ae3d2385" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-29c78314-f149-4d0d-ae93-44a23ee2025a 07/10/23 09:10:38.782
    STEP: Updating secret s-test-opt-upd-7c84c261-2416-4828-ba28-ad0886c200ef 07/10/23 09:10:38.795
    STEP: Creating secret with name s-test-opt-create-8d958d30-d8a7-4cbf-8913-dc448224ab3c 07/10/23 09:10:38.81
    STEP: waiting to observe update in volume 07/10/23 09:10:38.818
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 09:10:40.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4983" for this suite. 07/10/23 09:10:40.87
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:10:40.887
Jul 10 09:10:40.887: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 09:10:40.888
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:40.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:40.923
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8795 07/10/23 09:10:40.927
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 07/10/23 09:10:40.946
STEP: creating service externalsvc in namespace services-8795 07/10/23 09:10:40.946
STEP: creating replication controller externalsvc in namespace services-8795 07/10/23 09:10:40.972
I0710 09:10:40.992806      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8795, replica count: 2
I0710 09:10:44.044512      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 07/10/23 09:10:44.049
Jul 10 09:10:44.120: INFO: Creating new exec pod
Jul 10 09:10:44.141: INFO: Waiting up to 5m0s for pod "execpod4tntt" in namespace "services-8795" to be "running"
Jul 10 09:10:44.144: INFO: Pod "execpod4tntt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227978ms
Jul 10 09:10:46.149: INFO: Pod "execpod4tntt": Phase="Running", Reason="", readiness=true. Elapsed: 2.007896701s
Jul 10 09:10:46.149: INFO: Pod "execpod4tntt" satisfied condition "running"
Jul 10 09:10:46.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-8795 exec execpod4tntt -- /bin/sh -x -c nslookup clusterip-service.services-8795.svc.cluster.local'
Jul 10 09:10:46.332: INFO: stderr: "+ nslookup clusterip-service.services-8795.svc.cluster.local\n"
Jul 10 09:10:46.332: INFO: stdout: "Server:\t\t192.168.0.2\nAddress:\t192.168.0.2#53\n\nclusterip-service.services-8795.svc.cluster.local\tcanonical name = externalsvc.services-8795.svc.cluster.local.\nName:\texternalsvc.services-8795.svc.cluster.local\nAddress: 192.168.129.139\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8795, will wait for the garbage collector to delete the pods 07/10/23 09:10:46.332
Jul 10 09:10:46.423: INFO: Deleting ReplicationController externalsvc took: 37.400114ms
Jul 10 09:10:46.524: INFO: Terminating ReplicationController externalsvc pods took: 100.604112ms
Jul 10 09:10:48.581: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 09:10:48.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8795" for this suite. 07/10/23 09:10:48.611
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":268,"skipped":5065,"failed":0}
------------------------------
• [SLOW TEST] [7.739 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:10:40.887
    Jul 10 09:10:40.887: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 09:10:40.888
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:40.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:40.923
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8795 07/10/23 09:10:40.927
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 07/10/23 09:10:40.946
    STEP: creating service externalsvc in namespace services-8795 07/10/23 09:10:40.946
    STEP: creating replication controller externalsvc in namespace services-8795 07/10/23 09:10:40.972
    I0710 09:10:40.992806      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8795, replica count: 2
    I0710 09:10:44.044512      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 07/10/23 09:10:44.049
    Jul 10 09:10:44.120: INFO: Creating new exec pod
    Jul 10 09:10:44.141: INFO: Waiting up to 5m0s for pod "execpod4tntt" in namespace "services-8795" to be "running"
    Jul 10 09:10:44.144: INFO: Pod "execpod4tntt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227978ms
    Jul 10 09:10:46.149: INFO: Pod "execpod4tntt": Phase="Running", Reason="", readiness=true. Elapsed: 2.007896701s
    Jul 10 09:10:46.149: INFO: Pod "execpod4tntt" satisfied condition "running"
    Jul 10 09:10:46.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-8795 exec execpod4tntt -- /bin/sh -x -c nslookup clusterip-service.services-8795.svc.cluster.local'
    Jul 10 09:10:46.332: INFO: stderr: "+ nslookup clusterip-service.services-8795.svc.cluster.local\n"
    Jul 10 09:10:46.332: INFO: stdout: "Server:\t\t192.168.0.2\nAddress:\t192.168.0.2#53\n\nclusterip-service.services-8795.svc.cluster.local\tcanonical name = externalsvc.services-8795.svc.cluster.local.\nName:\texternalsvc.services-8795.svc.cluster.local\nAddress: 192.168.129.139\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-8795, will wait for the garbage collector to delete the pods 07/10/23 09:10:46.332
    Jul 10 09:10:46.423: INFO: Deleting ReplicationController externalsvc took: 37.400114ms
    Jul 10 09:10:46.524: INFO: Terminating ReplicationController externalsvc pods took: 100.604112ms
    Jul 10 09:10:48.581: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 09:10:48.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8795" for this suite. 07/10/23 09:10:48.611
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:10:48.627
Jul 10 09:10:48.627: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:10:48.628
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:48.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:48.66
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:10:48.663
Jul 10 09:10:48.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65" in namespace "downward-api-2885" to be "Succeeded or Failed"
Jul 10 09:10:48.683: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934646ms
Jul 10 09:10:50.688: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010785016s
Jul 10 09:10:52.689: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011861665s
STEP: Saw pod success 07/10/23 09:10:52.689
Jul 10 09:10:52.690: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65" satisfied condition "Succeeded or Failed"
Jul 10 09:10:52.694: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65 container client-container: <nil>
STEP: delete the pod 07/10/23 09:10:52.704
Jul 10 09:10:52.731: INFO: Waiting for pod downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65 to disappear
Jul 10 09:10:52.735: INFO: Pod downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 09:10:52.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2885" for this suite. 07/10/23 09:10:52.742
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":269,"skipped":5085,"failed":0}
------------------------------
• [4.127 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:10:48.627
    Jul 10 09:10:48.627: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:10:48.628
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:48.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:48.66
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:10:48.663
    Jul 10 09:10:48.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65" in namespace "downward-api-2885" to be "Succeeded or Failed"
    Jul 10 09:10:48.683: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934646ms
    Jul 10 09:10:50.688: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010785016s
    Jul 10 09:10:52.689: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011861665s
    STEP: Saw pod success 07/10/23 09:10:52.689
    Jul 10 09:10:52.690: INFO: Pod "downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65" satisfied condition "Succeeded or Failed"
    Jul 10 09:10:52.694: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65 container client-container: <nil>
    STEP: delete the pod 07/10/23 09:10:52.704
    Jul 10 09:10:52.731: INFO: Waiting for pod downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65 to disappear
    Jul 10 09:10:52.735: INFO: Pod downwardapi-volume-847bab5c-0a45-4710-bf90-1964648e1c65 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 09:10:52.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2885" for this suite. 07/10/23 09:10:52.742
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:10:52.755
Jul 10 09:10:52.755: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 09:10:52.756
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:52.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:52.799
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 07/10/23 09:10:52.802
Jul 10 09:10:52.817: INFO: Waiting up to 5m0s for pod "pod-380da491-1d18-41e0-9afa-578cb5af777b" in namespace "emptydir-1792" to be "Succeeded or Failed"
Jul 10 09:10:52.820: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.52548ms
Jul 10 09:10:54.827: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010279677s
Jul 10 09:10:56.826: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009337087s
STEP: Saw pod success 07/10/23 09:10:56.826
Jul 10 09:10:56.826: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b" satisfied condition "Succeeded or Failed"
Jul 10 09:10:56.830: INFO: Trying to get logs from node 10-62-109-100.test pod pod-380da491-1d18-41e0-9afa-578cb5af777b container test-container: <nil>
STEP: delete the pod 07/10/23 09:10:56.845
Jul 10 09:10:56.911: INFO: Waiting for pod pod-380da491-1d18-41e0-9afa-578cb5af777b to disappear
Jul 10 09:10:56.915: INFO: Pod pod-380da491-1d18-41e0-9afa-578cb5af777b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 09:10:56.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1792" for this suite. 07/10/23 09:10:56.919
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":270,"skipped":5087,"failed":0}
------------------------------
• [4.181 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:10:52.755
    Jul 10 09:10:52.755: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 09:10:52.756
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:52.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:52.799
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 07/10/23 09:10:52.802
    Jul 10 09:10:52.817: INFO: Waiting up to 5m0s for pod "pod-380da491-1d18-41e0-9afa-578cb5af777b" in namespace "emptydir-1792" to be "Succeeded or Failed"
    Jul 10 09:10:52.820: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.52548ms
    Jul 10 09:10:54.827: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010279677s
    Jul 10 09:10:56.826: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009337087s
    STEP: Saw pod success 07/10/23 09:10:56.826
    Jul 10 09:10:56.826: INFO: Pod "pod-380da491-1d18-41e0-9afa-578cb5af777b" satisfied condition "Succeeded or Failed"
    Jul 10 09:10:56.830: INFO: Trying to get logs from node 10-62-109-100.test pod pod-380da491-1d18-41e0-9afa-578cb5af777b container test-container: <nil>
    STEP: delete the pod 07/10/23 09:10:56.845
    Jul 10 09:10:56.911: INFO: Waiting for pod pod-380da491-1d18-41e0-9afa-578cb5af777b to disappear
    Jul 10 09:10:56.915: INFO: Pod pod-380da491-1d18-41e0-9afa-578cb5af777b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 09:10:56.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1792" for this suite. 07/10/23 09:10:56.919
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:10:56.936
Jul 10 09:10:56.936: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 09:10:56.937
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:56.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:56.972
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:10:56.975
Jul 10 09:10:56.987: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc" in namespace "projected-3905" to be "Succeeded or Failed"
Jul 10 09:10:56.993: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.538154ms
Jul 10 09:10:58.998: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010945817s
Jul 10 09:11:01.000: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012931864s
STEP: Saw pod success 07/10/23 09:11:01
Jul 10 09:11:01.000: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc" satisfied condition "Succeeded or Failed"
Jul 10 09:11:01.006: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc container client-container: <nil>
STEP: delete the pod 07/10/23 09:11:01.023
Jul 10 09:11:01.059: INFO: Waiting for pod downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc to disappear
Jul 10 09:11:01.068: INFO: Pod downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 09:11:01.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3905" for this suite. 07/10/23 09:11:01.084
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":271,"skipped":5089,"failed":0}
------------------------------
• [4.162 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:10:56.936
    Jul 10 09:10:56.936: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 09:10:56.937
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:10:56.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:10:56.972
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:10:56.975
    Jul 10 09:10:56.987: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc" in namespace "projected-3905" to be "Succeeded or Failed"
    Jul 10 09:10:56.993: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.538154ms
    Jul 10 09:10:58.998: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010945817s
    Jul 10 09:11:01.000: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012931864s
    STEP: Saw pod success 07/10/23 09:11:01
    Jul 10 09:11:01.000: INFO: Pod "downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc" satisfied condition "Succeeded or Failed"
    Jul 10 09:11:01.006: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc container client-container: <nil>
    STEP: delete the pod 07/10/23 09:11:01.023
    Jul 10 09:11:01.059: INFO: Waiting for pod downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc to disappear
    Jul 10 09:11:01.068: INFO: Pod downwardapi-volume-bf60f586-2efb-4685-838b-986e7482f7cc no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 09:11:01.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3905" for this suite. 07/10/23 09:11:01.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:01.099
Jul 10 09:11:01.099: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:11:01.1
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:01.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:01.164
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Jul 10 09:11:01.167: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 07/10/23 09:11:04.31
Jul 10 09:11:04.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 create -f -'
Jul 10 09:11:05.047: INFO: stderr: ""
Jul 10 09:11:05.047: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jul 10 09:11:05.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 delete e2e-test-crd-publish-openapi-3760-crds test-cr'
Jul 10 09:11:05.171: INFO: stderr: ""
Jul 10 09:11:05.171: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jul 10 09:11:05.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 apply -f -'
Jul 10 09:11:05.410: INFO: stderr: ""
Jul 10 09:11:05.410: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jul 10 09:11:05.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 delete e2e-test-crd-publish-openapi-3760-crds test-cr'
Jul 10 09:11:05.501: INFO: stderr: ""
Jul 10 09:11:05.501: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 07/10/23 09:11:05.501
Jul 10 09:11:05.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 explain e2e-test-crd-publish-openapi-3760-crds'
Jul 10 09:11:06.267: INFO: stderr: ""
Jul 10 09:11:06.267: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3760-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:11:10.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9871" for this suite. 07/10/23 09:11:10.85
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":272,"skipped":5111,"failed":0}
------------------------------
• [SLOW TEST] [9.761 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:01.099
    Jul 10 09:11:01.099: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:11:01.1
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:01.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:01.164
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Jul 10 09:11:01.167: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 07/10/23 09:11:04.31
    Jul 10 09:11:04.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 create -f -'
    Jul 10 09:11:05.047: INFO: stderr: ""
    Jul 10 09:11:05.047: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Jul 10 09:11:05.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 delete e2e-test-crd-publish-openapi-3760-crds test-cr'
    Jul 10 09:11:05.171: INFO: stderr: ""
    Jul 10 09:11:05.171: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Jul 10 09:11:05.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 apply -f -'
    Jul 10 09:11:05.410: INFO: stderr: ""
    Jul 10 09:11:05.410: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Jul 10 09:11:05.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 --namespace=crd-publish-openapi-9871 delete e2e-test-crd-publish-openapi-3760-crds test-cr'
    Jul 10 09:11:05.501: INFO: stderr: ""
    Jul 10 09:11:05.501: INFO: stdout: "e2e-test-crd-publish-openapi-3760-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 07/10/23 09:11:05.501
    Jul 10 09:11:05.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-9871 explain e2e-test-crd-publish-openapi-3760-crds'
    Jul 10 09:11:06.267: INFO: stderr: ""
    Jul 10 09:11:06.267: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3760-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:11:10.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9871" for this suite. 07/10/23 09:11:10.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:10.861
Jul 10 09:11:10.861: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename events 07/10/23 09:11:10.862
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:10.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:10.895
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 07/10/23 09:11:10.897
STEP: get a list of Events with a label in the current namespace 07/10/23 09:11:10.931
STEP: delete a list of events 07/10/23 09:11:10.935
Jul 10 09:11:10.936: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 07/10/23 09:11:10.985
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Jul 10 09:11:10.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-518" for this suite. 07/10/23 09:11:10.994
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":273,"skipped":5122,"failed":0}
------------------------------
• [0.146 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:10.861
    Jul 10 09:11:10.861: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename events 07/10/23 09:11:10.862
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:10.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:10.895
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 07/10/23 09:11:10.897
    STEP: get a list of Events with a label in the current namespace 07/10/23 09:11:10.931
    STEP: delete a list of events 07/10/23 09:11:10.935
    Jul 10 09:11:10.936: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 07/10/23 09:11:10.985
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Jul 10 09:11:10.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-518" for this suite. 07/10/23 09:11:10.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:11.007
Jul 10 09:11:11.007: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 09:11:11.008
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:11.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:11.04
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 07/10/23 09:11:11.043
Jul 10 09:11:11.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 create -f -'
Jul 10 09:11:11.716: INFO: stderr: ""
Jul 10 09:11:11.716: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 09:11:11.716
Jul 10 09:11:11.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 09:11:11.801: INFO: stderr: ""
Jul 10 09:11:11.801: INFO: stdout: "update-demo-nautilus-wx856 "
STEP: Replicas for name=update-demo: expected=2 actual=1 07/10/23 09:11:11.801
Jul 10 09:11:16.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul 10 09:11:16.881: INFO: stderr: ""
Jul 10 09:11:16.881: INFO: stdout: "update-demo-nautilus-rmrs2 update-demo-nautilus-wx856 "
Jul 10 09:11:16.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-rmrs2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 09:11:16.958: INFO: stderr: ""
Jul 10 09:11:16.958: INFO: stdout: "true"
Jul 10 09:11:16.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-rmrs2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 09:11:17.031: INFO: stderr: ""
Jul 10 09:11:17.031: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 09:11:17.031: INFO: validating pod update-demo-nautilus-rmrs2
Jul 10 09:11:17.037: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 09:11:17.037: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 09:11:17.038: INFO: update-demo-nautilus-rmrs2 is verified up and running
Jul 10 09:11:17.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-wx856 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul 10 09:11:17.129: INFO: stderr: ""
Jul 10 09:11:17.129: INFO: stdout: "true"
Jul 10 09:11:17.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-wx856 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul 10 09:11:17.202: INFO: stderr: ""
Jul 10 09:11:17.202: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jul 10 09:11:17.202: INFO: validating pod update-demo-nautilus-wx856
Jul 10 09:11:17.207: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 10 09:11:17.207: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 10 09:11:17.207: INFO: update-demo-nautilus-wx856 is verified up and running
STEP: using delete to clean up resources 07/10/23 09:11:17.207
Jul 10 09:11:17.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 delete --grace-period=0 --force -f -'
Jul 10 09:11:17.287: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 10 09:11:17.287: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 10 09:11:17.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get rc,svc -l name=update-demo --no-headers'
Jul 10 09:11:17.378: INFO: stderr: "No resources found in kubectl-5423 namespace.\n"
Jul 10 09:11:17.378: INFO: stdout: ""
Jul 10 09:11:17.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 10 09:11:17.457: INFO: stderr: ""
Jul 10 09:11:17.457: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 09:11:17.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5423" for this suite. 07/10/23 09:11:17.462
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":274,"skipped":5134,"failed":0}
------------------------------
• [SLOW TEST] [6.467 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:11.007
    Jul 10 09:11:11.007: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 09:11:11.008
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:11.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:11.04
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 07/10/23 09:11:11.043
    Jul 10 09:11:11.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 create -f -'
    Jul 10 09:11:11.716: INFO: stderr: ""
    Jul 10 09:11:11.716: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 07/10/23 09:11:11.716
    Jul 10 09:11:11.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 09:11:11.801: INFO: stderr: ""
    Jul 10 09:11:11.801: INFO: stdout: "update-demo-nautilus-wx856 "
    STEP: Replicas for name=update-demo: expected=2 actual=1 07/10/23 09:11:11.801
    Jul 10 09:11:16.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jul 10 09:11:16.881: INFO: stderr: ""
    Jul 10 09:11:16.881: INFO: stdout: "update-demo-nautilus-rmrs2 update-demo-nautilus-wx856 "
    Jul 10 09:11:16.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-rmrs2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 09:11:16.958: INFO: stderr: ""
    Jul 10 09:11:16.958: INFO: stdout: "true"
    Jul 10 09:11:16.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-rmrs2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 09:11:17.031: INFO: stderr: ""
    Jul 10 09:11:17.031: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 09:11:17.031: INFO: validating pod update-demo-nautilus-rmrs2
    Jul 10 09:11:17.037: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 09:11:17.037: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 09:11:17.038: INFO: update-demo-nautilus-rmrs2 is verified up and running
    Jul 10 09:11:17.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-wx856 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jul 10 09:11:17.129: INFO: stderr: ""
    Jul 10 09:11:17.129: INFO: stdout: "true"
    Jul 10 09:11:17.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods update-demo-nautilus-wx856 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jul 10 09:11:17.202: INFO: stderr: ""
    Jul 10 09:11:17.202: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jul 10 09:11:17.202: INFO: validating pod update-demo-nautilus-wx856
    Jul 10 09:11:17.207: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jul 10 09:11:17.207: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jul 10 09:11:17.207: INFO: update-demo-nautilus-wx856 is verified up and running
    STEP: using delete to clean up resources 07/10/23 09:11:17.207
    Jul 10 09:11:17.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 delete --grace-period=0 --force -f -'
    Jul 10 09:11:17.287: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jul 10 09:11:17.287: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Jul 10 09:11:17.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get rc,svc -l name=update-demo --no-headers'
    Jul 10 09:11:17.378: INFO: stderr: "No resources found in kubectl-5423 namespace.\n"
    Jul 10 09:11:17.378: INFO: stdout: ""
    Jul 10 09:11:17.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5423 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jul 10 09:11:17.457: INFO: stderr: ""
    Jul 10 09:11:17.457: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 09:11:17.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5423" for this suite. 07/10/23 09:11:17.462
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:17.475
Jul 10 09:11:17.475: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 09:11:17.477
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:17.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:17.508
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
STEP: creating service in namespace services-3976 07/10/23 09:11:17.511
STEP: creating service affinity-nodeport-transition in namespace services-3976 07/10/23 09:11:17.511
STEP: creating replication controller affinity-nodeport-transition in namespace services-3976 07/10/23 09:11:17.557
I0710 09:11:17.568524      21 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3976, replica count: 3
I0710 09:11:20.619517      21 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 10 09:11:20.635: INFO: Creating new exec pod
Jul 10 09:11:20.647: INFO: Waiting up to 5m0s for pod "execpod-affinity4rtw4" in namespace "services-3976" to be "running"
Jul 10 09:11:20.652: INFO: Pod "execpod-affinity4rtw4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.202726ms
Jul 10 09:11:22.658: INFO: Pod "execpod-affinity4rtw4": Phase="Running", Reason="", readiness=true. Elapsed: 2.01052719s
Jul 10 09:11:22.658: INFO: Pod "execpod-affinity4rtw4" satisfied condition "running"
Jul 10 09:11:23.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Jul 10 09:11:23.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Jul 10 09:11:23.822: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 09:11:23.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.98.229 80'
Jul 10 09:11:23.954: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.98.229 80\nConnection to 192.168.98.229 80 port [tcp/http] succeeded!\n"
Jul 10 09:11:23.954: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 09:11:23.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 32646'
Jul 10 09:11:24.099: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 32646\nConnection to 10.62.109.101 32646 port [tcp/*] succeeded!\n"
Jul 10 09:11:24.099: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 09:11:24.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.102 32646'
Jul 10 09:11:24.246: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.102 32646\nConnection to 10.62.109.102 32646 port [tcp/*] succeeded!\n"
Jul 10 09:11:24.246: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul 10 09:11:24.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.62.109.100:32646/ ; done'
Jul 10 09:11:24.504: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n"
Jul 10 09:11:24.504: INFO: stdout: "\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-j7hzs"
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.62.109.100:32646/ ; done'
Jul 10 09:11:24.734: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n"
Jul 10 09:11:24.734: INFO: stdout: "\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs"
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
Jul 10 09:11:24.734: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3976, will wait for the garbage collector to delete the pods 07/10/23 09:11:24.773
Jul 10 09:11:24.845: INFO: Deleting ReplicationController affinity-nodeport-transition took: 10.995526ms
Jul 10 09:11:24.945: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.652332ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 09:11:27.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3976" for this suite. 07/10/23 09:11:27.613
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":275,"skipped":5141,"failed":0}
------------------------------
• [SLOW TEST] [10.152 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:17.475
    Jul 10 09:11:17.475: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 09:11:17.477
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:17.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:17.508
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2216
    STEP: creating service in namespace services-3976 07/10/23 09:11:17.511
    STEP: creating service affinity-nodeport-transition in namespace services-3976 07/10/23 09:11:17.511
    STEP: creating replication controller affinity-nodeport-transition in namespace services-3976 07/10/23 09:11:17.557
    I0710 09:11:17.568524      21 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3976, replica count: 3
    I0710 09:11:20.619517      21 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jul 10 09:11:20.635: INFO: Creating new exec pod
    Jul 10 09:11:20.647: INFO: Waiting up to 5m0s for pod "execpod-affinity4rtw4" in namespace "services-3976" to be "running"
    Jul 10 09:11:20.652: INFO: Pod "execpod-affinity4rtw4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.202726ms
    Jul 10 09:11:22.658: INFO: Pod "execpod-affinity4rtw4": Phase="Running", Reason="", readiness=true. Elapsed: 2.01052719s
    Jul 10 09:11:22.658: INFO: Pod "execpod-affinity4rtw4" satisfied condition "running"
    Jul 10 09:11:23.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Jul 10 09:11:23.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Jul 10 09:11:23.822: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 09:11:23.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.98.229 80'
    Jul 10 09:11:23.954: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.98.229 80\nConnection to 192.168.98.229 80 port [tcp/http] succeeded!\n"
    Jul 10 09:11:23.954: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 09:11:23.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.101 32646'
    Jul 10 09:11:24.099: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.101 32646\nConnection to 10.62.109.101 32646 port [tcp/*] succeeded!\n"
    Jul 10 09:11:24.099: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 09:11:24.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.62.109.102 32646'
    Jul 10 09:11:24.246: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.62.109.102 32646\nConnection to 10.62.109.102 32646 port [tcp/*] succeeded!\n"
    Jul 10 09:11:24.246: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jul 10 09:11:24.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.62.109.100:32646/ ; done'
    Jul 10 09:11:24.504: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n"
    Jul 10 09:11:24.504: INFO: stdout: "\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-2n4p5\naffinity-nodeport-transition-wfztc\naffinity-nodeport-transition-j7hzs"
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-2n4p5
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-wfztc
    Jul 10 09:11:24.504: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=services-3976 exec execpod-affinity4rtw4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.62.109.100:32646/ ; done'
    Jul 10 09:11:24.734: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.62.109.100:32646/\n"
    Jul 10 09:11:24.734: INFO: stdout: "\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs\naffinity-nodeport-transition-j7hzs"
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Received response from host: affinity-nodeport-transition-j7hzs
    Jul 10 09:11:24.734: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3976, will wait for the garbage collector to delete the pods 07/10/23 09:11:24.773
    Jul 10 09:11:24.845: INFO: Deleting ReplicationController affinity-nodeport-transition took: 10.995526ms
    Jul 10 09:11:24.945: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.652332ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 09:11:27.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3976" for this suite. 07/10/23 09:11:27.613
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:27.627
Jul 10 09:11:27.627: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename namespaces 07/10/23 09:11:27.628
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:27.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:27.655
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 07/10/23 09:11:27.658
STEP: patching the Namespace 07/10/23 09:11:27.685
STEP: get the Namespace and ensuring it has the label 07/10/23 09:11:27.704
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:11:27.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1087" for this suite. 07/10/23 09:11:27.722
STEP: Destroying namespace "nspatchtest-c8cc6b30-f493-4012-a831-798363b691a0-4590" for this suite. 07/10/23 09:11:27.741
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":276,"skipped":5147,"failed":0}
------------------------------
• [0.126 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:27.627
    Jul 10 09:11:27.627: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename namespaces 07/10/23 09:11:27.628
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:27.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:27.655
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 07/10/23 09:11:27.658
    STEP: patching the Namespace 07/10/23 09:11:27.685
    STEP: get the Namespace and ensuring it has the label 07/10/23 09:11:27.704
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:11:27.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1087" for this suite. 07/10/23 09:11:27.722
    STEP: Destroying namespace "nspatchtest-c8cc6b30-f493-4012-a831-798363b691a0-4590" for this suite. 07/10/23 09:11:27.741
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:27.753
Jul 10 09:11:27.754: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-runtime 07/10/23 09:11:27.755
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:27.783
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:27.786
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 07/10/23 09:11:27.789
STEP: wait for the container to reach Succeeded 07/10/23 09:11:27.8
STEP: get the container status 07/10/23 09:11:31.827
STEP: the container should be terminated 07/10/23 09:11:31.831
STEP: the termination message should be set 07/10/23 09:11:31.831
Jul 10 09:11:31.831: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 07/10/23 09:11:31.831
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jul 10 09:11:31.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5143" for this suite. 07/10/23 09:11:31.858
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":277,"skipped":5164,"failed":0}
------------------------------
• [4.114 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:27.753
    Jul 10 09:11:27.754: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-runtime 07/10/23 09:11:27.755
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:27.783
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:27.786
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 07/10/23 09:11:27.789
    STEP: wait for the container to reach Succeeded 07/10/23 09:11:27.8
    STEP: get the container status 07/10/23 09:11:31.827
    STEP: the container should be terminated 07/10/23 09:11:31.831
    STEP: the termination message should be set 07/10/23 09:11:31.831
    Jul 10 09:11:31.831: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 07/10/23 09:11:31.831
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jul 10 09:11:31.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5143" for this suite. 07/10/23 09:11:31.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:31.87
Jul 10 09:11:31.870: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename namespaces 07/10/23 09:11:31.871
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:31.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:31.901
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 07/10/23 09:11:31.904
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:31.934
STEP: Creating a service in the namespace 07/10/23 09:11:31.938
STEP: Deleting the namespace 07/10/23 09:11:31.971
STEP: Waiting for the namespace to be removed. 07/10/23 09:11:31.985
STEP: Recreating the namespace 07/10/23 09:11:37.991
STEP: Verifying there is no service in the namespace 07/10/23 09:11:38.052
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:11:38.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3727" for this suite. 07/10/23 09:11:38.061
STEP: Destroying namespace "nsdeletetest-4333" for this suite. 07/10/23 09:11:38.074
Jul 10 09:11:38.078: INFO: Namespace nsdeletetest-4333 was already deleted
STEP: Destroying namespace "nsdeletetest-9259" for this suite. 07/10/23 09:11:38.078
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":278,"skipped":5220,"failed":0}
------------------------------
• [SLOW TEST] [6.224 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:31.87
    Jul 10 09:11:31.870: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename namespaces 07/10/23 09:11:31.871
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:31.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:31.901
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 07/10/23 09:11:31.904
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:31.934
    STEP: Creating a service in the namespace 07/10/23 09:11:31.938
    STEP: Deleting the namespace 07/10/23 09:11:31.971
    STEP: Waiting for the namespace to be removed. 07/10/23 09:11:31.985
    STEP: Recreating the namespace 07/10/23 09:11:37.991
    STEP: Verifying there is no service in the namespace 07/10/23 09:11:38.052
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:11:38.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3727" for this suite. 07/10/23 09:11:38.061
    STEP: Destroying namespace "nsdeletetest-4333" for this suite. 07/10/23 09:11:38.074
    Jul 10 09:11:38.078: INFO: Namespace nsdeletetest-4333 was already deleted
    STEP: Destroying namespace "nsdeletetest-9259" for this suite. 07/10/23 09:11:38.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:38.096
Jul 10 09:11:38.096: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 09:11:38.097
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:38.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:38.125
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 09:11:38.128
Jul 10 09:11:38.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jul 10 09:11:38.216: INFO: stderr: ""
Jul 10 09:11:38.216: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 07/10/23 09:11:38.216
STEP: verifying the pod e2e-test-httpd-pod was created 07/10/23 09:11:43.269
Jul 10 09:11:43.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 get pod e2e-test-httpd-pod -o json'
Jul 10 09:11:43.344: INFO: stderr: ""
Jul 10 09:11:43.344: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"752f9e213551e5545d49f7447a826a4ecff3b90805fd710e1ae40c2c4e84c6ee\",\n            \"cni.projectcalico.org/podIP\": \"192.168.172.35/32\",\n            \"cni.projectcalico.org/podIPs\": \"192.168.172.35/32\"\n        },\n        \"creationTimestamp\": \"2023-07-10T09:11:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5605\",\n        \"resourceVersion\": \"102543\",\n        \"uid\": \"bddb0226-23ae-4085-8fba-256a7a5a8a6a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-gcqr2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10-62-109-100.test\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-gcqr2\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7abbbda1cbbbcb42d98e2b4b6383e9647a8ef495da8a93ab3f46c1ed041b3464\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-07-10T09:11:39Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.62.109.100\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.172.35\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.172.35\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-07-10T09:11:37Z\"\n    }\n}\n"
STEP: replace the image in the pod 07/10/23 09:11:43.344
Jul 10 09:11:43.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 replace -f -'
Jul 10 09:11:43.615: INFO: stderr: ""
Jul 10 09:11:43.615: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 07/10/23 09:11:43.615
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Jul 10 09:11:43.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 delete pods e2e-test-httpd-pod'
Jul 10 09:11:45.077: INFO: stderr: ""
Jul 10 09:11:45.077: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 09:11:45.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5605" for this suite. 07/10/23 09:11:45.083
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":279,"skipped":5243,"failed":0}
------------------------------
• [SLOW TEST] [6.997 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:38.096
    Jul 10 09:11:38.096: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 09:11:38.097
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:38.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:38.125
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 07/10/23 09:11:38.128
    Jul 10 09:11:38.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Jul 10 09:11:38.216: INFO: stderr: ""
    Jul 10 09:11:38.216: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 07/10/23 09:11:38.216
    STEP: verifying the pod e2e-test-httpd-pod was created 07/10/23 09:11:43.269
    Jul 10 09:11:43.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 get pod e2e-test-httpd-pod -o json'
    Jul 10 09:11:43.344: INFO: stderr: ""
    Jul 10 09:11:43.344: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"752f9e213551e5545d49f7447a826a4ecff3b90805fd710e1ae40c2c4e84c6ee\",\n            \"cni.projectcalico.org/podIP\": \"192.168.172.35/32\",\n            \"cni.projectcalico.org/podIPs\": \"192.168.172.35/32\"\n        },\n        \"creationTimestamp\": \"2023-07-10T09:11:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5605\",\n        \"resourceVersion\": \"102543\",\n        \"uid\": \"bddb0226-23ae-4085-8fba-256a7a5a8a6a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-gcqr2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10-62-109-100.test\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-gcqr2\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-07-10T09:11:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7abbbda1cbbbcb42d98e2b4b6383e9647a8ef495da8a93ab3f46c1ed041b3464\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-07-10T09:11:39Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.62.109.100\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.172.35\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.172.35\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-07-10T09:11:37Z\"\n    }\n}\n"
    STEP: replace the image in the pod 07/10/23 09:11:43.344
    Jul 10 09:11:43.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 replace -f -'
    Jul 10 09:11:43.615: INFO: stderr: ""
    Jul 10 09:11:43.615: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 07/10/23 09:11:43.615
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Jul 10 09:11:43.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-5605 delete pods e2e-test-httpd-pod'
    Jul 10 09:11:45.077: INFO: stderr: ""
    Jul 10 09:11:45.077: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 09:11:45.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5605" for this suite. 07/10/23 09:11:45.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:45.094
Jul 10 09:11:45.094: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename containers 07/10/23 09:11:45.095
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:45.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:45.139
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 07/10/23 09:11:45.143
Jul 10 09:11:45.155: INFO: Waiting up to 5m0s for pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120" in namespace "containers-1500" to be "Succeeded or Failed"
Jul 10 09:11:45.158: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884056ms
Jul 10 09:11:47.165: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010738121s
Jul 10 09:11:49.165: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009988492s
STEP: Saw pod success 07/10/23 09:11:49.165
Jul 10 09:11:49.165: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120" satisfied condition "Succeeded or Failed"
Jul 10 09:11:49.171: INFO: Trying to get logs from node 10-62-109-100.test pod client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 09:11:49.183
Jul 10 09:11:49.213: INFO: Waiting for pod client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120 to disappear
Jul 10 09:11:49.218: INFO: Pod client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jul 10 09:11:49.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1500" for this suite. 07/10/23 09:11:49.229
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":280,"skipped":5250,"failed":0}
------------------------------
• [4.148 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:45.094
    Jul 10 09:11:45.094: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename containers 07/10/23 09:11:45.095
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:45.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:45.139
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 07/10/23 09:11:45.143
    Jul 10 09:11:45.155: INFO: Waiting up to 5m0s for pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120" in namespace "containers-1500" to be "Succeeded or Failed"
    Jul 10 09:11:45.158: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884056ms
    Jul 10 09:11:47.165: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010738121s
    Jul 10 09:11:49.165: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009988492s
    STEP: Saw pod success 07/10/23 09:11:49.165
    Jul 10 09:11:49.165: INFO: Pod "client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120" satisfied condition "Succeeded or Failed"
    Jul 10 09:11:49.171: INFO: Trying to get logs from node 10-62-109-100.test pod client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 09:11:49.183
    Jul 10 09:11:49.213: INFO: Waiting for pod client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120 to disappear
    Jul 10 09:11:49.218: INFO: Pod client-containers-99d56ef7-00bf-4544-860f-a16f6ab2b120 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jul 10 09:11:49.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1500" for this suite. 07/10/23 09:11:49.229
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:49.244
Jul 10 09:11:49.244: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename disruption 07/10/23 09:11:49.245
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:49.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:49.28
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 07/10/23 09:11:49.34
STEP: Waiting for all pods to be running 07/10/23 09:11:49.403
Jul 10 09:11:49.407: INFO: running pods: 0 < 3
Jul 10 09:11:51.413: INFO: running pods: 2 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jul 10 09:11:53.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1776" for this suite. 07/10/23 09:11:53.424
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":281,"skipped":5274,"failed":0}
------------------------------
• [4.194 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:49.244
    Jul 10 09:11:49.244: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename disruption 07/10/23 09:11:49.245
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:49.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:49.28
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 07/10/23 09:11:49.34
    STEP: Waiting for all pods to be running 07/10/23 09:11:49.403
    Jul 10 09:11:49.407: INFO: running pods: 0 < 3
    Jul 10 09:11:51.413: INFO: running pods: 2 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jul 10 09:11:53.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1776" for this suite. 07/10/23 09:11:53.424
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:11:53.438
Jul 10 09:11:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 09:11:53.44
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:53.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:53.467
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Jul 10 09:11:53.498: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 07/10/23 09:11:53.508
Jul 10 09:11:53.512: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:53.512: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 07/10/23 09:11:53.512
Jul 10 09:11:53.560: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:53.560: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:11:54.565: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:54.565: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:11:55.566: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:55.566: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:11:56.565: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul 10 09:11:56.566: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 07/10/23 09:11:56.57
Jul 10 09:11:56.601: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul 10 09:11:56.601: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Jul 10 09:11:57.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:57.607: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 07/10/23 09:11:57.607
Jul 10 09:11:57.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:57.640: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:11:58.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:58.646: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:11:59.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:11:59.646: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:12:00.649: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:12:00.649: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:12:01.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul 10 09:12:01.646: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:12:01.655
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9089, will wait for the garbage collector to delete the pods 07/10/23 09:12:01.655
Jul 10 09:12:01.725: INFO: Deleting DaemonSet.extensions daemon-set took: 15.699359ms
Jul 10 09:12:01.826: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.971615ms
Jul 10 09:12:04.370: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:12:04.370: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul 10 09:12:04.374: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"102814"},"items":null}

Jul 10 09:12:04.378: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"102814"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:12:04.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9089" for this suite. 07/10/23 09:12:04.418
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":282,"skipped":5275,"failed":0}
------------------------------
• [SLOW TEST] [10.995 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:11:53.438
    Jul 10 09:11:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 09:11:53.44
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:11:53.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:11:53.467
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Jul 10 09:11:53.498: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 07/10/23 09:11:53.508
    Jul 10 09:11:53.512: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:53.512: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 07/10/23 09:11:53.512
    Jul 10 09:11:53.560: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:53.560: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:11:54.565: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:54.565: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:11:55.566: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:55.566: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:11:56.565: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jul 10 09:11:56.566: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 07/10/23 09:11:56.57
    Jul 10 09:11:56.601: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jul 10 09:11:56.601: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Jul 10 09:11:57.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:57.607: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 07/10/23 09:11:57.607
    Jul 10 09:11:57.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:57.640: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:11:58.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:58.646: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:11:59.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:11:59.646: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:12:00.649: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:12:00.649: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:12:01.646: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jul 10 09:12:01.646: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:12:01.655
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9089, will wait for the garbage collector to delete the pods 07/10/23 09:12:01.655
    Jul 10 09:12:01.725: INFO: Deleting DaemonSet.extensions daemon-set took: 15.699359ms
    Jul 10 09:12:01.826: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.971615ms
    Jul 10 09:12:04.370: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:12:04.370: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jul 10 09:12:04.374: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"102814"},"items":null}

    Jul 10 09:12:04.378: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"102814"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:12:04.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9089" for this suite. 07/10/23 09:12:04.418
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:04.435
Jul 10 09:12:04.435: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 09:12:04.436
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:04.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:04.472
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 09:12:04.494
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:12:05.324
STEP: Deploying the webhook pod 07/10/23 09:12:05.341
STEP: Wait for the deployment to be ready 07/10/23 09:12:05.359
Jul 10 09:12:05.373: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 07/10/23 09:12:07.388
STEP: Verifying the service has paired with the endpoint 07/10/23 09:12:07.412
Jul 10 09:12:08.412: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Jul 10 09:12:08.418: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Registering the custom resource webhook via the AdmissionRegistration API 07/10/23 09:12:08.932
STEP: Creating a custom resource that should be denied by the webhook 07/10/23 09:12:08.954
STEP: Creating a custom resource whose deletion would be denied by the webhook 07/10/23 09:12:10.991
STEP: Updating the custom resource with disallowed data should be denied 07/10/23 09:12:11.016
STEP: Deleting the custom resource should be denied 07/10/23 09:12:11.029
STEP: Remove the offending key and value from the custom resource data 07/10/23 09:12:11.038
STEP: Deleting the updated custom resource should be successful 07/10/23 09:12:11.051
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:12:11.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3079" for this suite. 07/10/23 09:12:11.604
STEP: Destroying namespace "webhook-3079-markers" for this suite. 07/10/23 09:12:11.621
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":283,"skipped":5295,"failed":0}
------------------------------
• [SLOW TEST] [7.292 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:04.435
    Jul 10 09:12:04.435: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 09:12:04.436
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:04.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:04.472
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 09:12:04.494
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:12:05.324
    STEP: Deploying the webhook pod 07/10/23 09:12:05.341
    STEP: Wait for the deployment to be ready 07/10/23 09:12:05.359
    Jul 10 09:12:05.373: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 07/10/23 09:12:07.388
    STEP: Verifying the service has paired with the endpoint 07/10/23 09:12:07.412
    Jul 10 09:12:08.412: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Jul 10 09:12:08.418: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 07/10/23 09:12:08.932
    STEP: Creating a custom resource that should be denied by the webhook 07/10/23 09:12:08.954
    STEP: Creating a custom resource whose deletion would be denied by the webhook 07/10/23 09:12:10.991
    STEP: Updating the custom resource with disallowed data should be denied 07/10/23 09:12:11.016
    STEP: Deleting the custom resource should be denied 07/10/23 09:12:11.029
    STEP: Remove the offending key and value from the custom resource data 07/10/23 09:12:11.038
    STEP: Deleting the updated custom resource should be successful 07/10/23 09:12:11.051
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:12:11.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3079" for this suite. 07/10/23 09:12:11.604
    STEP: Destroying namespace "webhook-3079-markers" for this suite. 07/10/23 09:12:11.621
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:11.734
Jul 10 09:12:11.734: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 09:12:11.735
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:11.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:11.771
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 07/10/23 09:12:11.778
Jul 10 09:12:11.789: INFO: Waiting up to 5m0s for pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293" in namespace "emptydir-1394" to be "Succeeded or Failed"
Jul 10 09:12:11.797: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021689ms
Jul 10 09:12:13.805: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016004825s
Jul 10 09:12:15.802: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013599592s
STEP: Saw pod success 07/10/23 09:12:15.802
Jul 10 09:12:15.803: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293" satisfied condition "Succeeded or Failed"
Jul 10 09:12:15.816: INFO: Trying to get logs from node 10-62-109-100.test pod pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293 container test-container: <nil>
STEP: delete the pod 07/10/23 09:12:15.828
Jul 10 09:12:15.861: INFO: Waiting for pod pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293 to disappear
Jul 10 09:12:15.866: INFO: Pod pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 09:12:15.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1394" for this suite. 07/10/23 09:12:15.872
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":284,"skipped":5325,"failed":0}
------------------------------
• [4.149 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:11.734
    Jul 10 09:12:11.734: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 09:12:11.735
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:11.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:11.771
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 07/10/23 09:12:11.778
    Jul 10 09:12:11.789: INFO: Waiting up to 5m0s for pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293" in namespace "emptydir-1394" to be "Succeeded or Failed"
    Jul 10 09:12:11.797: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021689ms
    Jul 10 09:12:13.805: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016004825s
    Jul 10 09:12:15.802: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013599592s
    STEP: Saw pod success 07/10/23 09:12:15.802
    Jul 10 09:12:15.803: INFO: Pod "pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293" satisfied condition "Succeeded or Failed"
    Jul 10 09:12:15.816: INFO: Trying to get logs from node 10-62-109-100.test pod pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293 container test-container: <nil>
    STEP: delete the pod 07/10/23 09:12:15.828
    Jul 10 09:12:15.861: INFO: Waiting for pod pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293 to disappear
    Jul 10 09:12:15.866: INFO: Pod pod-c45e058c-d9ed-4d25-8e2e-cc887eb5f293 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 09:12:15.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1394" for this suite. 07/10/23 09:12:15.872
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:15.883
Jul 10 09:12:15.883: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename dns 07/10/23 09:12:15.884
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:15.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:15.915
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9462.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9462.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 07/10/23 09:12:15.918
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9462.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9462.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 07/10/23 09:12:15.919
STEP: creating a pod to probe /etc/hosts 07/10/23 09:12:15.919
STEP: submitting the pod to kubernetes 07/10/23 09:12:15.919
Jul 10 09:12:15.934: INFO: Waiting up to 15m0s for pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e" in namespace "dns-9462" to be "running"
Jul 10 09:12:15.954: INFO: Pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.593331ms
Jul 10 09:12:17.962: INFO: Pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e": Phase="Running", Reason="", readiness=true. Elapsed: 2.027734146s
Jul 10 09:12:17.962: INFO: Pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e" satisfied condition "running"
STEP: retrieving the pod 07/10/23 09:12:17.962
STEP: looking for the results for each expected name from probers 07/10/23 09:12:17.967
Jul 10 09:12:17.986: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-9462/dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e: the server could not find the requested resource (get pods dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e)
Jul 10 09:12:17.986: INFO: Lookups using dns-9462/dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e failed for: [jessie_hosts@dns-querier-1]

Jul 10 09:12:23.005: INFO: DNS probes using dns-9462/dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e succeeded

STEP: deleting the pod 07/10/23 09:12:23.005
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jul 10 09:12:23.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9462" for this suite. 07/10/23 09:12:23.072
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":285,"skipped":5326,"failed":0}
------------------------------
• [SLOW TEST] [7.209 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:15.883
    Jul 10 09:12:15.883: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename dns 07/10/23 09:12:15.884
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:15.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:15.915
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9462.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9462.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     07/10/23 09:12:15.918
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9462.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9462.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     07/10/23 09:12:15.919
    STEP: creating a pod to probe /etc/hosts 07/10/23 09:12:15.919
    STEP: submitting the pod to kubernetes 07/10/23 09:12:15.919
    Jul 10 09:12:15.934: INFO: Waiting up to 15m0s for pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e" in namespace "dns-9462" to be "running"
    Jul 10 09:12:15.954: INFO: Pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.593331ms
    Jul 10 09:12:17.962: INFO: Pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e": Phase="Running", Reason="", readiness=true. Elapsed: 2.027734146s
    Jul 10 09:12:17.962: INFO: Pod "dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e" satisfied condition "running"
    STEP: retrieving the pod 07/10/23 09:12:17.962
    STEP: looking for the results for each expected name from probers 07/10/23 09:12:17.967
    Jul 10 09:12:17.986: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-9462/dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e: the server could not find the requested resource (get pods dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e)
    Jul 10 09:12:17.986: INFO: Lookups using dns-9462/dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e failed for: [jessie_hosts@dns-querier-1]

    Jul 10 09:12:23.005: INFO: DNS probes using dns-9462/dns-test-9ed15fb9-63b4-409b-a191-67c8e716da1e succeeded

    STEP: deleting the pod 07/10/23 09:12:23.005
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jul 10 09:12:23.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9462" for this suite. 07/10/23 09:12:23.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:23.094
Jul 10 09:12:23.094: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 09:12:23.096
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:23.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:23.13
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 07/10/23 09:12:23.133
STEP: Creating a ResourceQuota 07/10/23 09:12:28.142
STEP: Ensuring resource quota status is calculated 07/10/23 09:12:28.16
STEP: Creating a ReplicaSet 07/10/23 09:12:30.168
STEP: Ensuring resource quota status captures replicaset creation 07/10/23 09:12:30.193
STEP: Deleting a ReplicaSet 07/10/23 09:12:32.2
STEP: Ensuring resource quota status released usage 07/10/23 09:12:32.21
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 09:12:34.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-131" for this suite. 07/10/23 09:12:34.23
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":286,"skipped":5354,"failed":0}
------------------------------
• [SLOW TEST] [11.150 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:23.094
    Jul 10 09:12:23.094: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 09:12:23.096
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:23.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:23.13
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 07/10/23 09:12:23.133
    STEP: Creating a ResourceQuota 07/10/23 09:12:28.142
    STEP: Ensuring resource quota status is calculated 07/10/23 09:12:28.16
    STEP: Creating a ReplicaSet 07/10/23 09:12:30.168
    STEP: Ensuring resource quota status captures replicaset creation 07/10/23 09:12:30.193
    STEP: Deleting a ReplicaSet 07/10/23 09:12:32.2
    STEP: Ensuring resource quota status released usage 07/10/23 09:12:32.21
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 09:12:34.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-131" for this suite. 07/10/23 09:12:34.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:34.246
Jul 10 09:12:34.247: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 09:12:34.248
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:34.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:34.278
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:12:34.281
Jul 10 09:12:34.295: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3" in namespace "projected-1832" to be "Succeeded or Failed"
Jul 10 09:12:34.300: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.054822ms
Jul 10 09:12:36.307: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011422589s
Jul 10 09:12:38.307: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011245827s
STEP: Saw pod success 07/10/23 09:12:38.307
Jul 10 09:12:38.307: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3" satisfied condition "Succeeded or Failed"
Jul 10 09:12:38.312: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3 container client-container: <nil>
STEP: delete the pod 07/10/23 09:12:38.323
Jul 10 09:12:38.345: INFO: Waiting for pod downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3 to disappear
Jul 10 09:12:38.349: INFO: Pod downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 09:12:38.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1832" for this suite. 07/10/23 09:12:38.354
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":287,"skipped":5380,"failed":0}
------------------------------
• [4.131 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:34.246
    Jul 10 09:12:34.247: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 09:12:34.248
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:34.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:34.278
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:12:34.281
    Jul 10 09:12:34.295: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3" in namespace "projected-1832" to be "Succeeded or Failed"
    Jul 10 09:12:34.300: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.054822ms
    Jul 10 09:12:36.307: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011422589s
    Jul 10 09:12:38.307: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011245827s
    STEP: Saw pod success 07/10/23 09:12:38.307
    Jul 10 09:12:38.307: INFO: Pod "downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3" satisfied condition "Succeeded or Failed"
    Jul 10 09:12:38.312: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3 container client-container: <nil>
    STEP: delete the pod 07/10/23 09:12:38.323
    Jul 10 09:12:38.345: INFO: Waiting for pod downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3 to disappear
    Jul 10 09:12:38.349: INFO: Pod downwardapi-volume-6120e5c4-4a63-493a-9ce4-f13fb41684d3 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 09:12:38.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1832" for this suite. 07/10/23 09:12:38.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:38.379
Jul 10 09:12:38.379: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename job 07/10/23 09:12:38.38
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:38.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:38.413
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 07/10/23 09:12:38.415
STEP: Ensuring job reaches completions 07/10/23 09:12:38.433
STEP: Ensuring pods with index for job exist 07/10/23 09:12:46.441
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jul 10 09:12:46.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1428" for this suite. 07/10/23 09:12:46.463
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":288,"skipped":5402,"failed":0}
------------------------------
• [SLOW TEST] [8.100 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:38.379
    Jul 10 09:12:38.379: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename job 07/10/23 09:12:38.38
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:38.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:38.413
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 07/10/23 09:12:38.415
    STEP: Ensuring job reaches completions 07/10/23 09:12:38.433
    STEP: Ensuring pods with index for job exist 07/10/23 09:12:46.441
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jul 10 09:12:46.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1428" for this suite. 07/10/23 09:12:46.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:46.481
Jul 10 09:12:46.481: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:12:46.483
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:46.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:46.522
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:12:46.525
Jul 10 09:12:46.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284" in namespace "downward-api-5087" to be "Succeeded or Failed"
Jul 10 09:12:46.546: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284": Phase="Pending", Reason="", readiness=false. Elapsed: 4.478083ms
Jul 10 09:12:48.552: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011215271s
Jul 10 09:12:50.551: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010275969s
STEP: Saw pod success 07/10/23 09:12:50.551
Jul 10 09:12:50.552: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284" satisfied condition "Succeeded or Failed"
Jul 10 09:12:50.557: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284 container client-container: <nil>
STEP: delete the pod 07/10/23 09:12:50.568
Jul 10 09:12:50.609: INFO: Waiting for pod downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284 to disappear
Jul 10 09:12:50.613: INFO: Pod downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 09:12:50.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5087" for this suite. 07/10/23 09:12:50.618
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":289,"skipped":5435,"failed":0}
------------------------------
• [4.146 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:46.481
    Jul 10 09:12:46.481: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:12:46.483
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:46.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:46.522
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:12:46.525
    Jul 10 09:12:46.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284" in namespace "downward-api-5087" to be "Succeeded or Failed"
    Jul 10 09:12:46.546: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284": Phase="Pending", Reason="", readiness=false. Elapsed: 4.478083ms
    Jul 10 09:12:48.552: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011215271s
    Jul 10 09:12:50.551: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010275969s
    STEP: Saw pod success 07/10/23 09:12:50.551
    Jul 10 09:12:50.552: INFO: Pod "downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284" satisfied condition "Succeeded or Failed"
    Jul 10 09:12:50.557: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284 container client-container: <nil>
    STEP: delete the pod 07/10/23 09:12:50.568
    Jul 10 09:12:50.609: INFO: Waiting for pod downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284 to disappear
    Jul 10 09:12:50.613: INFO: Pod downwardapi-volume-c71d7e88-a7e0-4b90-b3a8-ee62a5807284 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 09:12:50.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5087" for this suite. 07/10/23 09:12:50.618
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:12:50.629
Jul 10 09:12:50.629: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename watch 07/10/23 09:12:50.63
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:50.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:50.668
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 07/10/23 09:12:50.67
STEP: creating a new configmap 07/10/23 09:12:50.672
STEP: modifying the configmap once 07/10/23 09:12:50.685
STEP: changing the label value of the configmap 07/10/23 09:12:50.698
STEP: Expecting to observe a delete notification for the watched object 07/10/23 09:12:50.713
Jul 10 09:12:50.713: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103253 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:12:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 09:12:50.713: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103254 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:12:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 09:12:50.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103255 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:12:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 07/10/23 09:12:50.714
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 07/10/23 09:12:50.733
STEP: changing the label value of the configmap back 07/10/23 09:13:00.733
STEP: modifying the configmap a third time 07/10/23 09:13:00.748
STEP: deleting the configmap 07/10/23 09:13:00.759
STEP: Expecting to observe an add notification for the watched object when the label value was restored 07/10/23 09:13:00.769
Jul 10 09:13:00.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103322 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 09:13:00.770: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103323 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 09:13:00.770: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103324 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jul 10 09:13:00.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4032" for this suite. 07/10/23 09:13:00.775
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":290,"skipped":5437,"failed":0}
------------------------------
• [SLOW TEST] [10.157 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:12:50.629
    Jul 10 09:12:50.629: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename watch 07/10/23 09:12:50.63
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:12:50.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:12:50.668
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 07/10/23 09:12:50.67
    STEP: creating a new configmap 07/10/23 09:12:50.672
    STEP: modifying the configmap once 07/10/23 09:12:50.685
    STEP: changing the label value of the configmap 07/10/23 09:12:50.698
    STEP: Expecting to observe a delete notification for the watched object 07/10/23 09:12:50.713
    Jul 10 09:12:50.713: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103253 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:12:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 09:12:50.713: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103254 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:12:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 09:12:50.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103255 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:12:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 07/10/23 09:12:50.714
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 07/10/23 09:12:50.733
    STEP: changing the label value of the configmap back 07/10/23 09:13:00.733
    STEP: modifying the configmap a third time 07/10/23 09:13:00.748
    STEP: deleting the configmap 07/10/23 09:13:00.759
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 07/10/23 09:13:00.769
    Jul 10 09:13:00.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103322 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 09:13:00.770: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103323 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 09:13:00.770: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4032  0ecf9894-6561-4d3e-a810-3b557957524a 103324 0 2023-07-10 09:12:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-07-10 09:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jul 10 09:13:00.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4032" for this suite. 07/10/23 09:13:00.775
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:13:00.787
Jul 10 09:13:00.787: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 09:13:00.788
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:00.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:00.817
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 07/10/23 09:13:00.82
STEP: listing secrets in all namespaces to ensure that there are more than zero 07/10/23 09:13:00.827
STEP: patching the secret 07/10/23 09:13:00.831
STEP: deleting the secret using a LabelSelector 07/10/23 09:13:00.845
STEP: listing secrets in all namespaces, searching for label name and value in patch 07/10/23 09:13:00.86
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jul 10 09:13:00.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9426" for this suite. 07/10/23 09:13:00.877
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":291,"skipped":5437,"failed":0}
------------------------------
• [0.101 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:13:00.787
    Jul 10 09:13:00.787: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 09:13:00.788
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:00.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:00.817
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 07/10/23 09:13:00.82
    STEP: listing secrets in all namespaces to ensure that there are more than zero 07/10/23 09:13:00.827
    STEP: patching the secret 07/10/23 09:13:00.831
    STEP: deleting the secret using a LabelSelector 07/10/23 09:13:00.845
    STEP: listing secrets in all namespaces, searching for label name and value in patch 07/10/23 09:13:00.86
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 09:13:00.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9426" for this suite. 07/10/23 09:13:00.877
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:13:00.888
Jul 10 09:13:00.888: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename proxy 07/10/23 09:13:00.889
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:00.918
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:00.921
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Jul 10 09:13:00.924: INFO: Creating pod...
Jul 10 09:13:00.942: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1386" to be "running"
Jul 10 09:13:00.949: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 7.404719ms
Jul 10 09:13:02.955: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.01357026s
Jul 10 09:13:02.956: INFO: Pod "agnhost" satisfied condition "running"
Jul 10 09:13:02.956: INFO: Creating service...
Jul 10 09:13:02.975: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/DELETE
Jul 10 09:13:02.983: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul 10 09:13:02.983: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/GET
Jul 10 09:13:02.997: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jul 10 09:13:02.997: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/HEAD
Jul 10 09:13:03.001: INFO: http.Client request:HEAD | StatusCode:200
Jul 10 09:13:03.001: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/OPTIONS
Jul 10 09:13:03.005: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul 10 09:13:03.005: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/PATCH
Jul 10 09:13:03.009: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul 10 09:13:03.009: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/POST
Jul 10 09:13:03.012: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul 10 09:13:03.012: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/PUT
Jul 10 09:13:03.018: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul 10 09:13:03.018: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/DELETE
Jul 10 09:13:03.032: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul 10 09:13:03.032: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/GET
Jul 10 09:13:03.038: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jul 10 09:13:03.038: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/HEAD
Jul 10 09:13:03.044: INFO: http.Client request:HEAD | StatusCode:200
Jul 10 09:13:03.044: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/OPTIONS
Jul 10 09:13:03.053: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul 10 09:13:03.053: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/PATCH
Jul 10 09:13:03.059: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul 10 09:13:03.059: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/POST
Jul 10 09:13:03.064: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul 10 09:13:03.064: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/PUT
Jul 10 09:13:03.071: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jul 10 09:13:03.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1386" for this suite. 07/10/23 09:13:03.078
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":292,"skipped":5439,"failed":0}
------------------------------
• [2.209 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:13:00.888
    Jul 10 09:13:00.888: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename proxy 07/10/23 09:13:00.889
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:00.918
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:00.921
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Jul 10 09:13:00.924: INFO: Creating pod...
    Jul 10 09:13:00.942: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1386" to be "running"
    Jul 10 09:13:00.949: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 7.404719ms
    Jul 10 09:13:02.955: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.01357026s
    Jul 10 09:13:02.956: INFO: Pod "agnhost" satisfied condition "running"
    Jul 10 09:13:02.956: INFO: Creating service...
    Jul 10 09:13:02.975: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/DELETE
    Jul 10 09:13:02.983: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jul 10 09:13:02.983: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/GET
    Jul 10 09:13:02.997: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Jul 10 09:13:02.997: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/HEAD
    Jul 10 09:13:03.001: INFO: http.Client request:HEAD | StatusCode:200
    Jul 10 09:13:03.001: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/OPTIONS
    Jul 10 09:13:03.005: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jul 10 09:13:03.005: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/PATCH
    Jul 10 09:13:03.009: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jul 10 09:13:03.009: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/POST
    Jul 10 09:13:03.012: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jul 10 09:13:03.012: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/pods/agnhost/proxy/some/path/with/PUT
    Jul 10 09:13:03.018: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jul 10 09:13:03.018: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/DELETE
    Jul 10 09:13:03.032: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jul 10 09:13:03.032: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/GET
    Jul 10 09:13:03.038: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Jul 10 09:13:03.038: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/HEAD
    Jul 10 09:13:03.044: INFO: http.Client request:HEAD | StatusCode:200
    Jul 10 09:13:03.044: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/OPTIONS
    Jul 10 09:13:03.053: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jul 10 09:13:03.053: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/PATCH
    Jul 10 09:13:03.059: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jul 10 09:13:03.059: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/POST
    Jul 10 09:13:03.064: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jul 10 09:13:03.064: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-1386/services/test-service/proxy/some/path/with/PUT
    Jul 10 09:13:03.071: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jul 10 09:13:03.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1386" for this suite. 07/10/23 09:13:03.078
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:13:03.097
Jul 10 09:13:03.098: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 09:13:03.099
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:03.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:03.135
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Jul 10 09:13:03.138: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:13:04.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3737" for this suite. 07/10/23 09:13:04.188
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":293,"skipped":5440,"failed":0}
------------------------------
• [1.103 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:13:03.097
    Jul 10 09:13:03.098: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 09:13:03.099
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:03.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:03.135
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Jul 10 09:13:03.138: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:13:04.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3737" for this suite. 07/10/23 09:13:04.188
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:13:04.201
Jul 10 09:13:04.201: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename taint-single-pod 07/10/23 09:13:04.202
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:04.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:04.232
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Jul 10 09:13:04.235: INFO: Waiting up to 1m0s for all nodes to be ready
Jul 10 09:14:04.268: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Jul 10 09:14:04.276: INFO: Starting informer...
STEP: Starting pod... 07/10/23 09:14:04.276
Jul 10 09:14:04.506: INFO: Pod is running on 10-62-109-100.test. Tainting Node
STEP: Trying to apply a taint on the Node 07/10/23 09:14:04.506
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:14:04.527
STEP: Waiting short time to make sure Pod is queued for deletion 07/10/23 09:14:04.537
Jul 10 09:14:04.537: INFO: Pod wasn't evicted. Proceeding
Jul 10 09:14:04.537: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:14:04.561
STEP: Waiting some time to make sure that toleration time passed. 07/10/23 09:14:04.575
Jul 10 09:15:19.576: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:15:19.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8111" for this suite. 07/10/23 09:15:19.583
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":294,"skipped":5444,"failed":0}
------------------------------
• [SLOW TEST] [135.393 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:13:04.201
    Jul 10 09:13:04.201: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename taint-single-pod 07/10/23 09:13:04.202
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:13:04.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:13:04.232
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Jul 10 09:13:04.235: INFO: Waiting up to 1m0s for all nodes to be ready
    Jul 10 09:14:04.268: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Jul 10 09:14:04.276: INFO: Starting informer...
    STEP: Starting pod... 07/10/23 09:14:04.276
    Jul 10 09:14:04.506: INFO: Pod is running on 10-62-109-100.test. Tainting Node
    STEP: Trying to apply a taint on the Node 07/10/23 09:14:04.506
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:14:04.527
    STEP: Waiting short time to make sure Pod is queued for deletion 07/10/23 09:14:04.537
    Jul 10 09:14:04.537: INFO: Pod wasn't evicted. Proceeding
    Jul 10 09:14:04.537: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:14:04.561
    STEP: Waiting some time to make sure that toleration time passed. 07/10/23 09:14:04.575
    Jul 10 09:15:19.576: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:15:19.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-8111" for this suite. 07/10/23 09:15:19.583
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:19.596
Jul 10 09:15:19.596: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 09:15:19.597
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:19.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:19.632
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Jul 10 09:15:19.662: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:15:19.675
Jul 10 09:15:19.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:15:19.688: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:15:20.708: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:15:20.708: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:15:21.699: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:15:21.699: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 07/10/23 09:15:21.715
STEP: Check that daemon pods images are updated. 07/10/23 09:15:21.729
Jul 10 09:15:21.740: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:21.740: INFO: Wrong image for pod: daemon-set-bzn4b. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:21.740: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:22.753: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:22.753: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:23.752: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:23.752: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:24.751: INFO: Pod daemon-set-28kvf is not available
Jul 10 09:15:24.751: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:24.751: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:25.753: INFO: Pod daemon-set-28kvf is not available
Jul 10 09:15:25.753: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:25.753: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:26.752: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:27.752: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:28.754: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:28.754: INFO: Pod daemon-set-sgtgk is not available
Jul 10 09:15:29.753: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jul 10 09:15:29.753: INFO: Pod daemon-set-sgtgk is not available
Jul 10 09:15:31.753: INFO: Pod daemon-set-24ttr is not available
STEP: Check that daemon pods are still running on every node of the cluster. 07/10/23 09:15:31.758
Jul 10 09:15:31.768: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:15:31.768: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:15:32.779: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:15:32.779: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:15:33.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:15:33.778: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:15:33.8
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8892, will wait for the garbage collector to delete the pods 07/10/23 09:15:33.8
Jul 10 09:15:33.866: INFO: Deleting DaemonSet.extensions daemon-set took: 11.289907ms
Jul 10 09:15:33.967: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.023306ms
Jul 10 09:15:36.472: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:15:36.473: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul 10 09:15:36.476: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"104045"},"items":null}

Jul 10 09:15:36.480: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"104045"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:15:36.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8892" for this suite. 07/10/23 09:15:36.555
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":295,"skipped":5484,"failed":0}
------------------------------
• [SLOW TEST] [16.969 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:19.596
    Jul 10 09:15:19.596: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 09:15:19.597
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:19.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:19.632
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Jul 10 09:15:19.662: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:15:19.675
    Jul 10 09:15:19.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:15:19.688: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:15:20.708: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:15:20.708: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:15:21.699: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:15:21.699: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 07/10/23 09:15:21.715
    STEP: Check that daemon pods images are updated. 07/10/23 09:15:21.729
    Jul 10 09:15:21.740: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:21.740: INFO: Wrong image for pod: daemon-set-bzn4b. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:21.740: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:22.753: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:22.753: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:23.752: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:23.752: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:24.751: INFO: Pod daemon-set-28kvf is not available
    Jul 10 09:15:24.751: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:24.751: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:25.753: INFO: Pod daemon-set-28kvf is not available
    Jul 10 09:15:25.753: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:25.753: INFO: Wrong image for pod: daemon-set-z9hbk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:26.752: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:27.752: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:28.754: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:28.754: INFO: Pod daemon-set-sgtgk is not available
    Jul 10 09:15:29.753: INFO: Wrong image for pod: daemon-set-742hr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jul 10 09:15:29.753: INFO: Pod daemon-set-sgtgk is not available
    Jul 10 09:15:31.753: INFO: Pod daemon-set-24ttr is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 07/10/23 09:15:31.758
    Jul 10 09:15:31.768: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:15:31.768: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:15:32.779: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:15:32.779: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:15:33.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:15:33.778: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:15:33.8
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8892, will wait for the garbage collector to delete the pods 07/10/23 09:15:33.8
    Jul 10 09:15:33.866: INFO: Deleting DaemonSet.extensions daemon-set took: 11.289907ms
    Jul 10 09:15:33.967: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.023306ms
    Jul 10 09:15:36.472: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:15:36.473: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jul 10 09:15:36.476: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"104045"},"items":null}

    Jul 10 09:15:36.480: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"104045"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:15:36.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8892" for this suite. 07/10/23 09:15:36.555
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:36.566
Jul 10 09:15:36.566: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:15:36.567
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:36.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:36.607
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-ed6a7aca-c435-4a17-8076-e4deb68107d1 07/10/23 09:15:36.611
STEP: Creating a pod to test consume configMaps 07/10/23 09:15:36.62
Jul 10 09:15:36.634: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba" in namespace "configmap-4831" to be "Succeeded or Failed"
Jul 10 09:15:36.639: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.471334ms
Jul 10 09:15:38.646: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011381807s
Jul 10 09:15:40.645: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010698363s
STEP: Saw pod success 07/10/23 09:15:40.645
Jul 10 09:15:40.645: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba" satisfied condition "Succeeded or Failed"
Jul 10 09:15:40.650: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba container agnhost-container: <nil>
STEP: delete the pod 07/10/23 09:15:40.664
Jul 10 09:15:40.687: INFO: Waiting for pod pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba to disappear
Jul 10 09:15:40.691: INFO: Pod pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:15:40.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4831" for this suite. 07/10/23 09:15:40.697
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":296,"skipped":5491,"failed":0}
------------------------------
• [4.141 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:36.566
    Jul 10 09:15:36.566: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:15:36.567
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:36.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:36.607
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-ed6a7aca-c435-4a17-8076-e4deb68107d1 07/10/23 09:15:36.611
    STEP: Creating a pod to test consume configMaps 07/10/23 09:15:36.62
    Jul 10 09:15:36.634: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba" in namespace "configmap-4831" to be "Succeeded or Failed"
    Jul 10 09:15:36.639: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.471334ms
    Jul 10 09:15:38.646: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011381807s
    Jul 10 09:15:40.645: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010698363s
    STEP: Saw pod success 07/10/23 09:15:40.645
    Jul 10 09:15:40.645: INFO: Pod "pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba" satisfied condition "Succeeded or Failed"
    Jul 10 09:15:40.650: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 09:15:40.664
    Jul 10 09:15:40.687: INFO: Waiting for pod pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba to disappear
    Jul 10 09:15:40.691: INFO: Pod pod-configmaps-cb60182a-3e51-4cb9-93ec-d7fede7c6fba no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:15:40.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4831" for this suite. 07/10/23 09:15:40.697
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:40.71
Jul 10 09:15:40.710: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 09:15:40.711
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:40.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:40.738
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Jul 10 09:15:40.746: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:15:41.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1969" for this suite. 07/10/23 09:15:41.334
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":297,"skipped":5539,"failed":0}
------------------------------
• [0.635 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:40.71
    Jul 10 09:15:40.710: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename custom-resource-definition 07/10/23 09:15:40.711
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:40.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:40.738
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Jul 10 09:15:40.746: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:15:41.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1969" for this suite. 07/10/23 09:15:41.334
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:41.347
Jul 10 09:15:41.348: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 09:15:41.349
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:41.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:41.385
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Jul 10 09:15:41.411: INFO: Waiting up to 2m0s for pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" in namespace "var-expansion-4398" to be "container 0 failed with reason CreateContainerConfigError"
Jul 10 09:15:41.416: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904": Phase="Pending", Reason="", readiness=false. Elapsed: 5.632388ms
Jul 10 09:15:43.422: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011117282s
Jul 10 09:15:45.430: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019503001s
Jul 10 09:15:45.430: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Jul 10 09:15:45.430: INFO: Deleting pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" in namespace "var-expansion-4398"
Jul 10 09:15:45.444: INFO: Wait up to 5m0s for pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 09:15:47.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4398" for this suite. 07/10/23 09:15:47.46
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":298,"skipped":5600,"failed":0}
------------------------------
• [SLOW TEST] [6.125 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:41.347
    Jul 10 09:15:41.348: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 09:15:41.349
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:41.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:41.385
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Jul 10 09:15:41.411: INFO: Waiting up to 2m0s for pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" in namespace "var-expansion-4398" to be "container 0 failed with reason CreateContainerConfigError"
    Jul 10 09:15:41.416: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904": Phase="Pending", Reason="", readiness=false. Elapsed: 5.632388ms
    Jul 10 09:15:43.422: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011117282s
    Jul 10 09:15:45.430: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019503001s
    Jul 10 09:15:45.430: INFO: Pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Jul 10 09:15:45.430: INFO: Deleting pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" in namespace "var-expansion-4398"
    Jul 10 09:15:45.444: INFO: Wait up to 5m0s for pod "var-expansion-108a6999-d5e7-4aee-a297-f6f1c48d0904" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 09:15:47.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4398" for this suite. 07/10/23 09:15:47.46
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:47.474
Jul 10 09:15:47.474: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename security-context 07/10/23 09:15:47.475
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:47.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:47.511
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 07/10/23 09:15:47.514
Jul 10 09:15:47.533: INFO: Waiting up to 5m0s for pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335" in namespace "security-context-5129" to be "Succeeded or Failed"
Jul 10 09:15:47.543: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Pending", Reason="", readiness=false. Elapsed: 9.688361ms
Jul 10 09:15:49.555: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021825355s
Jul 10 09:15:51.550: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016919531s
Jul 10 09:15:53.549: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015392191s
STEP: Saw pod success 07/10/23 09:15:53.549
Jul 10 09:15:53.549: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335" satisfied condition "Succeeded or Failed"
Jul 10 09:15:53.554: INFO: Trying to get logs from node 10-62-109-100.test pod security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335 container test-container: <nil>
STEP: delete the pod 07/10/23 09:15:53.565
Jul 10 09:15:53.588: INFO: Waiting for pod security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335 to disappear
Jul 10 09:15:53.592: INFO: Pod security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jul 10 09:15:53.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5129" for this suite. 07/10/23 09:15:53.598
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":299,"skipped":5612,"failed":0}
------------------------------
• [SLOW TEST] [6.134 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:47.474
    Jul 10 09:15:47.474: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename security-context 07/10/23 09:15:47.475
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:47.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:47.511
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 07/10/23 09:15:47.514
    Jul 10 09:15:47.533: INFO: Waiting up to 5m0s for pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335" in namespace "security-context-5129" to be "Succeeded or Failed"
    Jul 10 09:15:47.543: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Pending", Reason="", readiness=false. Elapsed: 9.688361ms
    Jul 10 09:15:49.555: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021825355s
    Jul 10 09:15:51.550: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016919531s
    Jul 10 09:15:53.549: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015392191s
    STEP: Saw pod success 07/10/23 09:15:53.549
    Jul 10 09:15:53.549: INFO: Pod "security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335" satisfied condition "Succeeded or Failed"
    Jul 10 09:15:53.554: INFO: Trying to get logs from node 10-62-109-100.test pod security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335 container test-container: <nil>
    STEP: delete the pod 07/10/23 09:15:53.565
    Jul 10 09:15:53.588: INFO: Waiting for pod security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335 to disappear
    Jul 10 09:15:53.592: INFO: Pod security-context-3f176dcc-e1c2-4052-bce9-15c5e8bde335 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jul 10 09:15:53.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5129" for this suite. 07/10/23 09:15:53.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:53.609
Jul 10 09:15:53.609: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:15:53.61
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:53.636
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:53.639
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 07/10/23 09:15:53.643
Jul 10 09:15:53.658: INFO: Waiting up to 5m0s for pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036" in namespace "downward-api-449" to be "Succeeded or Failed"
Jul 10 09:15:53.662: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036": Phase="Pending", Reason="", readiness=false. Elapsed: 4.096153ms
Jul 10 09:15:55.667: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009402163s
Jul 10 09:15:57.671: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013275945s
STEP: Saw pod success 07/10/23 09:15:57.671
Jul 10 09:15:57.671: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036" satisfied condition "Succeeded or Failed"
Jul 10 09:15:57.683: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036 container dapi-container: <nil>
STEP: delete the pod 07/10/23 09:15:57.695
Jul 10 09:15:57.716: INFO: Waiting for pod downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036 to disappear
Jul 10 09:15:57.720: INFO: Pod downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jul 10 09:15:57.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-449" for this suite. 07/10/23 09:15:57.726
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":300,"skipped":5632,"failed":0}
------------------------------
• [4.128 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:53.609
    Jul 10 09:15:53.609: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:15:53.61
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:53.636
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:53.639
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 07/10/23 09:15:53.643
    Jul 10 09:15:53.658: INFO: Waiting up to 5m0s for pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036" in namespace "downward-api-449" to be "Succeeded or Failed"
    Jul 10 09:15:53.662: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036": Phase="Pending", Reason="", readiness=false. Elapsed: 4.096153ms
    Jul 10 09:15:55.667: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009402163s
    Jul 10 09:15:57.671: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013275945s
    STEP: Saw pod success 07/10/23 09:15:57.671
    Jul 10 09:15:57.671: INFO: Pod "downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036" satisfied condition "Succeeded or Failed"
    Jul 10 09:15:57.683: INFO: Trying to get logs from node 10-62-109-100.test pod downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036 container dapi-container: <nil>
    STEP: delete the pod 07/10/23 09:15:57.695
    Jul 10 09:15:57.716: INFO: Waiting for pod downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036 to disappear
    Jul 10 09:15:57.720: INFO: Pod downward-api-bce5fc9c-e768-420a-9bd4-3f68e835f036 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jul 10 09:15:57.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-449" for this suite. 07/10/23 09:15:57.726
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:57.738
Jul 10 09:15:57.738: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir 07/10/23 09:15:57.739
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:57.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:57.799
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 07/10/23 09:15:57.802
Jul 10 09:15:57.816: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789" in namespace "emptydir-8164" to be "running"
Jul 10 09:15:57.827: INFO: Pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789": Phase="Pending", Reason="", readiness=false. Elapsed: 10.272216ms
Jul 10 09:15:59.833: INFO: Pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789": Phase="Running", Reason="", readiness=false. Elapsed: 2.016440359s
Jul 10 09:15:59.833: INFO: Pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789" satisfied condition "running"
STEP: Reading file content from the nginx-container 07/10/23 09:15:59.833
Jul 10 09:15:59.833: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8164 PodName:pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:15:59.833: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:15:59.834: INFO: ExecWithOptions: Clientset creation
Jul 10 09:15:59.834: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/emptydir-8164/pods/pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Jul 10 09:15:59.903: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jul 10 09:15:59.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8164" for this suite. 07/10/23 09:15:59.909
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":301,"skipped":5652,"failed":0}
------------------------------
• [2.182 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:57.738
    Jul 10 09:15:57.738: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir 07/10/23 09:15:57.739
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:57.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:57.799
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 07/10/23 09:15:57.802
    Jul 10 09:15:57.816: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789" in namespace "emptydir-8164" to be "running"
    Jul 10 09:15:57.827: INFO: Pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789": Phase="Pending", Reason="", readiness=false. Elapsed: 10.272216ms
    Jul 10 09:15:59.833: INFO: Pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789": Phase="Running", Reason="", readiness=false. Elapsed: 2.016440359s
    Jul 10 09:15:59.833: INFO: Pod "pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789" satisfied condition "running"
    STEP: Reading file content from the nginx-container 07/10/23 09:15:59.833
    Jul 10 09:15:59.833: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8164 PodName:pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:15:59.833: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:15:59.834: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:15:59.834: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/emptydir-8164/pods/pod-sharedvolume-72ae5328-3789-4135-a0a6-bc6af07ea789/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Jul 10 09:15:59.903: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jul 10 09:15:59.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8164" for this suite. 07/10/23 09:15:59.909
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:15:59.921
Jul 10 09:15:59.921: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename statefulset 07/10/23 09:15:59.922
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:59.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:59.972
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2001 07/10/23 09:15:59.975
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 07/10/23 09:15:59.984
Jul 10 09:16:00.002: INFO: Found 0 stateful pods, waiting for 3
Jul 10 09:16:10.010: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 09:16:10.010: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 09:16:10.010: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 07/10/23 09:16:10.021
Jul 10 09:16:10.048: INFO: Updating stateful set ss2
STEP: Creating a new revision 07/10/23 09:16:10.048
STEP: Not applying an update when the partition is greater than the number of replicas 07/10/23 09:16:20.092
STEP: Performing a canary update 07/10/23 09:16:20.092
Jul 10 09:16:20.121: INFO: Updating stateful set ss2
Jul 10 09:16:20.138: INFO: Waiting for Pod statefulset-2001/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 07/10/23 09:16:30.15
Jul 10 09:16:30.312: INFO: Found 2 stateful pods, waiting for 3
Jul 10 09:16:40.319: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 09:16:40.319: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 10 09:16:40.319: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 07/10/23 09:16:40.327
Jul 10 09:16:40.354: INFO: Updating stateful set ss2
Jul 10 09:16:40.368: INFO: Waiting for Pod statefulset-2001/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jul 10 09:16:50.410: INFO: Updating stateful set ss2
Jul 10 09:16:50.419: INFO: Waiting for StatefulSet statefulset-2001/ss2 to complete update
Jul 10 09:16:50.419: INFO: Waiting for Pod statefulset-2001/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul 10 09:17:00.430: INFO: Deleting all statefulset in ns statefulset-2001
Jul 10 09:17:00.435: INFO: Scaling statefulset ss2 to 0
Jul 10 09:17:10.461: INFO: Waiting for statefulset status.replicas updated to 0
Jul 10 09:17:10.466: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jul 10 09:17:10.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2001" for this suite. 07/10/23 09:17:10.498
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":302,"skipped":5652,"failed":0}
------------------------------
• [SLOW TEST] [70.593 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:15:59.921
    Jul 10 09:15:59.921: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename statefulset 07/10/23 09:15:59.922
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:15:59.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:15:59.972
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2001 07/10/23 09:15:59.975
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 07/10/23 09:15:59.984
    Jul 10 09:16:00.002: INFO: Found 0 stateful pods, waiting for 3
    Jul 10 09:16:10.010: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 09:16:10.010: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 09:16:10.010: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 07/10/23 09:16:10.021
    Jul 10 09:16:10.048: INFO: Updating stateful set ss2
    STEP: Creating a new revision 07/10/23 09:16:10.048
    STEP: Not applying an update when the partition is greater than the number of replicas 07/10/23 09:16:20.092
    STEP: Performing a canary update 07/10/23 09:16:20.092
    Jul 10 09:16:20.121: INFO: Updating stateful set ss2
    Jul 10 09:16:20.138: INFO: Waiting for Pod statefulset-2001/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 07/10/23 09:16:30.15
    Jul 10 09:16:30.312: INFO: Found 2 stateful pods, waiting for 3
    Jul 10 09:16:40.319: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 09:16:40.319: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jul 10 09:16:40.319: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 07/10/23 09:16:40.327
    Jul 10 09:16:40.354: INFO: Updating stateful set ss2
    Jul 10 09:16:40.368: INFO: Waiting for Pod statefulset-2001/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jul 10 09:16:50.410: INFO: Updating stateful set ss2
    Jul 10 09:16:50.419: INFO: Waiting for StatefulSet statefulset-2001/ss2 to complete update
    Jul 10 09:16:50.419: INFO: Waiting for Pod statefulset-2001/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jul 10 09:17:00.430: INFO: Deleting all statefulset in ns statefulset-2001
    Jul 10 09:17:00.435: INFO: Scaling statefulset ss2 to 0
    Jul 10 09:17:10.461: INFO: Waiting for statefulset status.replicas updated to 0
    Jul 10 09:17:10.466: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jul 10 09:17:10.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2001" for this suite. 07/10/23 09:17:10.498
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:17:10.515
Jul 10 09:17:10.515: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubectl 07/10/23 09:17:10.516
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:10.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:10.545
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 07/10/23 09:17:10.548
Jul 10 09:17:10.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-3779 api-versions'
Jul 10 09:17:10.634: INFO: stderr: ""
Jul 10 09:17:10.634: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninternal.apiserver.k8s.io/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1alpha1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jul 10 09:17:10.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3779" for this suite. 07/10/23 09:17:10.643
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":303,"skipped":5675,"failed":0}
------------------------------
• [0.144 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:17:10.515
    Jul 10 09:17:10.515: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubectl 07/10/23 09:17:10.516
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:10.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:10.545
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 07/10/23 09:17:10.548
    Jul 10 09:17:10.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=kubectl-3779 api-versions'
    Jul 10 09:17:10.634: INFO: stderr: ""
    Jul 10 09:17:10.634: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninternal.apiserver.k8s.io/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1alpha1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jul 10 09:17:10.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3779" for this suite. 07/10/23 09:17:10.643
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:17:10.661
Jul 10 09:17:10.661: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename ephemeral-containers-test 07/10/23 09:17:10.663
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:10.692
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:10.696
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 07/10/23 09:17:10.7
Jul 10 09:17:10.718: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6564" to be "running and ready"
Jul 10 09:17:10.722: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.781226ms
Jul 10 09:17:10.722: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:17:12.729: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011043887s
Jul 10 09:17:12.729: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Jul 10 09:17:12.729: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 07/10/23 09:17:12.734
Jul 10 09:17:12.753: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6564" to be "container debugger running"
Jul 10 09:17:12.756: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.473906ms
Jul 10 09:17:14.824: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.070623034s
Jul 10 09:17:16.762: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.00909813s
Jul 10 09:17:16.762: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 07/10/23 09:17:16.762
Jul 10 09:17:16.762: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6564 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:17:16.762: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:17:16.763: INFO: ExecWithOptions: Clientset creation
Jul 10 09:17:16.763: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/ephemeral-containers-test-6564/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Jul 10 09:17:16.832: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Jul 10 09:17:16.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-6564" for this suite. 07/10/23 09:17:16.848
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":304,"skipped":5692,"failed":0}
------------------------------
• [SLOW TEST] [6.196 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:17:10.661
    Jul 10 09:17:10.661: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename ephemeral-containers-test 07/10/23 09:17:10.663
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:10.692
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:10.696
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 07/10/23 09:17:10.7
    Jul 10 09:17:10.718: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6564" to be "running and ready"
    Jul 10 09:17:10.722: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.781226ms
    Jul 10 09:17:10.722: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:17:12.729: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011043887s
    Jul 10 09:17:12.729: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Jul 10 09:17:12.729: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 07/10/23 09:17:12.734
    Jul 10 09:17:12.753: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6564" to be "container debugger running"
    Jul 10 09:17:12.756: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.473906ms
    Jul 10 09:17:14.824: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.070623034s
    Jul 10 09:17:16.762: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.00909813s
    Jul 10 09:17:16.762: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 07/10/23 09:17:16.762
    Jul 10 09:17:16.762: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6564 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:17:16.762: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:17:16.763: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:17:16.763: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/ephemeral-containers-test-6564/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Jul 10 09:17:16.832: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Jul 10 09:17:16.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-6564" for this suite. 07/10/23 09:17:16.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:17:16.859
Jul 10 09:17:16.859: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 09:17:16.86
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:16.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:16.892
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 07/10/23 09:17:16.901
Jul 10 09:17:16.912: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-293" to be "running and ready"
Jul 10 09:17:16.916: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.708999ms
Jul 10 09:17:16.916: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:17:18.922: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.010538183s
Jul 10 09:17:18.922: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jul 10 09:17:18.922: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 07/10/23 09:17:18.927
Jul 10 09:17:18.937: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-293" to be "running and ready"
Jul 10 09:17:18.941: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019643ms
Jul 10 09:17:18.941: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:17:20.948: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010560538s
Jul 10 09:17:20.948: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:17:22.948: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.010482766s
Jul 10 09:17:22.948: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Jul 10 09:17:22.948: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 07/10/23 09:17:22.952
STEP: delete the pod with lifecycle hook 07/10/23 09:17:22.964
Jul 10 09:17:22.978: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 10 09:17:22.987: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 10 09:17:24.988: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 10 09:17:24.993: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jul 10 09:17:24.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-293" for this suite. 07/10/23 09:17:24.998
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":305,"skipped":5714,"failed":0}
------------------------------
• [SLOW TEST] [8.150 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:17:16.859
    Jul 10 09:17:16.859: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-lifecycle-hook 07/10/23 09:17:16.86
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:16.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:16.892
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 07/10/23 09:17:16.901
    Jul 10 09:17:16.912: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-293" to be "running and ready"
    Jul 10 09:17:16.916: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.708999ms
    Jul 10 09:17:16.916: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:17:18.922: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.010538183s
    Jul 10 09:17:18.922: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jul 10 09:17:18.922: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 07/10/23 09:17:18.927
    Jul 10 09:17:18.937: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-293" to be "running and ready"
    Jul 10 09:17:18.941: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019643ms
    Jul 10 09:17:18.941: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:17:20.948: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010560538s
    Jul 10 09:17:20.948: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:17:22.948: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.010482766s
    Jul 10 09:17:22.948: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Jul 10 09:17:22.948: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 07/10/23 09:17:22.952
    STEP: delete the pod with lifecycle hook 07/10/23 09:17:22.964
    Jul 10 09:17:22.978: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jul 10 09:17:22.987: INFO: Pod pod-with-poststart-exec-hook still exists
    Jul 10 09:17:24.988: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jul 10 09:17:24.993: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jul 10 09:17:24.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-293" for this suite. 07/10/23 09:17:24.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:17:25.01
Jul 10 09:17:25.010: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename replicaset 07/10/23 09:17:25.011
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:25.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:25.05
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 07/10/23 09:17:25.059
STEP: Verify that the required pods have come up. 07/10/23 09:17:25.069
Jul 10 09:17:25.074: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 10 09:17:30.101: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 07/10/23 09:17:30.101
STEP: Getting /status 07/10/23 09:17:30.101
Jul 10 09:17:30.105: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 07/10/23 09:17:30.105
Jul 10 09:17:30.119: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 07/10/23 09:17:30.119
Jul 10 09:17:30.121: INFO: Observed &ReplicaSet event: ADDED
Jul 10 09:17:30.121: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.121: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.122: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.122: INFO: Found replicaset test-rs in namespace replicaset-911 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul 10 09:17:30.122: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 07/10/23 09:17:30.122
Jul 10 09:17:30.122: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul 10 09:17:30.153: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 07/10/23 09:17:30.153
Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: ADDED
Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.156: INFO: Observed replicaset test-rs in namespace replicaset-911 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul 10 09:17:30.157: INFO: Observed &ReplicaSet event: MODIFIED
Jul 10 09:17:30.157: INFO: Found replicaset test-rs in namespace replicaset-911 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Jul 10 09:17:30.157: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jul 10 09:17:30.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-911" for this suite. 07/10/23 09:17:30.169
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":306,"skipped":5745,"failed":0}
------------------------------
• [SLOW TEST] [5.170 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:17:25.01
    Jul 10 09:17:25.010: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename replicaset 07/10/23 09:17:25.011
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:25.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:25.05
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 07/10/23 09:17:25.059
    STEP: Verify that the required pods have come up. 07/10/23 09:17:25.069
    Jul 10 09:17:25.074: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jul 10 09:17:30.101: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 07/10/23 09:17:30.101
    STEP: Getting /status 07/10/23 09:17:30.101
    Jul 10 09:17:30.105: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 07/10/23 09:17:30.105
    Jul 10 09:17:30.119: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 07/10/23 09:17:30.119
    Jul 10 09:17:30.121: INFO: Observed &ReplicaSet event: ADDED
    Jul 10 09:17:30.121: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.121: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.122: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.122: INFO: Found replicaset test-rs in namespace replicaset-911 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jul 10 09:17:30.122: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 07/10/23 09:17:30.122
    Jul 10 09:17:30.122: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jul 10 09:17:30.153: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 07/10/23 09:17:30.153
    Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: ADDED
    Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.156: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.156: INFO: Observed replicaset test-rs in namespace replicaset-911 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jul 10 09:17:30.157: INFO: Observed &ReplicaSet event: MODIFIED
    Jul 10 09:17:30.157: INFO: Found replicaset test-rs in namespace replicaset-911 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Jul 10 09:17:30.157: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jul 10 09:17:30.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-911" for this suite. 07/10/23 09:17:30.169
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:17:30.18
Jul 10 09:17:30.180: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:17:30.181
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:30.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:30.221
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-c48e5e27-6b72-4755-b2c6-7c6baaa97e0f 07/10/23 09:17:30.232
STEP: Creating the pod 07/10/23 09:17:30.239
Jul 10 09:17:30.253: INFO: Waiting up to 5m0s for pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57" in namespace "configmap-1893" to be "running and ready"
Jul 10 09:17:30.262: INFO: Pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57": Phase="Pending", Reason="", readiness=false. Elapsed: 8.218675ms
Jul 10 09:17:30.262: INFO: The phase of Pod pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:17:32.267: INFO: Pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57": Phase="Running", Reason="", readiness=true. Elapsed: 2.013799449s
Jul 10 09:17:32.267: INFO: The phase of Pod pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57 is Running (Ready = true)
Jul 10 09:17:32.267: INFO: Pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-c48e5e27-6b72-4755-b2c6-7c6baaa97e0f 07/10/23 09:17:32.283
STEP: waiting to observe update in volume 07/10/23 09:17:32.294
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:17:34.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1893" for this suite. 07/10/23 09:17:34.332
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":307,"skipped":5746,"failed":0}
------------------------------
• [4.162 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:17:30.18
    Jul 10 09:17:30.180: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:17:30.181
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:30.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:30.221
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-c48e5e27-6b72-4755-b2c6-7c6baaa97e0f 07/10/23 09:17:30.232
    STEP: Creating the pod 07/10/23 09:17:30.239
    Jul 10 09:17:30.253: INFO: Waiting up to 5m0s for pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57" in namespace "configmap-1893" to be "running and ready"
    Jul 10 09:17:30.262: INFO: Pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57": Phase="Pending", Reason="", readiness=false. Elapsed: 8.218675ms
    Jul 10 09:17:30.262: INFO: The phase of Pod pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:17:32.267: INFO: Pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57": Phase="Running", Reason="", readiness=true. Elapsed: 2.013799449s
    Jul 10 09:17:32.267: INFO: The phase of Pod pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57 is Running (Ready = true)
    Jul 10 09:17:32.267: INFO: Pod "pod-configmaps-bdc948cc-22ff-4ae2-ba03-dfbfcd656d57" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-c48e5e27-6b72-4755-b2c6-7c6baaa97e0f 07/10/23 09:17:32.283
    STEP: waiting to observe update in volume 07/10/23 09:17:32.294
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:17:34.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1893" for this suite. 07/10/23 09:17:34.332
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:17:34.344
Jul 10 09:17:34.344: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename endpointslice 07/10/23 09:17:34.345
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:34.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:34.384
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 07/10/23 09:17:39.624
STEP: referencing matching pods with named port 07/10/23 09:17:44.966
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 07/10/23 09:17:49.977
STEP: recreating EndpointSlices after they've been deleted 07/10/23 09:17:54.987
Jul 10 09:17:55.036: INFO: EndpointSlice for Service endpointslice-82/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jul 10 09:18:05.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-82" for this suite. 07/10/23 09:18:05.056
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":308,"skipped":5759,"failed":0}
------------------------------
• [SLOW TEST] [30.725 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:17:34.344
    Jul 10 09:17:34.344: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename endpointslice 07/10/23 09:17:34.345
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:17:34.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:17:34.384
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 07/10/23 09:17:39.624
    STEP: referencing matching pods with named port 07/10/23 09:17:44.966
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 07/10/23 09:17:49.977
    STEP: recreating EndpointSlices after they've been deleted 07/10/23 09:17:54.987
    Jul 10 09:17:55.036: INFO: EndpointSlice for Service endpointslice-82/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jul 10 09:18:05.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-82" for this suite. 07/10/23 09:18:05.056
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:18:05.069
Jul 10 09:18:05.069: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 09:18:05.071
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:05.109
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:05.113
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 09:18:05.158
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:18:05.871
STEP: Deploying the webhook pod 07/10/23 09:18:05.886
STEP: Wait for the deployment to be ready 07/10/23 09:18:05.92
Jul 10 09:18:05.957: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 07/10/23 09:18:07.98
STEP: Verifying the service has paired with the endpoint 07/10/23 09:18:08.011
Jul 10 09:18:09.011: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 07/10/23 09:18:09.016
STEP: create a pod that should be denied by the webhook 07/10/23 09:18:09.036
STEP: create a pod that causes the webhook to hang 07/10/23 09:18:09.051
STEP: create a configmap that should be denied by the webhook 07/10/23 09:18:19.062
STEP: create a configmap that should be admitted by the webhook 07/10/23 09:18:19.091
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 07/10/23 09:18:19.105
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 07/10/23 09:18:19.122
STEP: create a namespace that bypass the webhook 07/10/23 09:18:19.128
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 07/10/23 09:18:19.139
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:18:19.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1106" for this suite. 07/10/23 09:18:19.184
STEP: Destroying namespace "webhook-1106-markers" for this suite. 07/10/23 09:18:19.196
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":309,"skipped":5765,"failed":0}
------------------------------
• [SLOW TEST] [14.212 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:18:05.069
    Jul 10 09:18:05.069: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 09:18:05.071
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:05.109
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:05.113
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 09:18:05.158
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:18:05.871
    STEP: Deploying the webhook pod 07/10/23 09:18:05.886
    STEP: Wait for the deployment to be ready 07/10/23 09:18:05.92
    Jul 10 09:18:05.957: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 07/10/23 09:18:07.98
    STEP: Verifying the service has paired with the endpoint 07/10/23 09:18:08.011
    Jul 10 09:18:09.011: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 07/10/23 09:18:09.016
    STEP: create a pod that should be denied by the webhook 07/10/23 09:18:09.036
    STEP: create a pod that causes the webhook to hang 07/10/23 09:18:09.051
    STEP: create a configmap that should be denied by the webhook 07/10/23 09:18:19.062
    STEP: create a configmap that should be admitted by the webhook 07/10/23 09:18:19.091
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 07/10/23 09:18:19.105
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 07/10/23 09:18:19.122
    STEP: create a namespace that bypass the webhook 07/10/23 09:18:19.128
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 07/10/23 09:18:19.139
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:18:19.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1106" for this suite. 07/10/23 09:18:19.184
    STEP: Destroying namespace "webhook-1106-markers" for this suite. 07/10/23 09:18:19.196
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:18:19.282
Jul 10 09:18:19.282: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:18:19.283
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:19.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:19.331
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Jul 10 09:18:19.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 07/10/23 09:18:22.621
Jul 10 09:18:22.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
Jul 10 09:18:23.459: INFO: stderr: ""
Jul 10 09:18:23.459: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jul 10 09:18:23.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 delete e2e-test-crd-publish-openapi-1424-crds test-foo'
Jul 10 09:18:23.552: INFO: stderr: ""
Jul 10 09:18:23.552: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jul 10 09:18:23.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 apply -f -'
Jul 10 09:18:24.230: INFO: stderr: ""
Jul 10 09:18:24.230: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jul 10 09:18:24.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 delete e2e-test-crd-publish-openapi-1424-crds test-foo'
Jul 10 09:18:24.318: INFO: stderr: ""
Jul 10 09:18:24.318: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 07/10/23 09:18:24.318
Jul 10 09:18:24.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
Jul 10 09:18:25.141: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 07/10/23 09:18:25.141
Jul 10 09:18:25.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
Jul 10 09:18:25.390: INFO: rc: 1
Jul 10 09:18:25.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 apply -f -'
Jul 10 09:18:25.636: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 07/10/23 09:18:25.636
Jul 10 09:18:25.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
Jul 10 09:18:25.864: INFO: rc: 1
Jul 10 09:18:25.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 apply -f -'
Jul 10 09:18:26.111: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 07/10/23 09:18:26.111
Jul 10 09:18:26.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds'
Jul 10 09:18:26.353: INFO: stderr: ""
Jul 10 09:18:26.353: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 07/10/23 09:18:26.354
Jul 10 09:18:26.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.metadata'
Jul 10 09:18:26.575: INFO: stderr: ""
Jul 10 09:18:26.575: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jul 10 09:18:26.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.spec'
Jul 10 09:18:26.810: INFO: stderr: ""
Jul 10 09:18:26.810: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jul 10 09:18:26.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.spec.bars'
Jul 10 09:18:27.038: INFO: stderr: ""
Jul 10 09:18:27.039: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 07/10/23 09:18:27.039
Jul 10 09:18:27.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.spec.bars2'
Jul 10 09:18:27.267: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:18:32.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1155" for this suite. 07/10/23 09:18:32.071
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":310,"skipped":5771,"failed":0}
------------------------------
• [SLOW TEST] [12.799 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:18:19.282
    Jul 10 09:18:19.282: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:18:19.283
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:19.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:19.331
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Jul 10 09:18:19.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 07/10/23 09:18:22.621
    Jul 10 09:18:22.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
    Jul 10 09:18:23.459: INFO: stderr: ""
    Jul 10 09:18:23.459: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Jul 10 09:18:23.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 delete e2e-test-crd-publish-openapi-1424-crds test-foo'
    Jul 10 09:18:23.552: INFO: stderr: ""
    Jul 10 09:18:23.552: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Jul 10 09:18:23.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 apply -f -'
    Jul 10 09:18:24.230: INFO: stderr: ""
    Jul 10 09:18:24.230: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Jul 10 09:18:24.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 delete e2e-test-crd-publish-openapi-1424-crds test-foo'
    Jul 10 09:18:24.318: INFO: stderr: ""
    Jul 10 09:18:24.318: INFO: stdout: "e2e-test-crd-publish-openapi-1424-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 07/10/23 09:18:24.318
    Jul 10 09:18:24.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
    Jul 10 09:18:25.141: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 07/10/23 09:18:25.141
    Jul 10 09:18:25.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
    Jul 10 09:18:25.390: INFO: rc: 1
    Jul 10 09:18:25.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 apply -f -'
    Jul 10 09:18:25.636: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 07/10/23 09:18:25.636
    Jul 10 09:18:25.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 create -f -'
    Jul 10 09:18:25.864: INFO: rc: 1
    Jul 10 09:18:25.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 --namespace=crd-publish-openapi-1155 apply -f -'
    Jul 10 09:18:26.111: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 07/10/23 09:18:26.111
    Jul 10 09:18:26.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds'
    Jul 10 09:18:26.353: INFO: stderr: ""
    Jul 10 09:18:26.353: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 07/10/23 09:18:26.354
    Jul 10 09:18:26.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.metadata'
    Jul 10 09:18:26.575: INFO: stderr: ""
    Jul 10 09:18:26.575: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Jul 10 09:18:26.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.spec'
    Jul 10 09:18:26.810: INFO: stderr: ""
    Jul 10 09:18:26.810: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Jul 10 09:18:26.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.spec.bars'
    Jul 10 09:18:27.038: INFO: stderr: ""
    Jul 10 09:18:27.039: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1424-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 07/10/23 09:18:27.039
    Jul 10 09:18:27.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-1155 explain e2e-test-crd-publish-openapi-1424-crds.spec.bars2'
    Jul 10 09:18:27.267: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:18:32.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1155" for this suite. 07/10/23 09:18:32.071
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:18:32.082
Jul 10 09:18:32.082: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename runtimeclass 07/10/23 09:18:32.083
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:32.124
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:32.128
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Jul 10 09:18:32.154: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-3566 to be scheduled
Jul 10 09:18:32.159: INFO: 1 pods are not scheduled: [runtimeclass-3566/test-runtimeclass-runtimeclass-3566-preconfigured-handler-kw8jl(4c188f48-781b-4bf9-9dcf-f02d3992cfae)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jul 10 09:18:34.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3566" for this suite. 07/10/23 09:18:34.182
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":311,"skipped":5775,"failed":0}
------------------------------
• [2.114 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:18:32.082
    Jul 10 09:18:32.082: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename runtimeclass 07/10/23 09:18:32.083
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:32.124
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:32.128
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Jul 10 09:18:32.154: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-3566 to be scheduled
    Jul 10 09:18:32.159: INFO: 1 pods are not scheduled: [runtimeclass-3566/test-runtimeclass-runtimeclass-3566-preconfigured-handler-kw8jl(4c188f48-781b-4bf9-9dcf-f02d3992cfae)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jul 10 09:18:34.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3566" for this suite. 07/10/23 09:18:34.182
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:18:34.196
Jul 10 09:18:34.196: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 09:18:34.198
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:34.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:34.224
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-f3242c63-91e2-4b79-958f-5ef14355cfe8 07/10/23 09:18:34.228
STEP: Creating a pod to test consume secrets 07/10/23 09:18:34.238
Jul 10 09:18:34.250: INFO: Waiting up to 5m0s for pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a" in namespace "secrets-5598" to be "Succeeded or Failed"
Jul 10 09:18:34.254: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.918491ms
Jul 10 09:18:36.260: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009089715s
Jul 10 09:18:38.260: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00966138s
STEP: Saw pod success 07/10/23 09:18:38.26
Jul 10 09:18:38.260: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a" satisfied condition "Succeeded or Failed"
Jul 10 09:18:38.266: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a container secret-volume-test: <nil>
STEP: delete the pod 07/10/23 09:18:38.282
Jul 10 09:18:38.314: INFO: Waiting for pod pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a to disappear
Jul 10 09:18:38.319: INFO: Pod pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 09:18:38.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5598" for this suite. 07/10/23 09:18:38.325
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":312,"skipped":5779,"failed":0}
------------------------------
• [4.141 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:18:34.196
    Jul 10 09:18:34.196: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 09:18:34.198
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:34.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:34.224
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-f3242c63-91e2-4b79-958f-5ef14355cfe8 07/10/23 09:18:34.228
    STEP: Creating a pod to test consume secrets 07/10/23 09:18:34.238
    Jul 10 09:18:34.250: INFO: Waiting up to 5m0s for pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a" in namespace "secrets-5598" to be "Succeeded or Failed"
    Jul 10 09:18:34.254: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.918491ms
    Jul 10 09:18:36.260: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009089715s
    Jul 10 09:18:38.260: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00966138s
    STEP: Saw pod success 07/10/23 09:18:38.26
    Jul 10 09:18:38.260: INFO: Pod "pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a" satisfied condition "Succeeded or Failed"
    Jul 10 09:18:38.266: INFO: Trying to get logs from node 10-62-109-100.test pod pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a container secret-volume-test: <nil>
    STEP: delete the pod 07/10/23 09:18:38.282
    Jul 10 09:18:38.314: INFO: Waiting for pod pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a to disappear
    Jul 10 09:18:38.319: INFO: Pod pod-secrets-408f10cc-62a1-4827-922a-9d0aed83c00a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 09:18:38.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5598" for this suite. 07/10/23 09:18:38.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:18:38.339
Jul 10 09:18:38.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-watch 07/10/23 09:18:38.34
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:38.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:38.365
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Jul 10 09:18:38.370: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Creating first CR  07/10/23 09:18:40.959
Jul 10 09:18:40.967: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:18:40Z]] name:name1 resourceVersion:105457 uid:74956482-4871-4eea-894f-356799415a63] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 07/10/23 09:18:50.968
Jul 10 09:18:50.978: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:50Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:18:50Z]] name:name2 resourceVersion:105492 uid:80ef82e3-3407-4cfd-91b9-eced6faf6de7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 07/10/23 09:19:00.979
Jul 10 09:19:00.994: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:00Z]] name:name1 resourceVersion:105515 uid:74956482-4871-4eea-894f-356799415a63] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 07/10/23 09:19:10.995
Jul 10 09:19:11.007: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:10Z]] name:name2 resourceVersion:105538 uid:80ef82e3-3407-4cfd-91b9-eced6faf6de7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 07/10/23 09:19:21.007
Jul 10 09:19:21.022: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:00Z]] name:name1 resourceVersion:105562 uid:74956482-4871-4eea-894f-356799415a63] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 07/10/23 09:19:31.023
Jul 10 09:19:31.042: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:10Z]] name:name2 resourceVersion:105586 uid:80ef82e3-3407-4cfd-91b9-eced6faf6de7] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:19:41.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6619" for this suite. 07/10/23 09:19:41.569
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":313,"skipped":5797,"failed":0}
------------------------------
• [SLOW TEST] [63.241 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:18:38.339
    Jul 10 09:18:38.339: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-watch 07/10/23 09:18:38.34
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:18:38.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:18:38.365
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Jul 10 09:18:38.370: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Creating first CR  07/10/23 09:18:40.959
    Jul 10 09:18:40.967: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:18:40Z]] name:name1 resourceVersion:105457 uid:74956482-4871-4eea-894f-356799415a63] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 07/10/23 09:18:50.968
    Jul 10 09:18:50.978: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:50Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:18:50Z]] name:name2 resourceVersion:105492 uid:80ef82e3-3407-4cfd-91b9-eced6faf6de7] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 07/10/23 09:19:00.979
    Jul 10 09:19:00.994: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:00Z]] name:name1 resourceVersion:105515 uid:74956482-4871-4eea-894f-356799415a63] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 07/10/23 09:19:10.995
    Jul 10 09:19:11.007: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:10Z]] name:name2 resourceVersion:105538 uid:80ef82e3-3407-4cfd-91b9-eced6faf6de7] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 07/10/23 09:19:21.007
    Jul 10 09:19:21.022: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:00Z]] name:name1 resourceVersion:105562 uid:74956482-4871-4eea-894f-356799415a63] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 07/10/23 09:19:31.023
    Jul 10 09:19:31.042: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-07-10T09:18:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-07-10T09:19:10Z]] name:name2 resourceVersion:105586 uid:80ef82e3-3407-4cfd-91b9-eced6faf6de7] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:19:41.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-6619" for this suite. 07/10/23 09:19:41.569
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:19:41.581
Jul 10 09:19:41.581: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename namespaces 07/10/23 09:19:41.583
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:41.667
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:19:41.673
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 07/10/23 09:19:41.677
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:41.704
STEP: Creating a pod in the namespace 07/10/23 09:19:41.707
STEP: Waiting for the pod to have running status 07/10/23 09:19:41.717
Jul 10 09:19:41.717: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-8506" to be "running"
Jul 10 09:19:41.722: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.842334ms
Jul 10 09:19:43.727: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010629163s
Jul 10 09:19:43.727: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 07/10/23 09:19:43.727
STEP: Waiting for the namespace to be removed. 07/10/23 09:19:43.745
STEP: Recreating the namespace 07/10/23 09:19:54.75
STEP: Verifying there are no pods in the namespace 07/10/23 09:19:54.778
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:19:54.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4798" for this suite. 07/10/23 09:19:54.789
STEP: Destroying namespace "nsdeletetest-8506" for this suite. 07/10/23 09:19:54.807
Jul 10 09:19:54.817: INFO: Namespace nsdeletetest-8506 was already deleted
STEP: Destroying namespace "nsdeletetest-4914" for this suite. 07/10/23 09:19:54.818
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":314,"skipped":5800,"failed":0}
------------------------------
• [SLOW TEST] [13.252 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:19:41.581
    Jul 10 09:19:41.581: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename namespaces 07/10/23 09:19:41.583
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:41.667
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:19:41.673
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 07/10/23 09:19:41.677
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:41.704
    STEP: Creating a pod in the namespace 07/10/23 09:19:41.707
    STEP: Waiting for the pod to have running status 07/10/23 09:19:41.717
    Jul 10 09:19:41.717: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-8506" to be "running"
    Jul 10 09:19:41.722: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.842334ms
    Jul 10 09:19:43.727: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010629163s
    Jul 10 09:19:43.727: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 07/10/23 09:19:43.727
    STEP: Waiting for the namespace to be removed. 07/10/23 09:19:43.745
    STEP: Recreating the namespace 07/10/23 09:19:54.75
    STEP: Verifying there are no pods in the namespace 07/10/23 09:19:54.778
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:19:54.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4798" for this suite. 07/10/23 09:19:54.789
    STEP: Destroying namespace "nsdeletetest-8506" for this suite. 07/10/23 09:19:54.807
    Jul 10 09:19:54.817: INFO: Namespace nsdeletetest-8506 was already deleted
    STEP: Destroying namespace "nsdeletetest-4914" for this suite. 07/10/23 09:19:54.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:19:54.833
Jul 10 09:19:54.833: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename proxy 07/10/23 09:19:54.834
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:54.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:19:54.883
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Jul 10 09:19:54.885: INFO: Creating pod...
Jul 10 09:19:54.893: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3564" to be "running"
Jul 10 09:19:54.904: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.537622ms
Jul 10 09:19:56.911: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.01768201s
Jul 10 09:19:56.911: INFO: Pod "agnhost" satisfied condition "running"
Jul 10 09:19:56.911: INFO: Creating service...
Jul 10 09:19:56.938: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=DELETE
Jul 10 09:19:56.951: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul 10 09:19:56.951: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=OPTIONS
Jul 10 09:19:56.959: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul 10 09:19:56.959: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=PATCH
Jul 10 09:19:56.967: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul 10 09:19:56.967: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=POST
Jul 10 09:19:56.971: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul 10 09:19:56.971: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=PUT
Jul 10 09:19:56.982: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul 10 09:19:56.982: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=DELETE
Jul 10 09:19:56.988: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul 10 09:19:56.988: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=OPTIONS
Jul 10 09:19:56.995: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul 10 09:19:56.995: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=PATCH
Jul 10 09:19:57.003: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul 10 09:19:57.003: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=POST
Jul 10 09:19:57.011: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul 10 09:19:57.011: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=PUT
Jul 10 09:19:57.018: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul 10 09:19:57.018: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=GET
Jul 10 09:19:57.022: INFO: http.Client request:GET StatusCode:301
Jul 10 09:19:57.022: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=GET
Jul 10 09:19:57.028: INFO: http.Client request:GET StatusCode:301
Jul 10 09:19:57.028: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=HEAD
Jul 10 09:19:57.031: INFO: http.Client request:HEAD StatusCode:301
Jul 10 09:19:57.031: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=HEAD
Jul 10 09:19:57.037: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jul 10 09:19:57.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3564" for this suite. 07/10/23 09:19:57.041
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":315,"skipped":5805,"failed":0}
------------------------------
• [2.220 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:19:54.833
    Jul 10 09:19:54.833: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename proxy 07/10/23 09:19:54.834
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:54.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:19:54.883
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Jul 10 09:19:54.885: INFO: Creating pod...
    Jul 10 09:19:54.893: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3564" to be "running"
    Jul 10 09:19:54.904: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.537622ms
    Jul 10 09:19:56.911: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.01768201s
    Jul 10 09:19:56.911: INFO: Pod "agnhost" satisfied condition "running"
    Jul 10 09:19:56.911: INFO: Creating service...
    Jul 10 09:19:56.938: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=DELETE
    Jul 10 09:19:56.951: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jul 10 09:19:56.951: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=OPTIONS
    Jul 10 09:19:56.959: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jul 10 09:19:56.959: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=PATCH
    Jul 10 09:19:56.967: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jul 10 09:19:56.967: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=POST
    Jul 10 09:19:56.971: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jul 10 09:19:56.971: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=PUT
    Jul 10 09:19:56.982: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jul 10 09:19:56.982: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=DELETE
    Jul 10 09:19:56.988: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jul 10 09:19:56.988: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Jul 10 09:19:56.995: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jul 10 09:19:56.995: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=PATCH
    Jul 10 09:19:57.003: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jul 10 09:19:57.003: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=POST
    Jul 10 09:19:57.011: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jul 10 09:19:57.011: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=PUT
    Jul 10 09:19:57.018: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jul 10 09:19:57.018: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=GET
    Jul 10 09:19:57.022: INFO: http.Client request:GET StatusCode:301
    Jul 10 09:19:57.022: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=GET
    Jul 10 09:19:57.028: INFO: http.Client request:GET StatusCode:301
    Jul 10 09:19:57.028: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/pods/agnhost/proxy?method=HEAD
    Jul 10 09:19:57.031: INFO: http.Client request:HEAD StatusCode:301
    Jul 10 09:19:57.031: INFO: Starting http.Client for https://192.168.0.1:443/api/v1/namespaces/proxy-3564/services/e2e-proxy-test-service/proxy?method=HEAD
    Jul 10 09:19:57.037: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jul 10 09:19:57.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3564" for this suite. 07/10/23 09:19:57.041
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:19:57.054
Jul 10 09:19:57.054: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename kubelet-test 07/10/23 09:19:57.055
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:57.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:19:57.089
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jul 10 09:20:01.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2150" for this suite. 07/10/23 09:20:01.125
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":316,"skipped":5816,"failed":0}
------------------------------
• [4.083 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:19:57.054
    Jul 10 09:19:57.054: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename kubelet-test 07/10/23 09:19:57.055
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:19:57.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:19:57.089
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jul 10 09:20:01.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2150" for this suite. 07/10/23 09:20:01.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:01.138
Jul 10 09:20:01.139: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 09:20:01.139
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:01.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:01.17
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 07/10/23 09:20:01.172
Jul 10 09:20:01.190: INFO: Waiting up to 5m0s for pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b" in namespace "var-expansion-7858" to be "Succeeded or Failed"
Jul 10 09:20:01.195: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051958ms
Jul 10 09:20:03.200: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010601424s
Jul 10 09:20:05.205: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014975913s
STEP: Saw pod success 07/10/23 09:20:05.205
Jul 10 09:20:05.205: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b" satisfied condition "Succeeded or Failed"
Jul 10 09:20:05.209: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b container dapi-container: <nil>
STEP: delete the pod 07/10/23 09:20:05.221
Jul 10 09:20:05.251: INFO: Waiting for pod var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b to disappear
Jul 10 09:20:05.255: INFO: Pod var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 09:20:05.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7858" for this suite. 07/10/23 09:20:05.259
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":317,"skipped":5835,"failed":0}
------------------------------
• [4.133 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:01.138
    Jul 10 09:20:01.139: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 09:20:01.139
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:01.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:01.17
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 07/10/23 09:20:01.172
    Jul 10 09:20:01.190: INFO: Waiting up to 5m0s for pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b" in namespace "var-expansion-7858" to be "Succeeded or Failed"
    Jul 10 09:20:01.195: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051958ms
    Jul 10 09:20:03.200: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010601424s
    Jul 10 09:20:05.205: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014975913s
    STEP: Saw pod success 07/10/23 09:20:05.205
    Jul 10 09:20:05.205: INFO: Pod "var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b" satisfied condition "Succeeded or Failed"
    Jul 10 09:20:05.209: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b container dapi-container: <nil>
    STEP: delete the pod 07/10/23 09:20:05.221
    Jul 10 09:20:05.251: INFO: Waiting for pod var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b to disappear
    Jul 10 09:20:05.255: INFO: Pod var-expansion-2aa5d9e3-0bfb-46d2-9d11-cf1fff62159b no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 09:20:05.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7858" for this suite. 07/10/23 09:20:05.259
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:05.272
Jul 10 09:20:05.272: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename svcaccounts 07/10/23 09:20:05.273
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:05.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:05.304
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Jul 10 09:20:05.341: INFO: created pod pod-service-account-defaultsa
Jul 10 09:20:05.341: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul 10 09:20:05.355: INFO: created pod pod-service-account-mountsa
Jul 10 09:20:05.355: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul 10 09:20:05.379: INFO: created pod pod-service-account-nomountsa
Jul 10 09:20:05.379: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul 10 09:20:05.390: INFO: created pod pod-service-account-defaultsa-mountspec
Jul 10 09:20:05.390: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul 10 09:20:05.407: INFO: created pod pod-service-account-mountsa-mountspec
Jul 10 09:20:05.407: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul 10 09:20:05.466: INFO: created pod pod-service-account-nomountsa-mountspec
Jul 10 09:20:05.466: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul 10 09:20:05.498: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul 10 09:20:05.498: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul 10 09:20:05.522: INFO: created pod pod-service-account-mountsa-nomountspec
Jul 10 09:20:05.522: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul 10 09:20:05.552: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul 10 09:20:05.552: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jul 10 09:20:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-905" for this suite. 07/10/23 09:20:05.573
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":318,"skipped":5837,"failed":0}
------------------------------
• [0.339 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:05.272
    Jul 10 09:20:05.272: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename svcaccounts 07/10/23 09:20:05.273
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:05.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:05.304
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Jul 10 09:20:05.341: INFO: created pod pod-service-account-defaultsa
    Jul 10 09:20:05.341: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Jul 10 09:20:05.355: INFO: created pod pod-service-account-mountsa
    Jul 10 09:20:05.355: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Jul 10 09:20:05.379: INFO: created pod pod-service-account-nomountsa
    Jul 10 09:20:05.379: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Jul 10 09:20:05.390: INFO: created pod pod-service-account-defaultsa-mountspec
    Jul 10 09:20:05.390: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Jul 10 09:20:05.407: INFO: created pod pod-service-account-mountsa-mountspec
    Jul 10 09:20:05.407: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Jul 10 09:20:05.466: INFO: created pod pod-service-account-nomountsa-mountspec
    Jul 10 09:20:05.466: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Jul 10 09:20:05.498: INFO: created pod pod-service-account-defaultsa-nomountspec
    Jul 10 09:20:05.498: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Jul 10 09:20:05.522: INFO: created pod pod-service-account-mountsa-nomountspec
    Jul 10 09:20:05.522: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Jul 10 09:20:05.552: INFO: created pod pod-service-account-nomountsa-nomountspec
    Jul 10 09:20:05.552: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jul 10 09:20:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-905" for this suite. 07/10/23 09:20:05.573
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:05.611
Jul 10 09:20:05.612: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:20:05.613
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:05.677
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:05.681
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:20:05.684
Jul 10 09:20:05.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a" in namespace "downward-api-1107" to be "Succeeded or Failed"
Jul 10 09:20:05.706: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.712159ms
Jul 10 09:20:07.711: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010060221s
Jul 10 09:20:09.711: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010124677s
Jul 10 09:20:11.716: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014792863s
STEP: Saw pod success 07/10/23 09:20:11.716
Jul 10 09:20:11.716: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a" satisfied condition "Succeeded or Failed"
Jul 10 09:20:11.727: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a container client-container: <nil>
STEP: delete the pod 07/10/23 09:20:11.737
Jul 10 09:20:11.791: INFO: Waiting for pod downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a to disappear
Jul 10 09:20:11.796: INFO: Pod downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 09:20:11.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1107" for this suite. 07/10/23 09:20:11.8
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":319,"skipped":5851,"failed":0}
------------------------------
• [SLOW TEST] [6.210 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:05.611
    Jul 10 09:20:05.612: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:20:05.613
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:05.677
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:05.681
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:20:05.684
    Jul 10 09:20:05.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a" in namespace "downward-api-1107" to be "Succeeded or Failed"
    Jul 10 09:20:05.706: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.712159ms
    Jul 10 09:20:07.711: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010060221s
    Jul 10 09:20:09.711: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010124677s
    Jul 10 09:20:11.716: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014792863s
    STEP: Saw pod success 07/10/23 09:20:11.716
    Jul 10 09:20:11.716: INFO: Pod "downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a" satisfied condition "Succeeded or Failed"
    Jul 10 09:20:11.727: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a container client-container: <nil>
    STEP: delete the pod 07/10/23 09:20:11.737
    Jul 10 09:20:11.791: INFO: Waiting for pod downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a to disappear
    Jul 10 09:20:11.796: INFO: Pod downwardapi-volume-ec7aa955-4b01-4ca5-8d25-c0e5ee23a46a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 09:20:11.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1107" for this suite. 07/10/23 09:20:11.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:11.822
Jul 10 09:20:11.822: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename services 07/10/23 09:20:11.823
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:11.86
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:11.864
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
STEP: creating a Service 07/10/23 09:20:11.87
STEP: watching for the Service to be added 07/10/23 09:20:11.977
Jul 10 09:20:11.980: INFO: Found Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Jul 10 09:20:11.981: INFO: Service test-service-zhzf9 created
STEP: Getting /status 07/10/23 09:20:11.981
Jul 10 09:20:12.009: INFO: Service test-service-zhzf9 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 07/10/23 09:20:12.009
STEP: watching for the Service to be patched 07/10/23 09:20:12.024
Jul 10 09:20:12.026: INFO: observed Service test-service-zhzf9 in namespace services-295 with annotations: map[] & LoadBalancer: {[]}
Jul 10 09:20:12.027: INFO: Found Service test-service-zhzf9 in namespace services-295 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Jul 10 09:20:12.027: INFO: Service test-service-zhzf9 has service status patched
STEP: updating the ServiceStatus 07/10/23 09:20:12.027
Jul 10 09:20:12.055: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 07/10/23 09:20:12.055
Jul 10 09:20:12.058: INFO: Observed Service test-service-zhzf9 in namespace services-295 with annotations: map[] & Conditions: {[]}
Jul 10 09:20:12.058: INFO: Observed event: &Service{ObjectMeta:{test-service-zhzf9  services-295  19110ba3-bb4d-4b76-bc16-39f5ffcd64e7 105990 0 2023-07-10 09:20:11 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-07-10 09:20:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-07-10 09:20:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:192.168.208.105,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[192.168.208.105],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Jul 10 09:20:12.058: INFO: Found Service test-service-zhzf9 in namespace services-295 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul 10 09:20:12.058: INFO: Service test-service-zhzf9 has service status updated
STEP: patching the service 07/10/23 09:20:12.058
STEP: watching for the Service to be patched 07/10/23 09:20:12.077
Jul 10 09:20:12.078: INFO: observed Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true]
Jul 10 09:20:12.078: INFO: observed Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true]
Jul 10 09:20:12.078: INFO: observed Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true]
Jul 10 09:20:12.079: INFO: Found Service test-service-zhzf9 in namespace services-295 with labels: map[test-service:patched test-service-static:true]
Jul 10 09:20:12.079: INFO: Service test-service-zhzf9 patched
STEP: deleting the service 07/10/23 09:20:12.079
STEP: watching for the Service to be deleted 07/10/23 09:20:12.111
Jul 10 09:20:12.112: INFO: Observed event: ADDED
Jul 10 09:20:12.112: INFO: Observed event: MODIFIED
Jul 10 09:20:12.113: INFO: Observed event: MODIFIED
Jul 10 09:20:12.113: INFO: Observed event: MODIFIED
Jul 10 09:20:12.113: INFO: Found Service test-service-zhzf9 in namespace services-295 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Jul 10 09:20:12.113: INFO: Service test-service-zhzf9 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jul 10 09:20:12.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-295" for this suite. 07/10/23 09:20:12.117
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":320,"skipped":5856,"failed":0}
------------------------------
• [0.308 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:11.822
    Jul 10 09:20:11.822: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename services 07/10/23 09:20:11.823
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:11.86
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:11.864
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3394
    STEP: creating a Service 07/10/23 09:20:11.87
    STEP: watching for the Service to be added 07/10/23 09:20:11.977
    Jul 10 09:20:11.980: INFO: Found Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Jul 10 09:20:11.981: INFO: Service test-service-zhzf9 created
    STEP: Getting /status 07/10/23 09:20:11.981
    Jul 10 09:20:12.009: INFO: Service test-service-zhzf9 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 07/10/23 09:20:12.009
    STEP: watching for the Service to be patched 07/10/23 09:20:12.024
    Jul 10 09:20:12.026: INFO: observed Service test-service-zhzf9 in namespace services-295 with annotations: map[] & LoadBalancer: {[]}
    Jul 10 09:20:12.027: INFO: Found Service test-service-zhzf9 in namespace services-295 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Jul 10 09:20:12.027: INFO: Service test-service-zhzf9 has service status patched
    STEP: updating the ServiceStatus 07/10/23 09:20:12.027
    Jul 10 09:20:12.055: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 07/10/23 09:20:12.055
    Jul 10 09:20:12.058: INFO: Observed Service test-service-zhzf9 in namespace services-295 with annotations: map[] & Conditions: {[]}
    Jul 10 09:20:12.058: INFO: Observed event: &Service{ObjectMeta:{test-service-zhzf9  services-295  19110ba3-bb4d-4b76-bc16-39f5ffcd64e7 105990 0 2023-07-10 09:20:11 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-07-10 09:20:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-07-10 09:20:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:192.168.208.105,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[192.168.208.105],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Jul 10 09:20:12.058: INFO: Found Service test-service-zhzf9 in namespace services-295 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jul 10 09:20:12.058: INFO: Service test-service-zhzf9 has service status updated
    STEP: patching the service 07/10/23 09:20:12.058
    STEP: watching for the Service to be patched 07/10/23 09:20:12.077
    Jul 10 09:20:12.078: INFO: observed Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true]
    Jul 10 09:20:12.078: INFO: observed Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true]
    Jul 10 09:20:12.078: INFO: observed Service test-service-zhzf9 in namespace services-295 with labels: map[test-service-static:true]
    Jul 10 09:20:12.079: INFO: Found Service test-service-zhzf9 in namespace services-295 with labels: map[test-service:patched test-service-static:true]
    Jul 10 09:20:12.079: INFO: Service test-service-zhzf9 patched
    STEP: deleting the service 07/10/23 09:20:12.079
    STEP: watching for the Service to be deleted 07/10/23 09:20:12.111
    Jul 10 09:20:12.112: INFO: Observed event: ADDED
    Jul 10 09:20:12.112: INFO: Observed event: MODIFIED
    Jul 10 09:20:12.113: INFO: Observed event: MODIFIED
    Jul 10 09:20:12.113: INFO: Observed event: MODIFIED
    Jul 10 09:20:12.113: INFO: Found Service test-service-zhzf9 in namespace services-295 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Jul 10 09:20:12.113: INFO: Service test-service-zhzf9 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jul 10 09:20:12.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-295" for this suite. 07/10/23 09:20:12.117
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:12.132
Jul 10 09:20:12.132: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename podtemplate 07/10/23 09:20:12.133
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:12.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:12.175
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 07/10/23 09:20:12.177
STEP: Replace a pod template 07/10/23 09:20:12.188
Jul 10 09:20:12.199: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jul 10 09:20:12.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-4263" for this suite. 07/10/23 09:20:12.208
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":321,"skipped":5880,"failed":0}
------------------------------
• [0.086 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:12.132
    Jul 10 09:20:12.132: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename podtemplate 07/10/23 09:20:12.133
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:12.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:12.175
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 07/10/23 09:20:12.177
    STEP: Replace a pod template 07/10/23 09:20:12.188
    Jul 10 09:20:12.199: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jul 10 09:20:12.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-4263" for this suite. 07/10/23 09:20:12.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:12.219
Jul 10 09:20:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename deployment 07/10/23 09:20:12.221
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:12.251
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:12.254
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Jul 10 09:20:12.280: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul 10 09:20:17.287: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 07/10/23 09:20:17.287
Jul 10 09:20:17.287: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul 10 09:20:19.294: INFO: Creating deployment "test-rollover-deployment"
Jul 10 09:20:19.310: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul 10 09:20:21.321: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul 10 09:20:21.330: INFO: Ensure that both replica sets have 1 created replica
Jul 10 09:20:21.341: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul 10 09:20:21.357: INFO: Updating deployment test-rollover-deployment
Jul 10 09:20:21.357: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul 10 09:20:23.369: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul 10 09:20:23.379: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul 10 09:20:23.388: INFO: all replica sets need to contain the pod-template-hash label
Jul 10 09:20:23.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:20:25.399: INFO: all replica sets need to contain the pod-template-hash label
Jul 10 09:20:25.399: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:20:27.403: INFO: all replica sets need to contain the pod-template-hash label
Jul 10 09:20:27.403: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:20:29.396: INFO: all replica sets need to contain the pod-template-hash label
Jul 10 09:20:29.397: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:20:31.400: INFO: all replica sets need to contain the pod-template-hash label
Jul 10 09:20:31.400: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 10 09:20:33.406: INFO: 
Jul 10 09:20:33.406: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul 10 09:20:33.417: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7082  5330671e-5784-4011-ac1d-5b59be432c9c 106170 2 2023-07-10 09:20:19 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-07-10 09:20:19 +0000 UTC,LastTransitionTime:2023-07-10 09:20:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-07-10 09:20:33 +0000 UTC,LastTransitionTime:2023-07-10 09:20:19 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul 10 09:20:33.420: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7082  c658538f-e7d0-4dbd-9208-b016dca066f5 106159 2 2023-07-10 09:20:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5330671e-5784-4011-ac1d-5b59be432c9c 0xc003512a77 0xc003512a78}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5330671e-5784-4011-ac1d-5b59be432c9c\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:20:33.420: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul 10 09:20:33.421: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7082  d83db701-709a-4300-a423-fba80a3716bf 106169 2 2023-07-10 09:20:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5330671e-5784-4011-ac1d-5b59be432c9c 0xc003512827 0xc003512828}] [] [{e2e.test Update apps/v1 2023-07-10 09:20:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5330671e-5784-4011-ac1d-5b59be432c9c\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0035128e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:20:33.421: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7082  f3c063b1-d850-4953-8c22-4989542cd3dc 106106 2 2023-07-10 09:20:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5330671e-5784-4011-ac1d-5b59be432c9c 0xc003512957 0xc003512958}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5330671e-5784-4011-ac1d-5b59be432c9c\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul 10 09:20:33.425: INFO: Pod "test-rollover-deployment-6d45fd857b-cr8jm" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-cr8jm test-rollover-deployment-6d45fd857b- deployment-7082  3bef5bec-8a81-413d-a688-c34ed175974f 106124 0 2023-07-10 09:20:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:34ec7b5d93a61351fec5d7bafa4c23d994fc5a9607535af01aec57e189c2c1d1 cni.projectcalico.org/podIP:192.168.172.40/32 cni.projectcalico.org/podIPs:192.168.172.40/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b c658538f-e7d0-4dbd-9208-b016dca066f5 0xc0039c36b7 0xc0039c36b8}] [] [{calico Update v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c658538f-e7d0-4dbd-9208-b016dca066f5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:20:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cks8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cks8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.40,StartTime:2023-07-10 09:20:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:20:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://739e18f74b4af6b6f5ba88a8c5fcab40a41256fd2c0d272bc3fbae1bd369eb29,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jul 10 09:20:33.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7082" for this suite. 07/10/23 09:20:33.429
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":322,"skipped":5890,"failed":0}
------------------------------
• [SLOW TEST] [21.224 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:12.219
    Jul 10 09:20:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename deployment 07/10/23 09:20:12.221
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:12.251
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:12.254
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Jul 10 09:20:12.280: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Jul 10 09:20:17.287: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 07/10/23 09:20:17.287
    Jul 10 09:20:17.287: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Jul 10 09:20:19.294: INFO: Creating deployment "test-rollover-deployment"
    Jul 10 09:20:19.310: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Jul 10 09:20:21.321: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Jul 10 09:20:21.330: INFO: Ensure that both replica sets have 1 created replica
    Jul 10 09:20:21.341: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Jul 10 09:20:21.357: INFO: Updating deployment test-rollover-deployment
    Jul 10 09:20:21.357: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Jul 10 09:20:23.369: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Jul 10 09:20:23.379: INFO: Make sure deployment "test-rollover-deployment" is complete
    Jul 10 09:20:23.388: INFO: all replica sets need to contain the pod-template-hash label
    Jul 10 09:20:23.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:20:25.399: INFO: all replica sets need to contain the pod-template-hash label
    Jul 10 09:20:25.399: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:20:27.403: INFO: all replica sets need to contain the pod-template-hash label
    Jul 10 09:20:27.403: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:20:29.396: INFO: all replica sets need to contain the pod-template-hash label
    Jul 10 09:20:29.397: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:20:31.400: INFO: all replica sets need to contain the pod-template-hash label
    Jul 10 09:20:31.400: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.July, 10, 9, 20, 22, 0, time.Local), LastTransitionTime:time.Date(2023, time.July, 10, 9, 20, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jul 10 09:20:33.406: INFO: 
    Jul 10 09:20:33.406: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jul 10 09:20:33.417: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7082  5330671e-5784-4011-ac1d-5b59be432c9c 106170 2 2023-07-10 09:20:19 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-07-10 09:20:19 +0000 UTC,LastTransitionTime:2023-07-10 09:20:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-07-10 09:20:33 +0000 UTC,LastTransitionTime:2023-07-10 09:20:19 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jul 10 09:20:33.420: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7082  c658538f-e7d0-4dbd-9208-b016dca066f5 106159 2 2023-07-10 09:20:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5330671e-5784-4011-ac1d-5b59be432c9c 0xc003512a77 0xc003512a78}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5330671e-5784-4011-ac1d-5b59be432c9c\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:20:33.420: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Jul 10 09:20:33.421: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7082  d83db701-709a-4300-a423-fba80a3716bf 106169 2 2023-07-10 09:20:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5330671e-5784-4011-ac1d-5b59be432c9c 0xc003512827 0xc003512828}] [] [{e2e.test Update apps/v1 2023-07-10 09:20:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5330671e-5784-4011-ac1d-5b59be432c9c\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0035128e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:20:33.421: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7082  f3c063b1-d850-4953-8c22-4989542cd3dc 106106 2 2023-07-10 09:20:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5330671e-5784-4011-ac1d-5b59be432c9c 0xc003512957 0xc003512958}] [] [{kube-controller-manager Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5330671e-5784-4011-ac1d-5b59be432c9c\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003512a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jul 10 09:20:33.425: INFO: Pod "test-rollover-deployment-6d45fd857b-cr8jm" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-cr8jm test-rollover-deployment-6d45fd857b- deployment-7082  3bef5bec-8a81-413d-a688-c34ed175974f 106124 0 2023-07-10 09:20:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:34ec7b5d93a61351fec5d7bafa4c23d994fc5a9607535af01aec57e189c2c1d1 cni.projectcalico.org/podIP:192.168.172.40/32 cni.projectcalico.org/podIPs:192.168.172.40/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b c658538f-e7d0-4dbd-9208-b016dca066f5 0xc0039c36b7 0xc0039c36b8}] [] [{calico Update v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-07-10 09:20:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c658538f-e7d0-4dbd-9208-b016dca066f5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-07-10 09:20:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.172.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cks8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cks8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10-62-109-100.test,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-07-10 09:20:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.62.109.100,PodIP:192.168.172.40,StartTime:2023-07-10 09:20:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-07-10 09:20:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:docker://739e18f74b4af6b6f5ba88a8c5fcab40a41256fd2c0d272bc3fbae1bd369eb29,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.172.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jul 10 09:20:33.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7082" for this suite. 07/10/23 09:20:33.429
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:33.444
Jul 10 09:20:33.444: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename security-context-test 07/10/23 09:20:33.445
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:33.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:33.488
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Jul 10 09:20:33.502: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c" in namespace "security-context-test-1023" to be "Succeeded or Failed"
Jul 10 09:20:33.507: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095219ms
Jul 10 09:20:35.513: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011006725s
Jul 10 09:20:37.513: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011362607s
Jul 10 09:20:37.513: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jul 10 09:20:37.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1023" for this suite. 07/10/23 09:20:37.518
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":323,"skipped":5890,"failed":0}
------------------------------
• [4.084 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:33.444
    Jul 10 09:20:33.444: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename security-context-test 07/10/23 09:20:33.445
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:33.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:33.488
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Jul 10 09:20:33.502: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c" in namespace "security-context-test-1023" to be "Succeeded or Failed"
    Jul 10 09:20:33.507: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.095219ms
    Jul 10 09:20:35.513: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011006725s
    Jul 10 09:20:37.513: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011362607s
    Jul 10 09:20:37.513: INFO: Pod "busybox-readonly-false-1fb79bca-9003-4b37-bd65-20e8d4cb881c" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jul 10 09:20:37.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1023" for this suite. 07/10/23 09:20:37.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:37.533
Jul 10 09:20:37.533: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename watch 07/10/23 09:20:37.535
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:37.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:37.566
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 07/10/23 09:20:37.569
STEP: creating a new configmap 07/10/23 09:20:37.57
STEP: modifying the configmap once 07/10/23 09:20:37.578
STEP: closing the watch once it receives two notifications 07/10/23 09:20:37.588
Jul 10 09:20:37.588: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106209 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 09:20:37.589: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106210 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 07/10/23 09:20:37.589
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 07/10/23 09:20:37.6
STEP: deleting the configmap 07/10/23 09:20:37.601
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 07/10/23 09:20:37.61
Jul 10 09:20:37.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106211 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul 10 09:20:37.612: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106212 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jul 10 09:20:37.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-450" for this suite. 07/10/23 09:20:37.616
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":324,"skipped":5966,"failed":0}
------------------------------
• [0.092 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:37.533
    Jul 10 09:20:37.533: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename watch 07/10/23 09:20:37.535
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:37.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:37.566
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 07/10/23 09:20:37.569
    STEP: creating a new configmap 07/10/23 09:20:37.57
    STEP: modifying the configmap once 07/10/23 09:20:37.578
    STEP: closing the watch once it receives two notifications 07/10/23 09:20:37.588
    Jul 10 09:20:37.588: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106209 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 09:20:37.589: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106210 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 07/10/23 09:20:37.589
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 07/10/23 09:20:37.6
    STEP: deleting the configmap 07/10/23 09:20:37.601
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 07/10/23 09:20:37.61
    Jul 10 09:20:37.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106211 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jul 10 09:20:37.612: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-450  267e2186-0887-44c9-a844-fb23bb0addf2 106212 0 2023-07-10 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-07-10 09:20:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jul 10 09:20:37.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-450" for this suite. 07/10/23 09:20:37.616
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:37.626
Jul 10 09:20:37.626: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-runtime 07/10/23 09:20:37.627
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:37.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:37.652
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 07/10/23 09:20:37.655
STEP: wait for the container to reach Succeeded 07/10/23 09:20:37.67
STEP: get the container status 07/10/23 09:20:41.709
STEP: the container should be terminated 07/10/23 09:20:41.713
STEP: the termination message should be set 07/10/23 09:20:41.713
Jul 10 09:20:41.713: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 07/10/23 09:20:41.713
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jul 10 09:20:41.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6049" for this suite. 07/10/23 09:20:41.751
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":325,"skipped":5967,"failed":0}
------------------------------
• [4.141 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:37.626
    Jul 10 09:20:37.626: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-runtime 07/10/23 09:20:37.627
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:37.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:37.652
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 07/10/23 09:20:37.655
    STEP: wait for the container to reach Succeeded 07/10/23 09:20:37.67
    STEP: get the container status 07/10/23 09:20:41.709
    STEP: the container should be terminated 07/10/23 09:20:41.713
    STEP: the termination message should be set 07/10/23 09:20:41.713
    Jul 10 09:20:41.713: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 07/10/23 09:20:41.713
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jul 10 09:20:41.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6049" for this suite. 07/10/23 09:20:41.751
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:41.768
Jul 10 09:20:41.768: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:20:41.769
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:41.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:41.803
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Jul 10 09:20:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 07/10/23 09:20:44.988
Jul 10 09:20:44.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 create -f -'
Jul 10 09:20:45.913: INFO: stderr: ""
Jul 10 09:20:45.913: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jul 10 09:20:45.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 delete e2e-test-crd-publish-openapi-457-crds test-cr'
Jul 10 09:20:45.995: INFO: stderr: ""
Jul 10 09:20:45.995: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jul 10 09:20:45.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 apply -f -'
Jul 10 09:20:46.636: INFO: stderr: ""
Jul 10 09:20:46.636: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jul 10 09:20:46.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 delete e2e-test-crd-publish-openapi-457-crds test-cr'
Jul 10 09:20:46.750: INFO: stderr: ""
Jul 10 09:20:46.750: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 07/10/23 09:20:46.75
Jul 10 09:20:46.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 explain e2e-test-crd-publish-openapi-457-crds'
Jul 10 09:20:47.349: INFO: stderr: ""
Jul 10 09:20:47.349: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-457-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:20:50.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8695" for this suite. 07/10/23 09:20:50.41
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":326,"skipped":5977,"failed":0}
------------------------------
• [SLOW TEST] [8.671 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:41.768
    Jul 10 09:20:41.768: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:20:41.769
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:41.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:41.803
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Jul 10 09:20:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 07/10/23 09:20:44.988
    Jul 10 09:20:44.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 create -f -'
    Jul 10 09:20:45.913: INFO: stderr: ""
    Jul 10 09:20:45.913: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Jul 10 09:20:45.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 delete e2e-test-crd-publish-openapi-457-crds test-cr'
    Jul 10 09:20:45.995: INFO: stderr: ""
    Jul 10 09:20:45.995: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Jul 10 09:20:45.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 apply -f -'
    Jul 10 09:20:46.636: INFO: stderr: ""
    Jul 10 09:20:46.636: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Jul 10 09:20:46.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 --namespace=crd-publish-openapi-8695 delete e2e-test-crd-publish-openapi-457-crds test-cr'
    Jul 10 09:20:46.750: INFO: stderr: ""
    Jul 10 09:20:46.750: INFO: stdout: "e2e-test-crd-publish-openapi-457-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 07/10/23 09:20:46.75
    Jul 10 09:20:46.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=crd-publish-openapi-8695 explain e2e-test-crd-publish-openapi-457-crds'
    Jul 10 09:20:47.349: INFO: stderr: ""
    Jul 10 09:20:47.349: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-457-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:20:50.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8695" for this suite. 07/10/23 09:20:50.41
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:50.442
Jul 10 09:20:50.442: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 09:20:50.443
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:50.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:50.47
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 09:20:50.559
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:20:50.956
STEP: Deploying the webhook pod 07/10/23 09:20:50.968
STEP: Wait for the deployment to be ready 07/10/23 09:20:50.989
Jul 10 09:20:50.996: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 07/10/23 09:20:53.024
STEP: Verifying the service has paired with the endpoint 07/10/23 09:20:53.05
Jul 10 09:20:54.051: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Jul 10 09:20:54.055: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2067-crds.webhook.example.com via the AdmissionRegistration API 07/10/23 09:20:54.569
STEP: Creating a custom resource that should be mutated by the webhook 07/10/23 09:20:54.591
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:20:57.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9456" for this suite. 07/10/23 09:20:57.249
STEP: Destroying namespace "webhook-9456-markers" for this suite. 07/10/23 09:20:57.475
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":327,"skipped":6015,"failed":0}
------------------------------
• [SLOW TEST] [7.157 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:50.442
    Jul 10 09:20:50.442: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 09:20:50.443
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:50.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:50.47
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 09:20:50.559
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:20:50.956
    STEP: Deploying the webhook pod 07/10/23 09:20:50.968
    STEP: Wait for the deployment to be ready 07/10/23 09:20:50.989
    Jul 10 09:20:50.996: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 07/10/23 09:20:53.024
    STEP: Verifying the service has paired with the endpoint 07/10/23 09:20:53.05
    Jul 10 09:20:54.051: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Jul 10 09:20:54.055: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2067-crds.webhook.example.com via the AdmissionRegistration API 07/10/23 09:20:54.569
    STEP: Creating a custom resource that should be mutated by the webhook 07/10/23 09:20:54.591
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:20:57.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9456" for this suite. 07/10/23 09:20:57.249
    STEP: Destroying namespace "webhook-9456-markers" for this suite. 07/10/23 09:20:57.475
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:20:57.602
Jul 10 09:20:57.602: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename endpointslicemirroring 07/10/23 09:20:57.603
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:57.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:57.655
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 07/10/23 09:20:57.7
Jul 10 09:20:57.713: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 07/10/23 09:20:59.718
Jul 10 09:20:59.731: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 07/10/23 09:21:01.736
Jul 10 09:21:01.755: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Jul 10 09:21:03.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-9425" for this suite. 07/10/23 09:21:03.767
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":328,"skipped":6072,"failed":0}
------------------------------
• [SLOW TEST] [6.179 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:20:57.602
    Jul 10 09:20:57.602: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename endpointslicemirroring 07/10/23 09:20:57.603
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:20:57.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:20:57.655
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 07/10/23 09:20:57.7
    Jul 10 09:20:57.713: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 07/10/23 09:20:59.718
    Jul 10 09:20:59.731: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 07/10/23 09:21:01.736
    Jul 10 09:21:01.755: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Jul 10 09:21:03.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-9425" for this suite. 07/10/23 09:21:03.767
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:21:03.783
Jul 10 09:21:03.783: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename hostport 07/10/23 09:21:03.784
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:21:03.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:21:03.816
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 07/10/23 09:21:03.822
Jul 10 09:21:03.853: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1653" to be "running and ready"
Jul 10 09:21:03.857: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.264517ms
Jul 10 09:21:03.858: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:21:05.863: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009491994s
Jul 10 09:21:05.863: INFO: The phase of Pod pod1 is Running (Ready = true)
Jul 10 09:21:05.863: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.62.109.102 on the node which pod1 resides and expect scheduled 07/10/23 09:21:05.863
Jul 10 09:21:05.874: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1653" to be "running and ready"
Jul 10 09:21:05.880: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.613504ms
Jul 10 09:21:05.880: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:21:07.886: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011613045s
Jul 10 09:21:07.886: INFO: The phase of Pod pod2 is Running (Ready = false)
Jul 10 09:21:09.884: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.010128252s
Jul 10 09:21:09.884: INFO: The phase of Pod pod2 is Running (Ready = true)
Jul 10 09:21:09.884: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.62.109.102 but use UDP protocol on the node which pod2 resides 07/10/23 09:21:09.884
Jul 10 09:21:09.892: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1653" to be "running and ready"
Jul 10 09:21:09.896: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.521175ms
Jul 10 09:21:09.896: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:21:11.901: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008846039s
Jul 10 09:21:11.901: INFO: The phase of Pod pod3 is Running (Ready = false)
Jul 10 09:21:13.902: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.009844827s
Jul 10 09:21:13.902: INFO: The phase of Pod pod3 is Running (Ready = true)
Jul 10 09:21:13.902: INFO: Pod "pod3" satisfied condition "running and ready"
Jul 10 09:21:13.911: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1653" to be "running and ready"
Jul 10 09:21:13.915: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.318058ms
Jul 10 09:21:13.915: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:21:15.921: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.010690188s
Jul 10 09:21:15.921: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Jul 10 09:21:15.921: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 07/10/23 09:21:15.926
Jul 10 09:21:15.926: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.62.109.102 http://127.0.0.1:54323/hostname] Namespace:hostport-1653 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:21:15.926: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:21:15.927: INFO: ExecWithOptions: Clientset creation
Jul 10 09:21:15.927: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/hostport-1653/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.62.109.102+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.62.109.102, port: 54323 07/10/23 09:21:16.011
Jul 10 09:21:16.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.62.109.102:54323/hostname] Namespace:hostport-1653 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:21:16.011: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:21:16.012: INFO: ExecWithOptions: Clientset creation
Jul 10 09:21:16.012: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/hostport-1653/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.62.109.102%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.62.109.102, port: 54323 UDP 07/10/23 09:21:16.109
Jul 10 09:21:16.109: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.62.109.102 54323] Namespace:hostport-1653 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul 10 09:21:16.109: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:21:16.109: INFO: ExecWithOptions: Clientset creation
Jul 10 09:21:16.109: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/hostport-1653/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.62.109.102+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Jul 10 09:21:21.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-1653" for this suite. 07/10/23 09:21:21.206
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":329,"skipped":6096,"failed":0}
------------------------------
• [SLOW TEST] [17.433 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:21:03.783
    Jul 10 09:21:03.783: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename hostport 07/10/23 09:21:03.784
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:21:03.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:21:03.816
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 07/10/23 09:21:03.822
    Jul 10 09:21:03.853: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1653" to be "running and ready"
    Jul 10 09:21:03.857: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.264517ms
    Jul 10 09:21:03.858: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:21:05.863: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009491994s
    Jul 10 09:21:05.863: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jul 10 09:21:05.863: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.62.109.102 on the node which pod1 resides and expect scheduled 07/10/23 09:21:05.863
    Jul 10 09:21:05.874: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1653" to be "running and ready"
    Jul 10 09:21:05.880: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.613504ms
    Jul 10 09:21:05.880: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:21:07.886: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011613045s
    Jul 10 09:21:07.886: INFO: The phase of Pod pod2 is Running (Ready = false)
    Jul 10 09:21:09.884: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.010128252s
    Jul 10 09:21:09.884: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jul 10 09:21:09.884: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.62.109.102 but use UDP protocol on the node which pod2 resides 07/10/23 09:21:09.884
    Jul 10 09:21:09.892: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1653" to be "running and ready"
    Jul 10 09:21:09.896: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.521175ms
    Jul 10 09:21:09.896: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:21:11.901: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008846039s
    Jul 10 09:21:11.901: INFO: The phase of Pod pod3 is Running (Ready = false)
    Jul 10 09:21:13.902: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.009844827s
    Jul 10 09:21:13.902: INFO: The phase of Pod pod3 is Running (Ready = true)
    Jul 10 09:21:13.902: INFO: Pod "pod3" satisfied condition "running and ready"
    Jul 10 09:21:13.911: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1653" to be "running and ready"
    Jul 10 09:21:13.915: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.318058ms
    Jul 10 09:21:13.915: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:21:15.921: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.010690188s
    Jul 10 09:21:15.921: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Jul 10 09:21:15.921: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 07/10/23 09:21:15.926
    Jul 10 09:21:15.926: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.62.109.102 http://127.0.0.1:54323/hostname] Namespace:hostport-1653 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:21:15.926: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:21:15.927: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:21:15.927: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/hostport-1653/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.62.109.102+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.62.109.102, port: 54323 07/10/23 09:21:16.011
    Jul 10 09:21:16.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.62.109.102:54323/hostname] Namespace:hostport-1653 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:21:16.011: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:21:16.012: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:21:16.012: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/hostport-1653/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.62.109.102%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.62.109.102, port: 54323 UDP 07/10/23 09:21:16.109
    Jul 10 09:21:16.109: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.62.109.102 54323] Namespace:hostport-1653 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jul 10 09:21:16.109: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:21:16.109: INFO: ExecWithOptions: Clientset creation
    Jul 10 09:21:16.109: INFO: ExecWithOptions: execute(POST https://192.168.0.1:443/api/v1/namespaces/hostport-1653/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.62.109.102+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Jul 10 09:21:21.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-1653" for this suite. 07/10/23 09:21:21.206
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:21:21.218
Jul 10 09:21:21.218: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename endpointslice 07/10/23 09:21:21.219
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:21:21.249
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:21:21.252
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jul 10 09:21:23.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-558" for this suite. 07/10/23 09:21:23.345
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":330,"skipped":6127,"failed":0}
------------------------------
• [2.140 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:21:21.218
    Jul 10 09:21:21.218: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename endpointslice 07/10/23 09:21:21.219
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:21:21.249
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:21:21.252
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jul 10 09:21:23.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-558" for this suite. 07/10/23 09:21:23.345
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:21:23.358
Jul 10 09:21:23.358: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-preemption 07/10/23 09:21:23.359
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:21:23.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:21:23.489
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul 10 09:21:23.521: INFO: Waiting up to 1m0s for all nodes to be ready
Jul 10 09:22:23.550: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:22:23.554
Jul 10 09:22:23.554: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename sched-preemption-path 07/10/23 09:22:23.555
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:22:23.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:22:23.62
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 07/10/23 09:22:23.622
STEP: Trying to launch a pod without a label to get a node which can launch it. 07/10/23 09:22:23.622
Jul 10 09:22:23.640: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7656" to be "running"
Jul 10 09:22:23.732: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 91.62785ms
Jul 10 09:22:25.737: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.096422806s
Jul 10 09:22:25.737: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 07/10/23 09:22:25.74
Jul 10 09:22:25.766: INFO: found a healthy node: 10-62-109-100.test
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Jul 10 09:22:31.866: INFO: pods created so far: [1 1 1]
Jul 10 09:22:31.866: INFO: length of pods created so far: 3
Jul 10 09:22:33.881: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Jul 10 09:22:40.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7656" for this suite. 07/10/23 09:22:40.888
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:22:40.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2112" for this suite. 07/10/23 09:22:40.966
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":331,"skipped":6136,"failed":0}
------------------------------
• [SLOW TEST] [77.696 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:21:23.358
    Jul 10 09:21:23.358: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-preemption 07/10/23 09:21:23.359
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:21:23.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:21:23.489
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jul 10 09:21:23.521: INFO: Waiting up to 1m0s for all nodes to be ready
    Jul 10 09:22:23.550: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:22:23.554
    Jul 10 09:22:23.554: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename sched-preemption-path 07/10/23 09:22:23.555
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:22:23.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:22:23.62
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 07/10/23 09:22:23.622
    STEP: Trying to launch a pod without a label to get a node which can launch it. 07/10/23 09:22:23.622
    Jul 10 09:22:23.640: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7656" to be "running"
    Jul 10 09:22:23.732: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 91.62785ms
    Jul 10 09:22:25.737: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.096422806s
    Jul 10 09:22:25.737: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 07/10/23 09:22:25.74
    Jul 10 09:22:25.766: INFO: found a healthy node: 10-62-109-100.test
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Jul 10 09:22:31.866: INFO: pods created so far: [1 1 1]
    Jul 10 09:22:31.866: INFO: length of pods created so far: 3
    Jul 10 09:22:33.881: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Jul 10 09:22:40.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7656" for this suite. 07/10/23 09:22:40.888
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:22:40.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2112" for this suite. 07/10/23 09:22:40.966
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:22:41.055
Jul 10 09:22:41.055: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename taint-multiple-pods 07/10/23 09:22:41.056
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:22:41.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:22:41.251
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Jul 10 09:22:41.254: INFO: Waiting up to 1m0s for all nodes to be ready
Jul 10 09:23:41.277: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Jul 10 09:23:41.281: INFO: Starting informer...
STEP: Starting pods... 07/10/23 09:23:41.281
Jul 10 09:23:41.514: INFO: Pod1 is running on 10-62-109-100.test. Tainting Node
Jul 10 09:23:41.731: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4171" to be "running"
Jul 10 09:23:41.735: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.124289ms
Jul 10 09:23:43.742: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011224973s
Jul 10 09:23:43.742: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Jul 10 09:23:43.742: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4171" to be "running"
Jul 10 09:23:43.745: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.907664ms
Jul 10 09:23:43.745: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Jul 10 09:23:43.745: INFO: Pod2 is running on 10-62-109-100.test. Tainting Node
STEP: Trying to apply a taint on the Node 07/10/23 09:23:43.745
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:23:43.768
STEP: Waiting for Pod1 and Pod2 to be deleted 07/10/23 09:23:43.783
Jul 10 09:23:49.699: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jul 10 09:24:09.856: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:24:09.885
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:24:09.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4171" for this suite. 07/10/23 09:24:09.926
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":332,"skipped":6143,"failed":0}
------------------------------
• [SLOW TEST] [88.886 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:22:41.055
    Jul 10 09:22:41.055: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename taint-multiple-pods 07/10/23 09:22:41.056
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:22:41.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:22:41.251
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Jul 10 09:22:41.254: INFO: Waiting up to 1m0s for all nodes to be ready
    Jul 10 09:23:41.277: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Jul 10 09:23:41.281: INFO: Starting informer...
    STEP: Starting pods... 07/10/23 09:23:41.281
    Jul 10 09:23:41.514: INFO: Pod1 is running on 10-62-109-100.test. Tainting Node
    Jul 10 09:23:41.731: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4171" to be "running"
    Jul 10 09:23:41.735: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.124289ms
    Jul 10 09:23:43.742: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011224973s
    Jul 10 09:23:43.742: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Jul 10 09:23:43.742: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4171" to be "running"
    Jul 10 09:23:43.745: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.907664ms
    Jul 10 09:23:43.745: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Jul 10 09:23:43.745: INFO: Pod2 is running on 10-62-109-100.test. Tainting Node
    STEP: Trying to apply a taint on the Node 07/10/23 09:23:43.745
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:23:43.768
    STEP: Waiting for Pod1 and Pod2 to be deleted 07/10/23 09:23:43.783
    Jul 10 09:23:49.699: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Jul 10 09:24:09.856: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 07/10/23 09:24:09.885
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:24:09.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-4171" for this suite. 07/10/23 09:24:09.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:24:09.943
Jul 10 09:24:09.943: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename emptydir-wrapper 07/10/23 09:24:09.944
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:09.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:09.996
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Jul 10 09:24:10.076: INFO: Waiting up to 5m0s for pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222" in namespace "emptydir-wrapper-5339" to be "running and ready"
Jul 10 09:24:10.079: INFO: Pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222": Phase="Pending", Reason="", readiness=false. Elapsed: 3.492135ms
Jul 10 09:24:10.079: INFO: The phase of Pod pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:24:12.085: INFO: Pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222": Phase="Running", Reason="", readiness=true. Elapsed: 2.009674349s
Jul 10 09:24:12.085: INFO: The phase of Pod pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222 is Running (Ready = true)
Jul 10 09:24:12.085: INFO: Pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222" satisfied condition "running and ready"
STEP: Cleaning up the secret 07/10/23 09:24:12.09
STEP: Cleaning up the configmap 07/10/23 09:24:12.099
STEP: Cleaning up the pod 07/10/23 09:24:12.111
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Jul 10 09:24:12.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5339" for this suite. 07/10/23 09:24:12.141
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":333,"skipped":6174,"failed":0}
------------------------------
• [2.208 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:24:09.943
    Jul 10 09:24:09.943: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename emptydir-wrapper 07/10/23 09:24:09.944
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:09.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:09.996
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Jul 10 09:24:10.076: INFO: Waiting up to 5m0s for pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222" in namespace "emptydir-wrapper-5339" to be "running and ready"
    Jul 10 09:24:10.079: INFO: Pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222": Phase="Pending", Reason="", readiness=false. Elapsed: 3.492135ms
    Jul 10 09:24:10.079: INFO: The phase of Pod pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:24:12.085: INFO: Pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222": Phase="Running", Reason="", readiness=true. Elapsed: 2.009674349s
    Jul 10 09:24:12.085: INFO: The phase of Pod pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222 is Running (Ready = true)
    Jul 10 09:24:12.085: INFO: Pod "pod-secrets-2afc9423-7f9b-443b-ba8d-a060b7923222" satisfied condition "running and ready"
    STEP: Cleaning up the secret 07/10/23 09:24:12.09
    STEP: Cleaning up the configmap 07/10/23 09:24:12.099
    STEP: Cleaning up the pod 07/10/23 09:24:12.111
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Jul 10 09:24:12.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-5339" for this suite. 07/10/23 09:24:12.141
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:24:12.152
Jul 10 09:24:12.152: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename subpath 07/10/23 09:24:12.153
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:12.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:12.189
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 07/10/23 09:24:12.191
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-5g4m 07/10/23 09:24:12.212
STEP: Creating a pod to test atomic-volume-subpath 07/10/23 09:24:12.212
Jul 10 09:24:12.224: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5g4m" in namespace "subpath-8126" to be "Succeeded or Failed"
Jul 10 09:24:12.228: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Pending", Reason="", readiness=false. Elapsed: 3.610517ms
Jul 10 09:24:14.233: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 2.008711326s
Jul 10 09:24:16.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 4.010031412s
Jul 10 09:24:18.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 6.009494213s
Jul 10 09:24:20.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 8.009467147s
Jul 10 09:24:22.233: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 10.009213996s
Jul 10 09:24:24.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 12.00958227s
Jul 10 09:24:26.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 14.009610937s
Jul 10 09:24:28.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 16.009498082s
Jul 10 09:24:30.236: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 18.011475439s
Jul 10 09:24:32.235: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 20.010839385s
Jul 10 09:24:34.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=false. Elapsed: 22.009744012s
Jul 10 09:24:36.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.009781181s
STEP: Saw pod success 07/10/23 09:24:36.234
Jul 10 09:24:36.234: INFO: Pod "pod-subpath-test-projected-5g4m" satisfied condition "Succeeded or Failed"
Jul 10 09:24:36.238: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-projected-5g4m container test-container-subpath-projected-5g4m: <nil>
STEP: delete the pod 07/10/23 09:24:36.254
Jul 10 09:24:36.287: INFO: Waiting for pod pod-subpath-test-projected-5g4m to disappear
Jul 10 09:24:36.296: INFO: Pod pod-subpath-test-projected-5g4m no longer exists
STEP: Deleting pod pod-subpath-test-projected-5g4m 07/10/23 09:24:36.296
Jul 10 09:24:36.297: INFO: Deleting pod "pod-subpath-test-projected-5g4m" in namespace "subpath-8126"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jul 10 09:24:36.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8126" for this suite. 07/10/23 09:24:36.305
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":334,"skipped":6176,"failed":0}
------------------------------
• [SLOW TEST] [24.165 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:24:12.152
    Jul 10 09:24:12.152: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename subpath 07/10/23 09:24:12.153
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:12.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:12.189
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 07/10/23 09:24:12.191
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-5g4m 07/10/23 09:24:12.212
    STEP: Creating a pod to test atomic-volume-subpath 07/10/23 09:24:12.212
    Jul 10 09:24:12.224: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5g4m" in namespace "subpath-8126" to be "Succeeded or Failed"
    Jul 10 09:24:12.228: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Pending", Reason="", readiness=false. Elapsed: 3.610517ms
    Jul 10 09:24:14.233: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 2.008711326s
    Jul 10 09:24:16.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 4.010031412s
    Jul 10 09:24:18.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 6.009494213s
    Jul 10 09:24:20.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 8.009467147s
    Jul 10 09:24:22.233: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 10.009213996s
    Jul 10 09:24:24.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 12.00958227s
    Jul 10 09:24:26.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 14.009610937s
    Jul 10 09:24:28.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 16.009498082s
    Jul 10 09:24:30.236: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 18.011475439s
    Jul 10 09:24:32.235: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=true. Elapsed: 20.010839385s
    Jul 10 09:24:34.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Running", Reason="", readiness=false. Elapsed: 22.009744012s
    Jul 10 09:24:36.234: INFO: Pod "pod-subpath-test-projected-5g4m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.009781181s
    STEP: Saw pod success 07/10/23 09:24:36.234
    Jul 10 09:24:36.234: INFO: Pod "pod-subpath-test-projected-5g4m" satisfied condition "Succeeded or Failed"
    Jul 10 09:24:36.238: INFO: Trying to get logs from node 10-62-109-100.test pod pod-subpath-test-projected-5g4m container test-container-subpath-projected-5g4m: <nil>
    STEP: delete the pod 07/10/23 09:24:36.254
    Jul 10 09:24:36.287: INFO: Waiting for pod pod-subpath-test-projected-5g4m to disappear
    Jul 10 09:24:36.296: INFO: Pod pod-subpath-test-projected-5g4m no longer exists
    STEP: Deleting pod pod-subpath-test-projected-5g4m 07/10/23 09:24:36.296
    Jul 10 09:24:36.297: INFO: Deleting pod "pod-subpath-test-projected-5g4m" in namespace "subpath-8126"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jul 10 09:24:36.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8126" for this suite. 07/10/23 09:24:36.305
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:24:36.318
Jul 10 09:24:36.318: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename resourcequota 07/10/23 09:24:36.319
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:36.347
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:36.35
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 07/10/23 09:24:36.352
STEP: Creating a ResourceQuota 07/10/23 09:24:41.357
STEP: Ensuring resource quota status is calculated 07/10/23 09:24:41.365
STEP: Creating a Service 07/10/23 09:24:43.371
STEP: Creating a NodePort Service 07/10/23 09:24:43.404
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 07/10/23 09:24:43.448
STEP: Ensuring resource quota status captures service creation 07/10/23 09:24:43.51
STEP: Deleting Services 07/10/23 09:24:45.517
STEP: Ensuring resource quota status released usage 07/10/23 09:24:45.588
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jul 10 09:24:47.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8908" for this suite. 07/10/23 09:24:47.599
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":335,"skipped":6198,"failed":0}
------------------------------
• [SLOW TEST] [11.291 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:24:36.318
    Jul 10 09:24:36.318: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename resourcequota 07/10/23 09:24:36.319
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:36.347
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:36.35
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 07/10/23 09:24:36.352
    STEP: Creating a ResourceQuota 07/10/23 09:24:41.357
    STEP: Ensuring resource quota status is calculated 07/10/23 09:24:41.365
    STEP: Creating a Service 07/10/23 09:24:43.371
    STEP: Creating a NodePort Service 07/10/23 09:24:43.404
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 07/10/23 09:24:43.448
    STEP: Ensuring resource quota status captures service creation 07/10/23 09:24:43.51
    STEP: Deleting Services 07/10/23 09:24:45.517
    STEP: Ensuring resource quota status released usage 07/10/23 09:24:45.588
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jul 10 09:24:47.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8908" for this suite. 07/10/23 09:24:47.599
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:24:47.61
Jul 10 09:24:47.610: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:24:47.611
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:47.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:47.641
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:24:47.644
Jul 10 09:24:47.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84" in namespace "downward-api-8824" to be "Succeeded or Failed"
Jul 10 09:24:47.665: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84": Phase="Pending", Reason="", readiness=false. Elapsed: 3.924251ms
Jul 10 09:24:49.672: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010460305s
Jul 10 09:24:51.670: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009078432s
STEP: Saw pod success 07/10/23 09:24:51.67
Jul 10 09:24:51.671: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84" satisfied condition "Succeeded or Failed"
Jul 10 09:24:51.674: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84 container client-container: <nil>
STEP: delete the pod 07/10/23 09:24:51.683
Jul 10 09:24:51.712: INFO: Waiting for pod downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84 to disappear
Jul 10 09:24:51.715: INFO: Pod downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 09:24:51.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8824" for this suite. 07/10/23 09:24:51.721
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":336,"skipped":6203,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:24:47.61
    Jul 10 09:24:47.610: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:24:47.611
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:47.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:47.641
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:24:47.644
    Jul 10 09:24:47.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84" in namespace "downward-api-8824" to be "Succeeded or Failed"
    Jul 10 09:24:47.665: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84": Phase="Pending", Reason="", readiness=false. Elapsed: 3.924251ms
    Jul 10 09:24:49.672: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010460305s
    Jul 10 09:24:51.670: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009078432s
    STEP: Saw pod success 07/10/23 09:24:51.67
    Jul 10 09:24:51.671: INFO: Pod "downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84" satisfied condition "Succeeded or Failed"
    Jul 10 09:24:51.674: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84 container client-container: <nil>
    STEP: delete the pod 07/10/23 09:24:51.683
    Jul 10 09:24:51.712: INFO: Waiting for pod downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84 to disappear
    Jul 10 09:24:51.715: INFO: Pod downwardapi-volume-6832ef63-739f-4c2c-a715-15305e708c84 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 09:24:51.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8824" for this suite. 07/10/23 09:24:51.721
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:24:51.734
Jul 10 09:24:51.734: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:24:51.735
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:51.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:51.763
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-88ff2a5d-a692-47fc-8f41-43191a3f6206 07/10/23 09:24:51.765
STEP: Creating a pod to test consume configMaps 07/10/23 09:24:51.78
Jul 10 09:24:51.790: INFO: Waiting up to 5m0s for pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb" in namespace "configmap-9800" to be "Succeeded or Failed"
Jul 10 09:24:51.798: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.994675ms
Jul 10 09:24:53.804: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013965184s
Jul 10 09:24:55.803: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013043862s
STEP: Saw pod success 07/10/23 09:24:55.803
Jul 10 09:24:55.804: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb" satisfied condition "Succeeded or Failed"
Jul 10 09:24:55.807: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb container agnhost-container: <nil>
STEP: delete the pod 07/10/23 09:24:55.817
Jul 10 09:24:55.838: INFO: Waiting for pod pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb to disappear
Jul 10 09:24:55.846: INFO: Pod pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:24:55.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9800" for this suite. 07/10/23 09:24:55.85
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":337,"skipped":6207,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:24:51.734
    Jul 10 09:24:51.734: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:24:51.735
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:51.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:51.763
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-88ff2a5d-a692-47fc-8f41-43191a3f6206 07/10/23 09:24:51.765
    STEP: Creating a pod to test consume configMaps 07/10/23 09:24:51.78
    Jul 10 09:24:51.790: INFO: Waiting up to 5m0s for pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb" in namespace "configmap-9800" to be "Succeeded or Failed"
    Jul 10 09:24:51.798: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.994675ms
    Jul 10 09:24:53.804: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013965184s
    Jul 10 09:24:55.803: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013043862s
    STEP: Saw pod success 07/10/23 09:24:55.803
    Jul 10 09:24:55.804: INFO: Pod "pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb" satisfied condition "Succeeded or Failed"
    Jul 10 09:24:55.807: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 09:24:55.817
    Jul 10 09:24:55.838: INFO: Waiting for pod pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb to disappear
    Jul 10 09:24:55.846: INFO: Pod pod-configmaps-055582b7-7863-4e0b-8323-7423973adbcb no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:24:55.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9800" for this suite. 07/10/23 09:24:55.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:24:55.863
Jul 10 09:24:55.863: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 09:24:55.864
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:55.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:55.899
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 09:25:55.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2927" for this suite. 07/10/23 09:25:55.93
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":338,"skipped":6244,"failed":0}
------------------------------
• [SLOW TEST] [60.087 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:24:55.863
    Jul 10 09:24:55.863: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 09:24:55.864
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:24:55.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:24:55.899
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 09:25:55.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2927" for this suite. 07/10/23 09:25:55.93
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:25:55.952
Jul 10 09:25:55.952: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename disruption 07/10/23 09:25:55.954
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:25:55.989
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:25:55.992
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:25:55.995
Jul 10 09:25:55.995: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename disruption-2 07/10/23 09:25:55.996
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:25:56.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:25:56.03
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 07/10/23 09:25:56.042
STEP: Waiting for the pdb to be processed 07/10/23 09:25:58.065
STEP: Waiting for the pdb to be processed 07/10/23 09:26:00.084
STEP: listing a collection of PDBs across all namespaces 07/10/23 09:26:02.097
STEP: listing a collection of PDBs in namespace disruption-4590 07/10/23 09:26:02.103
STEP: deleting a collection of PDBs 07/10/23 09:26:02.107
STEP: Waiting for the PDB collection to be deleted 07/10/23 09:26:02.126
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Jul 10 09:26:02.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-5089" for this suite. 07/10/23 09:26:02.14
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jul 10 09:26:02.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4590" for this suite. 07/10/23 09:26:02.158
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":339,"skipped":6275,"failed":0}
------------------------------
• [SLOW TEST] [6.221 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:25:55.952
    Jul 10 09:25:55.952: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename disruption 07/10/23 09:25:55.954
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:25:55.989
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:25:55.992
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:25:55.995
    Jul 10 09:25:55.995: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename disruption-2 07/10/23 09:25:55.996
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:25:56.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:25:56.03
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 07/10/23 09:25:56.042
    STEP: Waiting for the pdb to be processed 07/10/23 09:25:58.065
    STEP: Waiting for the pdb to be processed 07/10/23 09:26:00.084
    STEP: listing a collection of PDBs across all namespaces 07/10/23 09:26:02.097
    STEP: listing a collection of PDBs in namespace disruption-4590 07/10/23 09:26:02.103
    STEP: deleting a collection of PDBs 07/10/23 09:26:02.107
    STEP: Waiting for the PDB collection to be deleted 07/10/23 09:26:02.126
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Jul 10 09:26:02.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-5089" for this suite. 07/10/23 09:26:02.14
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jul 10 09:26:02.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4590" for this suite. 07/10/23 09:26:02.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:02.175
Jul 10 09:26:02.175: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:26:02.176
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:02.199
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:02.201
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 07/10/23 09:26:02.209
Jul 10 09:26:02.210: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
Jul 10 09:26:07.374: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:26:20.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6504" for this suite. 07/10/23 09:26:20.088
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":340,"skipped":6297,"failed":0}
------------------------------
• [SLOW TEST] [17.923 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:02.175
    Jul 10 09:26:02.175: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename crd-publish-openapi 07/10/23 09:26:02.176
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:02.199
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:02.201
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 07/10/23 09:26:02.209
    Jul 10 09:26:02.210: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    Jul 10 09:26:07.374: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:26:20.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6504" for this suite. 07/10/23 09:26:20.088
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:20.099
Jul 10 09:26:20.099: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 09:26:20.1
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:20.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:20.14
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:26:20.143
Jul 10 09:26:20.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1" in namespace "projected-5586" to be "Succeeded or Failed"
Jul 10 09:26:20.160: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090649ms
Jul 10 09:26:22.166: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010211485s
Jul 10 09:26:24.168: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011732664s
Jul 10 09:26:26.167: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011078139s
STEP: Saw pod success 07/10/23 09:26:26.167
Jul 10 09:26:26.168: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1" satisfied condition "Succeeded or Failed"
Jul 10 09:26:26.172: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1 container client-container: <nil>
STEP: delete the pod 07/10/23 09:26:26.187
Jul 10 09:26:26.215: INFO: Waiting for pod downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1 to disappear
Jul 10 09:26:26.219: INFO: Pod downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 09:26:26.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5586" for this suite. 07/10/23 09:26:26.223
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":341,"skipped":6318,"failed":0}
------------------------------
• [SLOW TEST] [6.134 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:20.099
    Jul 10 09:26:20.099: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 09:26:20.1
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:20.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:20.14
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:26:20.143
    Jul 10 09:26:20.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1" in namespace "projected-5586" to be "Succeeded or Failed"
    Jul 10 09:26:20.160: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090649ms
    Jul 10 09:26:22.166: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010211485s
    Jul 10 09:26:24.168: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011732664s
    Jul 10 09:26:26.167: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011078139s
    STEP: Saw pod success 07/10/23 09:26:26.167
    Jul 10 09:26:26.168: INFO: Pod "downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1" satisfied condition "Succeeded or Failed"
    Jul 10 09:26:26.172: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1 container client-container: <nil>
    STEP: delete the pod 07/10/23 09:26:26.187
    Jul 10 09:26:26.215: INFO: Waiting for pod downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1 to disappear
    Jul 10 09:26:26.219: INFO: Pod downwardapi-volume-67128b94-7bdc-4e5e-99bf-4606be96b2d1 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 09:26:26.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5586" for this suite. 07/10/23 09:26:26.223
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:26.233
Jul 10 09:26:26.233: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename endpointslice 07/10/23 09:26:26.234
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:26.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:26.266
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 07/10/23 09:26:26.269
STEP: getting /apis/discovery.k8s.io 07/10/23 09:26:26.272
STEP: getting /apis/discovery.k8s.iov1 07/10/23 09:26:26.273
STEP: creating 07/10/23 09:26:26.274
STEP: getting 07/10/23 09:26:26.31
STEP: listing 07/10/23 09:26:26.314
STEP: watching 07/10/23 09:26:26.318
Jul 10 09:26:26.318: INFO: starting watch
STEP: cluster-wide listing 07/10/23 09:26:26.319
STEP: cluster-wide watching 07/10/23 09:26:26.324
Jul 10 09:26:26.324: INFO: starting watch
STEP: patching 07/10/23 09:26:26.325
STEP: updating 07/10/23 09:26:26.334
Jul 10 09:26:26.348: INFO: waiting for watch events with expected annotations
Jul 10 09:26:26.348: INFO: saw patched and updated annotations
STEP: deleting 07/10/23 09:26:26.348
STEP: deleting a collection 07/10/23 09:26:26.368
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jul 10 09:26:26.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6762" for this suite. 07/10/23 09:26:26.405
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":342,"skipped":6320,"failed":0}
------------------------------
• [0.182 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:26.233
    Jul 10 09:26:26.233: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename endpointslice 07/10/23 09:26:26.234
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:26.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:26.266
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 07/10/23 09:26:26.269
    STEP: getting /apis/discovery.k8s.io 07/10/23 09:26:26.272
    STEP: getting /apis/discovery.k8s.iov1 07/10/23 09:26:26.273
    STEP: creating 07/10/23 09:26:26.274
    STEP: getting 07/10/23 09:26:26.31
    STEP: listing 07/10/23 09:26:26.314
    STEP: watching 07/10/23 09:26:26.318
    Jul 10 09:26:26.318: INFO: starting watch
    STEP: cluster-wide listing 07/10/23 09:26:26.319
    STEP: cluster-wide watching 07/10/23 09:26:26.324
    Jul 10 09:26:26.324: INFO: starting watch
    STEP: patching 07/10/23 09:26:26.325
    STEP: updating 07/10/23 09:26:26.334
    Jul 10 09:26:26.348: INFO: waiting for watch events with expected annotations
    Jul 10 09:26:26.348: INFO: saw patched and updated annotations
    STEP: deleting 07/10/23 09:26:26.348
    STEP: deleting a collection 07/10/23 09:26:26.368
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jul 10 09:26:26.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6762" for this suite. 07/10/23 09:26:26.405
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:26.419
Jul 10 09:26:26.419: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 09:26:26.42
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:26.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:26.452
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 07/10/23 09:26:26.455
Jul 10 09:26:26.468: INFO: Waiting up to 5m0s for pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef" in namespace "projected-8921" to be "running and ready"
Jul 10 09:26:26.471: INFO: Pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667412ms
Jul 10 09:26:26.471: INFO: The phase of Pod annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:26:28.478: INFO: Pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef": Phase="Running", Reason="", readiness=true. Elapsed: 2.010014433s
Jul 10 09:26:28.478: INFO: The phase of Pod annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef is Running (Ready = true)
Jul 10 09:26:28.478: INFO: Pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef" satisfied condition "running and ready"
Jul 10 09:26:29.020: INFO: Successfully updated pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jul 10 09:26:31.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8921" for this suite. 07/10/23 09:26:31.05
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":343,"skipped":6362,"failed":0}
------------------------------
• [4.645 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:26.419
    Jul 10 09:26:26.419: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 09:26:26.42
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:26.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:26.452
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 07/10/23 09:26:26.455
    Jul 10 09:26:26.468: INFO: Waiting up to 5m0s for pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef" in namespace "projected-8921" to be "running and ready"
    Jul 10 09:26:26.471: INFO: Pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667412ms
    Jul 10 09:26:26.471: INFO: The phase of Pod annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:26:28.478: INFO: Pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef": Phase="Running", Reason="", readiness=true. Elapsed: 2.010014433s
    Jul 10 09:26:28.478: INFO: The phase of Pod annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef is Running (Ready = true)
    Jul 10 09:26:28.478: INFO: Pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef" satisfied condition "running and ready"
    Jul 10 09:26:29.020: INFO: Successfully updated pod "annotationupdate123fa24e-698a-4aa3-9664-a0ae9f2523ef"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jul 10 09:26:31.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8921" for this suite. 07/10/23 09:26:31.05
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:31.065
Jul 10 09:26:31.065: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename job 07/10/23 09:26:31.066
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:31.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:31.098
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 07/10/23 09:26:31.101
STEP: Ensure pods equal to paralellism count is attached to the job 07/10/23 09:26:31.113
STEP: patching /status 07/10/23 09:26:35.119
STEP: updating /status 07/10/23 09:26:35.133
STEP: get /status 07/10/23 09:26:35.151
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jul 10 09:26:35.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8744" for this suite. 07/10/23 09:26:35.161
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":344,"skipped":6389,"failed":0}
------------------------------
• [4.108 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:31.065
    Jul 10 09:26:31.065: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename job 07/10/23 09:26:31.066
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:31.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:31.098
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 07/10/23 09:26:31.101
    STEP: Ensure pods equal to paralellism count is attached to the job 07/10/23 09:26:31.113
    STEP: patching /status 07/10/23 09:26:35.119
    STEP: updating /status 07/10/23 09:26:35.133
    STEP: get /status 07/10/23 09:26:35.151
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jul 10 09:26:35.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8744" for this suite. 07/10/23 09:26:35.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:35.177
Jul 10 09:26:35.177: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename controllerrevisions 07/10/23 09:26:35.178
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:35.211
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:35.214
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-r7nzb-daemon-set" 07/10/23 09:26:35.242
STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:26:35.253
Jul 10 09:26:35.271: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 0
Jul 10 09:26:35.271: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:26:36.306: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 0
Jul 10 09:26:36.306: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:26:37.282: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 2
Jul 10 09:26:37.282: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
Jul 10 09:26:38.282: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 3
Jul 10 09:26:38.282: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-r7nzb-daemon-set
STEP: Confirm DaemonSet "e2e-r7nzb-daemon-set" successfully created with "daemonset-name=e2e-r7nzb-daemon-set" label 07/10/23 09:26:38.287
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-r7nzb-daemon-set" 07/10/23 09:26:38.297
Jul 10 09:26:38.302: INFO: Located ControllerRevision: "e2e-r7nzb-daemon-set-844fffb48d"
STEP: Patching ControllerRevision "e2e-r7nzb-daemon-set-844fffb48d" 07/10/23 09:26:38.307
Jul 10 09:26:38.319: INFO: e2e-r7nzb-daemon-set-844fffb48d has been patched
STEP: Create a new ControllerRevision 07/10/23 09:26:38.319
Jul 10 09:26:38.334: INFO: Created ControllerRevision: e2e-r7nzb-daemon-set-fdcc4776b
STEP: Confirm that there are two ControllerRevisions 07/10/23 09:26:38.334
Jul 10 09:26:38.334: INFO: Requesting list of ControllerRevisions to confirm quantity
Jul 10 09:26:38.340: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-r7nzb-daemon-set-844fffb48d" 07/10/23 09:26:38.34
STEP: Confirm that there is only one ControllerRevision 07/10/23 09:26:38.35
Jul 10 09:26:38.350: INFO: Requesting list of ControllerRevisions to confirm quantity
Jul 10 09:26:38.354: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-r7nzb-daemon-set-fdcc4776b" 07/10/23 09:26:38.358
Jul 10 09:26:38.373: INFO: e2e-r7nzb-daemon-set-fdcc4776b has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 07/10/23 09:26:38.373
W0710 09:26:38.387592      21 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 07/10/23 09:26:38.387
Jul 10 09:26:38.387: INFO: Requesting list of ControllerRevisions to confirm quantity
Jul 10 09:26:39.392: INFO: Requesting list of ControllerRevisions to confirm quantity
Jul 10 09:26:39.398: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-r7nzb-daemon-set-fdcc4776b=updated" 07/10/23 09:26:39.398
STEP: Confirm that there is only one ControllerRevision 07/10/23 09:26:39.417
Jul 10 09:26:39.417: INFO: Requesting list of ControllerRevisions to confirm quantity
Jul 10 09:26:39.421: INFO: Found 1 ControllerRevisions
Jul 10 09:26:39.424: INFO: ControllerRevision "e2e-r7nzb-daemon-set-7c588f7bf9" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-r7nzb-daemon-set" 07/10/23 09:26:39.428
STEP: deleting DaemonSet.extensions e2e-r7nzb-daemon-set in namespace controllerrevisions-3942, will wait for the garbage collector to delete the pods 07/10/23 09:26:39.428
Jul 10 09:26:39.494: INFO: Deleting DaemonSet.extensions e2e-r7nzb-daemon-set took: 11.288502ms
Jul 10 09:26:39.595: INFO: Terminating DaemonSet.extensions e2e-r7nzb-daemon-set pods took: 100.992749ms
Jul 10 09:26:40.900: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 0
Jul 10 09:26:40.900: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-r7nzb-daemon-set
Jul 10 09:26:40.904: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"108126"},"items":null}

Jul 10 09:26:40.908: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"108126"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:26:40.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-3942" for this suite. 07/10/23 09:26:40.932
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":345,"skipped":6460,"failed":0}
------------------------------
• [SLOW TEST] [5.765 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:35.177
    Jul 10 09:26:35.177: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename controllerrevisions 07/10/23 09:26:35.178
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:35.211
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:35.214
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-r7nzb-daemon-set" 07/10/23 09:26:35.242
    STEP: Check that daemon pods launch on every node of the cluster. 07/10/23 09:26:35.253
    Jul 10 09:26:35.271: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 0
    Jul 10 09:26:35.271: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:26:36.306: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 0
    Jul 10 09:26:36.306: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:26:37.282: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 2
    Jul 10 09:26:37.282: INFO: Node 10-62-109-101.test is running 0 daemon pod, expected 1
    Jul 10 09:26:38.282: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 3
    Jul 10 09:26:38.282: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-r7nzb-daemon-set
    STEP: Confirm DaemonSet "e2e-r7nzb-daemon-set" successfully created with "daemonset-name=e2e-r7nzb-daemon-set" label 07/10/23 09:26:38.287
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-r7nzb-daemon-set" 07/10/23 09:26:38.297
    Jul 10 09:26:38.302: INFO: Located ControllerRevision: "e2e-r7nzb-daemon-set-844fffb48d"
    STEP: Patching ControllerRevision "e2e-r7nzb-daemon-set-844fffb48d" 07/10/23 09:26:38.307
    Jul 10 09:26:38.319: INFO: e2e-r7nzb-daemon-set-844fffb48d has been patched
    STEP: Create a new ControllerRevision 07/10/23 09:26:38.319
    Jul 10 09:26:38.334: INFO: Created ControllerRevision: e2e-r7nzb-daemon-set-fdcc4776b
    STEP: Confirm that there are two ControllerRevisions 07/10/23 09:26:38.334
    Jul 10 09:26:38.334: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jul 10 09:26:38.340: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-r7nzb-daemon-set-844fffb48d" 07/10/23 09:26:38.34
    STEP: Confirm that there is only one ControllerRevision 07/10/23 09:26:38.35
    Jul 10 09:26:38.350: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jul 10 09:26:38.354: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-r7nzb-daemon-set-fdcc4776b" 07/10/23 09:26:38.358
    Jul 10 09:26:38.373: INFO: e2e-r7nzb-daemon-set-fdcc4776b has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 07/10/23 09:26:38.373
    W0710 09:26:38.387592      21 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 07/10/23 09:26:38.387
    Jul 10 09:26:38.387: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jul 10 09:26:39.392: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jul 10 09:26:39.398: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-r7nzb-daemon-set-fdcc4776b=updated" 07/10/23 09:26:39.398
    STEP: Confirm that there is only one ControllerRevision 07/10/23 09:26:39.417
    Jul 10 09:26:39.417: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jul 10 09:26:39.421: INFO: Found 1 ControllerRevisions
    Jul 10 09:26:39.424: INFO: ControllerRevision "e2e-r7nzb-daemon-set-7c588f7bf9" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-r7nzb-daemon-set" 07/10/23 09:26:39.428
    STEP: deleting DaemonSet.extensions e2e-r7nzb-daemon-set in namespace controllerrevisions-3942, will wait for the garbage collector to delete the pods 07/10/23 09:26:39.428
    Jul 10 09:26:39.494: INFO: Deleting DaemonSet.extensions e2e-r7nzb-daemon-set took: 11.288502ms
    Jul 10 09:26:39.595: INFO: Terminating DaemonSet.extensions e2e-r7nzb-daemon-set pods took: 100.992749ms
    Jul 10 09:26:40.900: INFO: Number of nodes with available pods controlled by daemonset e2e-r7nzb-daemon-set: 0
    Jul 10 09:26:40.900: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-r7nzb-daemon-set
    Jul 10 09:26:40.904: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"108126"},"items":null}

    Jul 10 09:26:40.908: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"108126"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:26:40.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-3942" for this suite. 07/10/23 09:26:40.932
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:40.943
Jul 10 09:26:40.943: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename podtemplate 07/10/23 09:26:40.944
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:40.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:40.981
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 07/10/23 09:26:40.986
Jul 10 09:26:41.026: INFO: created test-podtemplate-1
Jul 10 09:26:41.039: INFO: created test-podtemplate-2
Jul 10 09:26:41.048: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 07/10/23 09:26:41.048
STEP: delete collection of pod templates 07/10/23 09:26:41.052
Jul 10 09:26:41.052: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 07/10/23 09:26:41.085
Jul 10 09:26:41.086: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jul 10 09:26:41.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9585" for this suite. 07/10/23 09:26:41.094
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":346,"skipped":6476,"failed":0}
------------------------------
• [0.162 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:40.943
    Jul 10 09:26:40.943: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename podtemplate 07/10/23 09:26:40.944
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:40.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:40.981
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 07/10/23 09:26:40.986
    Jul 10 09:26:41.026: INFO: created test-podtemplate-1
    Jul 10 09:26:41.039: INFO: created test-podtemplate-2
    Jul 10 09:26:41.048: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 07/10/23 09:26:41.048
    STEP: delete collection of pod templates 07/10/23 09:26:41.052
    Jul 10 09:26:41.052: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 07/10/23 09:26:41.085
    Jul 10 09:26:41.086: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jul 10 09:26:41.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-9585" for this suite. 07/10/23 09:26:41.094
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:26:41.106
Jul 10 09:26:41.106: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 09:26:41.107
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:41.145
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:41.148
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 in namespace container-probe-8039 07/10/23 09:26:41.151
Jul 10 09:26:41.164: INFO: Waiting up to 5m0s for pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48" in namespace "container-probe-8039" to be "not pending"
Jul 10 09:26:41.169: INFO: Pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48": Phase="Pending", Reason="", readiness=false. Elapsed: 5.34055ms
Jul 10 09:26:43.176: INFO: Pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48": Phase="Running", Reason="", readiness=true. Elapsed: 2.011968693s
Jul 10 09:26:43.176: INFO: Pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48" satisfied condition "not pending"
Jul 10 09:26:43.176: INFO: Started pod liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 in namespace container-probe-8039
STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 09:26:43.176
Jul 10 09:26:43.180: INFO: Initial restart count of pod liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 is 0
Jul 10 09:27:03.247: INFO: Restart count of pod container-probe-8039/liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 is now 1 (20.066965779s elapsed)
STEP: deleting the pod 07/10/23 09:27:03.247
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 09:27:03.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8039" for this suite. 07/10/23 09:27:03.283
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":347,"skipped":6480,"failed":0}
------------------------------
• [SLOW TEST] [22.196 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:26:41.106
    Jul 10 09:26:41.106: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 09:26:41.107
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:26:41.145
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:26:41.148
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 in namespace container-probe-8039 07/10/23 09:26:41.151
    Jul 10 09:26:41.164: INFO: Waiting up to 5m0s for pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48" in namespace "container-probe-8039" to be "not pending"
    Jul 10 09:26:41.169: INFO: Pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48": Phase="Pending", Reason="", readiness=false. Elapsed: 5.34055ms
    Jul 10 09:26:43.176: INFO: Pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48": Phase="Running", Reason="", readiness=true. Elapsed: 2.011968693s
    Jul 10 09:26:43.176: INFO: Pod "liveness-6453c4e6-e238-444f-b153-f6b953d5cc48" satisfied condition "not pending"
    Jul 10 09:26:43.176: INFO: Started pod liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 in namespace container-probe-8039
    STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 09:26:43.176
    Jul 10 09:26:43.180: INFO: Initial restart count of pod liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 is 0
    Jul 10 09:27:03.247: INFO: Restart count of pod container-probe-8039/liveness-6453c4e6-e238-444f-b153-f6b953d5cc48 is now 1 (20.066965779s elapsed)
    STEP: deleting the pod 07/10/23 09:27:03.247
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 09:27:03.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8039" for this suite. 07/10/23 09:27:03.283
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:27:03.305
Jul 10 09:27:03.305: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename runtimeclass 07/10/23 09:27:03.306
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:27:03.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:27:03.337
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jul 10 09:27:03.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7920" for this suite. 07/10/23 09:27:03.352
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":348,"skipped":6534,"failed":0}
------------------------------
• [0.060 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:27:03.305
    Jul 10 09:27:03.305: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename runtimeclass 07/10/23 09:27:03.306
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:27:03.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:27:03.337
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jul 10 09:27:03.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7920" for this suite. 07/10/23 09:27:03.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:27:03.366
Jul 10 09:27:03.366: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename var-expansion 07/10/23 09:27:03.367
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:27:03.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:27:03.396
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 07/10/23 09:27:03.399
Jul 10 09:27:03.414: INFO: Waiting up to 5m0s for pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70" in namespace "var-expansion-2428" to be "Succeeded or Failed"
Jul 10 09:27:03.422: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70": Phase="Pending", Reason="", readiness=false. Elapsed: 8.891595ms
Jul 10 09:27:05.434: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020242276s
Jul 10 09:27:07.428: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014859814s
STEP: Saw pod success 07/10/23 09:27:07.428
Jul 10 09:27:07.429: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70" satisfied condition "Succeeded or Failed"
Jul 10 09:27:07.435: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70 container dapi-container: <nil>
STEP: delete the pod 07/10/23 09:27:07.443
Jul 10 09:27:07.468: INFO: Waiting for pod var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70 to disappear
Jul 10 09:27:07.472: INFO: Pod var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jul 10 09:27:07.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2428" for this suite. 07/10/23 09:27:07.478
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":349,"skipped":6543,"failed":0}
------------------------------
• [4.127 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:27:03.366
    Jul 10 09:27:03.366: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename var-expansion 07/10/23 09:27:03.367
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:27:03.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:27:03.396
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 07/10/23 09:27:03.399
    Jul 10 09:27:03.414: INFO: Waiting up to 5m0s for pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70" in namespace "var-expansion-2428" to be "Succeeded or Failed"
    Jul 10 09:27:03.422: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70": Phase="Pending", Reason="", readiness=false. Elapsed: 8.891595ms
    Jul 10 09:27:05.434: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020242276s
    Jul 10 09:27:07.428: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014859814s
    STEP: Saw pod success 07/10/23 09:27:07.428
    Jul 10 09:27:07.429: INFO: Pod "var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70" satisfied condition "Succeeded or Failed"
    Jul 10 09:27:07.435: INFO: Trying to get logs from node 10-62-109-100.test pod var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70 container dapi-container: <nil>
    STEP: delete the pod 07/10/23 09:27:07.443
    Jul 10 09:27:07.468: INFO: Waiting for pod var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70 to disappear
    Jul 10 09:27:07.472: INFO: Pod var-expansion-eaee80ad-f6d9-4d97-8b2b-7f6be9036f70 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jul 10 09:27:07.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2428" for this suite. 07/10/23 09:27:07.478
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:27:07.494
Jul 10 09:27:07.494: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename cronjob 07/10/23 09:27:07.496
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:27:07.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:27:07.564
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 07/10/23 09:27:07.569
STEP: Ensuring a job is scheduled 07/10/23 09:27:07.583
STEP: Ensuring exactly one is scheduled 07/10/23 09:28:01.59
STEP: Ensuring exactly one running job exists by listing jobs explicitly 07/10/23 09:28:01.595
STEP: Ensuring the job is replaced with a new one 07/10/23 09:28:01.599
STEP: Removing cronjob 07/10/23 09:29:01.605
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jul 10 09:29:01.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-469" for this suite. 07/10/23 09:29:01.624
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":350,"skipped":6545,"failed":0}
------------------------------
• [SLOW TEST] [114.143 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:27:07.494
    Jul 10 09:27:07.494: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename cronjob 07/10/23 09:27:07.496
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:27:07.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:27:07.564
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 07/10/23 09:27:07.569
    STEP: Ensuring a job is scheduled 07/10/23 09:27:07.583
    STEP: Ensuring exactly one is scheduled 07/10/23 09:28:01.59
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 07/10/23 09:28:01.595
    STEP: Ensuring the job is replaced with a new one 07/10/23 09:28:01.599
    STEP: Removing cronjob 07/10/23 09:29:01.605
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jul 10 09:29:01.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-469" for this suite. 07/10/23 09:29:01.624
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:29:01.637
Jul 10 09:29:01.637: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 09:29:01.638
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:29:01.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:29:01.69
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 09:29:01.717
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:29:02.783
STEP: Deploying the webhook pod 07/10/23 09:29:02.797
STEP: Wait for the deployment to be ready 07/10/23 09:29:02.817
Jul 10 09:29:02.832: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 07/10/23 09:29:04.845
STEP: Verifying the service has paired with the endpoint 07/10/23 09:29:04.867
Jul 10 09:29:05.868: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 07/10/23 09:29:05.874
Jul 10 09:29:05.912: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod 07/10/23 09:29:06.023
Jul 10 09:29:06.038: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-8840" to be "running"
Jul 10 09:29:06.042: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.778695ms
Jul 10 09:29:08.047: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009315952s
Jul 10 09:29:10.049: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.01081589s
Jul 10 09:29:10.049: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 07/10/23 09:29:10.049
Jul 10 09:29:10.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=webhook-8840 attach --namespace=webhook-8840 to-be-attached-pod -i -c=container1'
Jul 10 09:29:10.153: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:29:10.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8840" for this suite. 07/10/23 09:29:10.172
STEP: Destroying namespace "webhook-8840-markers" for this suite. 07/10/23 09:29:10.182
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":351,"skipped":6551,"failed":0}
------------------------------
• [SLOW TEST] [8.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:29:01.637
    Jul 10 09:29:01.637: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 09:29:01.638
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:29:01.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:29:01.69
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 09:29:01.717
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:29:02.783
    STEP: Deploying the webhook pod 07/10/23 09:29:02.797
    STEP: Wait for the deployment to be ready 07/10/23 09:29:02.817
    Jul 10 09:29:02.832: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 07/10/23 09:29:04.845
    STEP: Verifying the service has paired with the endpoint 07/10/23 09:29:04.867
    Jul 10 09:29:05.868: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 07/10/23 09:29:05.874
    Jul 10 09:29:05.912: INFO: Waiting for webhook configuration to be ready...
    STEP: create a pod 07/10/23 09:29:06.023
    Jul 10 09:29:06.038: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-8840" to be "running"
    Jul 10 09:29:06.042: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.778695ms
    Jul 10 09:29:08.047: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009315952s
    Jul 10 09:29:10.049: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.01081589s
    Jul 10 09:29:10.049: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 07/10/23 09:29:10.049
    Jul 10 09:29:10.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-597014847 --namespace=webhook-8840 attach --namespace=webhook-8840 to-be-attached-pod -i -c=container1'
    Jul 10 09:29:10.153: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:29:10.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8840" for this suite. 07/10/23 09:29:10.172
    STEP: Destroying namespace "webhook-8840-markers" for this suite. 07/10/23 09:29:10.182
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:29:10.278
Jul 10 09:29:10.279: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename webhook 07/10/23 09:29:10.28
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:29:10.322
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:29:10.325
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 07/10/23 09:29:10.354
STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:29:11.21
STEP: Deploying the webhook pod 07/10/23 09:29:11.219
STEP: Wait for the deployment to be ready 07/10/23 09:29:11.241
Jul 10 09:29:11.270: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 07/10/23 09:29:13.284
STEP: Verifying the service has paired with the endpoint 07/10/23 09:29:13.309
Jul 10 09:29:14.310: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Jul 10 09:29:14.315: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9891-crds.webhook.example.com via the AdmissionRegistration API 07/10/23 09:29:14.836
STEP: Creating a custom resource while v1 is storage version 07/10/23 09:29:14.86
STEP: Patching Custom Resource Definition to set v2 as storage 07/10/23 09:29:16.932
STEP: Patching the custom resource while v2 is storage version 07/10/23 09:29:16.957
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jul 10 09:29:17.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-79" for this suite. 07/10/23 09:29:17.569
STEP: Destroying namespace "webhook-79-markers" for this suite. 07/10/23 09:29:17.585
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":352,"skipped":6566,"failed":0}
------------------------------
• [SLOW TEST] [7.423 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:29:10.278
    Jul 10 09:29:10.279: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename webhook 07/10/23 09:29:10.28
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:29:10.322
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:29:10.325
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 07/10/23 09:29:10.354
    STEP: Create role binding to let webhook read extension-apiserver-authentication 07/10/23 09:29:11.21
    STEP: Deploying the webhook pod 07/10/23 09:29:11.219
    STEP: Wait for the deployment to be ready 07/10/23 09:29:11.241
    Jul 10 09:29:11.270: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 07/10/23 09:29:13.284
    STEP: Verifying the service has paired with the endpoint 07/10/23 09:29:13.309
    Jul 10 09:29:14.310: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Jul 10 09:29:14.315: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9891-crds.webhook.example.com via the AdmissionRegistration API 07/10/23 09:29:14.836
    STEP: Creating a custom resource while v1 is storage version 07/10/23 09:29:14.86
    STEP: Patching Custom Resource Definition to set v2 as storage 07/10/23 09:29:16.932
    STEP: Patching the custom resource while v2 is storage version 07/10/23 09:29:16.957
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jul 10 09:29:17.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-79" for this suite. 07/10/23 09:29:17.569
    STEP: Destroying namespace "webhook-79-markers" for this suite. 07/10/23 09:29:17.585
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:29:17.702
Jul 10 09:29:17.702: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename container-probe 07/10/23 09:29:17.703
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:29:17.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:29:17.749
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-89beec1d-148a-4f53-8a77-e214757da926 in namespace container-probe-4957 07/10/23 09:29:17.797
Jul 10 09:29:17.858: INFO: Waiting up to 5m0s for pod "busybox-89beec1d-148a-4f53-8a77-e214757da926" in namespace "container-probe-4957" to be "not pending"
Jul 10 09:29:17.862: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926": Phase="Pending", Reason="", readiness=false. Elapsed: 3.906582ms
Jul 10 09:29:19.868: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009241413s
Jul 10 09:29:21.868: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926": Phase="Running", Reason="", readiness=true. Elapsed: 4.009093827s
Jul 10 09:29:21.868: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926" satisfied condition "not pending"
Jul 10 09:29:21.868: INFO: Started pod busybox-89beec1d-148a-4f53-8a77-e214757da926 in namespace container-probe-4957
STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 09:29:21.868
Jul 10 09:29:21.873: INFO: Initial restart count of pod busybox-89beec1d-148a-4f53-8a77-e214757da926 is 0
STEP: deleting the pod 07/10/23 09:33:22.63
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jul 10 09:33:22.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4957" for this suite. 07/10/23 09:33:22.673
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":353,"skipped":6579,"failed":0}
------------------------------
• [SLOW TEST] [244.995 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:29:17.702
    Jul 10 09:29:17.702: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename container-probe 07/10/23 09:29:17.703
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:29:17.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:29:17.749
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-89beec1d-148a-4f53-8a77-e214757da926 in namespace container-probe-4957 07/10/23 09:29:17.797
    Jul 10 09:29:17.858: INFO: Waiting up to 5m0s for pod "busybox-89beec1d-148a-4f53-8a77-e214757da926" in namespace "container-probe-4957" to be "not pending"
    Jul 10 09:29:17.862: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926": Phase="Pending", Reason="", readiness=false. Elapsed: 3.906582ms
    Jul 10 09:29:19.868: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009241413s
    Jul 10 09:29:21.868: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926": Phase="Running", Reason="", readiness=true. Elapsed: 4.009093827s
    Jul 10 09:29:21.868: INFO: Pod "busybox-89beec1d-148a-4f53-8a77-e214757da926" satisfied condition "not pending"
    Jul 10 09:29:21.868: INFO: Started pod busybox-89beec1d-148a-4f53-8a77-e214757da926 in namespace container-probe-4957
    STEP: checking the pod's current state and verifying that restartCount is present 07/10/23 09:29:21.868
    Jul 10 09:29:21.873: INFO: Initial restart count of pod busybox-89beec1d-148a-4f53-8a77-e214757da926 is 0
    STEP: deleting the pod 07/10/23 09:33:22.63
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jul 10 09:33:22.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4957" for this suite. 07/10/23 09:33:22.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:22.698
Jul 10 09:33:22.699: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename downward-api 07/10/23 09:33:22.701
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:22.801
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:22.807
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 07/10/23 09:33:22.811
Jul 10 09:33:22.828: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837" in namespace "downward-api-3070" to be "Succeeded or Failed"
Jul 10 09:33:22.833: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346207ms
Jul 10 09:33:24.838: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009978075s
Jul 10 09:33:26.839: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01036183s
Jul 10 09:33:28.837: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0090017s
STEP: Saw pod success 07/10/23 09:33:28.837
Jul 10 09:33:28.838: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837" satisfied condition "Succeeded or Failed"
Jul 10 09:33:28.842: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837 container client-container: <nil>
STEP: delete the pod 07/10/23 09:33:28.857
Jul 10 09:33:28.892: INFO: Waiting for pod downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837 to disappear
Jul 10 09:33:28.896: INFO: Pod downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jul 10 09:33:28.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3070" for this suite. 07/10/23 09:33:28.901
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":354,"skipped":6587,"failed":0}
------------------------------
• [SLOW TEST] [6.214 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:22.698
    Jul 10 09:33:22.699: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename downward-api 07/10/23 09:33:22.701
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:22.801
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:22.807
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 07/10/23 09:33:22.811
    Jul 10 09:33:22.828: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837" in namespace "downward-api-3070" to be "Succeeded or Failed"
    Jul 10 09:33:22.833: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346207ms
    Jul 10 09:33:24.838: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009978075s
    Jul 10 09:33:26.839: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01036183s
    Jul 10 09:33:28.837: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0090017s
    STEP: Saw pod success 07/10/23 09:33:28.837
    Jul 10 09:33:28.838: INFO: Pod "downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837" satisfied condition "Succeeded or Failed"
    Jul 10 09:33:28.842: INFO: Trying to get logs from node 10-62-109-100.test pod downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837 container client-container: <nil>
    STEP: delete the pod 07/10/23 09:33:28.857
    Jul 10 09:33:28.892: INFO: Waiting for pod downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837 to disappear
    Jul 10 09:33:28.896: INFO: Pod downwardapi-volume-e6386873-668a-4f9d-b12a-4e7b8416f837 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jul 10 09:33:28.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3070" for this suite. 07/10/23 09:33:28.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:28.916
Jul 10 09:33:28.917: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename secrets 07/10/23 09:33:28.918
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:28.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:28.958
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jul 10 09:33:29.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6395" for this suite. 07/10/23 09:33:29.035
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":355,"skipped":6631,"failed":0}
------------------------------
• [0.129 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:28.916
    Jul 10 09:33:28.917: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename secrets 07/10/23 09:33:28.918
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:28.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:28.958
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jul 10 09:33:29.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6395" for this suite. 07/10/23 09:33:29.035
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:29.046
Jul 10 09:33:29.046: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename pods 07/10/23 09:33:29.048
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:29.077
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:29.081
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Jul 10 09:33:29.097: INFO: Waiting up to 5m0s for pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096" in namespace "pods-9346" to be "running and ready"
Jul 10 09:33:29.101: INFO: Pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096": Phase="Pending", Reason="", readiness=false. Elapsed: 3.977186ms
Jul 10 09:33:29.101: INFO: The phase of Pod server-envvars-281fa519-a6e2-4c5b-9423-af296f866096 is Pending, waiting for it to be Running (with Ready = true)
Jul 10 09:33:31.106: INFO: Pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096": Phase="Running", Reason="", readiness=true. Elapsed: 2.009485653s
Jul 10 09:33:31.106: INFO: The phase of Pod server-envvars-281fa519-a6e2-4c5b-9423-af296f866096 is Running (Ready = true)
Jul 10 09:33:31.106: INFO: Pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096" satisfied condition "running and ready"
Jul 10 09:33:31.149: INFO: Waiting up to 5m0s for pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f" in namespace "pods-9346" to be "Succeeded or Failed"
Jul 10 09:33:31.159: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.993631ms
Jul 10 09:33:33.165: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015439345s
Jul 10 09:33:35.166: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016675966s
STEP: Saw pod success 07/10/23 09:33:35.166
Jul 10 09:33:35.166: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f" satisfied condition "Succeeded or Failed"
Jul 10 09:33:35.170: INFO: Trying to get logs from node 10-62-109-100.test pod client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f container env3cont: <nil>
STEP: delete the pod 07/10/23 09:33:35.183
Jul 10 09:33:35.220: INFO: Waiting for pod client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f to disappear
Jul 10 09:33:35.224: INFO: Pod client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jul 10 09:33:35.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9346" for this suite. 07/10/23 09:33:35.229
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":356,"skipped":6640,"failed":0}
------------------------------
• [SLOW TEST] [6.192 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:29.046
    Jul 10 09:33:29.046: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename pods 07/10/23 09:33:29.048
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:29.077
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:29.081
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Jul 10 09:33:29.097: INFO: Waiting up to 5m0s for pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096" in namespace "pods-9346" to be "running and ready"
    Jul 10 09:33:29.101: INFO: Pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096": Phase="Pending", Reason="", readiness=false. Elapsed: 3.977186ms
    Jul 10 09:33:29.101: INFO: The phase of Pod server-envvars-281fa519-a6e2-4c5b-9423-af296f866096 is Pending, waiting for it to be Running (with Ready = true)
    Jul 10 09:33:31.106: INFO: Pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096": Phase="Running", Reason="", readiness=true. Elapsed: 2.009485653s
    Jul 10 09:33:31.106: INFO: The phase of Pod server-envvars-281fa519-a6e2-4c5b-9423-af296f866096 is Running (Ready = true)
    Jul 10 09:33:31.106: INFO: Pod "server-envvars-281fa519-a6e2-4c5b-9423-af296f866096" satisfied condition "running and ready"
    Jul 10 09:33:31.149: INFO: Waiting up to 5m0s for pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f" in namespace "pods-9346" to be "Succeeded or Failed"
    Jul 10 09:33:31.159: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.993631ms
    Jul 10 09:33:33.165: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015439345s
    Jul 10 09:33:35.166: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016675966s
    STEP: Saw pod success 07/10/23 09:33:35.166
    Jul 10 09:33:35.166: INFO: Pod "client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f" satisfied condition "Succeeded or Failed"
    Jul 10 09:33:35.170: INFO: Trying to get logs from node 10-62-109-100.test pod client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f container env3cont: <nil>
    STEP: delete the pod 07/10/23 09:33:35.183
    Jul 10 09:33:35.220: INFO: Waiting for pod client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f to disappear
    Jul 10 09:33:35.224: INFO: Pod client-envvars-6dfaf230-198e-4811-88d6-056fa71f4c9f no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jul 10 09:33:35.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9346" for this suite. 07/10/23 09:33:35.229
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:35.239
Jul 10 09:33:35.239: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename cronjob 07/10/23 09:33:35.241
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:35.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:35.274
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 07/10/23 09:33:35.277
STEP: creating 07/10/23 09:33:35.277
STEP: getting 07/10/23 09:33:35.286
STEP: listing 07/10/23 09:33:35.29
STEP: watching 07/10/23 09:33:35.294
Jul 10 09:33:35.294: INFO: starting watch
STEP: cluster-wide listing 07/10/23 09:33:35.296
STEP: cluster-wide watching 07/10/23 09:33:35.3
Jul 10 09:33:35.300: INFO: starting watch
STEP: patching 07/10/23 09:33:35.301
STEP: updating 07/10/23 09:33:35.313
Jul 10 09:33:35.326: INFO: waiting for watch events with expected annotations
Jul 10 09:33:35.326: INFO: saw patched and updated annotations
STEP: patching /status 07/10/23 09:33:35.326
STEP: updating /status 07/10/23 09:33:35.335
STEP: get /status 07/10/23 09:33:35.344
STEP: deleting 07/10/23 09:33:35.349
STEP: deleting a collection 07/10/23 09:33:35.376
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jul 10 09:33:35.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7755" for this suite. 07/10/23 09:33:35.402
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":357,"skipped":6643,"failed":0}
------------------------------
• [0.173 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:35.239
    Jul 10 09:33:35.239: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename cronjob 07/10/23 09:33:35.241
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:35.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:35.274
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 07/10/23 09:33:35.277
    STEP: creating 07/10/23 09:33:35.277
    STEP: getting 07/10/23 09:33:35.286
    STEP: listing 07/10/23 09:33:35.29
    STEP: watching 07/10/23 09:33:35.294
    Jul 10 09:33:35.294: INFO: starting watch
    STEP: cluster-wide listing 07/10/23 09:33:35.296
    STEP: cluster-wide watching 07/10/23 09:33:35.3
    Jul 10 09:33:35.300: INFO: starting watch
    STEP: patching 07/10/23 09:33:35.301
    STEP: updating 07/10/23 09:33:35.313
    Jul 10 09:33:35.326: INFO: waiting for watch events with expected annotations
    Jul 10 09:33:35.326: INFO: saw patched and updated annotations
    STEP: patching /status 07/10/23 09:33:35.326
    STEP: updating /status 07/10/23 09:33:35.335
    STEP: get /status 07/10/23 09:33:35.344
    STEP: deleting 07/10/23 09:33:35.349
    STEP: deleting a collection 07/10/23 09:33:35.376
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jul 10 09:33:35.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7755" for this suite. 07/10/23 09:33:35.402
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:35.414
Jul 10 09:33:35.414: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename daemonsets 07/10/23 09:33:35.415
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:35.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:35.456
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Jul 10 09:33:35.494: INFO: Create a RollingUpdate DaemonSet
Jul 10 09:33:35.508: INFO: Check that daemon pods launch on every node of the cluster
Jul 10 09:33:35.520: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:33:35.520: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:33:36.541: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:33:36.541: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
Jul 10 09:33:37.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul 10 09:33:37.539: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
Jul 10 09:33:38.531: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul 10 09:33:38.531: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Jul 10 09:33:38.532: INFO: Update the DaemonSet to trigger a rollout
Jul 10 09:33:38.549: INFO: Updating DaemonSet daemon-set
Jul 10 09:33:40.575: INFO: Roll back the DaemonSet before rollout is complete
Jul 10 09:33:40.590: INFO: Updating DaemonSet daemon-set
Jul 10 09:33:40.590: INFO: Make sure DaemonSet rollback is complete
Jul 10 09:33:40.596: INFO: Wrong image for pod: daemon-set-9z8cg. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Jul 10 09:33:40.596: INFO: Pod daemon-set-9z8cg is not available
Jul 10 09:33:44.616: INFO: Pod daemon-set-2ngh8 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:33:44.631
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9618, will wait for the garbage collector to delete the pods 07/10/23 09:33:44.631
Jul 10 09:33:44.699: INFO: Deleting DaemonSet.extensions daemon-set took: 13.30002ms
Jul 10 09:33:44.900: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.058194ms
Jul 10 09:33:47.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul 10 09:33:47.608: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul 10 09:33:47.612: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"109749"},"items":null}

Jul 10 09:33:47.616: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"109749"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jul 10 09:33:47.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9618" for this suite. 07/10/23 09:33:47.637
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":358,"skipped":6669,"failed":0}
------------------------------
• [SLOW TEST] [12.234 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:35.414
    Jul 10 09:33:35.414: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename daemonsets 07/10/23 09:33:35.415
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:35.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:35.456
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Jul 10 09:33:35.494: INFO: Create a RollingUpdate DaemonSet
    Jul 10 09:33:35.508: INFO: Check that daemon pods launch on every node of the cluster
    Jul 10 09:33:35.520: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:33:35.520: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:33:36.541: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:33:36.541: INFO: Node 10-62-109-100.test is running 0 daemon pod, expected 1
    Jul 10 09:33:37.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jul 10 09:33:37.539: INFO: Node 10-62-109-102.test is running 0 daemon pod, expected 1
    Jul 10 09:33:38.531: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Jul 10 09:33:38.531: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Jul 10 09:33:38.532: INFO: Update the DaemonSet to trigger a rollout
    Jul 10 09:33:38.549: INFO: Updating DaemonSet daemon-set
    Jul 10 09:33:40.575: INFO: Roll back the DaemonSet before rollout is complete
    Jul 10 09:33:40.590: INFO: Updating DaemonSet daemon-set
    Jul 10 09:33:40.590: INFO: Make sure DaemonSet rollback is complete
    Jul 10 09:33:40.596: INFO: Wrong image for pod: daemon-set-9z8cg. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Jul 10 09:33:40.596: INFO: Pod daemon-set-9z8cg is not available
    Jul 10 09:33:44.616: INFO: Pod daemon-set-2ngh8 is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 07/10/23 09:33:44.631
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9618, will wait for the garbage collector to delete the pods 07/10/23 09:33:44.631
    Jul 10 09:33:44.699: INFO: Deleting DaemonSet.extensions daemon-set took: 13.30002ms
    Jul 10 09:33:44.900: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.058194ms
    Jul 10 09:33:47.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jul 10 09:33:47.608: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jul 10 09:33:47.612: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"109749"},"items":null}

    Jul 10 09:33:47.616: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"109749"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jul 10 09:33:47.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9618" for this suite. 07/10/23 09:33:47.637
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:47.649
Jul 10 09:33:47.649: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename configmap 07/10/23 09:33:47.65
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:47.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:47.699
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-dd900fe1-c13c-4456-ad1f-91b63d9a14ae 07/10/23 09:33:47.701
STEP: Creating a pod to test consume configMaps 07/10/23 09:33:47.715
Jul 10 09:33:47.735: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928" in namespace "configmap-5352" to be "Succeeded or Failed"
Jul 10 09:33:47.745: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928": Phase="Pending", Reason="", readiness=false. Elapsed: 10.514665ms
Jul 10 09:33:49.752: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016790619s
Jul 10 09:33:51.752: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017381135s
STEP: Saw pod success 07/10/23 09:33:51.752
Jul 10 09:33:51.753: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928" satisfied condition "Succeeded or Failed"
Jul 10 09:33:51.757: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928 container agnhost-container: <nil>
STEP: delete the pod 07/10/23 09:33:51.768
Jul 10 09:33:51.794: INFO: Waiting for pod pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928 to disappear
Jul 10 09:33:51.799: INFO: Pod pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jul 10 09:33:51.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5352" for this suite. 07/10/23 09:33:51.804
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":359,"skipped":6685,"failed":0}
------------------------------
• [4.167 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:47.649
    Jul 10 09:33:47.649: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename configmap 07/10/23 09:33:47.65
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:47.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:47.699
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-dd900fe1-c13c-4456-ad1f-91b63d9a14ae 07/10/23 09:33:47.701
    STEP: Creating a pod to test consume configMaps 07/10/23 09:33:47.715
    Jul 10 09:33:47.735: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928" in namespace "configmap-5352" to be "Succeeded or Failed"
    Jul 10 09:33:47.745: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928": Phase="Pending", Reason="", readiness=false. Elapsed: 10.514665ms
    Jul 10 09:33:49.752: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016790619s
    Jul 10 09:33:51.752: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017381135s
    STEP: Saw pod success 07/10/23 09:33:51.752
    Jul 10 09:33:51.753: INFO: Pod "pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928" satisfied condition "Succeeded or Failed"
    Jul 10 09:33:51.757: INFO: Trying to get logs from node 10-62-109-100.test pod pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928 container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 09:33:51.768
    Jul 10 09:33:51.794: INFO: Waiting for pod pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928 to disappear
    Jul 10 09:33:51.799: INFO: Pod pod-configmaps-b2566ba0-4c48-463c-b76f-db548b56e928 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jul 10 09:33:51.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5352" for this suite. 07/10/23 09:33:51.804
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 07/10/23 09:33:51.818
Jul 10 09:33:51.818: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
STEP: Building a namespace api object, basename projected 07/10/23 09:33:51.819
STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:51.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:51.865
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-f0140813-e950-4531-8146-6f90321f2771 07/10/23 09:33:51.867
STEP: Creating a pod to test consume configMaps 07/10/23 09:33:51.875
Jul 10 09:33:51.890: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa" in namespace "projected-3079" to be "Succeeded or Failed"
Jul 10 09:33:51.896: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.178284ms
Jul 10 09:33:53.902: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012039431s
Jul 10 09:33:55.903: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01223384s
STEP: Saw pod success 07/10/23 09:33:55.903
Jul 10 09:33:55.903: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa" satisfied condition "Succeeded or Failed"
Jul 10 09:33:55.907: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa container agnhost-container: <nil>
STEP: delete the pod 07/10/23 09:33:55.917
Jul 10 09:33:55.943: INFO: Waiting for pod pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa to disappear
Jul 10 09:33:55.948: INFO: Pod pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jul 10 09:33:55.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3079" for this suite. 07/10/23 09:33:55.96
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":360,"skipped":6706,"failed":0}
------------------------------
• [4.154 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 07/10/23 09:33:51.818
    Jul 10 09:33:51.818: INFO: >>> kubeConfig: /tmp/kubeconfig-597014847
    STEP: Building a namespace api object, basename projected 07/10/23 09:33:51.819
    STEP: Waiting for a default service account to be provisioned in namespace 07/10/23 09:33:51.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 07/10/23 09:33:51.865
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-f0140813-e950-4531-8146-6f90321f2771 07/10/23 09:33:51.867
    STEP: Creating a pod to test consume configMaps 07/10/23 09:33:51.875
    Jul 10 09:33:51.890: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa" in namespace "projected-3079" to be "Succeeded or Failed"
    Jul 10 09:33:51.896: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.178284ms
    Jul 10 09:33:53.902: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012039431s
    Jul 10 09:33:55.903: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01223384s
    STEP: Saw pod success 07/10/23 09:33:55.903
    Jul 10 09:33:55.903: INFO: Pod "pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa" satisfied condition "Succeeded or Failed"
    Jul 10 09:33:55.907: INFO: Trying to get logs from node 10-62-109-100.test pod pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa container agnhost-container: <nil>
    STEP: delete the pod 07/10/23 09:33:55.917
    Jul 10 09:33:55.943: INFO: Waiting for pod pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa to disappear
    Jul 10 09:33:55.948: INFO: Pod pod-projected-configmaps-4581082d-0ec8-4c18-a735-9c43e060d9fa no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jul 10 09:33:55.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3079" for this suite. 07/10/23 09:33:55.96
  << End Captured GinkgoWriter Output
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":360,"skipped":6706,"failed":0}
Jul 10 09:33:55.976: INFO: Running AfterSuite actions on all nodes
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Jul 10 09:33:55.976: INFO: Running AfterSuite actions on node 1
Jul 10 09:33:55.976: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Jul 10 09:33:55.976: INFO: Running AfterSuite actions on all nodes
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Jul 10 09:33:55.976: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Jul 10 09:33:55.976: INFO: Running AfterSuite actions on node 1
    Jul 10 09:33:55.976: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.098 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 360 of 7066 Specs in 5796.692 seconds
SUCCESS! -- 360 Passed | 0 Failed | 0 Pending | 6706 Skipped
PASS

Ginkgo ran 1 suite in 1h36m37.047111812s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

